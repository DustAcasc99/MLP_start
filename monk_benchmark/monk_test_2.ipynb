{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "41KkKrgdD-zi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from train_val import search_space_dict, sigmoid, performing_tv \n",
        "\n",
        "from train_val import train_test\n",
        "\n",
        "#perform one-hot-encoding tranformation\n",
        "\n",
        "monks_2_train = pd.read_csv('monks-2.train', header=None, sep = '\\s+', index_col=None,\n",
        "                            names = ['class','a1','a2','a3','a4','a5','a6','Id'])\n",
        "\n",
        "monks_2_test = pd.read_csv('monks-2.test', header=None, sep = '\\s+', index_col=None,\n",
        "                            names = ['class','a1','a2','a3','a4','a5','a6','Id'])\n",
        "\n",
        "\n",
        "monks_2_train[['a1','a2','a3','a4','a5','a6']] = monks_2_train[['a1','a2','a3','a4','a5','a6']].astype(str)\n",
        "monks_2_test[['a1','a2','a3','a4','a5','a6']] = monks_2_test[['a1','a2','a3','a4','a5','a6']].astype(str)\n",
        "  \n",
        "one_hot_monks_2_train = pd.get_dummies(monks_2_train, columns = ['a1','a2','a3','a4','a5','a6'])\n",
        "one_hot_monks_2_test = pd.get_dummies(monks_2_test, columns = ['a1','a2','a3','a4','a5','a6'])\n",
        "\n",
        "train_columns = [x for x in one_hot_monks_2_train.columns[2:]] + [x for x in one_hot_monks_2_train.columns[:2]]\n",
        "test_columns = [x for x in one_hot_monks_2_test.columns[2:]] + [x for x in one_hot_monks_2_test.columns[:2]]\n",
        "\n",
        "one_hot_monks_2_train = one_hot_monks_2_train.reindex(columns = train_columns)\n",
        "one_hot_monks_2_test = one_hot_monks_2_test.reindex(columns = test_columns)\n",
        "\n",
        "one_hot_monks_2_train = one_hot_monks_2_train.drop(['Id'], axis = 1)\n",
        "one_hot_monks_2_test = one_hot_monks_2_test.drop(['Id'], axis = 1)\n",
        "\n",
        "X_train = np.array(one_hot_monks_2_train)\n",
        "X_test = np.array(one_hot_monks_2_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_space_def = search_space_dict(layers_range=[1], units_range=[4], eta_0_range=[0.9],\n",
        "                        alpha_range=[0.9], lamb_range=[0.001], lamb0_range = [0.0], minibatch_size_range = [30],num_targets=1, configurations = 0)    \n",
        "\n",
        "search_space_def[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7CdV303EBcK",
        "outputId": "de9c4eda-e22e-4e76-9ae9-9168401bb1e3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'units': array([4, 1]),\n",
              " 'layers': 2,\n",
              " 'eta_0': 0.9,\n",
              " 'alpha': 0.9,\n",
              " 'lamb': 0.001,\n",
              " 'lamb0': 0.0,\n",
              " 'minibatch_size': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "train_test(hyperparams = search_space_def[0][0],\n",
        "           num_inputs = 17, seed = seed, activation_output = sigmoid, activation_hidden = sigmoid,\n",
        "           task = 'binary_classification', thr = 0.5, stop_class = 'GL', stop_param = 3, data_train = X_train, data_val = X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uU7-pTCifgg8",
        "outputId": "e4582f25-f207-46bd-a41d-cf6b029ecbca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error 0.1232271755044077, test error 0.2370592267883917\n",
            "training error 0.12036237452639842, test error 0.22777764443027937\n",
            "training error 0.11834457235658472, test error 0.22776576981641422\n",
            "training error 0.11827018260674049, test error 0.2264366768948725\n",
            "training error 0.11824682476738271, test error 0.22556149935181577\n",
            "training error 0.11793355926087433, test error 0.22361158823552665\n",
            "training error 0.1175723891191181, test error 0.2234486749044318\n",
            "training error 0.11845473858734255, test error 0.22395360735106634\n",
            "training error 0.11758551672499744, test error 0.2226564821298579\n",
            "training error 0.11758249798027944, test error 0.22335154332946458\n",
            "training error 0.11772165422851526, test error 0.22399234375106902\n",
            "training error 0.11743615441790102, test error 0.22333437555706742\n",
            "training error 0.1178235777653484, test error 0.2226897963174804\n",
            "training error 0.11735015035408639, test error 0.22392858634620882\n",
            "training error 0.11769319144089403, test error 0.2231473682977184\n",
            "training error 0.11757293161295317, test error 0.2221685215229341\n",
            "training error 0.1174116078279762, test error 0.22305216044571455\n",
            "training error 0.11739713795130756, test error 0.2232575279994893\n",
            "training error 0.11753316661020019, test error 0.2226865495162259\n",
            "training error 0.11740169577099722, test error 0.2224910420091156\n",
            "training error 0.1173690073972606, test error 0.22245112174730342\n",
            "training error 0.11728928546272635, test error 0.22275202868100308\n",
            "training error 0.11734797130839254, test error 0.2239018413110264\n",
            "training error 0.11730916896940119, test error 0.22276733114412542\n",
            "training error 0.11750186819794517, test error 0.22338000296733665\n",
            "training error 0.11752059653210264, test error 0.2246236476828055\n",
            "training error 0.11722840350925451, test error 0.22281838839480883\n",
            "training error 0.11725952442338466, test error 0.22181938181829297\n",
            "training error 0.11729855920341134, test error 0.22105857090326406\n",
            "training error 0.11714414157443616, test error 0.2214606651904616\n",
            "training error 0.11727489265031886, test error 0.22235709011432636\n",
            "training error 0.11704632884778338, test error 0.22188995083009758\n",
            "training error 0.11698599336112131, test error 0.22180855281643683\n",
            "training error 0.11704883342168737, test error 0.2212665894001466\n",
            "training error 0.11708850342951606, test error 0.2222512580325562\n",
            "training error 0.11700878720772273, test error 0.2228865269237006\n",
            "training error 0.11722300454821465, test error 0.22216071804871507\n",
            "training error 0.11720692806782178, test error 0.22272937118542693\n",
            "training error 0.11702576452705805, test error 0.22203523824447313\n",
            "training error 0.11688038429848892, test error 0.22149192077326893\n",
            "training error 0.11693269612313419, test error 0.2220779994674963\n",
            "training error 0.11699394000431622, test error 0.22243734387233538\n",
            "training error 0.11676132202454727, test error 0.2221223286765877\n",
            "training error 0.11691450521517015, test error 0.22160959982078327\n",
            "training error 0.11683460653941885, test error 0.22193997118016123\n",
            "training error 0.1168473675098324, test error 0.22254155421606028\n",
            "training error 0.11692114607843558, test error 0.222503852048201\n",
            "training error 0.11671818797837494, test error 0.2228436848766439\n",
            "training error 0.11689365147855457, test error 0.2231629574899687\n",
            "training error 0.11678293028595507, test error 0.22181412078595766\n",
            "Loss: 0.34178719223885157\n",
            "training error 0.11661596825517452, test error 0.2217793273864213\n",
            "Loss: 0.3260477439133824\n",
            "training error 0.1166647580255806, test error 0.22232380326235085\n",
            "Loss: 0.5723516414301244\n",
            "training error 0.11682322289852008, test error 0.2213970828932766\n",
            "Loss: 0.1531322620196729\n",
            "training error 0.11686499040508294, test error 0.2211069396345688\n",
            "Loss: 0.021880504839555392\n",
            "training error 0.11650119524986083, test error 0.22104577956902158\n",
            "Loss: 0.0\n",
            "training error 0.11649524654009635, test error 0.22122317348403553\n",
            "Loss: 0.0802521158105085\n",
            "training error 0.11660864453259522, test error 0.2213896553923323\n",
            "Loss: 0.15556769461113618\n",
            "training error 0.1165554347873712, test error 0.22104985036151886\n",
            "Loss: 0.001841606071484314\n",
            "training error 0.11695542330960759, test error 0.2211919256451341\n",
            "Loss: 0.06611575050086138\n",
            "training error 0.11659318884029886, test error 0.22162097616664853\n",
            "Loss: 0.2602160506065321\n",
            "training error 0.11644872304197414, test error 0.22187576509454718\n",
            "Loss: 0.3754812813634656\n",
            "training error 0.11647665996923726, test error 0.22105724056887854\n",
            "Loss: 0.005184898747812028\n",
            "training error 0.11649860412640103, test error 0.22109700994297965\n",
            "Loss: 0.023176363764076946\n",
            "training error 0.11661049005148746, test error 0.220566693072626\n",
            "Loss: 0.0\n",
            "training error 0.11647148305107767, test error 0.22072089437541767\n",
            "Loss: 0.06991141801309109\n",
            "training error 0.11637327040145347, test error 0.22057620029363703\n",
            "Loss: 0.004310361133219587\n",
            "training error 0.11657846516703275, test error 0.2209143985439325\n",
            "Loss: 0.15764187532703033\n",
            "training error 0.11638701050965931, test error 0.22117784062193674\n",
            "Loss: 0.2770806148458371\n",
            "training error 0.1163598516638669, test error 0.22173879607336244\n",
            "Loss: 0.5314052563459848\n",
            "training error 0.11628848778551415, test error 0.22194852673025217\n",
            "Loss: 0.6264924401669258\n",
            "training error 0.11627213439723562, test error 0.22119438105203135\n",
            "Loss: 0.28457967549917473\n",
            "training error 0.11633038647720491, test error 0.2207770003822211\n",
            "Loss: 0.0953486252458946\n",
            "training error 0.11660618584905219, test error 0.22022719138665253\n",
            "Loss: 0.0\n",
            "training error 0.11635370678047163, test error 0.22089493846024263\n",
            "Loss: 0.3032082775000111\n",
            "training error 0.11630383741045004, test error 0.22078809744730563\n",
            "Loss: 0.25469428053881416\n",
            "training error 0.11658550037840072, test error 0.2204804951907631\n",
            "Loss: 0.11501931369857221\n",
            "training error 0.11615467371758197, test error 0.22043325894227292\n",
            "Loss: 0.09357044165294592\n",
            "training error 0.1162683739793666, test error 0.22106123524645077\n",
            "Loss: 0.3787197459799163\n",
            "training error 0.11614659447276503, test error 0.22103856216213238\n",
            "Loss: 0.3684244304125617\n",
            "training error 0.11601888765835325, test error 0.22108873525566988\n",
            "Loss: 0.3912068548813874\n",
            "training error 0.11619558925738156, test error 0.221293793636965\n",
            "Loss: 0.4843190541534037\n",
            "training error 0.11615771350796783, test error 0.2213177841900245\n",
            "Loss: 0.49521260136184964\n",
            "training error 0.11604830577577618, test error 0.2210843365681872\n",
            "Loss: 0.38920951411027804\n",
            "training error 0.11608446387643435, test error 0.2206966860732106\n",
            "Loss: 0.2131865205208916\n",
            "training error 0.11594067522302187, test error 0.2209199902419289\n",
            "Loss: 0.31458370372623445\n",
            "training error 0.1165328314424232, test error 0.22113920167697562\n",
            "Loss: 0.4141224726068815\n",
            "training error 0.11621291281418177, test error 0.22190778215784998\n",
            "Loss: 0.7631168343090078\n",
            "training error 0.11622786431749865, test error 0.22231269137062265\n",
            "Loss: 0.9469766066755092\n",
            "training error 0.11620899832892113, test error 0.22263983314722616\n",
            "Loss: 1.0955240110826159\n",
            "training error 0.11603295041273085, test error 0.2214181854063914\n",
            "Loss: 0.5408024378097176\n",
            "training error 0.116142862159384, test error 0.22122187027864026\n",
            "Loss: 0.45166034481245454\n",
            "training error 0.11598513716517811, test error 0.22085570396489837\n",
            "Loss: 0.2853928137976247\n",
            "training error 0.11606384135854614, test error 0.22096048468761867\n",
            "Loss: 0.3329712813158858\n",
            "training error 0.11594292807842803, test error 0.22096557666386274\n",
            "Loss: 0.3352834282456252\n",
            "training error 0.11605810219235566, test error 0.22089136637523343\n",
            "Loss: 0.3015862775159306\n",
            "training error 0.116070284371535, test error 0.22121642430291552\n",
            "Loss: 0.4491874550251129\n",
            "training error 0.11590490272218598, test error 0.2212110781633015\n",
            "Loss: 0.4467598984730037\n",
            "training error 0.11600155828245608, test error 0.22067754071340698\n",
            "Loss: 0.204493061877975\n",
            "training error 0.11612944135264439, test error 0.22067647122767262\n",
            "Loss: 0.20400743350137418\n",
            "training error 0.11602031565693856, test error 0.22066701926989385\n",
            "Loss: 0.1997155212632773\n",
            "training error 0.11606955872449894, test error 0.22059815131116342\n",
            "Loss: 0.16844419718344827\n",
            "training error 0.1160072644516081, test error 0.22126116933727763\n",
            "Loss: 0.46950512519126075\n",
            "training error 0.115654429159086, test error 0.22100277255253623\n",
            "Loss: 0.3521732084944995\n",
            "training error 0.11584235887209834, test error 0.22104020750232634\n",
            "Loss: 0.3691715407868834\n",
            "training error 0.11562840189080406, test error 0.22061441623225606\n",
            "Loss: 0.1758297161968958\n",
            "training error 0.11579039441376217, test error 0.22124727778105158\n",
            "Loss: 0.4631972954729724\n",
            "training error 0.1156636170933934, test error 0.2212853579060793\n",
            "Loss: 0.4804885867017994\n",
            "training error 0.11584431301445001, test error 0.22089866309909487\n",
            "Loss: 0.3048995486045314\n",
            "training error 0.11557412958775105, test error 0.22100754479284346\n",
            "Loss: 0.3543401708378857\n",
            "training error 0.11558016469419206, test error 0.22069192029816304\n",
            "Loss: 0.21102249390021477\n",
            "training error 0.11594935662028687, test error 0.22044448163195232\n",
            "Loss: 0.09866640169708951\n",
            "training error 0.11555198970870047, test error 0.22081893199631553\n",
            "Loss: 0.26869552571466837\n",
            "training error 0.11554706572596064, test error 0.2206553700821316\n",
            "Loss: 0.19442589844744784\n",
            "training error 0.11560905531265551, test error 0.22092787066428488\n",
            "Loss: 0.3181620186047507\n",
            "training error 0.11568914918845921, test error 0.22032602117437064\n",
            "Loss: 0.04487628757186002\n",
            "training error 0.11562398515814354, test error 0.22024911987982443\n",
            "Loss: 0.009957214199496356\n",
            "training error 0.11605826488471396, test error 0.22076039259933364\n",
            "Loss: 0.24211415916619572\n",
            "training error 0.11554327201226114, test error 0.2204935437340257\n",
            "Loss: 0.12094435101137613\n",
            "training error 0.115538940074655, test error 0.2202313463905821\n",
            "Loss: 0.0018866897876668176\n",
            "training error 0.1155615059487757, test error 0.22064589329077613\n",
            "Loss: 0.19012270986487056\n",
            "training error 0.1154978869427659, test error 0.22002283679629278\n",
            "Loss: 0.0\n",
            "training error 0.11561596166575044, test error 0.22080766088478082\n",
            "Loss: 0.35670119516486576\n",
            "training error 0.11540100220297504, test error 0.2208432399985596\n",
            "Loss: 0.3728718410382026\n",
            "training error 0.11551239389495596, test error 0.2204160114204491\n",
            "Loss: 0.178697188837873\n",
            "training error 0.11546702738884877, test error 0.22107283146644124\n",
            "Loss: 0.4772207673699791\n",
            "training error 0.11550187783474782, test error 0.22124546500051384\n",
            "Loss: 0.5556824109822056\n",
            "training error 0.11564510071818238, test error 0.22024774009356549\n",
            "Loss: 0.10221816087252478\n",
            "training error 0.11527731629951728, test error 0.21997059687269607\n",
            "Loss: 0.0\n",
            "training error 0.11536214610027412, test error 0.22011080441360514\n",
            "Loss: 0.06373921919673453\n",
            "training error 0.11531780515728858, test error 0.22012383565812543\n",
            "Loss: 0.06966330391786624\n",
            "training error 0.11555721076941049, test error 0.22004191229542922\n",
            "Loss: 0.03242043425213392\n",
            "training error 0.11524643665120482, test error 0.21988563626643948\n",
            "Loss: 0.0\n",
            "training error 0.11531693882714508, test error 0.21965816793739093\n",
            "Loss: 0.0\n",
            "training error 0.11530483238244212, test error 0.21955058679339431\n",
            "Loss: 0.0\n",
            "training error 0.11521068613326375, test error 0.21983079382064233\n",
            "Loss: 0.12762754649875419\n",
            "training error 0.11526321572908503, test error 0.21930564896290974\n",
            "Loss: 0.0\n",
            "training error 0.11546309844291829, test error 0.21932235865917882\n",
            "Loss: 0.007619364274513707\n",
            "training error 0.11523224848735183, test error 0.21948611992829378\n",
            "Loss: 0.08229198209781519\n",
            "training error 0.1151513346981601, test error 0.219546405410117\n",
            "Loss: 0.10978123379210558\n",
            "training error 0.11509300964215921, test error 0.2195003652116357\n",
            "Loss: 0.08878761201400742\n",
            "training error 0.11543710646436824, test error 0.21964560278363687\n",
            "Loss: 0.15501370910178114\n",
            "training error 0.11525258179416213, test error 0.21959018208030917\n",
            "Loss: 0.12974272151446975\n",
            "training error 0.11534393847290951, test error 0.22015564425599443\n",
            "Loss: 0.38758476906741723\n",
            "training error 0.1151110341119124, test error 0.22065638848456667\n",
            "Loss: 0.6159164289859964\n",
            "training error 0.11513296669124043, test error 0.21996932363371335\n",
            "Loss: 0.30262543347245874\n",
            "training error 0.1152051056746462, test error 0.21974787301452875\n",
            "Loss: 0.20164736007042272\n",
            "training error 0.11505941982407908, test error 0.22002692141210856\n",
            "Loss: 0.3288891337773103\n",
            "training error 0.11498219457582169, test error 0.21968592940769233\n",
            "Loss: 0.17340202889479794\n",
            "training error 0.1150523740816887, test error 0.21927661911508448\n",
            "Loss: 0.0\n",
            "training error 0.1150342553776308, test error 0.2193756716692206\n",
            "Loss: 0.04517241944710371\n",
            "training error 0.11497790056854036, test error 0.21950470783564177\n",
            "Loss: 0.1040187145705529\n",
            "training error 0.11519506007833835, test error 0.21980350754083847\n",
            "Loss: 0.24028481827214065\n",
            "training error 0.11533164247406671, test error 0.219949205021329\n",
            "Loss: 0.3067294219323724\n",
            "training error 0.11496843263749924, test error 0.21996185708948693\n",
            "Loss: 0.31249933402284213\n",
            "training error 0.1150270915711416, test error 0.21992295584717314\n",
            "Loss: 0.2947586179944839\n",
            "training error 0.11491990145333476, test error 0.22006259522671248\n",
            "Loss: 0.35844045516566503\n",
            "training error 0.11494360277466517, test error 0.21954214883129508\n",
            "Loss: 0.12109349244902035\n",
            "training error 0.11484312265698174, test error 0.21974471624657474\n",
            "Loss: 0.21347334402515017\n",
            "training error 0.11489253969489724, test error 0.21970468105966637\n",
            "Loss: 0.19521549826395646\n",
            "training error 0.11506837118412247, test error 0.21958135590166136\n",
            "Loss: 0.1389736798235397\n",
            "training error 0.11495156731420687, test error 0.21926355189068222\n",
            "Loss: 0.0\n",
            "training error 0.11479634695930215, test error 0.21961811587215438\n",
            "Loss: 0.16170675810676105\n",
            "training error 0.1148318867000509, test error 0.2195830020669335\n",
            "Loss: 0.1456923293893242\n",
            "training error 0.11481306479214771, test error 0.219941705815164\n",
            "Loss: 0.309287119830981\n",
            "training error 0.1149099107876017, test error 0.21963816277675227\n",
            "Loss: 0.17084959303077518\n",
            "training error 0.1147992837481659, test error 0.2201418548432975\n",
            "Loss: 0.4005695178436186\n",
            "training error 0.11478845366545501, test error 0.21955910770170145\n",
            "Loss: 0.1347947748135514\n",
            "training error 0.11474218155011402, test error 0.21976798337592135\n",
            "Loss: 0.23005715308790364\n",
            "training error 0.1149284962246486, test error 0.21947363637987174\n",
            "Loss: 0.09581368511910604\n",
            "training error 0.11476280720079797, test error 0.21937746775881872\n",
            "Loss: 0.051953855145647765\n",
            "training error 0.1147646334143921, test error 0.21923964986217487\n",
            "Loss: 0.0\n",
            "training error 0.11475112515593518, test error 0.21954652738819186\n",
            "Loss: 0.1399735523250012\n",
            "training error 0.11482807139887978, test error 0.21984752141418923\n",
            "Loss: 0.27726351159405027\n",
            "training error 0.11467334125577945, test error 0.21992337679420595\n",
            "Loss: 0.3118628096974829\n",
            "training error 0.11470355298287788, test error 0.22020058875438928\n",
            "Loss: 0.43830524853443187\n",
            "training error 0.1147737087287477, test error 0.21994869505799217\n",
            "Loss: 0.3234110236278065\n",
            "training error 0.11463705956318024, test error 0.22006246138331484\n",
            "Loss: 0.37530233315790085\n",
            "training error 0.11499942296592522, test error 0.21912920257728524\n",
            "Loss: 0.0\n",
            "training error 0.11461781296600326, test error 0.21948062836305088\n",
            "Loss: 0.1603737802321037\n",
            "training error 0.11484174539390876, test error 0.21958984243289012\n",
            "Loss: 0.21021381458383726\n",
            "training error 0.11465567599736311, test error 0.21949055395345934\n",
            "Loss: 0.16490334100798254\n",
            "training error 0.11476272587375716, test error 0.22006003225849113\n",
            "Loss: 0.42478577490263625\n",
            "training error 0.1146688838043026, test error 0.21945601264091105\n",
            "Loss: 0.1491403518025125\n",
            "training error 0.11460314454526636, test error 0.21979654754868924\n",
            "Loss: 0.30454406056108496\n",
            "training error 0.11472637870866358, test error 0.2191378021258698\n",
            "Loss: 0.003924419239154098\n",
            "training error 0.11455046727318838, test error 0.21956101970132438\n",
            "Loss: 0.19706050994587887\n",
            "training error 0.11489584791558669, test error 0.218886779858488\n",
            "Loss: 0.0\n",
            "training error 0.11462735907939202, test error 0.21953182661434206\n",
            "Loss: 0.29469425073140876\n",
            "training error 0.11451912367405019, test error 0.2194038364807144\n",
            "Loss: 0.23622103745173373\n",
            "training error 0.11452771154315579, test error 0.21926477822009371\n",
            "Loss: 0.1726912707336936\n",
            "training error 0.11469652496265235, test error 0.21879247342681601\n",
            "Loss: 0.0\n",
            "training error 0.11445490886444776, test error 0.21898446691072476\n",
            "Loss: 0.0877514116009781\n",
            "training error 0.11462287078376612, test error 0.21894360866354812\n",
            "Loss: 0.06907698165523612\n",
            "training error 0.11450268178617574, test error 0.21910923340763996\n",
            "Loss: 0.14477645225301483\n",
            "training error 0.11463907233246161, test error 0.21921113945271017\n",
            "Loss: 0.19135302935098242\n",
            "training error 0.11447123327110599, test error 0.21911046848115356\n",
            "Loss: 0.14534094768297035\n",
            "training error 0.11441605725147308, test error 0.2193589423160355\n",
            "Loss: 0.2589069360326768\n",
            "training error 0.11457740270653474, test error 0.2187237257710293\n",
            "Loss: 0.0\n",
            "training error 0.11457611268061701, test error 0.21915938408315394\n",
            "Loss: 0.19918200944541997\n",
            "training error 0.11431737340593606, test error 0.21929278731635893\n",
            "Loss: 0.26017367037964867\n",
            "training error 0.11429722340720683, test error 0.21947611555541438\n",
            "Loss: 0.3439909327316082\n",
            "training error 0.11434848917450491, test error 0.21921024420554788\n",
            "Loss: 0.22243514406292686\n",
            "training error 0.11458031397435461, test error 0.21934943551124586\n",
            "Loss: 0.286073098842321\n",
            "training error 0.1143170289573788, test error 0.21932098369941472\n",
            "Loss: 0.27306499387755867\n",
            "training error 0.11445355400864823, test error 0.21902380358140217\n",
            "Loss: 0.13719490618360197\n",
            "training error 0.1143931332457718, test error 0.21908455773377655\n",
            "Loss: 0.16497156925947554\n",
            "training error 0.11424041813158342, test error 0.21893954652387276\n",
            "Loss: 0.09867276724675467\n",
            "training error 0.1143096211580947, test error 0.21927018023615932\n",
            "Loss: 0.24983776369194022\n",
            "training error 0.11423461970323273, test error 0.21928376490411355\n",
            "Loss: 0.2560486436073761\n",
            "training error 0.11431189932212206, test error 0.2193424477471259\n",
            "Loss: 0.28287830865880714\n",
            "training error 0.11428083076448531, test error 0.2190176436407187\n",
            "Loss: 0.134378595030471\n",
            "training error 0.11426990077085633, test error 0.21936194405155413\n",
            "Loss: 0.2917919755961673\n",
            "training error 0.11416366666969043, test error 0.2194483543472051\n",
            "Loss: 0.331298570203753\n",
            "training error 0.11421878909367546, test error 0.2189550815120918\n",
            "Loss: 0.10577532924100908\n",
            "training error 0.11422777794851788, test error 0.21924174505706795\n",
            "Loss: 0.2368372631787352\n",
            "training error 0.11449355345296892, test error 0.22003831667291227\n",
            "Loss: 0.6010280307949589\n",
            "training error 0.11431989449772258, test error 0.22031804757143048\n",
            "Loss: 0.728920374221409\n",
            "training error 0.11428822908279647, test error 0.21955911662911592\n",
            "Loss: 0.38193883866131095\n",
            "training error 0.11433093808685238, test error 0.21908180072755498\n",
            "Loss: 0.1637110721589119\n",
            "training error 0.11425220887192498, test error 0.21954780949895683\n",
            "Loss: 0.37676924395033673\n",
            "training error 0.11410909488613799, test error 0.21951490676228003\n",
            "Loss: 0.361726186064959\n",
            "training error 0.11413123135402076, test error 0.2193877217860762\n",
            "Loss: 0.3035774983743744\n",
            "training error 0.1141227327752274, test error 0.21915187691180216\n",
            "Loss: 0.1957497474330161\n",
            "training error 0.11408114043921973, test error 0.21912864439970398\n",
            "Loss: 0.185127894675019\n",
            "training error 0.1141318369342351, test error 0.21872557885053742\n",
            "Loss: 0.0008472238215428973\n",
            "training error 0.11415220558212853, test error 0.21851188566072924\n",
            "Loss: 0.0\n",
            "training error 0.1141482404054538, test error 0.21842008139966346\n",
            "Loss: 0.0\n",
            "training error 0.11435599906978235, test error 0.21874188958459256\n",
            "Loss: 0.147334522937137\n",
            "training error 0.11408654497671661, test error 0.21892240196062454\n",
            "Loss: 0.22997911077689004\n",
            "training error 0.11413762156502202, test error 0.21942426655386618\n",
            "Loss: 0.4597494643202138\n",
            "training error 0.11402799020315714, test error 0.21944819106454297\n",
            "Loss: 0.47070290345614385\n",
            "training error 0.11399481744020219, test error 0.21923081978236253\n",
            "Loss: 0.3711830787278103\n",
            "training error 0.1139668985975964, test error 0.2188756868610985\n",
            "Loss: 0.20859137974653663\n",
            "training error 0.11398565474060962, test error 0.21864359805128805\n",
            "Loss: 0.10233337987619606\n",
            "training error 0.11413922831904857, test error 0.21882800629655855\n",
            "Loss: 0.18676162662383256\n",
            "training error 0.11415063077088192, test error 0.21927032073949668\n",
            "Loss: 0.3892679346993999\n",
            "training error 0.11415767461462749, test error 0.21864218643495867\n",
            "Loss: 0.10168709482751837\n",
            "training error 0.11395622785358162, test error 0.21841403934037293\n",
            "Loss: 0.0\n",
            "training error 0.11388482177456002, test error 0.21837367622787515\n",
            "Loss: 0.0\n",
            "training error 0.11405033669247805, test error 0.21844225592712987\n",
            "Loss: 0.031404746414187557\n",
            "training error 0.11415425609863972, test error 0.2191862448703976\n",
            "Loss: 0.3721000885081649\n",
            "training error 0.11410129903741952, test error 0.21927736946835932\n",
            "Loss: 0.4138288350932662\n",
            "training error 0.11390371940011618, test error 0.21904836516275467\n",
            "Loss: 0.30896074404840324\n",
            "training error 0.11384093411586921, test error 0.21863323062445678\n",
            "Loss: 0.11885791413375202\n",
            "training error 0.11392183326775406, test error 0.21846182785835763\n",
            "Loss: 0.040367333648072545\n",
            "training error 0.11403270657447626, test error 0.2186614330646541\n",
            "Loss: 0.1317726759697324\n",
            "training error 0.11386896984960204, test error 0.21869941954509162\n",
            "Loss: 0.1491678497350435\n",
            "training error 0.11415875905967918, test error 0.21870597565757116\n",
            "Loss: 0.1521700945993354\n",
            "training error 0.11389526947774864, test error 0.21907930596585598\n",
            "Loss: 0.3231294861952616\n",
            "training error 0.1138319246948474, test error 0.21909090151684463\n",
            "Loss: 0.32843944442326745\n",
            "training error 0.11383304191548975, test error 0.21896364524966597\n",
            "Loss: 0.2701648989849703\n",
            "training error 0.11388991418408535, test error 0.21884717926225947\n",
            "Loss: 0.21683155340124216\n",
            "training error 0.11377766282010944, test error 0.2188698384084477\n",
            "Loss: 0.22720787099577144\n",
            "training error 0.11387135324964338, test error 0.21856515166109253\n",
            "Loss: 0.08768247003250185\n",
            "training error 0.11378105455286257, test error 0.21859862007342307\n",
            "Loss: 0.10300868192243406\n",
            "training error 0.11381351425147422, test error 0.2181056017947138\n",
            "Loss: 0.0\n",
            "training error 0.11388306741225235, test error 0.21836118008647942\n",
            "Loss: 0.11718098465265392\n",
            "training error 0.11382238844971757, test error 0.21849316985995848\n",
            "Loss: 0.17769743741358202\n",
            "training error 0.11371298683141655, test error 0.21859044703155242\n",
            "Loss: 0.22229838795930768\n",
            "training error 0.11376760113145727, test error 0.2183237725328731\n",
            "Loss: 0.10002986459956009\n",
            "training error 0.11366161477892685, test error 0.21847305235054415\n",
            "Loss: 0.16847369017884972\n",
            "training error 0.11366225079914381, test error 0.21839737091053327\n",
            "Loss: 0.1337742421187782\n",
            "training error 0.1138097349603687, test error 0.21849964395502108\n",
            "Loss: 0.18066576789630417\n",
            "training error 0.11369745232140002, test error 0.21868344671759365\n",
            "Loss: 0.26493813919723497\n",
            "training error 0.1136542053070481, test error 0.21838936332648198\n",
            "Loss: 0.13010281690759573\n",
            "training error 0.11365418549233379, test error 0.21859350301556704\n",
            "Loss: 0.2236995367558059\n",
            "training error 0.11364160382395108, test error 0.2185324320360964\n",
            "Loss: 0.1956988898361045\n",
            "training error 0.11362457579058627, test error 0.21860652471609357\n",
            "Loss: 0.22966990176218616\n",
            "training error 0.1137141373174119, test error 0.21869439737528015\n",
            "Loss: 0.2699589445302353\n",
            "training error 0.11371820458325634, test error 0.21856729103455516\n",
            "Loss: 0.2116815139282524\n",
            "training error 0.11361672821106118, test error 0.21862220454069528\n",
            "Loss: 0.23685899937027077\n",
            "training error 0.11367233569013944, test error 0.21813196587650405\n",
            "Loss: 0.012087760045265128\n",
            "training error 0.11358096835033023, test error 0.21798238110868676\n",
            "Loss: 0.0\n",
            "training error 0.11350052415807313, test error 0.2178696398220002\n",
            "Loss: 0.0\n",
            "training error 0.11348969759004383, test error 0.2178349784826391\n",
            "Loss: 0.0\n",
            "training error 0.11349151564199933, test error 0.21782363491835705\n",
            "Loss: 0.0\n",
            "training error 0.11348465886884185, test error 0.21782032792867329\n",
            "Loss: 0.0\n",
            "training error 0.11349652140939112, test error 0.21776429157494825\n",
            "Loss: 0.0\n",
            "training error 0.1134999205623444, test error 0.21798559859285316\n",
            "Loss: 0.10162686283610167\n",
            "training error 0.11345437175832825, test error 0.21809105915264276\n",
            "Loss: 0.15005562910761494\n",
            "training error 0.11353520640279416, test error 0.2179889783844655\n",
            "Loss: 0.10317890407660624\n",
            "training error 0.11356429550824126, test error 0.21831907151119828\n",
            "Loss: 0.25476166557780733\n",
            "training error 0.11344248639992495, test error 0.21842593721278927\n",
            "Loss: 0.303835689981935\n",
            "training error 0.11336772639827938, test error 0.21829247322095807\n",
            "Loss: 0.24254740857181378\n",
            "training error 0.11336924111426136, test error 0.21819670601402208\n",
            "Loss: 0.1985699473253666\n",
            "training error 0.1133932281128475, test error 0.2181023822224476\n",
            "Loss: 0.15525531989388774\n",
            "training error 0.11334479577420593, test error 0.21807784458383545\n",
            "Loss: 0.14398733907174943\n",
            "training error 0.11341033701537266, test error 0.21781122578869405\n",
            "Loss: 0.021552759364884544\n",
            "training error 0.11338927712864863, test error 0.21779330512620307\n",
            "Loss: 0.013323374114726505\n",
            "training error 0.1133741651896994, test error 0.21769718605148244\n",
            "Loss: 0.0\n",
            "training error 0.11342195380169649, test error 0.21800810175230742\n",
            "Loss: 0.14282026629020006\n",
            "training error 0.11329464791174286, test error 0.21774421569522542\n",
            "Loss: 0.021603239158030085\n",
            "training error 0.11331381956754766, test error 0.21778069624044682\n",
            "Loss: 0.03836071126093188\n",
            "training error 0.1132767019162342, test error 0.21781027924966812\n",
            "Loss: 0.05194977493137021\n",
            "training error 0.11329275480515114, test error 0.21756227876404868\n",
            "Loss: 0.0\n",
            "training error 0.11333992435322368, test error 0.2173899711269711\n",
            "Loss: 0.0\n",
            "training error 0.11334952642266823, test error 0.21740560805694334\n",
            "Loss: 0.007193031900776248\n",
            "training error 0.11322148484291246, test error 0.2173520522300479\n",
            "Loss: 0.0\n",
            "training error 0.11333017274944203, test error 0.21725727600544711\n",
            "Loss: 0.0\n",
            "training error 0.11319274987425862, test error 0.2175427574197224\n",
            "Loss: 0.13140246417713275\n",
            "training error 0.1131827419837475, test error 0.21770998216650025\n",
            "Loss: 0.20837330255478737\n",
            "training error 0.11332520261376368, test error 0.21766362292030753\n",
            "Loss: 0.18703489352882574\n",
            "training error 0.11314747363877563, test error 0.21767323575107894\n",
            "Loss: 0.19145952360251073\n",
            "training error 0.11319351043750166, test error 0.21781004007733099\n",
            "Loss: 0.2544283358638877\n",
            "training error 0.11322492895203606, test error 0.2175922469454159\n",
            "Loss: 0.1541816900808346\n",
            "training error 0.11323830067724923, test error 0.21788304303610526\n",
            "Loss: 0.2880304136016365\n",
            "training error 0.1131144085502426, test error 0.21764813276658224\n",
            "Loss: 0.17990502703593148\n",
            "training error 0.11309470842272343, test error 0.21772137151919083\n",
            "Loss: 0.21361563685078355\n",
            "training error 0.11312470260176903, test error 0.2175183049222902\n",
            "Loss: 0.12014737625476446\n",
            "training error 0.11303682019105872, test error 0.21747338949466194\n",
            "Loss: 0.09947353349373245\n",
            "training error 0.11309171915150093, test error 0.217742846305009\n",
            "Loss: 0.22350013241891897\n",
            "training error 0.11300724465304102, test error 0.21777048992796808\n",
            "Loss: 0.23622404365784\n",
            "training error 0.11302795742288742, test error 0.21793227477032798\n",
            "Loss: 0.3106909822729875\n",
            "training error 0.11309337268528248, test error 0.21758460932441354\n",
            "Loss: 0.15066621702382044\n",
            "training error 0.11304711238081534, test error 0.21778457203646284\n",
            "Loss: 0.24270580977112655\n",
            "training error 0.11298647100160182, test error 0.2175540235975335\n",
            "Loss: 0.13658810307413116\n",
            "training error 0.11297342641739878, test error 0.21766703743750726\n",
            "Loss: 0.18860654040873115\n",
            "training error 0.11296885777613763, test error 0.21771528325400274\n",
            "Loss: 0.21081330714287638\n",
            "training error 0.11301472272268208, test error 0.21785428814319305\n",
            "Loss: 0.2747950028292534\n",
            "training error 0.1129177538913163, test error 0.21752419522577782\n",
            "Loss: 0.1228585874030852\n",
            "training error 0.1129049698390587, test error 0.21736818816315165\n",
            "Loss: 0.05105106707761209\n",
            "training error 0.11297365983189468, test error 0.21779997881623445\n",
            "Loss: 0.2497973005855636\n",
            "training error 0.11294289599704807, test error 0.21777596918095116\n",
            "Loss: 0.2387460549266196\n",
            "training error 0.11323006098463285, test error 0.21729823228021247\n",
            "Loss: 0.018851508919937032\n",
            "training error 0.1130340141486582, test error 0.21739002331074528\n",
            "Loss: 0.061101431325516486\n",
            "training error 0.11282679712273637, test error 0.21735864931665635\n",
            "Loss: 0.046660490766115004\n",
            "training error 0.11283291942755548, test error 0.2170035419720152\n",
            "Loss: 0.0\n",
            "training error 0.11279304565856549, test error 0.21689728302847042\n",
            "Loss: 0.0\n",
            "training error 0.11280449723044894, test error 0.21713329928799435\n",
            "Loss: 0.10881476071462615\n",
            "training error 0.11276757828474313, test error 0.21728892837884625\n",
            "Loss: 0.18056719978571945\n",
            "training error 0.11274569172337806, test error 0.21718731747402392\n",
            "Loss: 0.13371972276639\n",
            "training error 0.11270489947212388, test error 0.21719040686076535\n",
            "Loss: 0.13514407751085145\n",
            "training error 0.11268281123589165, test error 0.21713720093193406\n",
            "Loss: 0.11061360479658333\n",
            "training error 0.1127419726156209, test error 0.2172938836462842\n",
            "Loss: 0.18285181458992383\n",
            "training error 0.11269977383667297, test error 0.2173567148947439\n",
            "Loss: 0.21182001907011916\n",
            "training error 0.11265040745669015, test error 0.21715381739672598\n",
            "Loss: 0.11827458817079695\n",
            "training error 0.11277356780432138, test error 0.21710668940829184\n",
            "Loss: 0.09654633608016105\n",
            "training error 0.11268358862968239, test error 0.21687521432930287\n",
            "Loss: 0.0\n",
            "training error 0.11283968094265896, test error 0.2168491629121811\n",
            "Loss: 0.0\n",
            "training error 0.11258350965062354, test error 0.21691121878617595\n",
            "Loss: 0.02861706873178438\n",
            "training error 0.11252855217474034, test error 0.21696095166149879\n",
            "Loss: 0.05155138614161281\n",
            "training error 0.11252153831228318, test error 0.21694742920841015\n",
            "Loss: 0.045315506368281966\n",
            "training error 0.11246562670334448, test error 0.21694477115140368\n",
            "Loss: 0.04408974327527737\n",
            "training error 0.11256115850683035, test error 0.21675207195308616\n",
            "Loss: 0.0\n",
            "training error 0.11253605634705072, test error 0.21685979908472158\n",
            "Loss: 0.04970062369633599\n",
            "training error 0.11248876021588475, test error 0.21694879750659707\n",
            "Loss: 0.0907606334455302\n",
            "training error 0.1124190256046753, test error 0.21695242135769563\n",
            "Loss: 0.09243252108466216\n",
            "training error 0.11242046506970085, test error 0.21661333979610087\n",
            "Loss: 0.0\n",
            "training error 0.1124355651217179, test error 0.21642323041012618\n",
            "Loss: 0.0\n",
            "training error 0.11232860683145286, test error 0.21638249082639374\n",
            "Loss: 0.0\n",
            "training error 0.11234635290114228, test error 0.2163859666955214\n",
            "Loss: 0.0016063541529609537\n",
            "training error 0.11226175027415752, test error 0.2163203125851851\n",
            "Loss: 0.0\n",
            "training error 0.11227274182925215, test error 0.2161497554363311\n",
            "Loss: 0.0\n",
            "training error 0.11221494061307291, test error 0.2162934546907593\n",
            "Loss: 0.06648134028099939\n",
            "training error 0.1122239529727178, test error 0.21644288778708734\n",
            "Loss: 0.1356153978358643\n",
            "training error 0.1122588365681916, test error 0.2164613538065105\n",
            "Loss: 0.14415855782505815\n",
            "training error 0.11215747965874173, test error 0.21625910347340668\n",
            "Loss: 0.05058901725558673\n",
            "training error 0.11215938785727958, test error 0.2160373270095495\n",
            "Loss: 0.0\n",
            "training error 0.11218493428273235, test error 0.21622829489597775\n",
            "Loss: 0.08839578283608152\n",
            "training error 0.1120827641770771, test error 0.2160368302288496\n",
            "Loss: 0.0\n",
            "training error 0.11208543484611773, test error 0.2158677494805035\n",
            "Loss: 0.0\n",
            "training error 0.11198470703474313, test error 0.21602381896324713\n",
            "Loss: 0.07229865652429446\n",
            "training error 0.11205088618343514, test error 0.21585647865029206\n",
            "Loss: 0.0\n",
            "training error 0.11191003717836281, test error 0.2158295941044315\n",
            "Loss: 0.0\n",
            "training error 0.11186552014825862, test error 0.21566831680881013\n",
            "Loss: 0.0\n",
            "training error 0.11185002189248355, test error 0.21553124076565944\n",
            "Loss: 0.0\n",
            "training error 0.11180079360496953, test error 0.21559147244217594\n",
            "Loss: 0.027945682631691504\n",
            "training error 0.11188686908168101, test error 0.2156780416530178\n",
            "Loss: 0.06811118742546807\n",
            "training error 0.11177107490024374, test error 0.21535286164230685\n",
            "Loss: 0.0\n",
            "training error 0.11184065463620209, test error 0.21519195131532506\n",
            "Loss: 0.0\n",
            "training error 0.11169364314977383, test error 0.2151660629309711\n",
            "Loss: 0.0\n",
            "training error 0.1117006625392594, test error 0.2150251744545353\n",
            "Loss: 0.0\n",
            "training error 0.11169210900390947, test error 0.21521777004140719\n",
            "Loss: 0.08956885507032109\n",
            "training error 0.11185228724443516, test error 0.2149954845942324\n",
            "Loss: 0.0\n",
            "training error 0.11155513763406733, test error 0.2148976303866333\n",
            "Loss: 0.0\n",
            "training error 0.11154872151508152, test error 0.21480981095237558\n",
            "Loss: 0.0\n",
            "training error 0.11147399059505263, test error 0.2148423297142021\n",
            "Loss: 0.015138396929992304\n",
            "training error 0.11144111744065816, test error 0.21505072927196692\n",
            "Loss: 0.1121542440371881\n",
            "training error 0.11143165973575196, test error 0.21481815698726658\n",
            "Loss: 0.003885313642792987\n",
            "training error 0.11142191201915576, test error 0.2148849459308106\n",
            "Loss: 0.03497744265119618\n",
            "training error 0.11139172511874633, test error 0.21463429249461827\n",
            "Loss: 0.0\n",
            "training error 0.11127858215212255, test error 0.2147131418189615\n",
            "Loss: 0.03673659200811308\n",
            "training error 0.1112326871230361, test error 0.2146317920909189\n",
            "Loss: 0.0\n",
            "training error 0.1111624362124527, test error 0.21458878461170633\n",
            "Loss: 0.0\n",
            "training error 0.11115259849231092, test error 0.21465276012297443\n",
            "Loss: 0.02981307312208692\n",
            "training error 0.11109849435221743, test error 0.21463570648672636\n",
            "Loss: 0.02186594938078379\n",
            "training error 0.111049974762901, test error 0.2143223155958632\n",
            "Loss: 0.0\n",
            "training error 0.11108431675066266, test error 0.21414622934900304\n",
            "Loss: 0.0\n",
            "training error 0.11098584082843152, test error 0.21395404702494045\n",
            "Loss: 0.0\n",
            "training error 0.11089234028597394, test error 0.2140169729677212\n",
            "Loss: 0.029410961678810743\n",
            "training error 0.11087442083235595, test error 0.21393813054356153\n",
            "Loss: 0.0\n",
            "training error 0.1108575447200983, test error 0.21405146924687957\n",
            "Loss: 0.05297732715063841\n",
            "training error 0.11078089684552439, test error 0.21390212747313034\n",
            "Loss: 0.0\n",
            "training error 0.11067736988924202, test error 0.21401285679914195\n",
            "Loss: 0.05176635095671678\n",
            "training error 0.11070329501506446, test error 0.21373629092948318\n",
            "Loss: 0.0\n",
            "training error 0.11076604133565948, test error 0.21359407391218765\n",
            "Loss: 0.0\n",
            "training error 0.11053186204660186, test error 0.21347853410796871\n",
            "Loss: 0.0\n",
            "training error 0.11048234684343369, test error 0.21355898702006312\n",
            "Loss: 0.0376866519299357\n",
            "training error 0.11037235180845029, test error 0.21346627799840284\n",
            "Loss: 0.0\n",
            "training error 0.1104874176477941, test error 0.21316844823439043\n",
            "Loss: 0.0\n",
            "training error 0.11035885149624738, test error 0.21325653700589248\n",
            "Loss: 0.0413235505684062\n",
            "training error 0.11018714266230478, test error 0.21305164535030843\n",
            "Loss: 0.0\n",
            "training error 0.11020232974073989, test error 0.21292651072726515\n",
            "Loss: 0.0\n",
            "training error 0.1100238127805298, test error 0.21285470642445836\n",
            "Loss: 0.0\n",
            "training error 0.1101238222179074, test error 0.2127695184586651\n",
            "Loss: 0.0\n",
            "training error 0.1099556716985575, test error 0.21242717082581136\n",
            "Loss: 0.0\n",
            "training error 0.10998709519081735, test error 0.21258404917837617\n",
            "Loss: 0.07385041751248878\n",
            "training error 0.10989196434897328, test error 0.21251197367962635\n",
            "Loss: 0.03992090723861086\n",
            "training error 0.1097616857481763, test error 0.21236393213679383\n",
            "Loss: 0.0\n",
            "training error 0.10961230281913514, test error 0.21229687629589175\n",
            "Loss: 0.0\n",
            "training error 0.10960037023598555, test error 0.2121926283180159\n",
            "Loss: 0.0\n",
            "training error 0.10952647922952444, test error 0.2121361853114\n",
            "Loss: 0.0\n",
            "training error 0.10939886620978606, test error 0.21195936411272223\n",
            "Loss: 0.0\n",
            "training error 0.10931194513564982, test error 0.2120216105963167\n",
            "Loss: 0.029367177928207866\n",
            "training error 0.10924224815452167, test error 0.2117491339869389\n",
            "Loss: 0.0\n",
            "training error 0.10910456713246289, test error 0.21134227698271116\n",
            "Loss: 0.0\n",
            "training error 0.10902395854602588, test error 0.21123048013151619\n",
            "Loss: 0.0\n",
            "training error 0.10894934042474731, test error 0.21097599156430294\n",
            "Loss: 0.0\n",
            "training error 0.10889273788041384, test error 0.21101693593105947\n",
            "Loss: 0.019407121375736303\n",
            "training error 0.10875709685755615, test error 0.21084280394107732\n",
            "Loss: 0.0\n",
            "training error 0.10861689791551159, test error 0.21071010455030315\n",
            "Loss: 0.0\n",
            "training error 0.10860424924248398, test error 0.21040282895676526\n",
            "Loss: 0.0\n",
            "training error 0.10867303461313228, test error 0.21012614691806042\n",
            "Loss: 0.0\n",
            "training error 0.10832660732583012, test error 0.2100811135530654\n",
            "Loss: 0.0\n",
            "training error 0.10846142617820584, test error 0.20994866652150665\n",
            "Loss: 0.0\n",
            "training error 0.10815463680558188, test error 0.2096757882205162\n",
            "Loss: 0.0\n",
            "training error 0.10809841914715852, test error 0.20947159799020354\n",
            "Loss: 0.0\n",
            "training error 0.10796073428162176, test error 0.20938135168236943\n",
            "Loss: 0.0\n",
            "training error 0.10794737113551332, test error 0.2092366036128078\n",
            "Loss: 0.0\n",
            "training error 0.10785159128967824, test error 0.20913015420658174\n",
            "Loss: 0.0\n",
            "training error 0.10775795321415466, test error 0.2092006429361812\n",
            "Loss: 0.03370567475882158\n",
            "training error 0.10752520562985682, test error 0.20904016351537463\n",
            "Loss: 0.0\n",
            "training error 0.10752450565596156, test error 0.20853593378640237\n",
            "Loss: 0.0\n",
            "training error 0.10737824663143593, test error 0.2084715900879538\n",
            "Loss: 0.0\n",
            "training error 0.10730613833640477, test error 0.20803426163899605\n",
            "Loss: 0.0\n",
            "training error 0.10722195334127595, test error 0.20774611367612852\n",
            "Loss: 0.0\n",
            "training error 0.10711547634317564, test error 0.20746744518889004\n",
            "Loss: 0.0\n",
            "training error 0.10696728057265933, test error 0.20731783746632096\n",
            "Loss: 0.0\n",
            "training error 0.10683652862578968, test error 0.20728537430478194\n",
            "Loss: 0.0\n",
            "training error 0.10671580094171393, test error 0.20720421260541697\n",
            "Loss: 0.0\n",
            "training error 0.10655620668749494, test error 0.2070755923795785\n",
            "Loss: 0.0\n",
            "training error 0.10640416186069573, test error 0.2068298643016092\n",
            "Loss: 0.0\n",
            "training error 0.10628126169116789, test error 0.20667865015407313\n",
            "Loss: 0.0\n",
            "training error 0.1061863166593763, test error 0.20647563454037682\n",
            "Loss: 0.0\n",
            "training error 0.10611210314453307, test error 0.20627961571026127\n",
            "Loss: 0.0\n",
            "training error 0.10596708802938763, test error 0.2062052397763697\n",
            "Loss: 0.0\n",
            "training error 0.1058249415863126, test error 0.20614378832846839\n",
            "Loss: 0.0\n",
            "training error 0.10566884830358544, test error 0.20581374976882702\n",
            "Loss: 0.0\n",
            "training error 0.10571144921169678, test error 0.20536140466353664\n",
            "Loss: 0.0\n",
            "training error 0.10542898751569993, test error 0.20538736802110294\n",
            "Loss: 0.012642763916059785\n",
            "training error 0.10544204189821862, test error 0.2052843061630689\n",
            "Loss: 0.0\n",
            "training error 0.10536036821581092, test error 0.2052072129050749\n",
            "Loss: 0.0\n",
            "training error 0.10502971627811518, test error 0.2048286516517155\n",
            "Loss: 0.0\n",
            "training error 0.10497853005873882, test error 0.20456694810071796\n",
            "Loss: 0.0\n",
            "training error 0.10481149136812543, test error 0.20445343059780424\n",
            "Loss: 0.0\n",
            "training error 0.10474880719704513, test error 0.20415508364947285\n",
            "Loss: 0.0\n",
            "training error 0.10477030746530343, test error 0.20378680874775268\n",
            "Loss: 0.0\n",
            "training error 0.10446508398565459, test error 0.20357909134392174\n",
            "Loss: 0.0\n",
            "training error 0.10426238787294369, test error 0.20338140405347283\n",
            "Loss: 0.0\n",
            "training error 0.1041670256775137, test error 0.2031404416694134\n",
            "Loss: 0.0\n",
            "training error 0.10402275264179814, test error 0.20292243213116265\n",
            "Loss: 0.0\n",
            "training error 0.10392460704088194, test error 0.20283822720745312\n",
            "Loss: 0.0\n",
            "training error 0.10373290351987617, test error 0.20282872440366959\n",
            "Loss: 0.0\n",
            "training error 0.10366567428746629, test error 0.20235608869140975\n",
            "Loss: 0.0\n",
            "training error 0.10354422336020556, test error 0.202084096141204\n",
            "Loss: 0.0\n",
            "training error 0.1033165447270596, test error 0.2018170765746764\n",
            "Loss: 0.0\n",
            "training error 0.1031759020662737, test error 0.2016232959575176\n",
            "Loss: 0.0\n",
            "training error 0.10305012392663566, test error 0.2015087218606383\n",
            "Loss: 0.0\n",
            "training error 0.10296320764544475, test error 0.20136739195086312\n",
            "Loss: 0.0\n",
            "training error 0.10295175596466732, test error 0.20110721315108057\n",
            "Loss: 0.0\n",
            "training error 0.10285667451621147, test error 0.20106491132289597\n",
            "Loss: 0.0\n",
            "training error 0.10250170928523337, test error 0.20061445426809377\n",
            "Loss: 0.0\n",
            "training error 0.10237157058735148, test error 0.20035004417954963\n",
            "Loss: 0.0\n",
            "training error 0.1022460044113542, test error 0.20001929978940378\n",
            "Loss: 0.0\n",
            "training error 0.10213639020524934, test error 0.1999906199082285\n",
            "Loss: 0.0\n",
            "training error 0.10206760709377369, test error 0.19979379025302324\n",
            "Loss: 0.0\n",
            "training error 0.10183589998160411, test error 0.1993766913493599\n",
            "Loss: 0.0\n",
            "training error 0.10182760018021024, test error 0.19906023751998952\n",
            "Loss: 0.0\n",
            "training error 0.10180715413180724, test error 0.19920732884378836\n",
            "Loss: 0.0738928706362385\n",
            "training error 0.10148741748575531, test error 0.1989027139638772\n",
            "Loss: 0.0\n",
            "training error 0.10132795026058343, test error 0.1986355540166661\n",
            "Loss: 0.0\n",
            "training error 0.10124065961799052, test error 0.19826628649615707\n",
            "Loss: 0.0\n",
            "training error 0.10109877171694157, test error 0.19799885618317578\n",
            "Loss: 0.0\n",
            "training error 0.10108468731392817, test error 0.19780314685756878\n",
            "Loss: 0.0\n",
            "training error 0.10088632184728928, test error 0.19734216269950647\n",
            "Loss: 0.0\n",
            "training error 0.10071894742413635, test error 0.19712121974404617\n",
            "Loss: 0.0\n",
            "training error 0.10063198637174567, test error 0.19696520071479706\n",
            "Loss: 0.0\n",
            "training error 0.10057581564358324, test error 0.1969424305197123\n",
            "Loss: 0.0\n",
            "training error 0.10024238795938495, test error 0.19688913208310435\n",
            "Loss: 0.0\n",
            "training error 0.10021448547927883, test error 0.19662830837722833\n",
            "Loss: 0.0\n",
            "training error 0.10024172633100142, test error 0.19689296473831788\n",
            "Loss: 0.13459728320595055\n",
            "training error 0.09980675910938724, test error 0.1964299733673813\n",
            "Loss: 0.0\n",
            "training error 0.09975791280369593, test error 0.19646615663465283\n",
            "Loss: 0.018420440959832085\n",
            "training error 0.09958081531431547, test error 0.19654847859925256\n",
            "Loss: 0.06032950564505146\n",
            "training error 0.09979126485487114, test error 0.19553614985549028\n",
            "Loss: 0.0\n",
            "training error 0.09945077894439268, test error 0.19571862817808514\n",
            "Loss: 0.09332203929028893\n",
            "training error 0.09916907620107915, test error 0.19532146788045415\n",
            "Loss: 0.0\n",
            "training error 0.09899012149864155, test error 0.19518647502418135\n",
            "Loss: 0.0\n",
            "training error 0.09889132580531165, test error 0.1948079977838323\n",
            "Loss: 0.0\n",
            "training error 0.09894814605857191, test error 0.19449050215857444\n",
            "Loss: 0.0\n",
            "training error 0.09859162517060378, test error 0.1941626743968946\n",
            "Loss: 0.0\n",
            "training error 0.0986186530940747, test error 0.19391355379381073\n",
            "Loss: 0.0\n",
            "training error 0.09842199145840581, test error 0.19368130730655714\n",
            "Loss: 0.0\n",
            "training error 0.09845948059787679, test error 0.19380546745653643\n",
            "Loss: 0.06410538616552497\n",
            "training error 0.09811255029310335, test error 0.19363007588930173\n",
            "Loss: 0.0\n",
            "training error 0.09796100355143952, test error 0.19351837141006542\n",
            "Loss: 0.0\n",
            "training error 0.09781563847245382, test error 0.1933329793866081\n",
            "Loss: 0.0\n",
            "training error 0.0978880626224048, test error 0.19298154905003667\n",
            "Loss: 0.0\n",
            "training error 0.09759384167659753, test error 0.19271629183435515\n",
            "Loss: 0.0\n",
            "training error 0.09742335013188078, test error 0.1926928198066401\n",
            "Loss: 0.0\n",
            "training error 0.0972849001452143, test error 0.19227514352909403\n",
            "Loss: 0.0\n",
            "training error 0.09712639710557168, test error 0.19209790912731445\n",
            "Loss: 0.0\n",
            "training error 0.09699427633711918, test error 0.19207509903894687\n",
            "Loss: 0.0\n",
            "training error 0.0968699849655333, test error 0.19193793288413546\n",
            "Loss: 0.0\n",
            "training error 0.09684445608778774, test error 0.19150089359695188\n",
            "Loss: 0.0\n",
            "training error 0.096662907290331, test error 0.19121404188212918\n",
            "Loss: 0.0\n",
            "training error 0.09656430596972528, test error 0.19108597277012226\n",
            "Loss: 0.0\n",
            "training error 0.09642345512300879, test error 0.19123328604422776\n",
            "Loss: 0.07709266775051127\n",
            "training error 0.09618452760074232, test error 0.19109531583690068\n",
            "Loss: 0.00488945716055067\n",
            "training error 0.09622269718643979, test error 0.19048970575874669\n",
            "Loss: 0.0\n",
            "training error 0.09599181271378773, test error 0.19056040355586285\n",
            "Loss: 0.03711371007402153\n",
            "training error 0.09588194701070687, test error 0.19003194139092477\n",
            "Loss: 0.0\n",
            "training error 0.09572674078100321, test error 0.18989558760146513\n",
            "Loss: 0.0\n",
            "training error 0.09557687017433494, test error 0.1898133918824234\n",
            "Loss: 0.0\n",
            "training error 0.09565573313562115, test error 0.1892835188621251\n",
            "Loss: 0.0\n",
            "training error 0.09535209179989568, test error 0.18944480475943612\n",
            "Loss: 0.08520863215168983\n",
            "training error 0.09514749483721166, test error 0.18937472499466887\n",
            "Loss: 0.04818493078111441\n",
            "training error 0.09505341424656294, test error 0.1891025876778411\n",
            "Loss: 0.0\n",
            "training error 0.09486393526576657, test error 0.18924790839102437\n",
            "Loss: 0.07684755400112486\n",
            "training error 0.09483864424824807, test error 0.1891030434390191\n",
            "Loss: 0.00024101266069553873\n",
            "training error 0.09459828868235944, test error 0.1884755119225706\n",
            "Loss: 0.0\n",
            "training error 0.09444848225024856, test error 0.188412625614608\n",
            "Loss: 0.0\n",
            "training error 0.09439307027204463, test error 0.1883000440016549\n",
            "Loss: 0.0\n",
            "training error 0.0941426600503934, test error 0.18822147137626333\n",
            "Loss: 0.0\n",
            "training error 0.09401816386126426, test error 0.18763914428140144\n",
            "Loss: 0.0\n",
            "training error 0.09383706939685754, test error 0.18732346959257498\n",
            "Loss: 0.0\n",
            "training error 0.0936862969890799, test error 0.1871517970560277\n",
            "Loss: 0.0\n",
            "training error 0.09360080045798068, test error 0.18715437479542715\n",
            "Loss: 0.0013773522028692753\n",
            "training error 0.09343633568273509, test error 0.18675684434171055\n",
            "Loss: 0.0\n",
            "training error 0.09322600116635935, test error 0.18655363070701025\n",
            "Loss: 0.0\n",
            "training error 0.0931466591561234, test error 0.18638496036986787\n",
            "Loss: 0.0\n",
            "training error 0.09300067814571007, test error 0.18616917719974194\n",
            "Loss: 0.0\n",
            "training error 0.09287744991695254, test error 0.18629446280539558\n",
            "Loss: 0.06729664251521328\n",
            "training error 0.09267066423356263, test error 0.18588369429406687\n",
            "Loss: 0.0\n",
            "training error 0.09249538090299776, test error 0.1857771593660563\n",
            "Loss: 0.0\n",
            "training error 0.09240407733792949, test error 0.18519381351890676\n",
            "Loss: 0.0\n",
            "training error 0.09224583737203396, test error 0.18541902725265907\n",
            "Loss: 0.12160975006290098\n",
            "training error 0.09223950289045246, test error 0.18510429494383351\n",
            "Loss: 0.0\n",
            "training error 0.0919784095841379, test error 0.18505866590175593\n",
            "Loss: 0.0\n",
            "training error 0.09165007292200616, test error 0.18493624211007284\n",
            "Loss: 0.0\n",
            "training error 0.09152623897233583, test error 0.1842653464580129\n",
            "Loss: 0.0\n",
            "training error 0.09142268396487394, test error 0.1836013575652268\n",
            "Loss: 0.0\n",
            "training error 0.09137168908047796, test error 0.18308206125198456\n",
            "Loss: 0.0\n",
            "training error 0.09119178677559066, test error 0.18312428544772585\n",
            "Loss: 0.023062989051214622\n",
            "training error 0.09089222749072048, test error 0.18306676783828074\n",
            "Loss: 0.0\n",
            "training error 0.09071179312887893, test error 0.18268641041509906\n",
            "Loss: 0.0\n",
            "training error 0.09050310390369053, test error 0.18265845846353093\n",
            "Loss: 0.0\n",
            "training error 0.09032979616644296, test error 0.18258748749034112\n",
            "Loss: 0.0\n",
            "training error 0.09008652837092712, test error 0.18219182669874165\n",
            "Loss: 0.0\n",
            "training error 0.09000396519380224, test error 0.18199345564656644\n",
            "Loss: 0.0\n",
            "training error 0.08994244561474346, test error 0.1813522127257132\n",
            "Loss: 0.0\n",
            "training error 0.08960392167335021, test error 0.1811487597100192\n",
            "Loss: 0.0\n",
            "training error 0.08962965558787454, test error 0.18096269698122186\n",
            "Loss: 0.0\n",
            "training error 0.08924916343786664, test error 0.1804768128229702\n",
            "Loss: 0.0\n",
            "training error 0.08906361185305282, test error 0.18014479613747172\n",
            "Loss: 0.0\n",
            "training error 0.08880981353819543, test error 0.17974689717586917\n",
            "Loss: 0.0\n",
            "training error 0.08852390665787077, test error 0.17972509245262136\n",
            "Loss: 0.0\n",
            "training error 0.08833446038300014, test error 0.17959139013991252\n",
            "Loss: 0.0\n",
            "training error 0.08817514933813358, test error 0.17900715983907728\n",
            "Loss: 0.0\n",
            "training error 0.08791206733044744, test error 0.17913494749322703\n",
            "Loss: 0.0713868955100061\n",
            "training error 0.08770760658141671, test error 0.17873097106183838\n",
            "Loss: 0.0\n",
            "training error 0.08747579130765772, test error 0.17856631814703797\n",
            "Loss: 0.0\n",
            "training error 0.08730406222371698, test error 0.17823840872671226\n",
            "Loss: 0.0\n",
            "training error 0.08707290740269863, test error 0.17764813687268566\n",
            "Loss: 0.0\n",
            "training error 0.0868785899970441, test error 0.17714114705535955\n",
            "Loss: 0.0\n",
            "training error 0.08669342973773875, test error 0.176672982775588\n",
            "Loss: 0.0\n",
            "training error 0.08631550624562413, test error 0.17633564575703137\n",
            "Loss: 0.0\n",
            "training error 0.08608888191681206, test error 0.1760011609825086\n",
            "Loss: 0.0\n",
            "training error 0.08608546860549289, test error 0.1760179421514771\n",
            "Loss: 0.009534692200219297\n",
            "training error 0.08562004566580256, test error 0.17497307035592863\n",
            "Loss: 0.0\n",
            "training error 0.08539959436456497, test error 0.1745760130640281\n",
            "Loss: 0.0\n",
            "training error 0.08511663413049456, test error 0.17467665661460563\n",
            "Loss: 0.0576502744054741\n",
            "training error 0.08487040872958362, test error 0.1738235271346219\n",
            "Loss: 0.0\n",
            "training error 0.08467691593153902, test error 0.17353893372417833\n",
            "Loss: 0.0\n",
            "training error 0.08444431651019613, test error 0.1729369360603671\n",
            "Loss: 0.0\n",
            "training error 0.0840029200411927, test error 0.17276336084835484\n",
            "Loss: 0.0\n",
            "training error 0.08369681117207065, test error 0.17213231172330512\n",
            "Loss: 0.0\n",
            "training error 0.08351332418083454, test error 0.17141576752103743\n",
            "Loss: 0.0\n",
            "training error 0.08333686795174637, test error 0.17114191592574787\n",
            "Loss: 0.0\n",
            "training error 0.08298683788704991, test error 0.17012192279804217\n",
            "Loss: 0.0\n",
            "training error 0.0826463221023055, test error 0.16974987114181495\n",
            "Loss: 0.0\n",
            "training error 0.08231061137672578, test error 0.16952026841337695\n",
            "Loss: 0.0\n",
            "training error 0.08195248353279547, test error 0.1690291517572457\n",
            "Loss: 0.0\n",
            "training error 0.08196080410494307, test error 0.1692630585033538\n",
            "Loss: 0.13838248827280353\n",
            "training error 0.08135359942279029, test error 0.1685891798094359\n",
            "Loss: 0.0\n",
            "training error 0.08110071913849907, test error 0.1680660147128666\n",
            "Loss: 0.0\n",
            "training error 0.08082655617181811, test error 0.16746232288799057\n",
            "Loss: 0.0\n",
            "training error 0.0805617902247088, test error 0.16758980874944787\n",
            "Loss: 0.07612808616215272\n",
            "training error 0.08019609006355573, test error 0.16707787980823\n",
            "Loss: 0.0\n",
            "training error 0.07981853436567284, test error 0.1663457451671544\n",
            "Loss: 0.0\n",
            "training error 0.07998204435074081, test error 0.16508291281992662\n",
            "Loss: 0.0\n",
            "training error 0.07918942077253652, test error 0.16521946474770208\n",
            "Loss: 0.08271717856371819\n",
            "training error 0.07898811923400369, test error 0.1643963843929616\n",
            "Loss: 0.0\n",
            "training error 0.07843616906842645, test error 0.16425239484416268\n",
            "Loss: 0.0\n",
            "training error 0.0783396825340041, test error 0.16404030439880954\n",
            "Loss: 0.0\n",
            "training error 0.07784018618527043, test error 0.1629565842111771\n",
            "Loss: 0.0\n",
            "training error 0.07775540058189084, test error 0.16285821743762188\n",
            "Loss: 0.0\n",
            "training error 0.07737139037704914, test error 0.16227057861534072\n",
            "Loss: 0.0\n",
            "training error 0.07673382386446125, test error 0.16154257544604755\n",
            "Loss: 0.0\n",
            "training error 0.07718437462121683, test error 0.16099071077714414\n",
            "Loss: 0.0\n",
            "training error 0.07629122372098442, test error 0.15995462789536674\n",
            "Loss: 0.0\n",
            "training error 0.07576096791506381, test error 0.15954766049535418\n",
            "Loss: 0.0\n",
            "training error 0.07548561932601913, test error 0.1589732059416723\n",
            "Loss: 0.0\n",
            "training error 0.07521995580962876, test error 0.15881210561595877\n",
            "Loss: 0.0\n",
            "training error 0.07489775810120615, test error 0.15843284963869664\n",
            "Loss: 0.0\n",
            "training error 0.07454325188317999, test error 0.15816074951221376\n",
            "Loss: 0.0\n",
            "training error 0.0741284621484428, test error 0.15824601601662758\n",
            "Loss: 0.05391129257845684\n",
            "training error 0.07376409228008786, test error 0.15674044149608132\n",
            "Loss: 0.0\n",
            "training error 0.07343718848819883, test error 0.1568126195101748\n",
            "Loss: 0.046049388022995075\n",
            "training error 0.07314984776598918, test error 0.15560120261618818\n",
            "Loss: 0.0\n",
            "training error 0.07264315830680447, test error 0.15524753711822428\n",
            "Loss: 0.0\n",
            "training error 0.0724757981813476, test error 0.1544082420758833\n",
            "Loss: 0.0\n",
            "training error 0.0722144994094632, test error 0.15313899507977893\n",
            "Loss: 0.0\n",
            "training error 0.07176797341282792, test error 0.1530983790910201\n",
            "Loss: 0.0\n",
            "training error 0.07134714140077392, test error 0.15189679105641857\n",
            "Loss: 0.0\n",
            "training error 0.07106043816612816, test error 0.15108120213562432\n",
            "Loss: 0.0\n",
            "training error 0.07075155314294923, test error 0.15089660994689888\n",
            "Loss: 0.0\n",
            "training error 0.07047123269143507, test error 0.15091001406653337\n",
            "Loss: 0.00888298261916276\n",
            "training error 0.07025842204594032, test error 0.15009467865285925\n",
            "Loss: 0.0\n",
            "training error 0.06960689692051973, test error 0.14933591716177758\n",
            "Loss: 0.0\n",
            "training error 0.06928229213871655, test error 0.14887151760985454\n",
            "Loss: 0.0\n",
            "training error 0.06901106124024968, test error 0.14792251647133403\n",
            "Loss: 0.0\n",
            "training error 0.06857347830293298, test error 0.14824721797686563\n",
            "Loss: 0.2195078296917119\n",
            "training error 0.06823583745881193, test error 0.14763007413917623\n",
            "Loss: 0.0\n",
            "training error 0.06785343408129076, test error 0.1462183249253803\n",
            "Loss: 0.0\n",
            "training error 0.06754535049916566, test error 0.1457870471153913\n",
            "Loss: 0.0\n",
            "training error 0.06723034457166564, test error 0.1449951160184749\n",
            "Loss: 0.0\n",
            "training error 0.06705521048316232, test error 0.14391854247134722\n",
            "Loss: 0.0\n",
            "training error 0.06648789284971761, test error 0.14392017685022\n",
            "Loss: 0.0011356277271223902\n",
            "training error 0.06619498417340683, test error 0.14265459337854505\n",
            "Loss: 0.0\n",
            "training error 0.06573843505093131, test error 0.1428354997459678\n",
            "Loss: 0.12681426033207543\n",
            "training error 0.06558430993929588, test error 0.14171208789777628\n",
            "Loss: 0.0\n",
            "training error 0.06507826135871675, test error 0.14080096632863545\n",
            "Loss: 0.0\n",
            "training error 0.06479373039601193, test error 0.14000503744569232\n",
            "Loss: 0.0\n",
            "training error 0.06439088835056145, test error 0.13987219461384054\n",
            "Loss: 0.0\n",
            "training error 0.06418975744607998, test error 0.13898855072099034\n",
            "Loss: 0.0\n",
            "training error 0.06391874272693489, test error 0.1389465331219979\n",
            "Loss: 0.0\n",
            "training error 0.06330597467198033, test error 0.13753386434219605\n",
            "Loss: 0.0\n",
            "training error 0.06310228072371797, test error 0.13761662856386814\n",
            "Loss: 0.06017734037209177\n",
            "training error 0.06256668523183634, test error 0.136618474720857\n",
            "Loss: 0.0\n",
            "training error 0.062213460818815666, test error 0.13574797724267973\n",
            "Loss: 0.0\n",
            "training error 0.062181983470266225, test error 0.1352102032218167\n",
            "Loss: 0.0\n",
            "training error 0.06149314982460842, test error 0.13454336233454814\n",
            "Loss: 0.0\n",
            "training error 0.06117589771752399, test error 0.1344675523916797\n",
            "Loss: 0.0\n",
            "training error 0.06111434844477584, test error 0.13273354497117018\n",
            "Loss: 0.0\n",
            "training error 0.060607987909241066, test error 0.13318272719078006\n",
            "Loss: 0.33840896791195174\n",
            "training error 0.060114285150759665, test error 0.13194422292670163\n",
            "Loss: 0.0\n",
            "training error 0.05964385323350815, test error 0.1313857479984612\n",
            "Loss: 0.0\n",
            "training error 0.059310819080126725, test error 0.1307497281442372\n",
            "Loss: 0.0\n",
            "training error 0.05896727497478667, test error 0.1306450148149846\n",
            "Loss: 0.0\n",
            "training error 0.05903905574733496, test error 0.12918982313471786\n",
            "Loss: 0.0\n",
            "training error 0.0582757707333359, test error 0.12837781000259849\n",
            "Loss: 0.0\n",
            "training error 0.05794658918093709, test error 0.12773219061349567\n",
            "Loss: 0.0\n",
            "training error 0.05783163810374248, test error 0.12733786898934063\n",
            "Loss: 0.0\n",
            "training error 0.05720044694539994, test error 0.1260567616009445\n",
            "Loss: 0.0\n",
            "training error 0.05735634305857923, test error 0.1247963862519265\n",
            "Loss: 0.0\n",
            "training error 0.056728550124933316, test error 0.1242343794581377\n",
            "Loss: 0.0\n",
            "training error 0.05622792385144524, test error 0.12401844339108244\n",
            "Loss: 0.0\n",
            "training error 0.05610619793827189, test error 0.12309505852471758\n",
            "Loss: 0.0\n",
            "training error 0.05569068307721981, test error 0.1222857459486519\n",
            "Loss: 0.0\n",
            "training error 0.05527022106284247, test error 0.12235060862772659\n",
            "Loss: 0.05304189672437065\n",
            "training error 0.054925819049722685, test error 0.12261081210202436\n",
            "Loss: 0.26582505659242806\n",
            "training error 0.05450799421393651, test error 0.12093432685287699\n",
            "Loss: 0.0\n",
            "training error 0.05429265460960874, test error 0.11995755745799476\n",
            "Loss: 0.0\n",
            "training error 0.05387671561089844, test error 0.11965382610082573\n",
            "Loss: 0.0\n",
            "training error 0.05352270858327311, test error 0.11937636253126849\n",
            "Loss: 0.0\n",
            "training error 0.05324361471269001, test error 0.11864216549299542\n",
            "Loss: 0.0\n",
            "training error 0.05276394167002047, test error 0.11777820281013077\n",
            "Loss: 0.0\n",
            "training error 0.052531054601998146, test error 0.11765266996336213\n",
            "Loss: 0.0\n",
            "training error 0.05213099208836131, test error 0.11744207858880232\n",
            "Loss: 0.0\n",
            "training error 0.05175568810419364, test error 0.11593778194773277\n",
            "Loss: 0.0\n",
            "training error 0.05153224731079145, test error 0.11585027988571803\n",
            "Loss: 0.0\n",
            "training error 0.051401953308558006, test error 0.11519348549707491\n",
            "Loss: 0.0\n",
            "training error 0.05099104988062517, test error 0.11339347286743975\n",
            "Loss: 0.0\n",
            "training error 0.0508251732089724, test error 0.11244748245711346\n",
            "Loss: 0.0\n",
            "training error 0.05016220967399155, test error 0.11248143813205823\n",
            "Loss: 0.030196918777369852\n",
            "training error 0.0497767995596118, test error 0.11138261195497332\n",
            "Loss: 0.0\n",
            "training error 0.0494644340462858, test error 0.11064654916339157\n",
            "Loss: 0.0\n",
            "training error 0.04907057727421152, test error 0.10998678051422778\n",
            "Loss: 0.0\n",
            "training error 0.04882054235504614, test error 0.10966009216190048\n",
            "Loss: 0.0\n",
            "training error 0.048351311645919486, test error 0.10963006819949178\n",
            "Loss: 0.0\n",
            "training error 0.04817438469428908, test error 0.10902061563881964\n",
            "Loss: 0.0\n",
            "training error 0.04775892865560952, test error 0.10809401794039615\n",
            "Loss: 0.0\n",
            "training error 0.04736779531854033, test error 0.10750622615908138\n",
            "Loss: 0.0\n",
            "training error 0.04706280199867527, test error 0.10602241766431439\n",
            "Loss: 0.0\n",
            "training error 0.04675337686083307, test error 0.10571977733649524\n",
            "Loss: 0.0\n",
            "training error 0.04648672639735624, test error 0.10485387994361016\n",
            "Loss: 0.0\n",
            "training error 0.046229230292961485, test error 0.10444106854800891\n",
            "Loss: 0.0\n",
            "training error 0.04573657756829459, test error 0.10441865586238687\n",
            "Loss: 0.0\n",
            "training error 0.045511404980454306, test error 0.1030916648913689\n",
            "Loss: 0.0\n",
            "training error 0.045466214661710906, test error 0.10203333681653673\n",
            "Loss: 0.0\n",
            "training error 0.04489069453826645, test error 0.1016211049603712\n",
            "Loss: 0.0\n",
            "training error 0.04530748670387527, test error 0.10203641258634555\n",
            "Loss: 0.40868245443335116\n",
            "training error 0.04440715679425283, test error 0.10005368534133453\n",
            "Loss: 0.0\n",
            "training error 0.043983579883279056, test error 0.09985167087639774\n",
            "Loss: 0.0\n",
            "training error 0.0437256513304154, test error 0.09937648524353704\n",
            "Loss: 0.0\n",
            "training error 0.04367778464443515, test error 0.09811905771127048\n",
            "Loss: 0.0\n",
            "training error 0.043311107306963255, test error 0.09778057583092344\n",
            "Loss: 0.0\n",
            "training error 0.042740688304819335, test error 0.09713412917143727\n",
            "Loss: 0.0\n",
            "training error 0.04254214811820443, test error 0.09640814987835218\n",
            "Loss: 0.0\n",
            "training error 0.04236210881140393, test error 0.09603961584908896\n",
            "Loss: 0.0\n",
            "training error 0.04216213191293409, test error 0.09625683206042344\n",
            "Loss: 0.22617355287615215\n",
            "training error 0.041614431822092936, test error 0.09470906104716299\n",
            "Loss: 0.0\n",
            "training error 0.04139213536800936, test error 0.09428565589517425\n",
            "Loss: 0.0\n",
            "training error 0.04117178091479336, test error 0.09333847527549059\n",
            "Loss: 0.0\n",
            "training error 0.04070897771861558, test error 0.09352019524974911\n",
            "Loss: 0.1946892465536587\n",
            "training error 0.040567399167281464, test error 0.09280748728301684\n",
            "Loss: 0.0\n",
            "training error 0.040495243106266565, test error 0.09248147362964795\n",
            "Loss: 0.0\n",
            "training error 0.04001809329982187, test error 0.0919893923793942\n",
            "Loss: 0.0\n",
            "training error 0.039605785765154916, test error 0.09165937821756925\n",
            "Loss: 0.0\n",
            "training error 0.03939730613295104, test error 0.09044504781320953\n",
            "Loss: 0.0\n",
            "training error 0.039259771530136274, test error 0.0901781353156514\n",
            "Loss: 0.0\n",
            "training error 0.038901362183991636, test error 0.08909756227165486\n",
            "Loss: 0.0\n",
            "training error 0.03870598505730477, test error 0.08754359898905145\n",
            "Loss: 0.0\n",
            "training error 0.03836266513812369, test error 0.08745163663134108\n",
            "Loss: 0.0\n",
            "training error 0.038073406894834495, test error 0.08665424363722105\n",
            "Loss: 0.0\n",
            "training error 0.03783712764360949, test error 0.08645590177449128\n",
            "Loss: 0.0\n",
            "training error 0.0375553443646342, test error 0.08576960929104857\n",
            "Loss: 0.0\n",
            "training error 0.037384858970193766, test error 0.0855641819690248\n",
            "Loss: 0.0\n",
            "training error 0.0370026543113415, test error 0.08468767337686128\n",
            "Loss: 0.0\n",
            "training error 0.03682695588497748, test error 0.08395876573268457\n",
            "Loss: 0.0\n",
            "training error 0.03665229181726289, test error 0.08383515013420713\n",
            "Loss: 0.0\n",
            "training error 0.0365321164076361, test error 0.08321366267499064\n",
            "Loss: 0.0\n",
            "training error 0.03648148808042341, test error 0.08336322088570094\n",
            "Loss: 0.17972795079870263\n",
            "training error 0.035913783841671196, test error 0.08224478919716709\n",
            "Loss: 0.0\n",
            "training error 0.03560291619659589, test error 0.08198083158551657\n",
            "Loss: 0.0\n",
            "training error 0.0354791886806378, test error 0.08148661234117409\n",
            "Loss: 0.0\n",
            "training error 0.03537522587768539, test error 0.08121778500659023\n",
            "Loss: 0.0\n",
            "training error 0.03510569141152988, test error 0.08078733734974128\n",
            "Loss: 0.0\n",
            "training error 0.0347224640869468, test error 0.08028504898986837\n",
            "Loss: 0.0\n",
            "training error 0.03455215969367089, test error 0.07974331578994458\n",
            "Loss: 0.0\n",
            "training error 0.03426905896195652, test error 0.07949066635581083\n",
            "Loss: 0.0\n",
            "training error 0.034359373940781604, test error 0.07832799828893122\n",
            "Loss: 0.0\n",
            "training error 0.033890977257722874, test error 0.07768445461769469\n",
            "Loss: 0.0\n",
            "training error 0.033701657944311195, test error 0.07785728376835055\n",
            "Loss: 0.22247584990640057\n",
            "training error 0.03352119267449024, test error 0.07680928694610063\n",
            "Loss: 0.0\n",
            "training error 0.033327942113501076, test error 0.07642248058096102\n",
            "Loss: 0.0\n",
            "training error 0.033116139684059805, test error 0.07675100733939862\n",
            "Loss: 0.429882353909683\n",
            "training error 0.03285345967006118, test error 0.07555437393830285\n",
            "Loss: 0.0\n",
            "training error 0.032613381524333, test error 0.07528572878652763\n",
            "Loss: 0.0\n",
            "training error 0.03245596210149871, test error 0.07491563527327541\n",
            "Loss: 0.0\n",
            "training error 0.03233308147781515, test error 0.07422490999069004\n",
            "Loss: 0.0\n",
            "training error 0.03239482810188861, test error 0.0739948753441689\n",
            "Loss: 0.0\n",
            "training error 0.03178106180153297, test error 0.07320628581723826\n",
            "Loss: 0.0\n",
            "training error 0.03170925003180953, test error 0.07269693489051589\n",
            "Loss: 0.0\n",
            "training error 0.031687196071739795, test error 0.07204438962185435\n",
            "Loss: 0.0\n",
            "training error 0.03139864975215884, test error 0.07204205570304512\n",
            "Loss: 0.0\n",
            "training error 0.031441609146163944, test error 0.07190448761156058\n",
            "Loss: 0.0\n",
            "training error 0.030984656257340433, test error 0.0715588756019885\n",
            "Loss: 0.0\n",
            "training error 0.030920607310939218, test error 0.07115002130496478\n",
            "Loss: 0.0\n",
            "training error 0.030762974432150248, test error 0.07050143472531922\n",
            "Loss: 0.0\n",
            "training error 0.0305781974616414, test error 0.07050158340428603\n",
            "Loss: 0.0002108878597750774\n",
            "training error 0.030359102150078903, test error 0.06999305851335348\n",
            "Loss: 0.0\n",
            "training error 0.030521126255295863, test error 0.06947015087103367\n",
            "Loss: 0.0\n",
            "training error 0.030152283479800795, test error 0.06886265846001588\n",
            "Loss: 0.0\n",
            "training error 0.02991402273092097, test error 0.06887731910386537\n",
            "Loss: 0.021289686133729724\n",
            "training error 0.02972836157914323, test error 0.06859306382375215\n",
            "Loss: 0.0\n",
            "training error 0.02965395696105734, test error 0.06868098120325401\n",
            "Loss: 0.12817240490636816\n",
            "training error 0.029599317389608276, test error 0.06781504889213787\n",
            "Loss: 0.0\n",
            "training error 0.029267574195181105, test error 0.06789886295401029\n",
            "Loss: 0.12359212776758\n",
            "training error 0.02922158153443559, test error 0.06798116190851529\n",
            "Loss: 0.2449500797995885\n",
            "training error 0.029128075381129093, test error 0.06651610844747413\n",
            "Loss: 0.0\n",
            "training error 0.028883228952780657, test error 0.06609298406001206\n",
            "Loss: 0.0\n",
            "training error 0.028797468904829697, test error 0.06716607404947496\n",
            "Loss: 1.6236065063858218\n",
            "training error 0.028756454587654127, test error 0.0657832313929286\n",
            "Loss: 0.0\n",
            "training error 0.02867815894244151, test error 0.06596154435683672\n",
            "Loss: 0.27106142421469137\n",
            "training error 0.02841845352141433, test error 0.06604695736461623\n",
            "Loss: 0.4009015156345441\n",
            "training error 0.02850523312315901, test error 0.06524019819342634\n",
            "Loss: 0.0\n",
            "training error 0.028221878683791668, test error 0.06496759251570955\n",
            "Loss: 0.0\n",
            "training error 0.02823641678139398, test error 0.06422615315130478\n",
            "Loss: 0.0\n",
            "training error 0.02781757313511085, test error 0.06484113544702712\n",
            "Loss: 0.9575262810362473\n",
            "training error 0.027742505511570766, test error 0.06456099358330575\n",
            "Loss: 0.5213459246300234\n",
            "training error 0.027590757202623967, test error 0.06377486161326384\n",
            "Loss: 0.0\n",
            "training error 0.027460004859651586, test error 0.06368359602936775\n",
            "Loss: 0.0\n",
            "training error 0.027311416350772756, test error 0.06324826995608132\n",
            "Loss: 0.0\n",
            "training error 0.027393127941737032, test error 0.0628414398016243\n",
            "Loss: 0.0\n",
            "training error 0.02714055025249732, test error 0.06333695949638182\n",
            "Loss: 0.7885237771791509\n",
            "training error 0.02697039268976888, test error 0.06270449834107138\n",
            "Loss: 0.0\n",
            "training error 0.0269398211989961, test error 0.06253798177403463\n",
            "Loss: 0.0\n",
            "training error 0.026804241621237474, test error 0.062100932563047107\n",
            "Loss: 0.0\n",
            "training error 0.026655331613299717, test error 0.06183672361505057\n",
            "Loss: 0.0\n",
            "training error 0.02669917155095214, test error 0.06212046483285372\n",
            "Loss: 0.45885551694089255\n",
            "training error 0.026520280827648828, test error 0.06187313876850369\n",
            "Loss: 0.05888920260364028\n",
            "training error 0.026383013608335285, test error 0.06089192503741563\n",
            "Loss: 0.0\n",
            "training error 0.026267795279297786, test error 0.06088300201500211\n",
            "Loss: 0.0\n",
            "training error 0.02614768100341635, test error 0.060398910105610285\n",
            "Loss: 0.0\n",
            "training error 0.02608939139941942, test error 0.060180895148330735\n",
            "Loss: 0.0\n",
            "training error 0.02604536281137499, test error 0.060089104343511904\n",
            "Loss: 0.0\n",
            "training error 0.025921689256617083, test error 0.059431613371049546\n",
            "Loss: 0.0\n",
            "training error 0.02580262290895585, test error 0.05917739281889262\n",
            "Loss: 0.0\n",
            "training error 0.02581842608270281, test error 0.05918164552733402\n",
            "Loss: 0.007186373442324978\n",
            "training error 0.025782837227977928, test error 0.05948907586198344\n",
            "Loss: 0.5266927592513237\n",
            "training error 0.025503016587584634, test error 0.05869024051603688\n",
            "Loss: 0.0\n",
            "training error 0.025368608415777014, test error 0.05848253954087168\n",
            "Loss: 0.0\n",
            "training error 0.02546546779413749, test error 0.058193293264290055\n",
            "Loss: 0.0\n",
            "training error 0.025273454377553798, test error 0.05756453355423557\n",
            "Loss: 0.0\n",
            "training error 0.02521109974348683, test error 0.05802668549576143\n",
            "Loss: 0.8028414598208133\n",
            "training error 0.025066306132482456, test error 0.058150885216798884\n",
            "Loss: 1.0185988252834122\n",
            "training error 0.025019241394507098, test error 0.057411674995002375\n",
            "Loss: 0.0\n",
            "training error 0.024951564993447133, test error 0.05786247212776786\n",
            "Loss: 0.785201150819459\n",
            "training error 0.02484536822709683, test error 0.05725214400728874\n",
            "Loss: 0.0\n",
            "training error 0.024686652378604415, test error 0.05685946462526475\n",
            "Loss: 0.0\n",
            "training error 0.024581180478053223, test error 0.05651520492314051\n",
            "Loss: 0.0\n",
            "training error 0.02465851819079657, test error 0.05619312614015039\n",
            "Loss: 0.0\n",
            "training error 0.02453151418224699, test error 0.05664719499852025\n",
            "Loss: 0.8080505384900238\n",
            "training error 0.024403426872127088, test error 0.05635235613328405\n",
            "Loss: 0.2833620481204946\n",
            "training error 0.024359815061854143, test error 0.05622077522935897\n",
            "Loss: 0.04920368576686318\n",
            "training error 0.024186015420858128, test error 0.0560137129693878\n",
            "Loss: 0.0\n",
            "training error 0.024196518184684417, test error 0.05584294493497559\n",
            "Loss: 0.0\n",
            "training error 0.02407467413553605, test error 0.05549743540333207\n",
            "Loss: 0.0\n",
            "training error 0.024021766211947414, test error 0.05526601301645602\n",
            "Loss: 0.0\n",
            "training error 0.024045082796006846, test error 0.055063572041181175\n",
            "Loss: 0.0\n",
            "training error 0.02395352600896531, test error 0.05484067848931792\n",
            "Loss: 0.0\n",
            "training error 0.023779281783660986, test error 0.055185272590018306\n",
            "Loss: 0.6283549186349102\n",
            "training error 0.023783077298442184, test error 0.05476692407762722\n",
            "Loss: 0.0\n",
            "training error 0.023654201282043968, test error 0.054593754966608524\n",
            "Loss: 0.0\n",
            "training error 0.023681595239515428, test error 0.05448958697033907\n",
            "Loss: 0.0\n",
            "training error 0.02369704911282096, test error 0.05457308447053337\n",
            "Loss: 0.15323570031784417\n",
            "training error 0.02363845866551216, test error 0.054624188979381316\n",
            "Loss: 0.2470233608405037\n",
            "training error 0.023434870612718237, test error 0.053999675992493085\n",
            "Loss: 0.0\n",
            "training error 0.023742460000041415, test error 0.05426541481050571\n",
            "Loss: 0.4921118749852571\n",
            "training error 0.023281246705740628, test error 0.05376710079941848\n",
            "Loss: 0.0\n",
            "training error 0.02329862133889046, test error 0.05381581168868484\n",
            "Loss: 0.09059608671868613\n",
            "training error 0.02325750009938237, test error 0.053956225958922875\n",
            "Loss: 0.35174885142112977\n",
            "training error 0.02320238747324244, test error 0.05292615984719806\n",
            "Loss: 0.0\n",
            "training error 0.023194648344575696, test error 0.052894433329168974\n",
            "Loss: 0.0\n",
            "training error 0.023061770862493332, test error 0.0526733153183259\n",
            "Loss: 0.0\n",
            "training error 0.02298827510041972, test error 0.052708908682090806\n",
            "Loss: 0.06757380573028104\n",
            "training error 0.023024354301976316, test error 0.05319833433780954\n",
            "Loss: 0.9967457265804169\n",
            "training error 0.022967452561061225, test error 0.05365078493265092\n",
            "Loss: 1.8557206973166318\n",
            "training error 0.022867270886509226, test error 0.05279109411256884\n",
            "Loss: 0.22360239436449714\n",
            "training error 0.022826374357650843, test error 0.052273326955150294\n",
            "Loss: 0.0\n",
            "training error 0.022746232120286248, test error 0.05200019575972372\n",
            "Loss: 0.0\n",
            "training error 0.022739901614263903, test error 0.051726249850872014\n",
            "Loss: 0.0\n",
            "training error 0.0226197557004338, test error 0.05212319286932373\n",
            "Loss: 0.7673918360525223\n",
            "training error 0.022601450100125913, test error 0.05198412939361565\n",
            "Loss: 0.49854676008238563\n",
            "training error 0.022550081200959155, test error 0.051932815145924696\n",
            "Loss: 0.3993432650698958\n",
            "training error 0.022669274481625673, test error 0.05211287064083654\n",
            "Loss: 0.7474363424357477\n",
            "training error 0.022489477934652346, test error 0.05124134345423995\n",
            "Loss: 0.0\n",
            "training error 0.02237991609376717, test error 0.051360361181358415\n",
            "Loss: 0.2322689435821479\n",
            "training error 0.02240856296690718, test error 0.051279333835704585\n",
            "Loss: 0.07414009646049546\n",
            "training error 0.022318875824825724, test error 0.05149194140018236\n",
            "Loss: 0.4890542071095405\n",
            "training error 0.02239585612595085, test error 0.05115833155648617\n",
            "Loss: 0.0\n",
            "training error 0.022240819146482498, test error 0.05135556099463818\n",
            "Loss: 0.3855275028550098\n",
            "training error 0.022208384977409793, test error 0.05075830711157467\n",
            "Loss: 0.0\n",
            "training error 0.022144481593597536, test error 0.051003251604224524\n",
            "Loss: 0.4825702561581213\n",
            "training error 0.02210132082485291, test error 0.05038690510110239\n",
            "Loss: 0.0\n",
            "training error 0.022037493954040838, test error 0.0505051631495312\n",
            "Loss: 0.23469996458707065\n",
            "training error 0.022052424685566962, test error 0.05064672639969951\n",
            "Loss: 0.5156524261130668\n",
            "training error 0.022044841541973535, test error 0.05126692932780742\n",
            "Loss: 1.7465335982419283\n",
            "training error 0.022017910438151104, test error 0.050722297385271314\n",
            "Loss: 0.6656338258838268\n",
            "training error 0.022070488368587042, test error 0.049968871714380254\n",
            "Loss: 0.0\n",
            "training error 0.021992566068630624, test error 0.05046614748571822\n",
            "Loss: 0.9951711020820486\n",
            "training error 0.022076993953201753, test error 0.05108992328963697\n",
            "Loss: 2.243499876612365\n",
            "training error 0.02183427767425411, test error 0.04989786526563352\n",
            "Loss: 0.0\n",
            "training error 0.021860320017480818, test error 0.04992083688944752\n",
            "Loss: 0.0460372877510995\n",
            "training error 0.021782413640267347, test error 0.049980765794872185\n",
            "Loss: 0.16614043265645861\n",
            "training error 0.02173480051308975, test error 0.049986943351747075\n",
            "Loss: 0.1785208357899526\n",
            "training error 0.02169479899177939, test error 0.049702113613538094\n",
            "Loss: 0.0\n",
            "training error 0.021733661377307933, test error 0.049371362980828254\n",
            "Loss: 0.0\n",
            "training error 0.02169676986279064, test error 0.049144762748764725\n",
            "Loss: 0.0\n",
            "training error 0.021745335895590964, test error 0.04966769813011903\n",
            "Loss: 1.0640714332626366\n",
            "training error 0.021516525944223288, test error 0.048905605639975105\n",
            "Loss: 0.0\n",
            "training error 0.021526816248661283, test error 0.04929440659154473\n",
            "Loss: 0.7950028355273364\n",
            "training error 0.021497778713541662, test error 0.04926396463020525\n",
            "Loss: 0.7327564714528778\n",
            "training error 0.02143681969027069, test error 0.04917344222133525\n",
            "Loss: 0.5476602893579541\n",
            "training error 0.021380433062365516, test error 0.04866117205092267\n",
            "Loss: 0.0\n",
            "training error 0.02147494863650198, test error 0.048752361591732185\n",
            "Loss: 0.1873969264737152\n",
            "training error 0.02131899976163612, test error 0.04841773982592277\n",
            "Loss: 0.0\n",
            "training error 0.021416463372154162, test error 0.048341167205576095\n",
            "Loss: 0.0\n",
            "training error 0.021367649982388572, test error 0.04870020364844523\n",
            "Loss: 0.7427136406166879\n",
            "training error 0.021360316491936957, test error 0.048372939426813734\n",
            "Loss: 0.06572497743491112\n",
            "training error 0.02131097141142253, test error 0.04786628123489816\n",
            "Loss: 0.0\n",
            "training error 0.02120946497358886, test error 0.04837150088933716\n",
            "Loss: 1.055481314622475\n",
            "training error 0.021210625595768307, test error 0.04825143154681244\n",
            "Loss: 0.8046380499546313\n",
            "training error 0.021210315899629295, test error 0.04815338233012434\n",
            "Loss: 0.599798204120483\n",
            "training error 0.021075260352660392, test error 0.04855201082481494\n",
            "Loss: 1.4325942442690254\n",
            "training error 0.021127738321187677, test error 0.04808027703995179\n",
            "Loss: 0.4470700449936249\n",
            "training error 0.0210835345038949, test error 0.04764134518395285\n",
            "Loss: 0.0\n",
            "training error 0.0210109666017145, test error 0.04761259261837974\n",
            "Loss: 0.0\n",
            "training error 0.021012913745031604, test error 0.047982830761495364\n",
            "Loss: 0.777605508868473\n",
            "training error 0.02113728665751142, test error 0.04783296310724069\n",
            "Loss: 0.4628407669946544\n",
            "training error 0.02097630610089728, test error 0.0475353667822119\n",
            "Loss: 0.0\n",
            "training error 0.021077421025457517, test error 0.047315992360252856\n",
            "Loss: 0.0\n",
            "training error 0.02096920162131795, test error 0.04747729077799793\n",
            "Loss: 0.34089619534338755\n",
            "training error 0.020907989582045046, test error 0.04753716140530017\n",
            "Loss: 0.46742979279263963\n",
            "training error 0.02095577696424551, test error 0.04803019495995542\n",
            "Loss: 1.5094317250387457\n",
            "training error 0.020828179241498806, test error 0.04774057708889989\n",
            "Loss: 0.8973387378507169\n",
            "training error 0.02083043984547864, test error 0.047627476499773315\n",
            "Loss: 0.6583062596444922\n",
            "training error 0.020785584286046734, test error 0.04746357408411946\n",
            "Loss: 0.3119066440432139\n",
            "training error 0.02091550988882378, test error 0.0470749554242376\n",
            "Loss: 0.0\n",
            "training error 0.020907649671584486, test error 0.047097598175864015\n",
            "Loss: 0.048099358613007404\n",
            "training error 0.020849210965099316, test error 0.047096244658552264\n",
            "Loss: 0.04522411996530362\n",
            "training error 0.020776603632617477, test error 0.04761434738556573\n",
            "Loss: 1.1458151292277563\n",
            "training error 0.02076754373771219, test error 0.04735179000354894\n",
            "Loss: 0.5880718883672253\n",
            "training error 0.020768856035603155, test error 0.047308369983607525\n",
            "Loss: 0.4958359647213806\n",
            "training error 0.020684423640589873, test error 0.047381539936496\n",
            "Loss: 0.6512688317927839\n",
            "training error 0.020846569097274822, test error 0.04692082283249505\n",
            "Loss: 0.0\n",
            "training error 0.020671677355142106, test error 0.04723617059980286\n",
            "Loss: 0.6720849044646648\n",
            "training error 0.02067106535707271, test error 0.04758087457306675\n",
            "Loss: 1.4067352205822337\n",
            "training error 0.020673730453716854, test error 0.04784947610991684\n",
            "Loss: 1.9791922250320226\n",
            "training error 0.020779175719128504, test error 0.04761745808964013\n",
            "Loss: 1.4847038374242283\n",
            "training error 0.02068780588358927, test error 0.04746263218542133\n",
            "Loss: 1.154731141140708\n",
            "training error 0.020604604942997366, test error 0.047571394526383703\n",
            "Loss: 1.3865308718288283\n",
            "training error 0.02063004830756761, test error 0.047647984431995055\n",
            "Loss: 1.5497631021858416\n",
            "training error 0.02062987003878979, test error 0.047427989758344544\n",
            "Loss: 1.0808994711368314\n",
            "training error 0.02058729681691942, test error 0.04777881866977002\n",
            "Loss: 1.8286035612332885\n",
            "training error 0.020577996376890697, test error 0.04744060153754697\n",
            "Loss: 1.1077783245777795\n",
            "training error 0.02057163040010834, test error 0.047084635865871874\n",
            "Loss: 0.3491265146001954\n",
            "training error 0.020576475830528008, test error 0.0468794653292343\n",
            "Loss: 0.0\n",
            "training error 0.020485362117702723, test error 0.04691019803635765\n",
            "Loss: 0.06555686355957935\n",
            "training error 0.020562935888584995, test error 0.04730932854103294\n",
            "Loss: 0.9169541691222527\n",
            "training error 0.02047673942462244, test error 0.04719474023039715\n",
            "Loss: 0.6725223910910128\n",
            "training error 0.02052229587536195, test error 0.04707258716518172\n",
            "Loss: 0.41195400713538444\n",
            "training error 0.02043812312144092, test error 0.046480318364226836\n",
            "Loss: 0.0\n",
            "training error 0.020433841660605592, test error 0.046297909875711175\n",
            "Loss: 0.0\n",
            "training error 0.02042255108602114, test error 0.046228450671649025\n",
            "Loss: 0.0\n",
            "training error 0.020370744036837408, test error 0.04655497082780215\n",
            "Loss: 0.70631862285917\n",
            "training error 0.020456555441088653, test error 0.04653476610688305\n",
            "Loss: 0.6626123756768632\n",
            "training error 0.020331871386810835, test error 0.046319313564209985\n",
            "Loss: 0.19655188794092116\n",
            "training error 0.02040939108073084, test error 0.04605439990634754\n",
            "Loss: 0.0\n",
            "training error 0.02031419508670703, test error 0.046094375986223686\n",
            "Loss: 0.0868018690015182\n",
            "training error 0.020306626188732736, test error 0.04648893392625198\n",
            "Loss: 0.9435233567000489\n",
            "training error 0.02030024864317974, test error 0.04631429307045437\n",
            "Loss: 0.5643177734056426\n",
            "training error 0.02032980709274448, test error 0.04639291014378712\n",
            "Loss: 0.7350225779251041\n",
            "training error 0.020257211038869457, test error 0.04591894183333741\n",
            "Loss: 0.0\n",
            "training error 0.020326277360717397, test error 0.046123650050809324\n",
            "Loss: 0.4458034294755775\n",
            "training error 0.02027290594704748, test error 0.046170038874146224\n",
            "Loss: 0.546826714169879\n",
            "training error 0.020264386709989417, test error 0.04612154795609099\n",
            "Loss: 0.4412255915847041\n",
            "training error 0.02025222733958183, test error 0.04632448494998433\n",
            "Loss: 0.8831717379700121\n",
            "training error 0.020265869928935802, test error 0.04650034101635073\n",
            "Loss: 1.2661423800302218\n",
            "training error 0.020206922526036224, test error 0.046333432893737946\n",
            "Loss: 0.902658127238487\n",
            "training error 0.020235644322479325, test error 0.046602831977718695\n",
            "Loss: 1.4893421256601647\n",
            "training error 0.020191033713621354, test error 0.046144177340244605\n",
            "Loss: 0.49050674496089464\n",
            "training error 0.02021584263491325, test error 0.04653041521301364\n",
            "Loss: 1.3316364778081624\n",
            "training error 0.020247147047108748, test error 0.046832757484567306\n",
            "Loss: 1.990062520487923\n",
            "training error 0.020138204420396853, test error 0.046229204744845216\n",
            "Loss: 0.6756752205525629\n",
            "training error 0.020272066224931513, test error 0.04603657180216376\n",
            "Loss: 0.2561687271742441\n",
            "training error 0.020089865101342835, test error 0.046376327092086805\n",
            "Loss: 0.9960709905064258\n",
            "training error 0.02020022582821711, test error 0.04595538197973694\n",
            "Loss: 0.07935754820262986\n",
            "training error 0.020178913223223564, test error 0.04629614983066228\n",
            "Loss: 0.8214649167960886\n",
            "training error 0.020231864982407467, test error 0.04617006744884866\n",
            "Loss: 0.5468889427433066\n",
            "training error 0.02014985205041146, test error 0.04627514680827082\n",
            "Loss: 0.7757255736124291\n",
            "training error 0.02013182324775306, test error 0.04606897066770217\n",
            "Loss: 0.326725373832204\n",
            "training error 0.02011553725597603, test error 0.045680797225671366\n",
            "Loss: 0.0\n",
            "training error 0.020109673057878825, test error 0.0459198879950826\n",
            "Loss: 0.5233944763049614\n",
            "training error 0.020093923407669644, test error 0.04589082968960316\n",
            "Loss: 0.4597828336799781\n",
            "training error 0.02008303605059674, test error 0.04592020425582967\n",
            "Loss: 0.5240868038611346\n",
            "training error 0.02008112173096413, test error 0.045924418331631064\n",
            "Loss: 0.5333118525847169\n",
            "training error 0.020146551367292216, test error 0.04605399794255565\n",
            "Loss: 0.816975051990898\n",
            "training error 0.02002658566125174, test error 0.0457894099884439\n",
            "Loss: 0.23776459556072993\n",
            "training error 0.02004968541464159, test error 0.04604781998667238\n",
            "Loss: 0.8034508662093875\n",
            "training error 0.02008976614118268, test error 0.04594645203989014\n",
            "Loss: 0.5815459237858533\n",
            "training error 0.02005730347371617, test error 0.04581975691690588\n",
            "Loss: 0.30419716746192815\n",
            "training error 0.020026317336642976, test error 0.04584393427568622\n",
            "Loss: 0.3571239118462133\n",
            "training error 0.02002648256654463, test error 0.04597205903364128\n",
            "Loss: 0.6376022873047171\n",
            "training error 0.020031349378681982, test error 0.04567721853595728\n",
            "Loss: 0.0\n",
            "training error 0.020027040791532762, test error 0.04587135075304386\n",
            "Loss: 0.42500884096907665\n",
            "training error 0.02001109215195603, test error 0.04566517541698427\n",
            "Loss: 0.0\n",
            "training error 0.020129756361245595, test error 0.04583227413581938\n",
            "Loss: 0.36592155249439706\n",
            "training error 0.0199720451403922, test error 0.045640904057076145\n",
            "Loss: 0.0\n",
            "training error 0.020013466251936736, test error 0.04531282283120316\n",
            "Loss: 0.0\n",
            "training error 0.019930397170343037, test error 0.045450537935100656\n",
            "Loss: 0.3039208226124135\n",
            "training error 0.020029798678909732, test error 0.045471175666267113\n",
            "Loss: 0.34946583587132096\n",
            "training error 0.0199429709150319, test error 0.04553899393779143\n",
            "Loss: 0.49913267913321846\n",
            "training error 0.01992491928102638, test error 0.04581647922104218\n",
            "Loss: 1.1115096309828543\n",
            "training error 0.019974362921198918, test error 0.045640705403896\n",
            "Loss: 0.7235977637373159\n",
            "training error 0.01990533542124348, test error 0.04524843286422443\n",
            "Loss: 0.0\n",
            "training error 0.0200042953664653, test error 0.04507642622956212\n",
            "Loss: 0.0\n",
            "training error 0.01995864945373725, test error 0.04542097197171511\n",
            "Loss: 0.7643590474504469\n",
            "training error 0.01991483447602792, test error 0.04513374559954189\n",
            "Loss: 0.12716041348943552\n",
            "training error 0.019953558955957733, test error 0.04544344638639964\n",
            "Loss: 0.8142175135366303\n",
            "training error 0.019913371330384396, test error 0.04547135303997708\n",
            "Loss: 0.8761271543660243\n",
            "training error 0.019863955288024916, test error 0.04525240599722362\n",
            "Loss: 0.39040310508486886\n",
            "training error 0.01988919331283169, test error 0.04515120209605808\n",
            "Loss: 0.16588685650265056\n",
            "training error 0.01995544438679732, test error 0.045080515117737426\n",
            "Loss: 0.00907101231690799\n",
            "training error 0.019832083618014855, test error 0.04527985382214595\n",
            "Loss: 0.45129485542581005\n",
            "training error 0.019862505779463215, test error 0.045437269398029\n",
            "Loss: 0.80051414597333\n",
            "training error 0.01979275856413506, test error 0.04522663818577039\n",
            "Loss: 0.33323838816166074\n",
            "training error 0.019871555555061905, test error 0.04546925899556273\n",
            "Loss: 0.8714816121402569\n",
            "training error 0.019891789153274993, test error 0.04543864590692556\n",
            "Loss: 0.8035678683104841\n",
            "training error 0.019766604927553912, test error 0.04506549638376058\n",
            "Loss: 0.0\n",
            "training error 0.01979354773373282, test error 0.04495966500919959\n",
            "Loss: 0.0\n",
            "training error 0.01986955427675327, test error 0.04496964411195658\n",
            "Loss: 0.022195678626490967\n",
            "training error 0.019814255089859914, test error 0.044948391208399836\n",
            "Loss: 0.0\n",
            "training error 0.01974119919968652, test error 0.045119945355004624\n",
            "Loss: 0.3816691587678722\n",
            "training error 0.019805913573143805, test error 0.04490974739429459\n",
            "Loss: 0.0\n",
            "training error 0.019807035766891044, test error 0.04474679214359414\n",
            "Loss: 0.0\n",
            "training error 0.019746061085081902, test error 0.04483604416534158\n",
            "Loss: 0.19946015674381368\n",
            "training error 0.01973728970497445, test error 0.04491000171732264\n",
            "Loss: 0.36474027725776903\n",
            "training error 0.019750629381561677, test error 0.0445457458330642\n",
            "Loss: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.0445457458330642\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<topologyNN.HiddenLayer at 0x7f003bf462e0>,\n",
              "  <topologyNN.OutputLayer at 0x7f003bf46ee0>],\n",
              " 1.0,\n",
              " 0.0445457458330642,\n",
              " 0.019750629381561677,\n",
              " 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_vals = []\n",
        "acc_vals = []\n",
        "\n",
        "error_trains = []\n",
        "acc_trains = []\n",
        "\n",
        "models = []\n",
        "\n",
        "for i in range(10):\n",
        "  model, acc_val, error_val, error_train, acc_train = train_test(hyperparams = search_space_def[0][0],\n",
        "           num_inputs = 17, seed = i, activation_output = sigmoid, activation_hidden = sigmoid,\n",
        "           task = 'binary_classification', thr = 0.5, stop_class = 'GL', stop_param = 3, data_train = X_train, data_val = X_test)\n",
        "  \n",
        "  models += [model]\n",
        "\n",
        "  acc_vals += [acc_val]\n",
        "  error_vals += [error_val]\n",
        "  \n",
        "\n",
        "  error_trains += [error_train]\n",
        "  acc_trains += [acc_train]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_TbH-phWfgi_",
        "outputId": "a88ab08d-6b42-46cb-da5d-26b4a0aacb00"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training error 0.12306880616707778, test error 0.2387383345865731\n",
            "training error 0.12039099687398039, test error 0.22973125209139716\n",
            "training error 0.11865304529673648, test error 0.22710820738866735\n",
            "training error 0.11796265002492849, test error 0.2260545807648948\n",
            "training error 0.11789051592107046, test error 0.22497595581184093\n",
            "training error 0.11776791791987747, test error 0.22478784745916677\n",
            "training error 0.11785065967422181, test error 0.22521570559003673\n",
            "training error 0.1176485439009073, test error 0.22351874685517226\n",
            "training error 0.11771286165474337, test error 0.22334061137476993\n",
            "training error 0.1175112318869083, test error 0.222568631347858\n",
            "training error 0.11771252545325891, test error 0.222544510167683\n",
            "training error 0.11747645082275347, test error 0.2223656629950359\n",
            "training error 0.11773020218160153, test error 0.22252534938459473\n",
            "training error 0.11763274963428706, test error 0.22244863521457287\n",
            "training error 0.11750301837259983, test error 0.22262968846980244\n",
            "training error 0.11749006287214966, test error 0.22293558988709344\n",
            "training error 0.11737706266790586, test error 0.22261117100083747\n",
            "training error 0.11762531866984888, test error 0.22381492969353897\n",
            "training error 0.11773472128502047, test error 0.22283596912898906\n",
            "training error 0.1176167782705851, test error 0.22284260414769275\n",
            "training error 0.11747926856028248, test error 0.2220685954663455\n",
            "training error 0.11728802536864635, test error 0.2226838416637367\n",
            "training error 0.11742678875588264, test error 0.2229628016630118\n",
            "training error 0.11780687841504109, test error 0.2236591784939165\n",
            "training error 0.1171861276302724, test error 0.22274780030651822\n",
            "training error 0.1172645806325996, test error 0.22179604491530477\n",
            "training error 0.11726405846462004, test error 0.22166862392193665\n",
            "training error 0.11724200482507505, test error 0.22135130255128355\n",
            "training error 0.11765785745588958, test error 0.2227275058245949\n",
            "training error 0.11706586919644892, test error 0.22202391199511726\n",
            "training error 0.11711720979912767, test error 0.22263966776459035\n",
            "training error 0.11767739306801911, test error 0.22209129004103673\n",
            "training error 0.11753465969227257, test error 0.2229571215994709\n",
            "training error 0.11709045343671938, test error 0.2220264309751664\n",
            "training error 0.11703466907378925, test error 0.22186057332431164\n",
            "training error 0.1174808744835194, test error 0.2218040024590357\n",
            "training error 0.11683446878597253, test error 0.2221564555491525\n",
            "training error 0.11692335365141698, test error 0.2219772587956337\n",
            "training error 0.11705420150529942, test error 0.221903986119522\n",
            "training error 0.11701972236718969, test error 0.2215284996916014\n",
            "training error 0.11689285201984925, test error 0.22232678377499462\n",
            "training error 0.11682896242604068, test error 0.22248057227793275\n",
            "training error 0.11680408324569987, test error 0.22284222718200775\n",
            "training error 0.11680845925190558, test error 0.22278454223533858\n",
            "training error 0.11687157785827432, test error 0.22283591908042236\n",
            "training error 0.11738463044245093, test error 0.2240288828741884\n",
            "training error 0.11701793553778002, test error 0.22159880704105345\n",
            "training error 0.1166821987047539, test error 0.2217828234048131\n",
            "training error 0.11686863943030898, test error 0.222061660535841\n",
            "training error 0.11706434500440861, test error 0.22090360814804183\n",
            "Loss: 0.0\n",
            "training error 0.11687606629206637, test error 0.2213856629528808\n",
            "Loss: 0.21821952519487375\n",
            "training error 0.11678344690942, test error 0.2220092358563066\n",
            "Loss: 0.5005023310999279\n",
            "training error 0.11696128536360013, test error 0.22230298844781826\n",
            "Loss: 0.6334800556261788\n",
            "training error 0.11657650449547109, test error 0.22137674514288178\n",
            "Loss: 0.21418255627716487\n",
            "training error 0.1165627592167239, test error 0.22115027316252214\n",
            "Loss: 0.11166183139708075\n",
            "training error 0.11704583075109881, test error 0.22110518180967398\n",
            "Loss: 0.09124960127271375\n",
            "training error 0.11681815337881132, test error 0.2210461319265417\n",
            "Loss: 0.06451853806044294\n",
            "training error 0.11649493832961758, test error 0.22156117033049938\n",
            "Loss: 0.2976692811721193\n",
            "training error 0.11689553234447493, test error 0.22131690484316008\n",
            "Loss: 0.18709368243603475\n",
            "training error 0.11667672615311286, test error 0.22254612642974136\n",
            "Loss: 0.7435452482961624\n",
            "training error 0.11647604649163004, test error 0.2219201480175015\n",
            "Loss: 0.46017350190967754\n",
            "training error 0.11660982494272448, test error 0.2212654592322829\n",
            "Loss: 0.16380496782044673\n",
            "training error 0.11650060432062388, test error 0.22161928886963225\n",
            "Loss: 0.32397873787139986\n",
            "training error 0.11687152121617209, test error 0.22180898946225364\n",
            "Loss: 0.40985356545424345\n",
            "training error 0.11664842612410771, test error 0.22270826278093467\n",
            "Loss: 0.8169421260350918\n",
            "training error 0.11639021882351068, test error 0.22196096913688526\n",
            "Loss: 0.47865265656268363\n",
            "training error 0.11682169472992564, test error 0.2215339648672462\n",
            "Loss: 0.28535374523259716\n",
            "training error 0.11730502104098721, test error 0.2202049569535808\n",
            "Loss: 0.0\n",
            "training error 0.11661814088602912, test error 0.22074335687980362\n",
            "Loss: 0.24449945799189798\n",
            "training error 0.11641755135927266, test error 0.22023308647353826\n",
            "Loss: 0.012774244661262202\n",
            "training error 0.11667612990019079, test error 0.22042168511038177\n",
            "Loss: 0.0984211072263319\n",
            "training error 0.11644653046269851, test error 0.22074273491625537\n",
            "Loss: 0.24421701042267596\n",
            "training error 0.1163657664627242, test error 0.22033377450993524\n",
            "Loss: 0.05849893578080412\n",
            "training error 0.11639114673144944, test error 0.2212453210013414\n",
            "Loss: 0.4724526015006614\n",
            "training error 0.11652785417433133, test error 0.22050888462653567\n",
            "Loss: 0.13802035937771073\n",
            "training error 0.11624324484583783, test error 0.22159850033820874\n",
            "Loss: 0.632839243905714\n",
            "training error 0.11627417037241103, test error 0.22100257103764778\n",
            "Loss: 0.36221440929466997\n",
            "training error 0.11624380917736596, test error 0.221507010662378\n",
            "Loss: 0.5912917342145274\n",
            "training error 0.11629953489921745, test error 0.22111819510806774\n",
            "Loss: 0.4147218877908587\n",
            "training error 0.11619788660132364, test error 0.22069149046801864\n",
            "Loss: 0.22094575942739336\n",
            "training error 0.1161575702389916, test error 0.22072808760300006\n",
            "Loss: 0.23756533760932452\n",
            "training error 0.11655987063173755, test error 0.22106468667234883\n",
            "Loss: 0.39042250940302115\n",
            "training error 0.11620052029889334, test error 0.22218224296397943\n",
            "Loss: 0.8979298367090882\n",
            "training error 0.11631772691673453, test error 0.22241999915178112\n",
            "Loss: 1.0059002435023556\n",
            "training error 0.11614271951697677, test error 0.22087071962522423\n",
            "Loss: 0.302337731563318\n",
            "training error 0.11597047980066172, test error 0.22122824608226632\n",
            "Loss: 0.46469849854524625\n",
            "training error 0.11605223338591757, test error 0.22154630502939307\n",
            "Loss: 0.6091361858375555\n",
            "training error 0.1161435762704955, test error 0.22117221471395765\n",
            "Loss: 0.43925339999533186\n",
            "training error 0.11599567571413508, test error 0.22134680579073643\n",
            "Loss: 0.518539115991068\n",
            "training error 0.1159451352258485, test error 0.2213109983269722\n",
            "Loss: 0.5022781451847758\n",
            "training error 0.11594193205594698, test error 0.22061793526571769\n",
            "Loss: 0.18754269560967707\n",
            "training error 0.11609391809036436, test error 0.22076515707528785\n",
            "Loss: 0.2543994147348627\n",
            "training error 0.11654571303020116, test error 0.22146031946976527\n",
            "Loss: 0.5700882185177614\n",
            "training error 0.11596343847420976, test error 0.22085175797406548\n",
            "Loss: 0.29372682133628203\n",
            "training error 0.11584162168777373, test error 0.22098464499363357\n",
            "Loss: 0.3540737914528913\n",
            "training error 0.116009825471227, test error 0.22129734650180133\n",
            "Loss: 0.4960785457934991\n",
            "training error 0.11604601616800403, test error 0.22106520094659074\n",
            "Loss: 0.39065605284773763\n",
            "training error 0.1161001773405523, test error 0.22071436305102332\n",
            "Loss: 0.23133271134758715\n",
            "training error 0.11580952912505198, test error 0.22154222986643074\n",
            "Loss: 0.6072855631182872\n",
            "training error 0.11586796422573142, test error 0.2206551822789746\n",
            "Loss: 0.20445739806334018\n",
            "training error 0.115698527439081, test error 0.2209537778099765\n",
            "Loss: 0.3400563124260403\n",
            "training error 0.1157948564385672, test error 0.2208256198723136\n",
            "Loss: 0.2818569242579061\n",
            "training error 0.11588610029677775, test error 0.2209455918395217\n",
            "Loss: 0.3363388800085021\n",
            "training error 0.11588768451052668, test error 0.2202679189843657\n",
            "Loss: 0.028592467515697884\n",
            "training error 0.11585726739169648, test error 0.2207062929512188\n",
            "Loss: 0.227667898385997\n",
            "training error 0.11574432676931463, test error 0.2210151019561807\n",
            "Loss: 0.36790497989138693\n",
            "training error 0.11583465396504501, test error 0.22074023605280432\n",
            "Loss: 0.24308222059521434\n",
            "training error 0.11566930151504172, test error 0.22089973634650995\n",
            "Loss: 0.31551487420675706\n",
            "training error 0.11584371524973056, test error 0.22073286722915508\n",
            "Loss: 0.23973587283303566\n",
            "training error 0.1157732088115469, test error 0.21991253718958664\n",
            "Loss: 0.0\n",
            "training error 0.11559091311738098, test error 0.2198267651084881\n",
            "Loss: 0.0\n",
            "training error 0.11560823709924777, test error 0.2197412665586664\n",
            "Loss: 0.0\n",
            "training error 0.11567106615464377, test error 0.21953666067774097\n",
            "Loss: 0.0\n",
            "training error 0.11578442023573592, test error 0.22042013561939575\n",
            "Loss: 0.40242706567885644\n",
            "training error 0.11562624609220461, test error 0.22071139210315713\n",
            "Loss: 0.5350957884617591\n",
            "training error 0.11544757205758512, test error 0.22059885750028788\n",
            "Loss: 0.4838357380802627\n",
            "training error 0.11571807411071117, test error 0.22020341105950444\n",
            "Loss: 0.3037079910503948\n",
            "training error 0.11562392122326001, test error 0.21980178730342778\n",
            "Loss: 0.12076644732972319\n",
            "training error 0.11552330975809316, test error 0.22000798876950778\n",
            "Loss: 0.2146922023464004\n",
            "training error 0.11559556584821995, test error 0.2198493928896917\n",
            "Loss: 0.14245101979108998\n",
            "training error 0.11559620001811272, test error 0.219876655085408\n",
            "Loss: 0.1548690804612729\n",
            "training error 0.11542784897715617, test error 0.22019439486580936\n",
            "Loss: 0.29960107165603045\n",
            "training error 0.11549185280476318, test error 0.21981138184710772\n",
            "Loss: 0.12513680791110815\n",
            "training error 0.11538078230514502, test error 0.22006019997352752\n",
            "Loss: 0.23847465574555748\n",
            "training error 0.11554776289027331, test error 0.21982152762260687\n",
            "Loss: 0.12975825722523204\n",
            "training error 0.11541536145556995, test error 0.21980648053271998\n",
            "Loss: 0.122904235741772\n",
            "training error 0.11541325582723765, test error 0.2198616885664086\n",
            "Loss: 0.148051759402823\n",
            "training error 0.11533600601612243, test error 0.2197985954386383\n",
            "Loss: 0.11931253763663996\n",
            "training error 0.11533115621372901, test error 0.22020847477977262\n",
            "Loss: 0.3060145398757763\n",
            "training error 0.11576303293741147, test error 0.2193731068618008\n",
            "Loss: 0.0\n",
            "training error 0.1153000125377369, test error 0.21944591964033133\n",
            "Loss: 0.03319129658696518\n",
            "training error 0.11533600249990761, test error 0.21993537643562933\n",
            "Loss: 0.2563074306928259\n",
            "training error 0.11531194536986324, test error 0.22029723672601972\n",
            "Loss: 0.4212594138993886\n",
            "training error 0.11544819241400793, test error 0.21961477193994752\n",
            "Loss: 0.11016167004416211\n",
            "training error 0.11519632188418828, test error 0.2196633437850528\n",
            "Loss: 0.13230287312968603\n",
            "training error 0.1152171433118722, test error 0.22014456448522723\n",
            "Loss: 0.35166462948095223\n",
            "training error 0.1152145315115155, test error 0.21962241901801532\n",
            "Loss: 0.11364754767846375\n",
            "training error 0.11516531288609491, test error 0.21961962967539178\n",
            "Loss: 0.1123760414927677\n",
            "training error 0.11528193223956028, test error 0.22000791601501946\n",
            "Loss: 0.28937419098438166\n",
            "training error 0.11517604983395476, test error 0.21940141892187393\n",
            "Loss: 0.012905893743364594\n",
            "training error 0.1151923962685018, test error 0.21947193429835757\n",
            "Loss: 0.04504993249652145\n",
            "training error 0.11535386752304204, test error 0.21976441422031828\n",
            "Loss: 0.17837526400352743\n",
            "training error 0.11515871721689071, test error 0.21978401932808345\n",
            "Loss: 0.18731214238649763\n",
            "training error 0.11561904750981816, test error 0.21924178242217912\n",
            "Loss: 0.0\n",
            "training error 0.11504885081803129, test error 0.2196921969513997\n",
            "Loss: 0.20544192089864133\n",
            "training error 0.11511036054912692, test error 0.22009361697735538\n",
            "Loss: 0.3885365945146102\n",
            "training error 0.11510623215352352, test error 0.22028973249198514\n",
            "Loss: 0.4779883005092689\n",
            "training error 0.1149950338273716, test error 0.22011878840727697\n",
            "Loss: 0.40001772262965307\n",
            "training error 0.11510484009977116, test error 0.22016479338120604\n",
            "Loss: 0.4210013934522472\n",
            "training error 0.11528144285521014, test error 0.21984743688512123\n",
            "Loss: 0.2762495616715377\n",
            "training error 0.11522594762050842, test error 0.2207723556834755\n",
            "Loss: 0.6981211539089927\n",
            "training error 0.11544009255098961, test error 0.22093098587350896\n",
            "Loss: 0.7704751497034756\n",
            "training error 0.11492724281070783, test error 0.22032263105155012\n",
            "Loss: 0.4929939071967926\n",
            "training error 0.11507447170653792, test error 0.22072657724252012\n",
            "Loss: 0.6772408087258874\n",
            "training error 0.1151117503222246, test error 0.22070412590357272\n",
            "Loss: 0.6670003615358633\n",
            "training error 0.11508138240541006, test error 0.2203072010217864\n",
            "Loss: 0.48595600155980634\n",
            "training error 0.11503409235011902, test error 0.22013300560348192\n",
            "Loss: 0.40650243373163697\n",
            "training error 0.11504362090185039, test error 0.2198032328850784\n",
            "Loss: 0.25608734644297915\n",
            "training error 0.11491563653093864, test error 0.21965535064431765\n",
            "Loss: 0.18863567772959833\n",
            "training error 0.11488165003891301, test error 0.22012601234063858\n",
            "Loss: 0.40331268460349623\n",
            "training error 0.11500999203613402, test error 0.21985842525825336\n",
            "Loss: 0.2812615502672866\n",
            "training error 0.11485644542756938, test error 0.2197837370630957\n",
            "Loss: 0.24719496207752378\n",
            "training error 0.11509642279289291, test error 0.2201522825395884\n",
            "Loss: 0.41529498043215707\n",
            "training error 0.11487614501622852, test error 0.22008019111536103\n",
            "Loss: 0.38241282474498206\n",
            "training error 0.1148479875554752, test error 0.21972445986723307\n",
            "Loss: 0.22015759939613133\n",
            "training error 0.11485639271946467, test error 0.21992304519039219\n",
            "Loss: 0.3107358281284167\n",
            "training error 0.11478699166529245, test error 0.22008178221539795\n",
            "Loss: 0.38313855321669976\n",
            "training error 0.11499357535423824, test error 0.21997671846999525\n",
            "Loss: 0.3352171468853138\n",
            "training error 0.11478799539627621, test error 0.21995843260238745\n",
            "Loss: 0.32687664380885995\n",
            "training error 0.11472869193518007, test error 0.21971232620779813\n",
            "Loss: 0.21462322574667958\n",
            "training error 0.1147843398275082, test error 0.21967194834624715\n",
            "Loss: 0.19620617900273363\n",
            "training error 0.11469202185412566, test error 0.21978002834199736\n",
            "Loss: 0.245503349713605\n",
            "training error 0.11478241875767078, test error 0.21973906793713066\n",
            "Loss: 0.22682059480521044\n",
            "training error 0.11518376431413213, test error 0.21985176417107033\n",
            "Loss: 0.2782233122501365\n",
            "training error 0.11471414859277154, test error 0.21970450431068966\n",
            "Loss: 0.21105552208087186\n",
            "training error 0.11476310161581388, test error 0.21989909543684194\n",
            "Loss: 0.29981192790937694\n",
            "training error 0.11488182680350278, test error 0.21920859440402948\n",
            "Loss: 0.0\n",
            "training error 0.1146771265368612, test error 0.21906722442662402\n",
            "Loss: 0.0\n",
            "training error 0.11504451979828959, test error 0.21922302355609485\n",
            "Loss: 0.07111932416117295\n",
            "training error 0.11478341493706302, test error 0.21959158440601828\n",
            "Loss: 0.2393603063017391\n",
            "training error 0.1146399409749233, test error 0.21943574698655943\n",
            "Loss: 0.16822350349303683\n",
            "training error 0.11472117346115603, test error 0.2191822587331039\n",
            "Loss: 0.05251096177485426\n",
            "training error 0.11462895044557671, test error 0.21940376163811068\n",
            "Loss: 0.15362280339630274\n",
            "training error 0.11467829193446222, test error 0.21905973002758114\n",
            "Loss: 0.0\n",
            "training error 0.1146074898498151, test error 0.21915568291600868\n",
            "Loss: 0.04380215771080387\n",
            "training error 0.11459926615478178, test error 0.2189959666089002\n",
            "Loss: 0.0\n",
            "training error 0.11464463834784881, test error 0.21912298324670992\n",
            "Loss: 0.057999532948738164\n",
            "training error 0.11453850536633535, test error 0.21922118851968775\n",
            "Loss: 0.10284294924471915\n",
            "training error 0.11460456148702697, test error 0.21888475277944108\n",
            "Loss: 0.0\n",
            "training error 0.11458137114511303, test error 0.2187461657244941\n",
            "Loss: 0.0\n",
            "training error 0.11460393303376505, test error 0.21854251454783655\n",
            "Loss: 0.0\n",
            "training error 0.11450115864261777, test error 0.21864757597529538\n",
            "Loss: 0.04807367924553052\n",
            "training error 0.11449101761881351, test error 0.21880800513172988\n",
            "Loss: 0.1214823506733298\n",
            "training error 0.11445493906258983, test error 0.21902773467439376\n",
            "Loss: 0.22202550728454007\n",
            "training error 0.114526002392389, test error 0.219222739808615\n",
            "Loss: 0.31125534644178554\n",
            "training error 0.11449907966459248, test error 0.2195011779150995\n",
            "Loss: 0.43866218399033485\n",
            "training error 0.11473119903870561, test error 0.2194583738466769\n",
            "Loss: 0.4190760322929643\n",
            "training error 0.11448018340275991, test error 0.21951859968992604\n",
            "Loss: 0.4466339852037482\n",
            "training error 0.11442666237839957, test error 0.21933395123553254\n",
            "Loss: 0.36214312319662323\n",
            "training error 0.11440380953806718, test error 0.21940852225092125\n",
            "Loss: 0.39626509508983165\n",
            "training error 0.11444756460772854, test error 0.21937503964098845\n",
            "Loss: 0.3809442272019181\n",
            "training error 0.11436746383989119, test error 0.21924431821229945\n",
            "Loss: 0.32112912488213574\n",
            "training error 0.11444338095029644, test error 0.21934276498122396\n",
            "Loss: 0.3661760893724164\n",
            "training error 0.11441937833736603, test error 0.21921464487844883\n",
            "Loss: 0.3075512936249192\n",
            "training error 0.11430091392334282, test error 0.21904090261824177\n",
            "Loss: 0.2280508538287762\n",
            "training error 0.11449825108254488, test error 0.21868758583769302\n",
            "Loss: 0.06638126689291202\n",
            "training error 0.11448039922688566, test error 0.2189725310695708\n",
            "Loss: 0.1967656145185126\n",
            "training error 0.11434972216773563, test error 0.2189935197065728\n",
            "Loss: 0.20636952936565756\n",
            "training error 0.11436887017769086, test error 0.21890118400590555\n",
            "Loss: 0.16411884836737833\n",
            "training error 0.11428491726282493, test error 0.21895553148603783\n",
            "Loss: 0.18898699827620824\n",
            "training error 0.1142674232348387, test error 0.2192177396742285\n",
            "Loss: 0.3089674005943399\n",
            "training error 0.11430106492954933, test error 0.2192823344713013\n",
            "Loss: 0.3385244857255554\n",
            "training error 0.11454387981722043, test error 0.21869456215729954\n",
            "Loss: 0.06957346938996078\n",
            "training error 0.1147092419928407, test error 0.21867087877694694\n",
            "Loss: 0.058736502312140004\n",
            "training error 0.11424586068222801, test error 0.2189742408275771\n",
            "Loss: 0.1975479602372987\n",
            "training error 0.1145529428725359, test error 0.21861106250039913\n",
            "Loss: 0.03136595765103056\n",
            "training error 0.11424364972422757, test error 0.21904247453111342\n",
            "Loss: 0.22877012480215786\n",
            "training error 0.11419079865266239, test error 0.21889397589656\n",
            "Loss: 0.16082058424680135\n",
            "training error 0.11414320751201937, test error 0.21874613925389305\n",
            "Loss: 0.09317395586749821\n",
            "training error 0.11422860338375368, test error 0.2186692981923412\n",
            "Loss: 0.05801326335379553\n",
            "training error 0.11416549647466179, test error 0.2189247867668507\n",
            "Loss: 0.17491892586898317\n",
            "training error 0.11417713657801842, test error 0.21915155691947827\n",
            "Loss: 0.2786837027577205\n",
            "training error 0.11426537768919233, test error 0.21875798382017192\n",
            "Loss: 0.0985937554444094\n",
            "training error 0.11434231847787757, test error 0.21860937695224353\n",
            "Loss: 0.030594689799978703\n",
            "training error 0.11414489991465661, test error 0.21892121194831077\n",
            "Loss: 0.173283171586891\n",
            "training error 0.11412400720151059, test error 0.2188120455892823\n",
            "Loss: 0.12333117059781795\n",
            "training error 0.11419932555521975, test error 0.21880204800305147\n",
            "Loss: 0.11875650637218627\n",
            "training error 0.11412302889980745, test error 0.2188191136215743\n",
            "Loss: 0.1265653386985255\n",
            "training error 0.11424473538864013, test error 0.21848816483738698\n",
            "Loss: 0.0\n",
            "training error 0.11403175535469876, test error 0.21850534521058637\n",
            "Loss: 0.00786329694890675\n",
            "training error 0.11409700731467119, test error 0.21839577369759847\n",
            "Loss: 0.0\n",
            "training error 0.11404193386387282, test error 0.21881818306877643\n",
            "Loss: 0.19341462704440815\n",
            "training error 0.11404709017080954, test error 0.21891943682094134\n",
            "Loss: 0.23977713234870635\n",
            "training error 0.1142542719538208, test error 0.21873839431610945\n",
            "Loss: 0.15688060840655105\n",
            "training error 0.11421407616109616, test error 0.219023447566618\n",
            "Loss: 0.2874020217482176\n",
            "training error 0.11404442204904704, test error 0.21897224845414504\n",
            "Loss: 0.263958751026383\n",
            "training error 0.1140733179291896, test error 0.21936440938402027\n",
            "Loss: 0.4435230911395971\n",
            "training error 0.1143099941899862, test error 0.21952084392450666\n",
            "Loss: 0.5151520140980415\n",
            "training error 0.1143198713478115, test error 0.21933701913921558\n",
            "Loss: 0.43098152756400054\n",
            "training error 0.11401554072895276, test error 0.21914659090313326\n",
            "Loss: 0.34378742446472543\n",
            "training error 0.11408123238544692, test error 0.2187259966388491\n",
            "Loss: 0.15120390640337433\n",
            "training error 0.1139875115511263, test error 0.21835232896888576\n",
            "Loss: 0.0\n",
            "training error 0.11392194179984981, test error 0.21841286830490475\n",
            "Loss: 0.027725527959732155\n",
            "training error 0.11394276791593355, test error 0.21844750648886377\n",
            "Loss: 0.04358896487499653\n",
            "training error 0.11385299289898786, test error 0.21865109329211538\n",
            "Loss: 0.1368267170038795\n",
            "training error 0.11390249844536397, test error 0.2185310554991963\n",
            "Loss: 0.08185235813811254\n",
            "training error 0.11390516744943051, test error 0.21870663644847244\n",
            "Loss: 0.16226411747464198\n",
            "training error 0.11384518425899828, test error 0.21872708224106963\n",
            "Loss: 0.1716277879670658\n",
            "training error 0.11381670193156543, test error 0.21874493975473192\n",
            "Loss: 0.17980609032208772\n",
            "training error 0.11382476281311003, test error 0.21890117234017575\n",
            "Loss: 0.251356774567868\n",
            "training error 0.11389705933092042, test error 0.21880726110455734\n",
            "Loss: 0.20834773680677987\n",
            "training error 0.113860242207047, test error 0.21844689945722037\n",
            "Loss: 0.0433109593019676\n",
            "training error 0.11378133814360314, test error 0.21862010474775445\n",
            "Loss: 0.12263472532361153\n",
            "training error 0.11381302263597884, test error 0.2184341464389357\n",
            "Loss: 0.037470390371519\n",
            "training error 0.11394406639178828, test error 0.2182821748920265\n",
            "Loss: 0.0\n",
            "training error 0.11376440571126412, test error 0.21833810309875046\n",
            "Loss: 0.02562197611950534\n",
            "training error 0.11378539179550094, test error 0.21835269928827805\n",
            "Loss: 0.032308820583470954\n",
            "training error 0.11379747128207252, test error 0.21815138401046016\n",
            "Loss: 0.0\n",
            "training error 0.11372600834822921, test error 0.21813591738931737\n",
            "Loss: 0.0\n",
            "training error 0.11374998755830758, test error 0.21791401480949568\n",
            "Loss: 0.0\n",
            "training error 0.11378828479910402, test error 0.21796995547490153\n",
            "Loss: 0.02567098103110066\n",
            "training error 0.11372655123351419, test error 0.21795122284575769\n",
            "Loss: 0.017074641249914535\n",
            "training error 0.11367985454957608, test error 0.21802252487488485\n",
            "Loss: 0.049794899829658235\n",
            "training error 0.11369980409586261, test error 0.2180662890541368\n",
            "Loss: 0.06987813279206723\n",
            "training error 0.1136975161274313, test error 0.21817527690153007\n",
            "Loss: 0.11989228515787431\n",
            "training error 0.11397496190370723, test error 0.2179904071676802\n",
            "Loss: 0.0350561932656257\n",
            "training error 0.11365817712909705, test error 0.21790656685037726\n",
            "Loss: 0.0\n",
            "training error 0.11371586094912477, test error 0.217841150189578\n",
            "Loss: 0.0\n",
            "training error 0.11376081697311229, test error 0.21794983634847395\n",
            "Loss: 0.04989239122239475\n",
            "training error 0.11372796130430764, test error 0.21804807739771528\n",
            "Loss: 0.09498995389860543\n",
            "training error 0.11359770010396368, test error 0.2179411584733441\n",
            "Loss: 0.04590881184711737\n",
            "training error 0.11371372096785316, test error 0.2181332743592977\n",
            "Loss: 0.13409962693708977\n",
            "training error 0.11365863254937765, test error 0.2177999138359581\n",
            "Loss: 0.0\n",
            "training error 0.11363090440682656, test error 0.2178353471303267\n",
            "Loss: 0.01626873663287398\n",
            "training error 0.11368149267224908, test error 0.21767263668407194\n",
            "Loss: 0.0\n",
            "training error 0.11372524545784997, test error 0.217918473574844\n",
            "Loss: 0.11293881239140546\n",
            "training error 0.11351099911406473, test error 0.2179772583546769\n",
            "Loss: 0.13994486180965993\n",
            "training error 0.11356903676502893, test error 0.21788326721289264\n",
            "Loss: 0.09676481712601603\n",
            "training error 0.11364311931104067, test error 0.2180383487424559\n",
            "Loss: 0.16801012013041294\n",
            "training error 0.11351471464761202, test error 0.2178577879273283\n",
            "Loss: 0.0850594939616034\n",
            "training error 0.11351825189933708, test error 0.21790484407368246\n",
            "Loss: 0.10667734500204862\n",
            "training error 0.11347181837834766, test error 0.2179888716527155\n",
            "Loss: 0.14528007445535618\n",
            "training error 0.11350597764197967, test error 0.217704494300538\n",
            "Loss: 0.01463556327123694\n",
            "training error 0.11346807384398536, test error 0.2180055818122305\n",
            "Loss: 0.15295681314404508\n",
            "training error 0.1134022473768097, test error 0.21790836333572494\n",
            "Loss: 0.108294113235341\n",
            "training error 0.11351075928832272, test error 0.21787735565206673\n",
            "Loss: 0.09404901374532315\n",
            "training error 0.1133524929711368, test error 0.21795699405931773\n",
            "Loss: 0.1306353336724131\n",
            "training error 0.1134509628207241, test error 0.2181071472510911\n",
            "Loss: 0.19961653133728774\n",
            "training error 0.11333448704655735, test error 0.21810869309492964\n",
            "Loss: 0.20032670045275758\n",
            "training error 0.11334556751392144, test error 0.2179359412303347\n",
            "Loss: 0.12096354887496386\n",
            "training error 0.11335278498429756, test error 0.21796124607941858\n",
            "Loss: 0.13258873496604373\n",
            "training error 0.11343955894916759, test error 0.21813657205749082\n",
            "Loss: 0.21313444835615591\n",
            "training error 0.1133477350696934, test error 0.2179090927162458\n",
            "Loss: 0.10862919463647813\n",
            "training error 0.11331376915329368, test error 0.2181111871263153\n",
            "Loss: 0.2014724721141059\n",
            "training error 0.11333477100527858, test error 0.217890102145044\n",
            "Loss: 0.09990482234460973\n",
            "training error 0.11345352879065228, test error 0.21776798449629664\n",
            "Loss: 0.04380330650521902\n",
            "training error 0.11326431736569595, test error 0.2178590477269844\n",
            "Loss: 0.08563825281493465\n",
            "training error 0.11322890009898863, test error 0.2177465334956557\n",
            "Loss: 0.033948599470035035\n",
            "training error 0.11346126365278102, test error 0.2174920027778346\n",
            "Loss: 0.0\n",
            "training error 0.11324187403763963, test error 0.21757436669356825\n",
            "Loss: 0.037869859434680464\n",
            "training error 0.11327843494177373, test error 0.21757479435559002\n",
            "Loss: 0.03806649288158326\n",
            "training error 0.11325904742253007, test error 0.21755722927573115\n",
            "Loss: 0.02999029714356727\n",
            "training error 0.1133963095683881, test error 0.21777839250073866\n",
            "Loss: 0.1316782774751557\n",
            "training error 0.11332729286997889, test error 0.21809466193563817\n",
            "Loss: 0.27709485871036943\n",
            "training error 0.11321690641160392, test error 0.21780454211824513\n",
            "Loss: 0.14370153220291115\n",
            "training error 0.11320304565135142, test error 0.217732407119255\n",
            "Loss: 0.11053479592351145\n",
            "training error 0.11316095532227216, test error 0.21759974699764212\n",
            "Loss: 0.049539393831232736\n",
            "training error 0.11322710950406321, test error 0.21751400156021453\n",
            "Loss: 0.010114754611190158\n",
            "training error 0.11314955482141269, test error 0.2177581384869397\n",
            "Loss: 0.12236574481176987\n",
            "training error 0.11329618145724658, test error 0.2175513343412123\n",
            "Loss: 0.0272798827634535\n",
            "training error 0.1132610621114495, test error 0.21738462233198272\n",
            "Loss: 0.0\n",
            "training error 0.11311849205066964, test error 0.21713805304893302\n",
            "Loss: 0.0\n",
            "training error 0.11309806858440112, test error 0.21735389113097192\n",
            "Loss: 0.09940131589476486\n",
            "training error 0.11318899585735312, test error 0.2171142941773804\n",
            "Loss: 0.0\n",
            "training error 0.11309530918335799, test error 0.21720189553601071\n",
            "Loss: 0.0403480383280197\n",
            "training error 0.11312035782230441, test error 0.21749125155512078\n",
            "Loss: 0.17362163056495739\n",
            "training error 0.11319454145698551, test error 0.21746646544446435\n",
            "Loss: 0.16220547266050378\n",
            "training error 0.11301752388703219, test error 0.21748070775602948\n",
            "Loss: 0.16876529481275604\n",
            "training error 0.11306146707916571, test error 0.21758815652662564\n",
            "Loss: 0.21825479111849955\n",
            "training error 0.11302152960725903, test error 0.21744550011616035\n",
            "Loss: 0.15254911706059637\n",
            "training error 0.11301863590807233, test error 0.21750713776231054\n",
            "Loss: 0.1809386095091403\n",
            "training error 0.11307084117658005, test error 0.21763946410427887\n",
            "Loss: 0.24188638932700623\n",
            "training error 0.11298059803931149, test error 0.21739369472084075\n",
            "Loss: 0.12868823055569578\n",
            "training error 0.11294401192337149, test error 0.21744022868333057\n",
            "Loss: 0.1501211641477207\n",
            "training error 0.11288913162548445, test error 0.21733528500041463\n",
            "Loss: 0.10178547841428465\n",
            "training error 0.11286000445055325, test error 0.2174011588783778\n",
            "Loss: 0.13212612374706723\n",
            "training error 0.11281734068731747, test error 0.2173744519917654\n",
            "Loss: 0.11982528159681927\n",
            "training error 0.1128379770627623, test error 0.2171799915234147\n",
            "Loss: 0.030259337038684997\n",
            "training error 0.11282815658489495, test error 0.21743109056356\n",
            "Loss: 0.14591226587816752\n",
            "training error 0.11281497429321147, test error 0.21748141303729202\n",
            "Loss: 0.1690901381240506\n",
            "training error 0.1128299477814003, test error 0.2176607740343735\n",
            "Loss: 0.2517014639978665\n",
            "training error 0.11283793793568621, test error 0.2172869422395539\n",
            "Loss: 0.0795194359853868\n",
            "training error 0.11271978479874285, test error 0.21727275053446884\n",
            "Loss: 0.07298292251498584\n",
            "training error 0.11285353533011973, test error 0.21716168877411948\n",
            "Loss: 0.02182933045411506\n",
            "training error 0.11278339139046985, test error 0.21750808845664746\n",
            "Loss: 0.18137648686793462\n",
            "training error 0.11274072391540135, test error 0.21721524801110226\n",
            "Loss: 0.046498013456175435\n",
            "training error 0.11269407973854019, test error 0.2171286102372318\n",
            "Loss: 0.006593789646891501\n",
            "training error 0.11267792097390258, test error 0.21688421376332254\n",
            "Loss: 0.0\n",
            "training error 0.11271597509969078, test error 0.21699058503054883\n",
            "Loss: 0.04904518654473833\n",
            "training error 0.11272350360196483, test error 0.2168273634479773\n",
            "Loss: 0.0\n",
            "training error 0.11260609223563757, test error 0.21668268567789867\n",
            "Loss: 0.0\n",
            "training error 0.11265432728358377, test error 0.21666146441349335\n",
            "Loss: 0.0\n",
            "training error 0.11260572759331104, test error 0.2167382989433421\n",
            "Loss: 0.035462942178821066\n",
            "training error 0.11257812074555987, test error 0.2168276940212109\n",
            "Loss: 0.07672319956275597\n",
            "training error 0.11257421988142319, test error 0.21663856664780887\n",
            "Loss: 0.0\n",
            "training error 0.11248731807844213, test error 0.21652202404309928\n",
            "Loss: 0.0\n",
            "training error 0.11257717356270887, test error 0.21637082692647044\n",
            "Loss: 0.0\n",
            "training error 0.11251439193187987, test error 0.21649761995257008\n",
            "Loss: 0.05859987129537281\n",
            "training error 0.11245514341390281, test error 0.21668399229533533\n",
            "Loss: 0.1447354864393624\n",
            "training error 0.11246087115253772, test error 0.21663312428012085\n",
            "Loss: 0.12122584055176411\n",
            "training error 0.11248351073817013, test error 0.21664374673245776\n",
            "Loss: 0.12613521418951557\n",
            "training error 0.11243695340628693, test error 0.21687236514208974\n",
            "Loss: 0.23179567354048025\n",
            "training error 0.1124222373260929, test error 0.21689324409797733\n",
            "Loss: 0.2414452904431652\n",
            "training error 0.11236394838048153, test error 0.21689655641761346\n",
            "Loss: 0.24297614360075936\n",
            "training error 0.11244817094730401, test error 0.21683391657241102\n",
            "Loss: 0.21402591676462634\n",
            "training error 0.1123835700158924, test error 0.21657494982218886\n",
            "Loss: 0.09433937958178706\n",
            "training error 0.11231507713904204, test error 0.21638391660081288\n",
            "Loss: 0.006049648433825716\n",
            "training error 0.11230968541455738, test error 0.21629202535848038\n",
            "Loss: 0.0\n",
            "training error 0.11230801592026358, test error 0.21622259053165133\n",
            "Loss: 0.0\n",
            "training error 0.11225874106189491, test error 0.21610346517044876\n",
            "Loss: 0.0\n",
            "training error 0.1122011077742525, test error 0.21602599084948856\n",
            "Loss: 0.0\n",
            "training error 0.11219316617740398, test error 0.21610336307433398\n",
            "Loss: 0.03581616477774663\n",
            "training error 0.11212425388341578, test error 0.21624379736028146\n",
            "Loss: 0.10082421561239396\n",
            "training error 0.11210947022243221, test error 0.21612930375296832\n",
            "Loss: 0.047824293305409604\n",
            "training error 0.11209494713955905, test error 0.21620748830953418\n",
            "Loss: 0.08401649233589215\n",
            "training error 0.11215638127059883, test error 0.2162432063860878\n",
            "Loss: 0.10055064936633773\n",
            "training error 0.11207531578922138, test error 0.21628714008422137\n",
            "Loss: 0.12088787729007677\n",
            "training error 0.11209907573510988, test error 0.21595764563741615\n",
            "Loss: 0.0\n",
            "training error 0.11220971071055812, test error 0.21561546634735307\n",
            "Loss: 0.0\n",
            "training error 0.11198972110268432, test error 0.21587812961591463\n",
            "Loss: 0.12182023535287634\n",
            "training error 0.11196483970626149, test error 0.21576128982599688\n",
            "Loss: 0.06763127020252835\n",
            "training error 0.11195831251784161, test error 0.21576877326334512\n",
            "Loss: 0.07110200329742966\n",
            "training error 0.11188341110688692, test error 0.21558077142211451\n",
            "Loss: 0.0\n",
            "training error 0.11213124909101681, test error 0.21585436242814632\n",
            "Loss: 0.12690881669408238\n",
            "training error 0.11216036787769666, test error 0.21561017957530848\n",
            "Loss: 0.01364136188954923\n",
            "training error 0.11199793026102865, test error 0.21543459468407924\n",
            "Loss: 0.0\n",
            "training error 0.11188147273239747, test error 0.21535939824253014\n",
            "Loss: 0.0\n",
            "training error 0.11178916269784606, test error 0.2152710152644686\n",
            "Loss: 0.0\n",
            "training error 0.11172489352701565, test error 0.21537714738631367\n",
            "Loss: 0.04930163111587227\n",
            "training error 0.11170698365895544, test error 0.21536610347564294\n",
            "Loss: 0.04417139532579828\n",
            "training error 0.11168203254968981, test error 0.21527814579080523\n",
            "Loss: 0.003312348542539034\n",
            "training error 0.11157021296521773, test error 0.21525746367016824\n",
            "Loss: 0.0\n",
            "training error 0.11158332723366678, test error 0.21518145153170606\n",
            "Loss: 0.0\n",
            "training error 0.11167964217510662, test error 0.21507324137516928\n",
            "Loss: 0.0\n",
            "training error 0.11153476656752007, test error 0.21523563826889136\n",
            "Loss: 0.07550771666606781\n",
            "training error 0.11145514694812907, test error 0.21508225395973832\n",
            "Loss: 0.0041904722834829045\n",
            "training error 0.1114375291649345, test error 0.21496398275231787\n",
            "Loss: 0.0\n",
            "training error 0.1114036468561782, test error 0.2147684236444008\n",
            "Loss: 0.0\n",
            "training error 0.11132918356744816, test error 0.21480990410017545\n",
            "Loss: 0.019314038381801346\n",
            "training error 0.11133518457325689, test error 0.21489532310800283\n",
            "Loss: 0.059086648515949136\n",
            "training error 0.11126596803145337, test error 0.21491819086021455\n",
            "Loss: 0.06973428089305234\n",
            "training error 0.111216535935314, test error 0.2149798643475327\n",
            "Loss: 0.09845055411030756\n",
            "training error 0.11128768440602566, test error 0.21514353154785212\n",
            "Loss: 0.17465691514895187\n",
            "training error 0.1111281731329919, test error 0.2148670683806273\n",
            "Loss: 0.04593074463770108\n",
            "training error 0.11112197934976265, test error 0.21459278136720897\n",
            "Loss: 0.0\n",
            "training error 0.11103468039627232, test error 0.2144311780029814\n",
            "Loss: 0.0\n",
            "training error 0.11097139007189052, test error 0.21442034569907198\n",
            "Loss: 0.0\n",
            "training error 0.11095879444480593, test error 0.21441292410358204\n",
            "Loss: 0.0\n",
            "training error 0.11087365563648609, test error 0.21436430580242535\n",
            "Loss: 0.0\n",
            "training error 0.11092199524538192, test error 0.21440824079362963\n",
            "Loss: 0.020495478965032454\n",
            "training error 0.11090972718191397, test error 0.21408328745927388\n",
            "Loss: 0.0\n",
            "training error 0.1107450224811355, test error 0.21401162098513044\n",
            "Loss: 0.0\n",
            "training error 0.11075595503268135, test error 0.2143307939275424\n",
            "Loss: 0.14913813602399628\n",
            "training error 0.11075858525262243, test error 0.21419981724826911\n",
            "Loss: 0.08793740371311198\n",
            "training error 0.11062180149402691, test error 0.21400314916854174\n",
            "Loss: 0.0\n",
            "training error 0.11056114997747314, test error 0.21398873388680292\n",
            "Loss: 0.0\n",
            "training error 0.11044573253501867, test error 0.21365645568455446\n",
            "Loss: 0.0\n",
            "training error 0.11037497014664316, test error 0.21367625216991204\n",
            "Loss: 0.009265568547478509\n",
            "training error 0.11036786402906867, test error 0.21356563568051745\n",
            "Loss: 0.0\n",
            "training error 0.11025276096172272, test error 0.2133196327103644\n",
            "Loss: 0.0\n",
            "training error 0.11018689170646682, test error 0.21321002653476442\n",
            "Loss: 0.0\n",
            "training error 0.11007589792942185, test error 0.21313783839546013\n",
            "Loss: 0.0\n",
            "training error 0.11017972684150393, test error 0.2132042032175287\n",
            "Loss: 0.031137043787321517\n",
            "training error 0.11003107482493116, test error 0.21278768128381365\n",
            "Loss: 0.0\n",
            "training error 0.10990719693245309, test error 0.21263178113557063\n",
            "Loss: 0.0\n",
            "training error 0.10981850518653763, test error 0.2124964985896028\n",
            "Loss: 0.0\n",
            "training error 0.10979027638867676, test error 0.2123759948429812\n",
            "Loss: 0.0\n",
            "training error 0.10977788175036844, test error 0.2121429044233047\n",
            "Loss: 0.0\n",
            "training error 0.10974444308913707, test error 0.21231220044378474\n",
            "Loss: 0.07980282015100926\n",
            "training error 0.10972540716948956, test error 0.21214283391822059\n",
            "Loss: 0.0\n",
            "training error 0.10954299733406117, test error 0.21168403397080263\n",
            "Loss: 0.0\n",
            "training error 0.10938448662678389, test error 0.21152194503776045\n",
            "Loss: 0.0\n",
            "training error 0.10934126490882787, test error 0.21133560724530348\n",
            "Loss: 0.0\n",
            "training error 0.109297462672568, test error 0.21115907824729663\n",
            "Loss: 0.0\n",
            "training error 0.1091670224935317, test error 0.21113145815801068\n",
            "Loss: 0.0\n",
            "training error 0.10924084269463506, test error 0.2108372795184254\n",
            "Loss: 0.0\n",
            "training error 0.10897623821327729, test error 0.21088657983482983\n",
            "Loss: 0.02338311161909079\n",
            "training error 0.10891809639744802, test error 0.21074986491533287\n",
            "Loss: 0.0\n",
            "training error 0.108839565097398, test error 0.21065059383749402\n",
            "Loss: 0.0\n",
            "training error 0.10875375246003001, test error 0.2107673098170635\n",
            "Loss: 0.05540738216931462\n",
            "training error 0.10865635838163744, test error 0.2104572590338161\n",
            "Loss: 0.0\n",
            "training error 0.10859037979164944, test error 0.21013456694533184\n",
            "Loss: 0.0\n",
            "training error 0.10846811327000253, test error 0.21010414078484757\n",
            "Loss: 0.0\n",
            "training error 0.10835937185318988, test error 0.2100029568846576\n",
            "Loss: 0.0\n",
            "training error 0.10834362916414146, test error 0.20997445732279987\n",
            "Loss: 0.0\n",
            "training error 0.10828748797197253, test error 0.20976540231589597\n",
            "Loss: 0.0\n",
            "training error 0.10816768040039319, test error 0.20939017938793708\n",
            "Loss: 0.0\n",
            "training error 0.10809095968515994, test error 0.2095332892158197\n",
            "Loss: 0.06834600758305331\n",
            "training error 0.10786916154878783, test error 0.20924396979299384\n",
            "Loss: 0.0\n",
            "training error 0.10778835283139143, test error 0.2090977490411018\n",
            "Loss: 0.0\n",
            "training error 0.10768059291337674, test error 0.20888664523804465\n",
            "Loss: 0.0\n",
            "training error 0.1075605566331993, test error 0.20872065987654512\n",
            "Loss: 0.0\n",
            "training error 0.10744198283778258, test error 0.20860939329674266\n",
            "Loss: 0.0\n",
            "training error 0.10730703614798426, test error 0.2086108820946651\n",
            "Loss: 0.0007136773176430466\n",
            "training error 0.10721535857479905, test error 0.2083554714998916\n",
            "Loss: 0.0\n",
            "training error 0.10712402038347568, test error 0.20815086482371628\n",
            "Loss: 0.0\n",
            "training error 0.10706840032838723, test error 0.207809983993734\n",
            "Loss: 0.0\n",
            "training error 0.10689607527614435, test error 0.2077354617933685\n",
            "Loss: 0.0\n",
            "training error 0.10671227379103893, test error 0.20745630336871246\n",
            "Loss: 0.0\n",
            "training error 0.10660751905550739, test error 0.20733333166756365\n",
            "Loss: 0.0\n",
            "training error 0.10643602250064686, test error 0.2070042983819584\n",
            "Loss: 0.0\n",
            "training error 0.10653380741796241, test error 0.20684490566196442\n",
            "Loss: 0.0\n",
            "training error 0.10623112381892694, test error 0.20660467659772905\n",
            "Loss: 0.0\n",
            "training error 0.1060852683325975, test error 0.20637628169485248\n",
            "Loss: 0.0\n",
            "training error 0.10602291127867826, test error 0.2061278906196337\n",
            "Loss: 0.0\n",
            "training error 0.1058887831908206, test error 0.20588160702329766\n",
            "Loss: 0.0\n",
            "training error 0.10575865308403894, test error 0.20580793297702096\n",
            "Loss: 0.0\n",
            "training error 0.10565658477969105, test error 0.20534606122086219\n",
            "Loss: 0.0\n",
            "training error 0.10553036234889603, test error 0.20542126590887916\n",
            "Loss: 0.03662338959407041\n",
            "training error 0.10536586445172107, test error 0.20548482825429942\n",
            "Loss: 0.06757715858400903\n",
            "training error 0.10522229197011129, test error 0.2049244289667054\n",
            "Loss: 0.0\n",
            "training error 0.10507481918255202, test error 0.2047281796147938\n",
            "Loss: 0.0\n",
            "training error 0.10496636844666403, test error 0.20474010864565612\n",
            "Loss: 0.005826765462746408\n",
            "training error 0.10483119321332904, test error 0.20443668094705483\n",
            "Loss: 0.0\n",
            "training error 0.10475903157439526, test error 0.20437123768460275\n",
            "Loss: 0.0\n",
            "training error 0.10459691545617124, test error 0.20409547679309833\n",
            "Loss: 0.0\n",
            "training error 0.10439153873711088, test error 0.20399144241636824\n",
            "Loss: 0.0\n",
            "training error 0.10436163686511966, test error 0.2037438263346286\n",
            "Loss: 0.0\n",
            "training error 0.10413254354257184, test error 0.20363415701242935\n",
            "Loss: 0.0\n",
            "training error 0.10406949969999789, test error 0.20297671886236748\n",
            "Loss: 0.0\n",
            "training error 0.10391221609539807, test error 0.20282899797336082\n",
            "Loss: 0.0\n",
            "training error 0.10374342107803847, test error 0.20248265866346482\n",
            "Loss: 0.0\n",
            "training error 0.1037512855158967, test error 0.20204621243670573\n",
            "Loss: 0.0\n",
            "training error 0.10343295393686135, test error 0.20198922443491496\n",
            "Loss: 0.0\n",
            "training error 0.10335851894036939, test error 0.2019179856682724\n",
            "Loss: 0.0\n",
            "training error 0.10330851537104199, test error 0.20149451936837454\n",
            "Loss: 0.0\n",
            "training error 0.10312168387082359, test error 0.20122982546822904\n",
            "Loss: 0.0\n",
            "training error 0.10309875137469954, test error 0.2010982322746776\n",
            "Loss: 0.0\n",
            "training error 0.10281418449373177, test error 0.20087208950268956\n",
            "Loss: 0.0\n",
            "training error 0.10279028884687225, test error 0.20086740796445587\n",
            "Loss: 0.0\n",
            "training error 0.10253064132079011, test error 0.20073006805098362\n",
            "Loss: 0.0\n",
            "training error 0.10240105377592955, test error 0.2004402092288889\n",
            "Loss: 0.0\n",
            "training error 0.10232078510385653, test error 0.2005772177391721\n",
            "Loss: 0.06835380526206691\n",
            "training error 0.10214746779472982, test error 0.19984686851258532\n",
            "Loss: 0.0\n",
            "training error 0.10192167631756086, test error 0.19967102809979037\n",
            "Loss: 0.0\n",
            "training error 0.10178465931659601, test error 0.19944487981107395\n",
            "Loss: 0.0\n",
            "training error 0.10165644318034263, test error 0.19918417133854666\n",
            "Loss: 0.0\n",
            "training error 0.10150438997387898, test error 0.19890918724520898\n",
            "Loss: 0.0\n",
            "training error 0.10149502785523938, test error 0.19850717585223016\n",
            "Loss: 0.0\n",
            "training error 0.10120137815118553, test error 0.19819406502857106\n",
            "Loss: 0.0\n",
            "training error 0.10119922012030387, test error 0.19819274806547818\n",
            "Loss: 0.0\n",
            "training error 0.1010795603578796, test error 0.1978175244850988\n",
            "Loss: 0.0\n",
            "training error 0.10087742801998023, test error 0.19758498477377776\n",
            "Loss: 0.0\n",
            "training error 0.1006910799261474, test error 0.19749194179743643\n",
            "Loss: 0.0\n",
            "training error 0.10055611847935185, test error 0.1972816257950962\n",
            "Loss: 0.0\n",
            "training error 0.10040081065985304, test error 0.1971232256205343\n",
            "Loss: 0.0\n",
            "training error 0.10037344747090207, test error 0.19664714476445436\n",
            "Loss: 0.0\n",
            "training error 0.10022882740229748, test error 0.19648607899888756\n",
            "Loss: 0.0\n",
            "training error 0.10010483302504454, test error 0.19628079871822696\n",
            "Loss: 0.0\n",
            "training error 0.09992025604645625, test error 0.1961811754928406\n",
            "Loss: 0.0\n",
            "training error 0.10001239927320354, test error 0.19620972223698893\n",
            "Loss: 0.014551214751690189\n",
            "training error 0.09969310797665702, test error 0.1959515899287795\n",
            "Loss: 0.0\n",
            "training error 0.09953113362827937, test error 0.19574239390334683\n",
            "Loss: 0.0\n",
            "training error 0.09934708963851924, test error 0.19546107116119485\n",
            "Loss: 0.0\n",
            "training error 0.09922145888491937, test error 0.19523261431804817\n",
            "Loss: 0.0\n",
            "training error 0.09907858872626586, test error 0.19520319840499165\n",
            "Loss: 0.0\n",
            "training error 0.09888036993199285, test error 0.19500494569164614\n",
            "Loss: 0.0\n",
            "training error 0.09903486372945502, test error 0.19474978273730598\n",
            "Loss: 0.0\n",
            "training error 0.09874676616462962, test error 0.19442689206491257\n",
            "Loss: 0.0\n",
            "training error 0.09864012804746557, test error 0.19398165866655503\n",
            "Loss: 0.0\n",
            "training error 0.09860635488109949, test error 0.19409524615720913\n",
            "Loss: 0.058555788951863974\n",
            "training error 0.09828917626084692, test error 0.19368246025809352\n",
            "Loss: 0.0\n",
            "training error 0.09824343861307433, test error 0.1935702153620923\n",
            "Loss: 0.0\n",
            "training error 0.09802873596410791, test error 0.1934188718071138\n",
            "Loss: 0.0\n",
            "training error 0.0979064199238377, test error 0.19321464720111564\n",
            "Loss: 0.0\n",
            "training error 0.09782969254184724, test error 0.19338212695509635\n",
            "Loss: 0.08668067168136062\n",
            "training error 0.09762900476664407, test error 0.1928924196269134\n",
            "Loss: 0.0\n",
            "training error 0.09750654222990822, test error 0.19269681260760926\n",
            "Loss: 0.0\n",
            "training error 0.09748832968568187, test error 0.19219955869811975\n",
            "Loss: 0.0\n",
            "training error 0.09722053181891724, test error 0.19199653339396114\n",
            "Loss: 0.0\n",
            "training error 0.09719111166463117, test error 0.19205538759295218\n",
            "Loss: 0.0306537821025632\n",
            "training error 0.09700131327233365, test error 0.19170572259024654\n",
            "Loss: 0.0\n",
            "training error 0.09689634960232112, test error 0.19150730822242357\n",
            "Loss: 0.0\n",
            "training error 0.09675258592496716, test error 0.19174490234257996\n",
            "Loss: 0.12406530192594634\n",
            "training error 0.09654203324374669, test error 0.1914452309580263\n",
            "Loss: 0.0\n",
            "training error 0.09644073010445785, test error 0.19126923256644757\n",
            "Loss: 0.0\n",
            "training error 0.09639944019413572, test error 0.19065035709695588\n",
            "Loss: 0.0\n",
            "training error 0.09628820572456229, test error 0.19039922506561546\n",
            "Loss: 0.0\n",
            "training error 0.09608407719159469, test error 0.19016805470601605\n",
            "Loss: 0.0\n",
            "training error 0.09597797525479339, test error 0.1901138148734817\n",
            "Loss: 0.0\n",
            "training error 0.09601616233745558, test error 0.1899383128279711\n",
            "Loss: 0.0\n",
            "training error 0.09589967967550055, test error 0.1900376499965506\n",
            "Loss: 0.052299700413493966\n",
            "training error 0.09548115594878137, test error 0.1897261673107048\n",
            "Loss: 0.0\n",
            "training error 0.09542500410361598, test error 0.18955881132333907\n",
            "Loss: 0.0\n",
            "training error 0.09517697473912554, test error 0.1896028209243365\n",
            "Loss: 0.023216858499064408\n",
            "training error 0.09506592263134489, test error 0.18901504560214874\n",
            "Loss: 0.0\n",
            "training error 0.09492428690700905, test error 0.18879325677426936\n",
            "Loss: 0.0\n",
            "training error 0.09476761770030467, test error 0.18867123361992552\n",
            "Loss: 0.0\n",
            "training error 0.09470901847700378, test error 0.18878142984364377\n",
            "Loss: 0.058406478615724566\n",
            "training error 0.09457481891807183, test error 0.18829992340690643\n",
            "Loss: 0.0\n",
            "training error 0.09437461372505446, test error 0.18800214118718586\n",
            "Loss: 0.0\n",
            "training error 0.09439233839118688, test error 0.1875466890745801\n",
            "Loss: 0.0\n",
            "training error 0.09417422765426313, test error 0.18759110725815828\n",
            "Loss: 0.02368380044315277\n",
            "training error 0.09416450449500617, test error 0.18724602270398263\n",
            "Loss: 0.0\n",
            "training error 0.09388530359184875, test error 0.18714120864164766\n",
            "Loss: 0.0\n",
            "training error 0.09379304372941218, test error 0.1872020643593052\n",
            "Loss: 0.03251860886186453\n",
            "training error 0.09363118994647456, test error 0.18680789569720935\n",
            "Loss: 0.0\n",
            "training error 0.09364991261264982, test error 0.18696090104975704\n",
            "Loss: 0.08190518499051613\n",
            "training error 0.0933994634286305, test error 0.1867251104096544\n",
            "Loss: 0.0\n",
            "training error 0.09324104226398162, test error 0.1868043747867517\n",
            "Loss: 0.04244976849840931\n",
            "training error 0.09314061400254652, test error 0.1863680814253731\n",
            "Loss: 0.0\n",
            "training error 0.09289657231790258, test error 0.18607719671587789\n",
            "Loss: 0.0\n",
            "training error 0.09273468245399372, test error 0.18588279108420616\n",
            "Loss: 0.0\n",
            "training error 0.09263537293016963, test error 0.18565202919213164\n",
            "Loss: 0.0\n",
            "training error 0.09288410320060993, test error 0.18618945246045404\n",
            "Loss: 0.28947880109957413\n",
            "training error 0.09237389715094772, test error 0.1857485625093306\n",
            "Loss: 0.051996909281859516\n",
            "training error 0.0923550296240493, test error 0.1854851827488675\n",
            "Loss: 0.0\n",
            "training error 0.09220668412424932, test error 0.18491228860011416\n",
            "Loss: 0.0\n",
            "training error 0.09201668717684179, test error 0.18496702500792006\n",
            "Loss: 0.029601281894398035\n",
            "training error 0.09169949869862942, test error 0.1846295611903673\n",
            "Loss: 0.0\n",
            "training error 0.09168003561541807, test error 0.1846341686014602\n",
            "Loss: 0.002495489380560656\n",
            "training error 0.09162368604959414, test error 0.18387562043556493\n",
            "Loss: 0.0\n",
            "training error 0.0913342550309245, test error 0.18352930104873283\n",
            "Loss: 0.0\n",
            "training error 0.09115641261148763, test error 0.18370484074927437\n",
            "Loss: 0.09564668940515997\n",
            "training error 0.09093650437772742, test error 0.1833923026538994\n",
            "Loss: 0.0\n",
            "training error 0.09092448734715455, test error 0.18288946727729846\n",
            "Loss: 0.0\n",
            "training error 0.0907078082914714, test error 0.18293563115829614\n",
            "Loss: 0.025241410391174668\n",
            "training error 0.09054753900521924, test error 0.18231023672670757\n",
            "Loss: 0.0\n",
            "training error 0.09033415506131451, test error 0.1822806819708777\n",
            "Loss: 0.0\n",
            "training error 0.09013370276912952, test error 0.18230288009581516\n",
            "Loss: 0.012177990940909211\n",
            "training error 0.08994601294306923, test error 0.18178417306244\n",
            "Loss: 0.0\n",
            "training error 0.08982801452475403, test error 0.18152021302993276\n",
            "Loss: 0.0\n",
            "training error 0.089603340707664, test error 0.1814309035100931\n",
            "Loss: 0.0\n",
            "training error 0.08951594172313025, test error 0.18124964823057552\n",
            "Loss: 0.0\n",
            "training error 0.08925944101194107, test error 0.18108518772541005\n",
            "Loss: 0.0\n",
            "training error 0.08927404437811172, test error 0.1810946712348429\n",
            "Loss: 0.005237043157402255\n",
            "training error 0.08889507271095438, test error 0.18045021560575372\n",
            "Loss: 0.0\n",
            "training error 0.08867006397891976, test error 0.18025693647106372\n",
            "Loss: 0.0\n",
            "training error 0.08847407121769633, test error 0.17949665085963995\n",
            "Loss: 0.0\n",
            "training error 0.08851344761832373, test error 0.17920582931216142\n",
            "Loss: 0.0\n",
            "training error 0.0881091129362358, test error 0.17936152291779506\n",
            "Loss: 0.0868797662616494\n",
            "training error 0.08798633048544326, test error 0.17951072327033313\n",
            "Loss: 0.17013618326031654\n",
            "training error 0.08771863907092778, test error 0.17864531678070297\n",
            "Loss: 0.0\n",
            "training error 0.08756172060775762, test error 0.1781993630204631\n",
            "Loss: 0.0\n",
            "training error 0.08749599394561608, test error 0.17790368016526456\n",
            "Loss: 0.0\n",
            "training error 0.08704164157847111, test error 0.17763253391542444\n",
            "Loss: 0.0\n",
            "training error 0.08691545691967742, test error 0.17713221163728038\n",
            "Loss: 0.0\n",
            "training error 0.08676825068769964, test error 0.17748929666819907\n",
            "Loss: 0.201592374203452\n",
            "training error 0.08646819881010866, test error 0.1771137901710123\n",
            "Loss: 0.0\n",
            "training error 0.08631457787651647, test error 0.17638157273821906\n",
            "Loss: 0.0\n",
            "training error 0.08609331749628357, test error 0.17550687790264652\n",
            "Loss: 0.0\n",
            "training error 0.08581764541939427, test error 0.17531789253852142\n",
            "Loss: 0.0\n",
            "training error 0.08578109375154874, test error 0.17553608345480617\n",
            "Loss: 0.12445444850235354\n",
            "training error 0.08534863228396905, test error 0.1751568297509304\n",
            "Loss: 0.0\n",
            "training error 0.08523707705341613, test error 0.17425012969702583\n",
            "Loss: 0.0\n",
            "training error 0.08485105932562842, test error 0.1740726972802739\n",
            "Loss: 0.0\n",
            "training error 0.08451439969733991, test error 0.17361763126807844\n",
            "Loss: 0.0\n",
            "training error 0.08420776889298949, test error 0.17349362153925796\n",
            "Loss: 0.0\n",
            "training error 0.08395335179929625, test error 0.17283249514782523\n",
            "Loss: 0.0\n",
            "training error 0.0839497296351848, test error 0.17220898252589645\n",
            "Loss: 0.0\n",
            "training error 0.08344443874917364, test error 0.17180324304737152\n",
            "Loss: 0.0\n",
            "training error 0.08326527448053918, test error 0.17105806181005445\n",
            "Loss: 0.0\n",
            "training error 0.08303093829815614, test error 0.17085739888415216\n",
            "Loss: 0.0\n",
            "training error 0.08269724488133223, test error 0.17057398538175136\n",
            "Loss: 0.0\n",
            "training error 0.08228772629263902, test error 0.17049871044968457\n",
            "Loss: 0.0\n",
            "training error 0.08207739978143734, test error 0.1695938695930997\n",
            "Loss: 0.0\n",
            "training error 0.08229939220946528, test error 0.17018105636196262\n",
            "Loss: 0.3462311286792197\n",
            "training error 0.08127933694926034, test error 0.168735619579295\n",
            "Loss: 0.0\n",
            "training error 0.08105418021004741, test error 0.16885497839622396\n",
            "Loss: 0.07073717880465846\n",
            "training error 0.0808795428889367, test error 0.16773437956828421\n",
            "Loss: 0.0\n",
            "training error 0.08051992263624277, test error 0.16739594015937576\n",
            "Loss: 0.0\n",
            "training error 0.08021870422765347, test error 0.16657925493830122\n",
            "Loss: 0.0\n",
            "training error 0.0798698092467545, test error 0.16639984184206855\n",
            "Loss: 0.0\n",
            "training error 0.07951754339583923, test error 0.16615181101073634\n",
            "Loss: 0.0\n",
            "training error 0.07936170647193687, test error 0.1653691900071528\n",
            "Loss: 0.0\n",
            "training error 0.07888935712725556, test error 0.16566908363522304\n",
            "Loss: 0.18134794519901742\n",
            "training error 0.07862977263345038, test error 0.16473904437621484\n",
            "Loss: 0.0\n",
            "training error 0.07833359019718632, test error 0.16306698129069805\n",
            "Loss: 0.0\n",
            "training error 0.0781599551819439, test error 0.1621126329013466\n",
            "Loss: 0.0\n",
            "training error 0.07779446082292814, test error 0.1621799926256257\n",
            "Loss: 0.04155118763637944\n",
            "training error 0.07720016434504513, test error 0.16190804332759873\n",
            "Loss: 0.0\n",
            "training error 0.07698371595135298, test error 0.16213791877984063\n",
            "Loss: 0.14197901939732027\n",
            "training error 0.07719165547353064, test error 0.16017400670034204\n",
            "Loss: 0.0\n",
            "training error 0.07616552181352396, test error 0.16014254425052546\n",
            "Loss: 0.0\n",
            "training error 0.07579358112077615, test error 0.15986363829633368\n",
            "Loss: 0.0\n",
            "training error 0.07562052866105604, test error 0.15937452095801344\n",
            "Loss: 0.0\n",
            "training error 0.07531561636703395, test error 0.15824206891572948\n",
            "Loss: 0.0\n",
            "training error 0.07507346902370786, test error 0.15819218444290983\n",
            "Loss: 0.0\n",
            "training error 0.07448820283261236, test error 0.15802145615032956\n",
            "Loss: 0.0\n",
            "training error 0.07426671133409628, test error 0.15729306335500914\n",
            "Loss: 0.0\n",
            "training error 0.07383464824761503, test error 0.15664064379371062\n",
            "Loss: 0.0\n",
            "training error 0.07371275492325262, test error 0.15586153636411995\n",
            "Loss: 0.0\n",
            "training error 0.07334377106353919, test error 0.1548973172913735\n",
            "Loss: 0.0\n",
            "training error 0.07300910642149666, test error 0.15389312667543376\n",
            "Loss: 0.0\n",
            "training error 0.07262703861623653, test error 0.15351056189887477\n",
            "Loss: 0.0\n",
            "training error 0.07256831819621817, test error 0.15323841538673597\n",
            "Loss: 0.0\n",
            "training error 0.07191010339688274, test error 0.15309553818710833\n",
            "Loss: 0.0\n",
            "training error 0.07163503529611617, test error 0.15326168428619472\n",
            "Loss: 0.10852445541771338\n",
            "training error 0.07124825558319749, test error 0.1529959677377875\n",
            "Loss: 0.0\n",
            "training error 0.07076632423316408, test error 0.15195934498035635\n",
            "Loss: 0.0\n",
            "training error 0.07039652619904736, test error 0.1507557277657069\n",
            "Loss: 0.0\n",
            "training error 0.07015275145238521, test error 0.15072155389045383\n",
            "Loss: 0.0\n",
            "training error 0.06965848176030599, test error 0.15024592187735822\n",
            "Loss: 0.0\n",
            "training error 0.06935628886072367, test error 0.1495034918761331\n",
            "Loss: 0.0\n",
            "training error 0.06904861208858555, test error 0.148685247510242\n",
            "Loss: 0.0\n",
            "training error 0.0686849937034595, test error 0.14863284055932477\n",
            "Loss: 0.0\n",
            "training error 0.06849668630700376, test error 0.147155140623065\n",
            "Loss: 0.0\n",
            "training error 0.06804168563667932, test error 0.1461315783342572\n",
            "Loss: 0.0\n",
            "training error 0.06809126763696675, test error 0.14621793957125867\n",
            "Loss: 0.05909827156176384\n",
            "training error 0.06743583773059023, test error 0.14562605309918938\n",
            "Loss: 0.0\n",
            "training error 0.06693851014712102, test error 0.1446565440056248\n",
            "Loss: 0.0\n",
            "training error 0.06650363002983081, test error 0.14416600382797845\n",
            "Loss: 0.0\n",
            "training error 0.06620165158667887, test error 0.14296568367317086\n",
            "Loss: 0.0\n",
            "training error 0.06585004302304584, test error 0.14266852544898337\n",
            "Loss: 0.0\n",
            "training error 0.06576293341862163, test error 0.14209224823215785\n",
            "Loss: 0.0\n",
            "training error 0.0652433416217969, test error 0.14135018038471583\n",
            "Loss: 0.0\n",
            "training error 0.06481962794535233, test error 0.1405470080749747\n",
            "Loss: 0.0\n",
            "training error 0.0649955046451861, test error 0.1405482708567696\n",
            "Loss: 0.0008984764686248425\n",
            "training error 0.06406975524431617, test error 0.13929338422521056\n",
            "Loss: 0.0\n",
            "training error 0.0637597405657541, test error 0.13900154818797825\n",
            "Loss: 0.0\n",
            "training error 0.06348872044578756, test error 0.13850104850047992\n",
            "Loss: 0.0\n",
            "training error 0.06306338185834112, test error 0.1375890706918113\n",
            "Loss: 0.0\n",
            "training error 0.06307090760218166, test error 0.13858538161023315\n",
            "Loss: 0.7241206829963209\n",
            "training error 0.06246899678971986, test error 0.13717003566130592\n",
            "Loss: 0.0\n",
            "training error 0.06202236112374693, test error 0.13678997949915264\n",
            "Loss: 0.0\n",
            "training error 0.06155920733225722, test error 0.1361532120916746\n",
            "Loss: 0.0\n",
            "training error 0.061394193364743194, test error 0.1348906229906905\n",
            "Loss: 0.0\n",
            "training error 0.06081856845875422, test error 0.1342243736023418\n",
            "Loss: 0.0\n",
            "training error 0.0605262676362917, test error 0.13346133337478952\n",
            "Loss: 0.0\n",
            "training error 0.06015713254228876, test error 0.13343648767751348\n",
            "Loss: 0.0\n",
            "training error 0.06013891154646517, test error 0.13187373065718963\n",
            "Loss: 0.0\n",
            "training error 0.059463294918995775, test error 0.13092658120068223\n",
            "Loss: 0.0\n",
            "training error 0.059602317682737056, test error 0.1308860489823886\n",
            "Loss: 0.0\n",
            "training error 0.05892689456108439, test error 0.13002006306275496\n",
            "Loss: 0.0\n",
            "training error 0.05846718646211639, test error 0.12947923626815874\n",
            "Loss: 0.0\n",
            "training error 0.05811130609790258, test error 0.12862605070333513\n",
            "Loss: 0.0\n",
            "training error 0.05789789053404751, test error 0.12740796307417182\n",
            "Loss: 0.0\n",
            "training error 0.05743284731955623, test error 0.12699082527636996\n",
            "Loss: 0.0\n",
            "training error 0.05710567713421474, test error 0.12606117811138612\n",
            "Loss: 0.0\n",
            "training error 0.05683748103710991, test error 0.12526040269523125\n",
            "Loss: 0.0\n",
            "training error 0.05639038574693205, test error 0.12474976150491945\n",
            "Loss: 0.0\n",
            "training error 0.05629117005729816, test error 0.12394568806794494\n",
            "Loss: 0.0\n",
            "training error 0.05577298057222513, test error 0.12377756213535515\n",
            "Loss: 0.0\n",
            "training error 0.05557054090298974, test error 0.12255196979296967\n",
            "Loss: 0.0\n",
            "training error 0.055031193825917396, test error 0.12166618630782289\n",
            "Loss: 0.0\n",
            "training error 0.05482021052390325, test error 0.12169569570213488\n",
            "Loss: 0.024254392454881035\n",
            "training error 0.0542681554115008, test error 0.12120809905489782\n",
            "Loss: 0.0\n",
            "training error 0.054368136140903675, test error 0.12001727027239428\n",
            "Loss: 0.0\n",
            "training error 0.05362453841273113, test error 0.12041036504278665\n",
            "Loss: 0.32753183729323787\n",
            "training error 0.0534916374928288, test error 0.11933227453839641\n",
            "Loss: 0.0\n",
            "training error 0.05301835764301476, test error 0.11940447425458274\n",
            "Loss: 0.06050309228213813\n",
            "training error 0.05259573960212518, test error 0.11817697603369091\n",
            "Loss: 0.0\n",
            "training error 0.05247570846449748, test error 0.11833986218841261\n",
            "Loss: 0.1378323935749215\n",
            "training error 0.05222496574436622, test error 0.11671254550007912\n",
            "Loss: 0.0\n",
            "training error 0.05174546931173145, test error 0.11599019553712075\n",
            "Loss: 0.0\n",
            "training error 0.0513839688542492, test error 0.11452983486584731\n",
            "Loss: 0.0\n",
            "training error 0.051313148347140666, test error 0.11349861192139458\n",
            "Loss: 0.0\n",
            "training error 0.05089423419247339, test error 0.11375765096194454\n",
            "Loss: 0.22823102077174084\n",
            "training error 0.05049281725918106, test error 0.11294560025738153\n",
            "Loss: 0.0\n",
            "training error 0.050109097200013095, test error 0.11295031607224502\n",
            "Loss: 0.0041752975350473065\n",
            "training error 0.04974007716822029, test error 0.11244948848586801\n",
            "Loss: 0.0\n",
            "training error 0.04925233015400716, test error 0.11119618286139976\n",
            "Loss: 0.0\n",
            "training error 0.049060659672007026, test error 0.11042482266872965\n",
            "Loss: 0.0\n",
            "training error 0.048769402410129004, test error 0.1098518673135456\n",
            "Loss: 0.0\n",
            "training error 0.048492538561083307, test error 0.11046904132969676\n",
            "Loss: 0.5618238735893177\n",
            "training error 0.04811540244055675, test error 0.10940943228313152\n",
            "Loss: 0.0\n",
            "training error 0.04777263389814936, test error 0.10747357350725538\n",
            "Loss: 0.0\n",
            "training error 0.047535856545772776, test error 0.10683645354156472\n",
            "Loss: 0.0\n",
            "training error 0.04711169192865697, test error 0.10647528010613502\n",
            "Loss: 0.0\n",
            "training error 0.047096452259835234, test error 0.10490411879839145\n",
            "Loss: 0.0\n",
            "training error 0.046590021486023675, test error 0.10474296051608377\n",
            "Loss: 0.0\n",
            "training error 0.046265817067248596, test error 0.10419537311600263\n",
            "Loss: 0.0\n",
            "training error 0.04603692325467078, test error 0.10347617444480128\n",
            "Loss: 0.0\n",
            "training error 0.045642943596917666, test error 0.10297330336789616\n",
            "Loss: 0.0\n",
            "training error 0.04528962899503605, test error 0.102254052678778\n",
            "Loss: 0.0\n",
            "training error 0.04524607895792543, test error 0.10128109854366647\n",
            "Loss: 0.0\n",
            "training error 0.04464109989035097, test error 0.10057025296224095\n",
            "Loss: 0.0\n",
            "training error 0.044421313065613914, test error 0.09995597066017795\n",
            "Loss: 0.0\n",
            "training error 0.044160658821130815, test error 0.09920536721573002\n",
            "Loss: 0.0\n",
            "training error 0.04386862512208987, test error 0.09960085365289054\n",
            "Loss: 0.39865427472336457\n",
            "training error 0.04377118488791085, test error 0.09796361644787532\n",
            "Loss: 0.0\n",
            "training error 0.04336472013841303, test error 0.0985103252120575\n",
            "Loss: 0.5580732765955831\n",
            "training error 0.04296052224844501, test error 0.09769397507929593\n",
            "Loss: 0.0\n",
            "training error 0.04286027325753163, test error 0.09724821338657286\n",
            "Loss: 0.0\n",
            "training error 0.04264026326359717, test error 0.09595072739281166\n",
            "Loss: 0.0\n",
            "training error 0.042115351540129284, test error 0.09537424857483606\n",
            "Loss: 0.0\n",
            "training error 0.04192350541504411, test error 0.09471468486505169\n",
            "Loss: 0.0\n",
            "training error 0.04151686430283538, test error 0.09375906354249319\n",
            "Loss: 0.0\n",
            "training error 0.04129487520551908, test error 0.09381076605660046\n",
            "Loss: 0.05514401717956474\n",
            "training error 0.040992109533962574, test error 0.093455522400707\n",
            "Loss: 0.0\n",
            "training error 0.040609830527705164, test error 0.09231403430948745\n",
            "Loss: 0.0\n",
            "training error 0.040490306718449616, test error 0.09112148567490261\n",
            "Loss: 0.0\n",
            "training error 0.040141884048300845, test error 0.09126310043102348\n",
            "Loss: 0.15541313343607754\n",
            "training error 0.04003664207827346, test error 0.09088916832233546\n",
            "Loss: 0.0\n",
            "training error 0.03960397708493272, test error 0.0900357273942964\n",
            "Loss: 0.0\n",
            "training error 0.03945470303947736, test error 0.08928355943244559\n",
            "Loss: 0.0\n",
            "training error 0.03916535639729909, test error 0.08879774103153155\n",
            "Loss: 0.0\n",
            "training error 0.039009467551911245, test error 0.0882474050842785\n",
            "Loss: 0.0\n",
            "training error 0.03846093094031843, test error 0.0880063204091833\n",
            "Loss: 0.0\n",
            "training error 0.038196758507064964, test error 0.08785001546106098\n",
            "Loss: 0.0\n",
            "training error 0.03816045262688704, test error 0.08732393572071849\n",
            "Loss: 0.0\n",
            "training error 0.037913962923245115, test error 0.08627412914603061\n",
            "Loss: 0.0\n",
            "training error 0.03764955237370165, test error 0.0859263158388435\n",
            "Loss: 0.0\n",
            "training error 0.03746943259329543, test error 0.08533383358262751\n",
            "Loss: 0.0\n",
            "training error 0.03717484560748865, test error 0.08459503171532969\n",
            "Loss: 0.0\n",
            "training error 0.03711573882778804, test error 0.08483626049602673\n",
            "Loss: 0.2851571490732452\n",
            "training error 0.036603133186780844, test error 0.08418448108912226\n",
            "Loss: 0.0\n",
            "training error 0.036503280397008536, test error 0.08313773195515203\n",
            "Loss: 0.0\n",
            "training error 0.03625349668961224, test error 0.08241978425971276\n",
            "Loss: 0.0\n",
            "training error 0.03613336391281357, test error 0.08192678984245519\n",
            "Loss: 0.0\n",
            "training error 0.0357416371656858, test error 0.08142009376908302\n",
            "Loss: 0.0\n",
            "training error 0.03556894925631018, test error 0.081713650472557\n",
            "Loss: 0.36054576933619575\n",
            "training error 0.03534414389917725, test error 0.08029496896393926\n",
            "Loss: 0.0\n",
            "training error 0.03523730687708429, test error 0.08042312442211094\n",
            "Loss: 0.15960583810579188\n",
            "training error 0.03478614503713052, test error 0.07985245050251344\n",
            "Loss: 0.0\n",
            "training error 0.03461095112335498, test error 0.07926268802522611\n",
            "Loss: 0.0\n",
            "training error 0.034445007868678545, test error 0.07954691894139729\n",
            "Loss: 0.35859358703647093\n",
            "training error 0.034278032548562126, test error 0.07921282286506026\n",
            "Loss: 0.0\n",
            "training error 0.03400157312134879, test error 0.07805759941776175\n",
            "Loss: 0.0\n",
            "training error 0.034044459320514316, test error 0.07806779001584924\n",
            "Loss: 0.013055228656155826\n",
            "training error 0.03360901658450583, test error 0.07712299000857695\n",
            "Loss: 0.0\n",
            "training error 0.03344575715158429, test error 0.07673879125202157\n",
            "Loss: 0.0\n",
            "training error 0.033248008534007556, test error 0.07688725599838207\n",
            "Loss: 0.19346766340497812\n",
            "training error 0.03315135682018098, test error 0.07597765737056245\n",
            "Loss: 0.0\n",
            "training error 0.032913732727270634, test error 0.07616532418812075\n",
            "Loss: 0.24700263742405415\n",
            "training error 0.032580883939098644, test error 0.07526718184048006\n",
            "Loss: 0.0\n",
            "training error 0.03242888082309659, test error 0.07494186493683709\n",
            "Loss: 0.0\n",
            "training error 0.032224190089399425, test error 0.07407865973757684\n",
            "Loss: 0.0\n",
            "training error 0.03205215540897996, test error 0.07379681832941362\n",
            "Loss: 0.0\n",
            "training error 0.032022734297294506, test error 0.07439061404599344\n",
            "Loss: 0.8046359314967111\n",
            "training error 0.03176757660552899, test error 0.07329301893391\n",
            "Loss: 0.0\n",
            "training error 0.031877329011074866, test error 0.07365335234520005\n",
            "Loss: 0.4916340144413667\n",
            "training error 0.03136782859643931, test error 0.07246774303419935\n",
            "Loss: 0.0\n",
            "training error 0.031203186326960466, test error 0.07172602069242343\n",
            "Loss: 0.0\n",
            "training error 0.03106783167639588, test error 0.07131862812407007\n",
            "Loss: 0.0\n",
            "training error 0.03085355593695209, test error 0.070980740765061\n",
            "Loss: 0.0\n",
            "training error 0.030688400120492124, test error 0.07056134903252634\n",
            "Loss: 0.0\n",
            "training error 0.030480470640066468, test error 0.07075777771072955\n",
            "Loss: 0.27837999258299995\n",
            "training error 0.03043410865021429, test error 0.0699303347357387\n",
            "Loss: 0.0\n",
            "training error 0.030404340124627335, test error 0.06978635623149891\n",
            "Loss: 0.0\n",
            "training error 0.03020063396470668, test error 0.06903994864036989\n",
            "Loss: 0.0\n",
            "training error 0.0298900582982832, test error 0.06927142248113033\n",
            "Loss: 0.33527522154772615\n",
            "training error 0.029830192790144063, test error 0.0682176888247572\n",
            "Loss: 0.0\n",
            "training error 0.029639417619780346, test error 0.06905633761248534\n",
            "Loss: 1.2293714462864758\n",
            "training error 0.029637668886488045, test error 0.06794318875109229\n",
            "Loss: 0.0\n",
            "training error 0.02943479625128488, test error 0.0677262930667996\n",
            "Loss: 0.0\n",
            "training error 0.029295479761893884, test error 0.06711336825217627\n",
            "Loss: 0.0\n",
            "training error 0.02907213051934788, test error 0.06764865442902039\n",
            "Loss: 0.7975850278185925\n",
            "training error 0.028797263359394403, test error 0.06688732751732691\n",
            "Loss: 0.0\n",
            "training error 0.02869591345072655, test error 0.06662872792921248\n",
            "Loss: 0.0\n",
            "training error 0.028638830638016557, test error 0.06536015752684278\n",
            "Loss: 0.0\n",
            "training error 0.028358532092807788, test error 0.06543423808452602\n",
            "Loss: 0.11334207334614543\n",
            "training error 0.028312155325374115, test error 0.065576571287859\n",
            "Loss: 0.33110960745059703\n",
            "training error 0.028131021857295005, test error 0.0647509940691625\n",
            "Loss: 0.0\n",
            "training error 0.028035742364984333, test error 0.06465586428379796\n",
            "Loss: 0.0\n",
            "training error 0.027965163641847153, test error 0.06393380857696453\n",
            "Loss: 0.0\n",
            "training error 0.027759133947366867, test error 0.0638862237057914\n",
            "Loss: 0.0\n",
            "training error 0.02772206344394781, test error 0.0633815690581736\n",
            "Loss: 0.0\n",
            "training error 0.02753309199633792, test error 0.06362352540318078\n",
            "Loss: 0.38174559040200506\n",
            "training error 0.027448801443266398, test error 0.06304190713126562\n",
            "Loss: 0.0\n",
            "training error 0.027258526645225156, test error 0.0630027670224538\n",
            "Loss: 0.0\n",
            "training error 0.027222330133318533, test error 0.06312574496335627\n",
            "Loss: 0.19519450766127822\n",
            "training error 0.027224024802018697, test error 0.062334271751287015\n",
            "Loss: 0.0\n",
            "training error 0.026950689553813904, test error 0.06177174797031243\n",
            "Loss: 0.0\n",
            "training error 0.0268929010995786, test error 0.062341220553208114\n",
            "Loss: 0.9218981194596854\n",
            "training error 0.02677052997296603, test error 0.06217562999672235\n",
            "Loss: 0.6538296870019389\n",
            "training error 0.02668843972053535, test error 0.06226717586451528\n",
            "Loss: 0.8020299092733385\n",
            "training error 0.026616753038340005, test error 0.061929241755480716\n",
            "Loss: 0.2549608685899152\n",
            "training error 0.026498630994016975, test error 0.0616500295272632\n",
            "Loss: 0.0\n",
            "training error 0.026564274916306717, test error 0.06150115208958206\n",
            "Loss: 0.0\n",
            "training error 0.02622817396779679, test error 0.06033277951747059\n",
            "Loss: 0.0\n",
            "training error 0.026120373729614555, test error 0.05972478683655585\n",
            "Loss: 0.0\n",
            "training error 0.026067627541718683, test error 0.059597623558977776\n",
            "Loss: 0.0\n",
            "training error 0.025952760921483416, test error 0.05980211034629937\n",
            "Loss: 0.34311231742190085\n",
            "training error 0.0258738222803795, test error 0.05999456896097719\n",
            "Loss: 0.6660423323869624\n",
            "training error 0.025754988838118508, test error 0.05922379709022916\n",
            "Loss: 0.0\n",
            "training error 0.02564011997570589, test error 0.059015198216649106\n",
            "Loss: 0.0\n",
            "training error 0.025543391622066466, test error 0.059024220649765646\n",
            "Loss: 0.015288321295514606\n",
            "training error 0.025467666887523645, test error 0.059309161859842495\n",
            "Loss: 0.4981151501249226\n",
            "training error 0.025371974698255015, test error 0.05887536754765417\n",
            "Loss: 0.0\n",
            "training error 0.025337305406322473, test error 0.05842359059973122\n",
            "Loss: 0.0\n",
            "training error 0.025258236138991336, test error 0.05893402870744707\n",
            "Loss: 0.8736849318504492\n",
            "training error 0.025150733769402682, test error 0.05868730138241831\n",
            "Loss: 0.45137722618557863\n",
            "training error 0.02504575169224022, test error 0.05815782641509854\n",
            "Loss: 0.0\n",
            "training error 0.024912652925380335, test error 0.057379460861236374\n",
            "Loss: 0.0\n",
            "training error 0.024885311652122256, test error 0.05712754046605955\n",
            "Loss: 0.0\n",
            "training error 0.024825292563883328, test error 0.057093922254010075\n",
            "Loss: 0.0\n",
            "training error 0.024700027576051893, test error 0.05660943214652817\n",
            "Loss: 0.0\n",
            "training error 0.024664886262632156, test error 0.056262368395904025\n",
            "Loss: 0.0\n",
            "training error 0.02458454408071251, test error 0.05661295970649215\n",
            "Loss: 0.6231364241922721\n",
            "training error 0.024454403382100733, test error 0.0567354484266803\n",
            "Loss: 0.8408462783637827\n",
            "training error 0.024520627233911615, test error 0.056749973380260145\n",
            "Loss: 0.8666627414704031\n",
            "training error 0.024431669371786303, test error 0.0563094488840545\n",
            "Loss: 0.08368024577134481\n",
            "training error 0.02474500752872806, test error 0.05698877569530251\n",
            "Loss: 1.2911068625603095\n",
            "training error 0.0242761540946427, test error 0.05655009795734446\n",
            "Loss: 0.511406770891254\n",
            "training error 0.024106310493311595, test error 0.055921576864438494\n",
            "Loss: 0.0\n",
            "training error 0.024062102354147526, test error 0.056091793786148564\n",
            "Loss: 0.30438505359513535\n",
            "training error 0.023976259886979434, test error 0.05571212656770544\n",
            "Loss: 0.0\n",
            "training error 0.023890805887254857, test error 0.05500193739246952\n",
            "Loss: 0.0\n",
            "training error 0.02395245657265419, test error 0.05468501643833671\n",
            "Loss: 0.0\n",
            "training error 0.023781577374002164, test error 0.05470990818117858\n",
            "Loss: 0.04551839692676918\n",
            "training error 0.023746656754452162, test error 0.05466778516917304\n",
            "Loss: 0.0\n",
            "training error 0.0236319845297325, test error 0.054731522086504315\n",
            "Loss: 0.11658953647752934\n",
            "training error 0.02364429179348232, test error 0.05466556869598782\n",
            "Loss: 0.0\n",
            "training error 0.02350012001405209, test error 0.05416952539965202\n",
            "Loss: 0.0\n",
            "training error 0.02339360432702148, test error 0.05393930721012751\n",
            "Loss: 0.0\n",
            "training error 0.023499282871817868, test error 0.053661198150488164\n",
            "Loss: 0.0\n",
            "training error 0.02346323004475328, test error 0.0534766639446483\n",
            "Loss: 0.0\n",
            "training error 0.023240433829057744, test error 0.053494639085078774\n",
            "Loss: 0.03361305493754241\n",
            "training error 0.023266368953191542, test error 0.053322747501544865\n",
            "Loss: 0.0\n",
            "training error 0.023177993989901915, test error 0.053172749406503426\n",
            "Loss: 0.0\n",
            "training error 0.02303218423859631, test error 0.05301643679752212\n",
            "Loss: 0.0\n",
            "training error 0.023003552951288128, test error 0.052804359937491885\n",
            "Loss: 0.0\n",
            "training error 0.023033202040874442, test error 0.05265355261834605\n",
            "Loss: 0.0\n",
            "training error 0.023006235035853508, test error 0.05264393572349405\n",
            "Loss: 0.0\n",
            "training error 0.022858336029521337, test error 0.05242102169180348\n",
            "Loss: 0.0\n",
            "training error 0.022837661496322992, test error 0.05226159962482133\n",
            "Loss: 0.0\n",
            "training error 0.022782436046092303, test error 0.05226615937077141\n",
            "Loss: 0.008724849569885507\n",
            "training error 0.022759513959829114, test error 0.05227911864137607\n",
            "Loss: 0.03352177637214737\n",
            "training error 0.0226817055862751, test error 0.05212990955959729\n",
            "Loss: 0.0\n",
            "training error 0.022733542851635397, test error 0.05234652124662696\n",
            "Loss: 0.4155228521584897\n",
            "training error 0.022580151200340775, test error 0.052256493166057835\n",
            "Loss: 0.24282337631111872\n",
            "training error 0.02264028528853334, test error 0.05146023886075048\n",
            "Loss: 0.0\n",
            "training error 0.022618690004107943, test error 0.05211201583638229\n",
            "Loss: 1.2665642252370546\n",
            "training error 0.02254144805245656, test error 0.05150241670273421\n",
            "Loss: 0.08196200196011194\n",
            "training error 0.022534322390551458, test error 0.05155639245569218\n",
            "Loss: 0.1868502693932017\n",
            "training error 0.022314536952996865, test error 0.05084369895605724\n",
            "Loss: 0.0\n",
            "training error 0.02229066523849637, test error 0.050947272240123354\n",
            "Loss: 0.20370918362102586\n",
            "training error 0.022220524006511398, test error 0.05107267401099362\n",
            "Loss: 0.45035089821903185\n",
            "training error 0.022192115083431767, test error 0.05069756428477958\n",
            "Loss: 0.0\n",
            "training error 0.022164398588259224, test error 0.05070696703454376\n",
            "Loss: 0.018546748540737568\n",
            "training error 0.022207621194940647, test error 0.050896798046256235\n",
            "Loss: 0.3929848786373924\n",
            "training error 0.022159328857707987, test error 0.051215718976383905\n",
            "Loss: 1.0220504651736961\n",
            "training error 0.022110909861014022, test error 0.05071641499323519\n",
            "Loss: 0.0371826708472911\n",
            "training error 0.021995588850676713, test error 0.050440176504938\n",
            "Loss: 0.0\n",
            "training error 0.02197425770726736, test error 0.050375855943066476\n",
            "Loss: 0.0\n",
            "training error 0.021915659431710255, test error 0.05017200001690758\n",
            "Loss: 0.0\n",
            "training error 0.02198804216221024, test error 0.050633082337990534\n",
            "Loss: 0.9190032706042572\n",
            "training error 0.021828514897014706, test error 0.05050136894617375\n",
            "Loss: 0.6564795685943814\n",
            "training error 0.021874551095817922, test error 0.05031874635595826\n",
            "Loss: 0.2924865243586705\n",
            "training error 0.021719150769487054, test error 0.050394502248159986\n",
            "Loss: 0.4434788949561952\n",
            "training error 0.021741592737838347, test error 0.05006717184671714\n",
            "Loss: 0.0\n",
            "training error 0.021750362663459477, test error 0.05053510675204454\n",
            "Loss: 0.934614215398466\n",
            "training error 0.021710263625327002, test error 0.05021136867826375\n",
            "Loss: 0.2880067441957346\n",
            "training error 0.021648034354663597, test error 0.049727608485092896\n",
            "Loss: 0.0\n",
            "training error 0.021620993284138662, test error 0.049828807488879745\n",
            "Loss: 0.20350667741679818\n",
            "training error 0.021615581955483618, test error 0.04955736421431547\n",
            "Loss: 0.0\n",
            "training error 0.02160250641252899, test error 0.04969620851165972\n",
            "Loss: 0.280168849868212\n",
            "training error 0.021582522917067064, test error 0.04958016809837617\n",
            "Loss: 0.0460151269588982\n",
            "training error 0.021487562008931507, test error 0.04911645425379749\n",
            "Loss: 0.0\n",
            "training error 0.021634576989773106, test error 0.04948273577690119\n",
            "Loss: 0.7457409714696217\n",
            "training error 0.021420117546322653, test error 0.04933217254331059\n",
            "Loss: 0.43919760249473416\n",
            "training error 0.021604729518785632, test error 0.04917686663090389\n",
            "Loss: 0.12299824574926177\n",
            "training error 0.021443539554602008, test error 0.04943393078637924\n",
            "Loss: 0.6463751046467348\n",
            "training error 0.021461022332019256, test error 0.048792661229959386\n",
            "Loss: 0.0\n",
            "training error 0.021348709110869744, test error 0.048722917413304985\n",
            "Loss: 0.0\n",
            "training error 0.021411684423102192, test error 0.048488372082110556\n",
            "Loss: 0.0\n",
            "training error 0.02133093613027676, test error 0.04899712854908139\n",
            "Loss: 1.0492339608954238\n",
            "training error 0.021265192696972655, test error 0.048785778723294836\n",
            "Loss: 0.6133566222447095\n",
            "training error 0.021293249997510675, test error 0.04861718658970696\n",
            "Loss: 0.265660615246599\n",
            "training error 0.021250986234519712, test error 0.04817389574984365\n",
            "Loss: 0.0\n",
            "training error 0.02118615344533669, test error 0.04846142651398926\n",
            "Loss: 0.5968601037348087\n",
            "training error 0.021225408882166126, test error 0.0487394962055392\n",
            "Loss: 1.1740807897965944\n",
            "training error 0.02109469187423127, test error 0.04849218159271395\n",
            "Loss: 0.6607018965688161\n",
            "training error 0.021118851989270174, test error 0.048255348748688434\n",
            "Loss: 0.1690811954834448\n",
            "training error 0.021204947900362665, test error 0.04783278416359412\n",
            "Loss: 0.0\n",
            "training error 0.021077764479110597, test error 0.048065073620322744\n",
            "Loss: 0.4856281330690715\n",
            "training error 0.021102214860334905, test error 0.04820264068418491\n",
            "Loss: 0.7732280841646899\n",
            "training error 0.021011122849864543, test error 0.04848035563306662\n",
            "Loss: 1.3538234932295001\n",
            "training error 0.021126437735882228, test error 0.048511394548561515\n",
            "Loss: 1.4187139570351226\n",
            "training error 0.02100173101731732, test error 0.04833390222252668\n",
            "Loss: 1.047645600596181\n",
            "training error 0.021159862365418388, test error 0.048014040022787974\n",
            "Loss: 0.3789364603447254\n",
            "training error 0.020983742091373207, test error 0.047466513699120166\n",
            "Loss: 0.0\n",
            "training error 0.02091557690454744, test error 0.04795983992197212\n",
            "Loss: 1.0393142120759924\n",
            "training error 0.020911188731908985, test error 0.04819449278257968\n",
            "Loss: 1.5336687418713968\n",
            "training error 0.020957926087741427, test error 0.04780238352406602\n",
            "Loss: 0.7075932036527011\n",
            "training error 0.02095654549324486, test error 0.04748736237862001\n",
            "Loss: 0.04392292139254739\n",
            "training error 0.020857427878628557, test error 0.04793079676210081\n",
            "Loss: 0.9781275825809121\n",
            "training error 0.020854336538568455, test error 0.047571380745990946\n",
            "Loss: 0.22092847925487824\n",
            "training error 0.02086883568239752, test error 0.04724185214232853\n",
            "Loss: 0.0\n",
            "training error 0.020899402207128943, test error 0.04773112419778711\n",
            "Loss: 1.035675006950454\n",
            "training error 0.02085144545806497, test error 0.04821905870860912\n",
            "Loss: 2.068518743372927\n",
            "training error 0.020814962765674284, test error 0.048161104893007685\n",
            "Loss: 1.9458440111739472\n",
            "training error 0.02077739354855143, test error 0.047867858201998854\n",
            "Loss: 1.3251090532697907\n",
            "training error 0.020825426998689563, test error 0.04765378253516107\n",
            "Loss: 0.8719607173560462\n",
            "training error 0.02083820246942237, test error 0.04731112940405175\n",
            "Loss: 0.14664383080176258\n",
            "training error 0.02066926522109784, test error 0.047401983671770384\n",
            "Loss: 0.33896115876113075\n",
            "training error 0.0206712679584716, test error 0.04739040749844124\n",
            "Loss: 0.3144570955117221\n",
            "training error 0.02065143301709352, test error 0.04729314935103575\n",
            "Loss: 0.10858424549629042\n",
            "training error 0.020699333262888024, test error 0.04716425967721325\n",
            "Loss: 0.0\n",
            "training error 0.020645157719554177, test error 0.0468908029891996\n",
            "Loss: 0.0\n",
            "training error 0.02061379568552214, test error 0.04728968072028311\n",
            "Loss: 0.8506523788372355\n",
            "training error 0.02057151280495037, test error 0.047311177146846926\n",
            "Loss: 0.8964959669045314\n",
            "training error 0.02058155114897702, test error 0.047226182778534485\n",
            "Loss: 0.7152357561719169\n",
            "training error 0.020512718627457502, test error 0.047524798957328244\n",
            "Loss: 1.352068908426829\n",
            "training error 0.02073521676125505, test error 0.04721881562913917\n",
            "Loss: 0.6995244675488399\n",
            "training error 0.020718914697173536, test error 0.047895819408734754\n",
            "Loss: 2.1433124524795177\n",
            "training error 0.020550099376585515, test error 0.047180857600573105\n",
            "Loss: 0.6185746305950701\n",
            "training error 0.020653599320898632, test error 0.047153573762039616\n",
            "Loss: 0.5603887246301564\n",
            "training error 0.020547686769800077, test error 0.047570949890838155\n",
            "Loss: 1.4504910521477177\n",
            "training error 0.020538600491692698, test error 0.046853840700051975\n",
            "Loss: 0.0\n",
            "training error 0.02043486831984267, test error 0.04685786045321556\n",
            "Loss: 0.008579346118731124\n",
            "training error 0.020489665379997083, test error 0.046562351466399005\n",
            "Loss: 0.0\n",
            "training error 0.02039435217935028, test error 0.04700912826626598\n",
            "Loss: 0.9595237048742877\n",
            "training error 0.020433065745594683, test error 0.0470542141868922\n",
            "Loss: 1.056352836579011\n",
            "training error 0.020398834264362703, test error 0.04662459251444849\n",
            "Loss: 0.13367247591522524\n",
            "training error 0.02043580504110315, test error 0.04691164618653342\n",
            "Loss: 0.7501655503513005\n",
            "training error 0.02033119668225357, test error 0.04683019064961317\n",
            "Loss: 0.5752269264309939\n",
            "training error 0.020350081022021037, test error 0.046806044486989155\n",
            "Loss: 0.5233692305381288\n",
            "training error 0.020328570425873594, test error 0.04670722705381405\n",
            "Loss: 0.3111431937014464\n",
            "training error 0.020371118886705605, test error 0.04641411787725978\n",
            "Loss: 0.0\n",
            "training error 0.020354621544166052, test error 0.04655643815249797\n",
            "Loss: 0.30663143402736015\n",
            "training error 0.020400671438385077, test error 0.04647310884855389\n",
            "Loss: 0.12709704286550938\n",
            "training error 0.02037873946449618, test error 0.04624272022111375\n",
            "Loss: 0.0\n",
            "training error 0.020306095470188964, test error 0.04672697628146321\n",
            "Loss: 1.0472049612002543\n",
            "training error 0.020332209457082383, test error 0.046574569463823705\n",
            "Loss: 0.7176248307261934\n",
            "training error 0.0203763297104679, test error 0.04626600841283208\n",
            "Loss: 0.05036077377578163\n",
            "training error 0.020204753254034275, test error 0.04625469430165402\n",
            "Loss: 0.02589397959940065\n",
            "training error 0.020237324128064713, test error 0.04605408308160286\n",
            "Loss: 0.0\n",
            "training error 0.020320983102036998, test error 0.04627113743937467\n",
            "Loss: 0.47130317932335686\n",
            "training error 0.020180244276742348, test error 0.04605363117816123\n",
            "Loss: 0.0\n",
            "training error 0.02021749638733637, test error 0.04615362491027082\n",
            "Loss: 0.21712453405196008\n",
            "training error 0.02018741152530004, test error 0.046185733977743434\n",
            "Loss: 0.2868455672282444\n",
            "training error 0.020183058998926955, test error 0.04634790157379296\n",
            "Loss: 0.6389732755128996\n",
            "training error 0.020210752412646506, test error 0.04641461264134885\n",
            "Loss: 0.7838284494682712\n",
            "training error 0.020114046180817333, test error 0.046471174032614165\n",
            "Loss: 0.9066448047009512\n",
            "training error 0.020130066436738987, test error 0.046572585622730346\n",
            "Loss: 1.1268480493134225\n",
            "training error 0.020185777237139726, test error 0.04596800794792178\n",
            "Loss: 0.0\n",
            "training error 0.02009192596960012, test error 0.0461374806802292\n",
            "Loss: 0.36867538941305344\n",
            "training error 0.02011444016573438, test error 0.04600942956912034\n",
            "Loss: 0.0901096720255623\n",
            "training error 0.02018813150656569, test error 0.04610169077068186\n",
            "Loss: 0.29081708937992445\n",
            "training error 0.020113124306693528, test error 0.046255045949377585\n",
            "Loss: 0.6244299334898118\n",
            "training error 0.020104982089581884, test error 0.04618144744706459\n",
            "Loss: 0.46432183744968825\n",
            "training error 0.02007184546670647, test error 0.04604877472327913\n",
            "Loss: 0.17570214364923675\n",
            "training error 0.020103955803521603, test error 0.04638337893446957\n",
            "Loss: 0.9036088468709957\n",
            "training error 0.02007810454008326, test error 0.046019206795474894\n",
            "Loss: 0.11137930451787792\n",
            "training error 0.020065936473464312, test error 0.04584256414684867\n",
            "Loss: 0.0\n",
            "training error 0.020068802540650917, test error 0.04604828719368687\n",
            "Loss: 0.4487599039600054\n",
            "training error 0.02004538402474482, test error 0.045922983003766814\n",
            "Loss: 0.1754239938685398\n",
            "training error 0.020094826897994397, test error 0.045768079464639476\n",
            "Loss: 0.0\n",
            "training error 0.02015534300513175, test error 0.04605592984677634\n",
            "Loss: 0.628932621827083\n",
            "training error 0.020002711873270074, test error 0.04597932038797679\n",
            "Loss: 0.46154640047877393\n",
            "training error 0.020013795115343694, test error 0.045887934711690954\n",
            "Loss: 0.26187519435696416\n",
            "training error 0.020046761970497345, test error 0.04609770218776915\n",
            "Loss: 0.7202022173212308\n",
            "training error 0.020072203842679152, test error 0.04616158551059875\n",
            "Loss: 0.8597827362699206\n",
            "training error 0.02007464274928599, test error 0.0459433641700429\n",
            "Loss: 0.3829846204030707\n",
            "training error 0.020036986064309443, test error 0.046018552151421116\n",
            "Loss: 0.5472650146378877\n",
            "training error 0.019990391494292825, test error 0.04616461358601079\n",
            "Loss: 0.8663988657808375\n",
            "training error 0.020162145861363154, test error 0.04599853920023235\n",
            "Loss: 0.5035381390012805\n",
            "training error 0.020065444628257368, test error 0.04570411305229427\n",
            "Loss: 0.0\n",
            "training error 0.02015152497736083, test error 0.046270022676620046\n",
            "Loss: 1.238202836751845\n",
            "training error 0.019995571836242208, test error 0.045890449952279616\n",
            "Loss: 0.4077026935675132\n",
            "training error 0.020016986813994535, test error 0.04618035191199375\n",
            "Loss: 1.0420043796814715\n",
            "training error 0.019948612472214324, test error 0.045893852474912365\n",
            "Loss: 0.4151473684676832\n",
            "training error 0.02001968972668064, test error 0.046099508740162005\n",
            "Loss: 0.8651205798815731\n",
            "training error 0.019937384689114126, test error 0.0456613790369873\n",
            "Loss: 0.0\n",
            "training error 0.020000088633881415, test error 0.04539782093948186\n",
            "Loss: 0.0\n",
            "training error 0.019979943120501133, test error 0.0458892649829519\n",
            "Loss: 1.0825278246838543\n",
            "training error 0.019916731539604698, test error 0.04561790693006234\n",
            "Loss: 0.48479417299316374\n",
            "training error 0.01998900553704024, test error 0.04531451669100781\n",
            "Loss: 0.0\n",
            "training error 0.019984602485201935, test error 0.045563782866677546\n",
            "Loss: 0.5500801815220502\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.045563782866677546\n",
            "training error 0.12308360421103581, test error 0.2363218794786175\n",
            "training error 0.1196852518080045, test error 0.23132259359629131\n",
            "training error 0.11930727707229058, test error 0.22765041980241854\n",
            "training error 0.11826088081712176, test error 0.2243216051993731\n",
            "training error 0.11813970037544307, test error 0.22430121031548148\n",
            "training error 0.11769187774511806, test error 0.22362155901002015\n",
            "training error 0.11789877502711588, test error 0.2240470843020312\n",
            "training error 0.11790999399995439, test error 0.22493906034997974\n",
            "training error 0.11765573140697863, test error 0.22431461191699908\n",
            "training error 0.11800078534284614, test error 0.22276793651712723\n",
            "training error 0.11755291811463578, test error 0.22278543056686873\n",
            "training error 0.11744202032914877, test error 0.22280070333124624\n",
            "training error 0.11786512549719944, test error 0.2236402926362716\n",
            "training error 0.11755947563613788, test error 0.22334941363869995\n",
            "training error 0.11749552654864162, test error 0.224062445678996\n",
            "training error 0.1175579181366951, test error 0.22255057974189793\n",
            "training error 0.11732930229260773, test error 0.22257935610915824\n",
            "training error 0.11744638290049787, test error 0.22247930306856845\n",
            "training error 0.11730863072106519, test error 0.2223250087425247\n",
            "training error 0.11733195677261614, test error 0.22265062618436657\n",
            "training error 0.11790513625357697, test error 0.22304524360892\n",
            "training error 0.11725520669468599, test error 0.22286031213775218\n",
            "training error 0.1171894887162568, test error 0.2228230069089621\n",
            "training error 0.11740423811791252, test error 0.22239250049179318\n",
            "training error 0.1173102921686688, test error 0.22343525470695522\n",
            "training error 0.11716858138476914, test error 0.222390721205225\n",
            "training error 0.11761816249053669, test error 0.2213064623470471\n",
            "training error 0.11704167843227195, test error 0.22218917855323606\n",
            "training error 0.11721642745562989, test error 0.2223488595969813\n",
            "training error 0.11709001507939579, test error 0.22228589401324905\n",
            "training error 0.11709820838402692, test error 0.2220127902049142\n",
            "training error 0.11692240322688963, test error 0.222210626820361\n",
            "training error 0.11738149478520295, test error 0.222877984182797\n",
            "training error 0.11706444989643904, test error 0.2226117139831677\n",
            "training error 0.1170373210573573, test error 0.22210009355078192\n",
            "training error 0.11690229389002797, test error 0.22234192706400152\n",
            "training error 0.11694179331310496, test error 0.22195878908246094\n",
            "training error 0.11739132976795537, test error 0.22087268732758217\n",
            "training error 0.11699852546707393, test error 0.22139961569868874\n",
            "training error 0.11686718795752528, test error 0.22123304533015103\n",
            "training error 0.11715836362447399, test error 0.2211512133424438\n",
            "training error 0.11688733680353007, test error 0.22155061448081337\n",
            "training error 0.11683612839757772, test error 0.2212749558895544\n",
            "training error 0.11684237021342724, test error 0.22178054900381336\n",
            "training error 0.11695158325386158, test error 0.22216708800563406\n",
            "training error 0.11674237393033719, test error 0.2217875656079259\n",
            "training error 0.11669344105983134, test error 0.22225275884019235\n",
            "training error 0.11677869040920688, test error 0.2213558070079117\n",
            "training error 0.1167558367841318, test error 0.22051525834131622\n",
            "training error 0.11674327267903968, test error 0.22040442712445155\n",
            "Loss: 0.0\n",
            "training error 0.11665902028671597, test error 0.22097609424184372\n",
            "Loss: 0.25937188506173214\n",
            "training error 0.1169063193442141, test error 0.22137285439353763\n",
            "Loss: 0.4393864867965114\n",
            "training error 0.11667276142122149, test error 0.22078234196004692\n",
            "Loss: 0.17146426708660734\n",
            "training error 0.11671746256076766, test error 0.22207188814519183\n",
            "Loss: 0.7565460651109079\n",
            "training error 0.11657065967762029, test error 0.22254118606787263\n",
            "Loss: 0.9694718800791424\n",
            "training error 0.11726735786093581, test error 0.2220188663187953\n",
            "Loss: 0.7324894583139008\n",
            "training error 0.11690526808818359, test error 0.22081652527697035\n",
            "Loss: 0.18697362747894797\n",
            "training error 0.11653047183636209, test error 0.22086066975534427\n",
            "Loss: 0.20700248032454738\n",
            "training error 0.11661250341034614, test error 0.22060431986823634\n",
            "Loss: 0.0906936155469884\n",
            "training error 0.11650156828115854, test error 0.2212089772035838\n",
            "Loss: 0.3650335384043579\n",
            "training error 0.11640305084573924, test error 0.22100965519751212\n",
            "Loss: 0.27459887306111597\n",
            "training error 0.1166849962418924, test error 0.22157083657940221\n",
            "Loss: 0.529213260445105\n",
            "training error 0.11674278544377148, test error 0.22100122711977616\n",
            "Loss: 0.27077495815799324\n",
            "training error 0.11652842000399373, test error 0.22119409500272172\n",
            "Loss: 0.35828131429695986\n",
            "training error 0.11662991024055393, test error 0.22137233680956148\n",
            "Loss: 0.4391516530488637\n",
            "training error 0.11671230779391115, test error 0.22052570875613367\n",
            "Loss: 0.0550268582462099\n",
            "training error 0.11623174430291498, test error 0.22122568743799154\n",
            "Loss: 0.372615162161094\n",
            "training error 0.11626423478573199, test error 0.22092391980443302\n",
            "Loss: 0.2356997483032197\n",
            "training error 0.11639680227766272, test error 0.22149475877904348\n",
            "Loss: 0.4946958955485359\n",
            "training error 0.11620404784377732, test error 0.22119252407338494\n",
            "Loss: 0.35756856575679397\n",
            "training error 0.11663962283124236, test error 0.2205242078894119\n",
            "Loss: 0.05434589791279976\n",
            "training error 0.11617459912541758, test error 0.2213330464557095\n",
            "Loss: 0.4213251718095501\n",
            "training error 0.1164339347794945, test error 0.22075922609877954\n",
            "Loss: 0.16097633743430428\n",
            "training error 0.11611572001372292, test error 0.22125438033625\n",
            "Loss: 0.3856334570441877\n",
            "training error 0.11611192465969439, test error 0.22126340167292863\n",
            "Loss: 0.3897265402895256\n",
            "training error 0.11651761075697449, test error 0.22096544911401805\n",
            "Loss: 0.254542069270558\n",
            "training error 0.11615502600286642, test error 0.22146749096966317\n",
            "Loss: 0.48232417972773334\n",
            "training error 0.11603105615191533, test error 0.22141658858804722\n",
            "Loss: 0.4592291891778455\n",
            "training error 0.11610480431036416, test error 0.22159704803103256\n",
            "Loss: 0.5411056947180137\n",
            "training error 0.11607405883657873, test error 0.22215097899086378\n",
            "Loss: 0.7924304829984408\n",
            "training error 0.11619617042709708, test error 0.2212699212702625\n",
            "Loss: 0.3926845558879011\n",
            "training error 0.11604957669049021, test error 0.221769728005344\n",
            "Loss: 0.6194525666771478\n",
            "training error 0.11605513687956491, test error 0.22195941846956438\n",
            "Loss: 0.7055172917351582\n",
            "training error 0.1162189876647875, test error 0.22110118565641268\n",
            "Loss: 0.31612728521450695\n",
            "training error 0.1160221314417501, test error 0.22133742770843914\n",
            "Loss: 0.4233129960954818\n",
            "training error 0.11606279958047423, test error 0.22069950064077348\n",
            "Loss: 0.1338782165910546\n",
            "training error 0.11600536930789701, test error 0.22124479851004353\n",
            "Loss: 0.3812860733135137\n",
            "training error 0.11610112739194581, test error 0.22045201340878914\n",
            "Loss: 0.021590439429197694\n",
            "training error 0.1159258134927564, test error 0.22045013805812116\n",
            "Loss: 0.02073957146233596\n",
            "training error 0.11627823161646139, test error 0.22160584554118595\n",
            "Loss: 0.5450972253184583\n",
            "training error 0.11603064284957681, test error 0.2216837126157601\n",
            "Loss: 0.5804264043145491\n",
            "training error 0.11597683845001057, test error 0.22114535235700727\n",
            "Loss: 0.33616622053482814\n",
            "training error 0.11599307993393015, test error 0.22056652087679987\n",
            "Loss: 0.07354378242900861\n",
            "training error 0.11623164246579802, test error 0.22128983153670945\n",
            "Loss: 0.4017180706438195\n",
            "training error 0.1158305839768268, test error 0.2213467733255952\n",
            "Loss: 0.4275532090884715\n",
            "training error 0.11601200908555713, test error 0.22149215334471622\n",
            "Loss: 0.49351378030646487\n",
            "training error 0.11640652853091751, test error 0.2222275831428767\n",
            "Loss: 0.8271866596380573\n",
            "training error 0.1157779051438537, test error 0.2208361804985585\n",
            "Loss: 0.19589142547629113\n",
            "training error 0.11586916412147827, test error 0.22116948359706337\n",
            "Loss: 0.3471148391133827\n",
            "training error 0.11583725975688411, test error 0.22126239582514623\n",
            "Loss: 0.3892701756894601\n",
            "training error 0.11579710926746573, test error 0.22077999799571324\n",
            "Loss: 0.17040078375996082\n",
            "training error 0.11576143050796052, test error 0.22043288892947055\n",
            "Loss: 0.012913445247142441\n",
            "training error 0.11580998283961859, test error 0.2207058947194601\n",
            "Loss: 0.13677928294892894\n",
            "training error 0.11574068984822364, test error 0.22057472427831754\n",
            "Loss: 0.07726575917181844\n",
            "training error 0.11562317081024916, test error 0.22058905126278502\n",
            "Loss: 0.08376607527453839\n",
            "training error 0.11560854652251865, test error 0.22064561380329298\n",
            "Loss: 0.10942914440881246\n",
            "training error 0.11577737599725751, test error 0.22053909180026668\n",
            "Loss: 0.061098897863387513\n",
            "training error 0.115923306630371, test error 0.21984385069819629\n",
            "Loss: 0.0\n",
            "training error 0.11564962573372331, test error 0.2206332772665217\n",
            "Loss: 0.35908512601936504\n",
            "training error 0.11576970481638461, test error 0.22044815184716246\n",
            "Loss: 0.2748774400771259\n",
            "training error 0.11562575367409816, test error 0.22057075052985275\n",
            "Loss: 0.3306436952172698\n",
            "training error 0.11552498170733912, test error 0.22069908241692818\n",
            "Loss: 0.3890178033252978\n",
            "training error 0.11562832634959885, test error 0.22107384716449624\n",
            "Loss: 0.5594864092826057\n",
            "training error 0.11584090396216112, test error 0.2209877579145391\n",
            "Loss: 0.520327137970833\n",
            "training error 0.11553379153887294, test error 0.22063912544815\n",
            "Loss: 0.36174527849108795\n",
            "training error 0.11552387758849068, test error 0.2206734118963508\n",
            "Loss: 0.3773410971104951\n",
            "training error 0.1155944239923551, test error 0.22020347751569647\n",
            "Loss: 0.16358284134765366\n",
            "training error 0.11554394934288578, test error 0.22026002381200283\n",
            "Loss: 0.189303959371534\n",
            "training error 0.11549238759482391, test error 0.2199746154972921\n",
            "Loss: 0.059480762677943666\n",
            "training error 0.11555486062059737, test error 0.2201843837022898\n",
            "Loss: 0.15489767078407102\n",
            "training error 0.11548081290379708, test error 0.22054243620778954\n",
            "Loss: 0.3177644074986219\n",
            "training error 0.11556265286676977, test error 0.22046376360304226\n",
            "Loss: 0.28197873303128507\n",
            "training error 0.11539353929857434, test error 0.22088261877647664\n",
            "Loss: 0.47250267632292786\n",
            "training error 0.11546617165356723, test error 0.22088114880395146\n",
            "Loss: 0.47183403241020105\n",
            "training error 0.1153761869088841, test error 0.2206355721241123\n",
            "Loss: 0.3601289840046151\n",
            "training error 0.11584565819240375, test error 0.22180408942881247\n",
            "Loss: 0.8916504711824924\n",
            "training error 0.11543855886772415, test error 0.22164633739934497\n",
            "Loss: 0.8198940727358162\n",
            "training error 0.11542080035863785, test error 0.22131789220902515\n",
            "Loss: 0.6704947653288773\n",
            "training error 0.11569391819820596, test error 0.22070260632756142\n",
            "Loss: 0.39062071858630976\n",
            "training error 0.11533016974019358, test error 0.22053358467915551\n",
            "Loss: 0.3137381276614004\n",
            "training error 0.11529322049179162, test error 0.2202428609637287\n",
            "Loss: 0.1814971236471674\n",
            "training error 0.11539926710403282, test error 0.22031905691235804\n",
            "Loss: 0.2161562457410282\n",
            "training error 0.11533272364007537, test error 0.2209567490877334\n",
            "Loss: 0.5062222054438736\n",
            "training error 0.11535779462743216, test error 0.22090202152125613\n",
            "Loss: 0.48132836997678563\n",
            "training error 0.11525644675091813, test error 0.22089719808605182\n",
            "Loss: 0.4791343421752581\n",
            "training error 0.11526901732510698, test error 0.22112505636137117\n",
            "Loss: 0.5827798499280057\n",
            "training error 0.1153396961305083, test error 0.22134425442816827\n",
            "Loss: 0.6824861032987295\n",
            "training error 0.11522387086487544, test error 0.2207509299493365\n",
            "Loss: 0.41260160257357015\n",
            "training error 0.11524938660056705, test error 0.22028567093967794\n",
            "Loss: 0.2009700248965185\n",
            "training error 0.1151480181970024, test error 0.22008571545090735\n",
            "Loss: 0.11001661040004329\n",
            "training error 0.11517651095179864, test error 0.21974814134674509\n",
            "Loss: 0.0\n",
            "training error 0.1151274353159628, test error 0.21964589456931644\n",
            "Loss: 0.0\n",
            "training error 0.11523165005170471, test error 0.21972130614554325\n",
            "Loss: 0.03433325096955375\n",
            "training error 0.1152739487316356, test error 0.22017253412044777\n",
            "Loss: 0.23976753681829166\n",
            "training error 0.11509784232389313, test error 0.22017895696460257\n",
            "Loss: 0.24269171810900048\n",
            "training error 0.1151080489919134, test error 0.22008739000538424\n",
            "Loss: 0.201003272532585\n",
            "training error 0.115226199961277, test error 0.22057560858948067\n",
            "Loss: 0.4232785784533899\n",
            "training error 0.11509570844870048, test error 0.22007797890612482\n",
            "Loss: 0.19671860366687888\n",
            "training error 0.11506610019176168, test error 0.22020446211027114\n",
            "Loss: 0.254303656369248\n",
            "training error 0.11513968911300458, test error 0.21988711224614083\n",
            "Loss: 0.10982116342186377\n",
            "training error 0.11527868019800196, test error 0.22022596588975082\n",
            "Loss: 0.2640938596060627\n",
            "training error 0.11505449406735148, test error 0.22052426137695968\n",
            "Loss: 0.3999013090436154\n",
            "training error 0.11501013597194454, test error 0.22045360940772132\n",
            "Loss: 0.367735003646974\n",
            "training error 0.11498980108744919, test error 0.2203963687020184\n",
            "Loss: 0.3416745549346567\n",
            "training error 0.11533545362651797, test error 0.220010768470076\n",
            "Loss: 0.16611915350159823\n",
            "training error 0.11492524570537693, test error 0.21969308364800152\n",
            "Loss: 0.021484161485285647\n",
            "training error 0.11511137445058046, test error 0.21942107500421848\n",
            "Loss: 0.0\n",
            "training error 0.11518306440566962, test error 0.21916083694241792\n",
            "Loss: 0.0\n",
            "training error 0.11497344344123976, test error 0.21909115917229244\n",
            "Loss: 0.0\n",
            "training error 0.11505451101080322, test error 0.21962231084150888\n",
            "Loss: 0.24243409511506275\n",
            "training error 0.11497249051377918, test error 0.21920792374036768\n",
            "Loss: 0.053294970238138006\n",
            "training error 0.11489046402769006, test error 0.21927027269343108\n",
            "Loss: 0.0817529661239158\n",
            "training error 0.11492714043537149, test error 0.21923495134889873\n",
            "Loss: 0.06563120901341701\n",
            "training error 0.11495798158998548, test error 0.21902416706959404\n",
            "Loss: 0.0\n",
            "training error 0.1149790451268435, test error 0.21920094773690083\n",
            "Loss: 0.0807128590748718\n",
            "training error 0.11489182066991495, test error 0.21899799564017183\n",
            "Loss: 0.0\n",
            "training error 0.11492535575049954, test error 0.21923100886940158\n",
            "Loss: 0.1063997086131252\n",
            "training error 0.114924496727596, test error 0.21963119921241955\n",
            "Loss: 0.289136697528547\n",
            "training error 0.11479275549048233, test error 0.21962177545969508\n",
            "Loss: 0.2848335747091202\n",
            "training error 0.11484447863704467, test error 0.2200225322932572\n",
            "Loss: 0.4678292374733495\n",
            "training error 0.11493159350655739, test error 0.21981958489315132\n",
            "Loss: 0.375158343608506\n",
            "training error 0.11473813402227245, test error 0.21989020932290973\n",
            "Loss: 0.40740723682415325\n",
            "training error 0.11476410799424167, test error 0.22021951202916962\n",
            "Loss: 0.5577751455793312\n",
            "training error 0.11477673691689452, test error 0.22014855298124597\n",
            "Loss: 0.5253734572824964\n",
            "training error 0.11514455876113869, test error 0.22047466494755558\n",
            "Loss: 0.6742843938215781\n",
            "training error 0.11495723595296926, test error 0.21981949819177105\n",
            "Loss: 0.37511875357481017\n",
            "training error 0.11481709814152094, test error 0.21919662696164038\n",
            "Loss: 0.09070006366400651\n",
            "training error 0.11489114151748757, test error 0.2195898802791632\n",
            "Loss: 0.27026943203802833\n",
            "training error 0.11476067935101178, test error 0.2189667361930973\n",
            "Loss: 0.0\n",
            "training error 0.11493691623914405, test error 0.21973671047471025\n",
            "Loss: 0.3516398403700549\n",
            "training error 0.11477121471008564, test error 0.21988056725493102\n",
            "Loss: 0.4173378467073885\n",
            "training error 0.11462849501641383, test error 0.21978258225015754\n",
            "Loss: 0.3725890385198882\n",
            "training error 0.11474151882672984, test error 0.22010977784483263\n",
            "Loss: 0.5220161160585324\n",
            "training error 0.11514124678911299, test error 0.22031876112778204\n",
            "Loss: 0.6174567690922839\n",
            "training error 0.11564054323895873, test error 0.21924820223243455\n",
            "Loss: 0.12854282994336774\n",
            "training error 0.11480005293522282, test error 0.21955024273251078\n",
            "Loss: 0.2664818179958228\n",
            "training error 0.11466259914499174, test error 0.21925785861228422\n",
            "Loss: 0.13295280563994094\n",
            "training error 0.11456276823041002, test error 0.21916273807776285\n",
            "Loss: 0.08951217343473594\n",
            "training error 0.11484907160454313, test error 0.21906164266158962\n",
            "Loss: 0.043342870310958403\n",
            "training error 0.11459119355728031, test error 0.21947953290714767\n",
            "Loss: 0.2341893216137425\n",
            "training error 0.11455679615936375, test error 0.21926333067439865\n",
            "Loss: 0.1354518437173935\n",
            "training error 0.11453223506036153, test error 0.2190601808162164\n",
            "Loss: 0.042675259605040594\n",
            "training error 0.11447292685771279, test error 0.21916652342257587\n",
            "Loss: 0.09124090396195328\n",
            "training error 0.11453290852663608, test error 0.21943276007763723\n",
            "Loss: 0.21282862074947229\n",
            "training error 0.11480551630464673, test error 0.21965815489882326\n",
            "Loss: 0.31576426527004653\n",
            "training error 0.11465643073729971, test error 0.21903375618574872\n",
            "Loss: 0.030607385311842705\n",
            "training error 0.11441473076694923, test error 0.2192222632827888\n",
            "Loss: 0.11669676140495522\n",
            "training error 0.11443232411975553, test error 0.21924794049082663\n",
            "Loss: 0.12842329507132266\n",
            "training error 0.11441355353434372, test error 0.21923941629579827\n",
            "Loss: 0.12453037728090699\n",
            "training error 0.11446734129108707, test error 0.21913889515966234\n",
            "Loss: 0.07862334232044965\n",
            "training error 0.11448853141794528, test error 0.21949459239414984\n",
            "Loss: 0.24106684432061432\n",
            "training error 0.11453122765050068, test error 0.21936209777606344\n",
            "Loss: 0.1805578280243747\n",
            "training error 0.11440566402191259, test error 0.21923250544853595\n",
            "Loss: 0.1213742598803913\n",
            "training error 0.1143956605421727, test error 0.21923586173475784\n",
            "Loss: 0.1229070434804358\n",
            "training error 0.11445021974802752, test error 0.21897642280137958\n",
            "Loss: 0.004423780730666849\n",
            "training error 0.11446907537267369, test error 0.21923943876794308\n",
            "Loss: 0.12454064009306265\n",
            "training error 0.11444033864168367, test error 0.2193681965781709\n",
            "Loss: 0.18334309222181044\n",
            "training error 0.11447105150193128, test error 0.21965549076537863\n",
            "Loss: 0.3145475811787035\n",
            "training error 0.11449244584936501, test error 0.21983652262133188\n",
            "Loss: 0.397223086646159\n",
            "training error 0.11441076445342384, test error 0.2196555503449521\n",
            "Loss: 0.3145747905962004\n",
            "training error 0.1145544018290168, test error 0.2192336080413075\n",
            "Loss: 0.1218778033823531\n",
            "training error 0.11444878566924467, test error 0.21930476110908118\n",
            "Loss: 0.15437272430538496\n",
            "training error 0.11423256525225026, test error 0.21910398006838444\n",
            "Loss: 0.06267795632945994\n",
            "training error 0.11445445685923397, test error 0.21912831986205572\n",
            "Loss: 0.07379370573250554\n",
            "training error 0.11423641202704242, test error 0.219046798719912\n",
            "Loss: 0.036563785078347344\n",
            "training error 0.11421245832539793, test error 0.21884130559255766\n",
            "Loss: 0.0\n",
            "training error 0.11452692731813456, test error 0.2185984682095433\n",
            "Loss: 0.0\n",
            "training error 0.11443721319975134, test error 0.2193226758428501\n",
            "Loss: 0.3312958408347999\n",
            "training error 0.11424325022731271, test error 0.21900064471716388\n",
            "Loss: 0.18397956349587297\n",
            "training error 0.11436668789824396, test error 0.21922322314324505\n",
            "Loss: 0.285800234017608\n",
            "training error 0.11435949806219718, test error 0.21915051071258473\n",
            "Loss: 0.2525372238712409\n",
            "training error 0.11426610175124162, test error 0.21954517817646127\n",
            "Loss: 0.4330817021144462\n",
            "training error 0.11421132026137946, test error 0.21948691224721675\n",
            "Loss: 0.4064273848533251\n",
            "training error 0.11419072496414133, test error 0.21921846752290644\n",
            "Loss: 0.28362472913983083\n",
            "training error 0.11411894513492643, test error 0.2191651315549927\n",
            "Loss: 0.2592256707426799\n",
            "training error 0.1144056004792791, test error 0.21925664105104076\n",
            "Loss: 0.3010875816689351\n",
            "training error 0.11428429654738202, test error 0.2193870948549925\n",
            "Loss: 0.36076494584273977\n",
            "training error 0.11423855520126602, test error 0.21935031265134575\n",
            "Loss: 0.3439385682619589\n",
            "training error 0.11417712449846348, test error 0.21956141395244835\n",
            "Loss: 0.4405089160926856\n",
            "training error 0.11410169172935428, test error 0.21957906321461604\n",
            "Loss: 0.4485827431017331\n",
            "training error 0.11417606632058414, test error 0.2193605748448998\n",
            "Loss: 0.348633108730656\n",
            "training error 0.1141403343741435, test error 0.21962314516540266\n",
            "Loss: 0.4687484611635595\n",
            "training error 0.11416013672133783, test error 0.21953276075786698\n",
            "Loss: 0.427401232943736\n",
            "training error 0.11414123403155492, test error 0.21955348793624088\n",
            "Loss: 0.4368830827223169\n",
            "training error 0.11421386393811712, test error 0.21971165084219346\n",
            "Loss: 0.5092362456918575\n",
            "training error 0.11407889370816897, test error 0.2194190616524926\n",
            "Loss: 0.3753884689451148\n",
            "training error 0.11411680926404688, test error 0.21903850120709664\n",
            "Loss: 0.20129738380945117\n",
            "training error 0.11413345675489611, test error 0.2187609680992283\n",
            "Loss: 0.07433715845128752\n",
            "training error 0.11403380467213947, test error 0.2189972982954278\n",
            "Loss: 0.1824487102545458\n",
            "training error 0.11401447471268863, test error 0.21921937833060295\n",
            "Loss: 0.28404138699840153\n",
            "training error 0.11416301535771435, test error 0.218797162020296\n",
            "Loss: 0.09089442043219709\n",
            "training error 0.11413043484636516, test error 0.21922488035285967\n",
            "Loss: 0.28655834070892006\n",
            "training error 0.11400892795349961, test error 0.21898927654681066\n",
            "Loss: 0.17877908316024094\n",
            "training error 0.11409730631915047, test error 0.2190870685110032\n",
            "Loss: 0.2235149703755379\n",
            "training error 0.11415132796604309, test error 0.21912831584560136\n",
            "Loss: 0.24238396563245335\n",
            "training error 0.1140478506095808, test error 0.21907458147545164\n",
            "Loss: 0.21780265424913292\n",
            "training error 0.11398571948264967, test error 0.21894784064262868\n",
            "Loss: 0.15982382490917768\n",
            "training error 0.11398028786232518, test error 0.21908891189996718\n",
            "Loss: 0.22435824662492276\n",
            "training error 0.11397203095745918, test error 0.2188933361149\n",
            "Loss: 0.134890197434534\n",
            "training error 0.11391665306397912, test error 0.2187994495348995\n",
            "Loss: 0.09194086628436793\n",
            "training error 0.11409985116922103, test error 0.21861638659526694\n",
            "Loss: 0.00819694020293138\n",
            "training error 0.11384724270893429, test error 0.2190097163384976\n",
            "Loss: 0.18812946509767503\n",
            "training error 0.11383481621578564, test error 0.21899070966944534\n",
            "Loss: 0.17943467907837185\n",
            "training error 0.11391631737567597, test error 0.21910512661427514\n",
            "Loss: 0.23177582573277178\n",
            "training error 0.11401509484480647, test error 0.21887744498893213\n",
            "Loss: 0.12762064696694164\n",
            "training error 0.11395540488226952, test error 0.21900049546866715\n",
            "Loss: 0.18391128831629633\n",
            "training error 0.11377389171018293, test error 0.218519130663137\n",
            "Loss: 0.0\n",
            "training error 0.11384672424789971, test error 0.218637820835739\n",
            "Loss: 0.05431568954250565\n",
            "training error 0.1138515304208546, test error 0.21877158265103816\n",
            "Loss: 0.11552855218444069\n",
            "training error 0.11391031064053282, test error 0.21842850852027929\n",
            "Loss: 0.0\n",
            "training error 0.11393314058958924, test error 0.2182977784902815\n",
            "Loss: 0.0\n",
            "training error 0.1138276831715749, test error 0.21828259682607284\n",
            "Loss: 0.0\n",
            "training error 0.11387794171214193, test error 0.21830210582596712\n",
            "Loss: 0.00893749670287658\n",
            "training error 0.11376045162577818, test error 0.2184209863252389\n",
            "Loss: 0.06339923620952703\n",
            "training error 0.11380541477313519, test error 0.21857036148834927\n",
            "Loss: 0.1318312437457836\n",
            "training error 0.11366283178798235, test error 0.21851112714180176\n",
            "Loss: 0.10469470267069347\n",
            "training error 0.1139235291773483, test error 0.2182557492758906\n",
            "Loss: 0.0\n",
            "training error 0.11373219071381606, test error 0.21854346560759907\n",
            "Loss: 0.13182531624620353\n",
            "training error 0.11377912964099932, test error 0.21847600949325194\n",
            "Loss: 0.10091840333741331\n",
            "training error 0.11373439635407553, test error 0.21844037198337848\n",
            "Loss: 0.08459007751246972\n",
            "training error 0.1138141358610996, test error 0.21833440037798504\n",
            "Loss: 0.036036210892675946\n",
            "training error 0.11366556775926047, test error 0.21801795455489129\n",
            "Loss: 0.0\n",
            "training error 0.1137818261126116, test error 0.2183673179251057\n",
            "Loss: 0.16024522885176307\n",
            "training error 0.11376956075148104, test error 0.21816203390375258\n",
            "Loss: 0.06608600156599032\n",
            "training error 0.11371226039682648, test error 0.21867916957898562\n",
            "Loss: 0.3032846654507315\n",
            "training error 0.113717064015536, test error 0.21848916051396164\n",
            "Loss: 0.21613172182648466\n",
            "training error 0.1136316245135374, test error 0.21818796706637708\n",
            "Loss: 0.07798096805049504\n",
            "training error 0.11357340420007755, test error 0.21829041641630298\n",
            "Loss: 0.12497221248037871\n",
            "training error 0.11357275739013376, test error 0.2185173051160627\n",
            "Loss: 0.22904102654797143\n",
            "training error 0.11370236655948579, test error 0.21857076349575377\n",
            "Loss: 0.2535611995769349\n",
            "training error 0.11353896680341456, test error 0.218521309910008\n",
            "Loss: 0.2308779367022229\n",
            "training error 0.11353482115931829, test error 0.21826174909874652\n",
            "Loss: 0.11182314977358221\n",
            "training error 0.1134927163592827, test error 0.21844436934759978\n",
            "Loss: 0.19558700730821776\n",
            "training error 0.11356443255183346, test error 0.21817961223438698\n",
            "Loss: 0.07414879193126112\n",
            "training error 0.11361656564026472, test error 0.2178442095453717\n",
            "Loss: 0.0\n",
            "training error 0.11352553278534801, test error 0.2180455252575009\n",
            "Loss: 0.0924126982990936\n",
            "training error 0.11350140726577121, test error 0.21814389996749814\n",
            "Loss: 0.1375709837557082\n",
            "training error 0.11353386465190012, test error 0.2180137609966229\n",
            "Loss: 0.07783151620373019\n",
            "training error 0.11361826677205743, test error 0.21757253601515364\n",
            "Loss: 0.0\n",
            "training error 0.11356309870399614, test error 0.2174901049101185\n",
            "Loss: 0.0\n",
            "training error 0.113499451633187, test error 0.21766207315868125\n",
            "Loss: 0.0790694586467744\n",
            "training error 0.11350267980510324, test error 0.21804205185880912\n",
            "Loss: 0.25378025768976187\n",
            "training error 0.1134640823668174, test error 0.2181910400547209\n",
            "Loss: 0.3222836941901619\n",
            "training error 0.1135054080010859, test error 0.21828989557735262\n",
            "Loss: 0.36773657705699847\n",
            "training error 0.11338654694760375, test error 0.21813993219633385\n",
            "Loss: 0.2987847591888748\n",
            "training error 0.11336281802906686, test error 0.2181144739486506\n",
            "Loss: 0.2870792851886961\n",
            "training error 0.1135277528405453, test error 0.21819812483958317\n",
            "Loss: 0.3255412147404435\n",
            "training error 0.11351254103787758, test error 0.21777443357954013\n",
            "Loss: 0.13073177261979652\n",
            "training error 0.11335654696573322, test error 0.21805888652071695\n",
            "Loss: 0.26152068427827135\n",
            "training error 0.11333375959223764, test error 0.21820434572298028\n",
            "Loss: 0.32840152114366195\n",
            "training error 0.11333756055411887, test error 0.21801880917119212\n",
            "Loss: 0.243093478341061\n",
            "training error 0.11340073287281693, test error 0.217837298720595\n",
            "Loss: 0.15963660076396824\n",
            "training error 0.11339357941645184, test error 0.21804928493319703\n",
            "Loss: 0.25710596043420075\n",
            "training error 0.11333941856886531, test error 0.21782437647704442\n",
            "Loss: 0.15369506905340558\n",
            "training error 0.11338373786990018, test error 0.2182881573112528\n",
            "Loss: 0.36693733789134875\n",
            "training error 0.11328545509874952, test error 0.21800003434593293\n",
            "Loss: 0.23446098204107368\n",
            "training error 0.11319573684298721, test error 0.21790646691485863\n",
            "Loss: 0.19143951625395506\n",
            "training error 0.11318395822301505, test error 0.2177767120157947\n",
            "Loss: 0.13177937717885335\n",
            "training error 0.11328709402156986, test error 0.21741899472719764\n",
            "Loss: 0.0\n",
            "training error 0.11329060909803239, test error 0.21744142552305332\n",
            "Loss: 0.010316851976899244\n",
            "training error 0.11324573100665931, test error 0.21735841017913507\n",
            "Loss: 0.0\n",
            "training error 0.1133133049534217, test error 0.21758513140195887\n",
            "Loss: 0.10430754560495359\n",
            "training error 0.11327080759320475, test error 0.21756083022091796\n",
            "Loss: 0.09312731060926449\n",
            "training error 0.1131850439895662, test error 0.2174470421589431\n",
            "Loss: 0.040776880791026926\n",
            "training error 0.11321860718179173, test error 0.2174879974220803\n",
            "Loss: 0.05961915291818887\n",
            "training error 0.11320186109728989, test error 0.21719451651074198\n",
            "Loss: 0.0\n",
            "training error 0.1131227924006871, test error 0.21714681484493933\n",
            "Loss: 0.0\n",
            "training error 0.11327036562962618, test error 0.21736035433625636\n",
            "Loss: 0.0983387628639587\n",
            "training error 0.11315662990002723, test error 0.21722551631109788\n",
            "Loss: 0.03624343567496524\n",
            "training error 0.1130270590510826, test error 0.21741073247623893\n",
            "Loss: 0.12153879921659172\n",
            "training error 0.11307462080436328, test error 0.2173177609097547\n",
            "Loss: 0.07872372658903615\n",
            "training error 0.11319622154254108, test error 0.2177396689217041\n",
            "Loss: 0.27301992764117156\n",
            "training error 0.11304698671021807, test error 0.21746426200135874\n",
            "Loss: 0.14619010490486417\n",
            "training error 0.11301850529127598, test error 0.21757158311132999\n",
            "Loss: 0.19561339948457324\n",
            "training error 0.1129888221509103, test error 0.21749498647301205\n",
            "Loss: 0.16033927475349596\n",
            "training error 0.11302292670227153, test error 0.2176076797027588\n",
            "Loss: 0.21223652677040405\n",
            "training error 0.1130360119277243, test error 0.21762435833017482\n",
            "Loss: 0.21991733361435006\n",
            "training error 0.11293820518884828, test error 0.21732793247664123\n",
            "Loss: 0.08340791543786086\n",
            "training error 0.11305399417740371, test error 0.2171334260020391\n",
            "Loss: 0.0\n",
            "training error 0.11288558577544094, test error 0.21742723014072146\n",
            "Loss: 0.13531041447281122\n",
            "training error 0.11291658114580012, test error 0.21732720420685495\n",
            "Loss: 0.0892438388615524\n",
            "training error 0.11302520496357507, test error 0.21749161357955185\n",
            "Loss: 0.1649619702078331\n",
            "training error 0.11293069482403115, test error 0.21712235036657615\n",
            "Loss: 0.0\n",
            "training error 0.1130413037375462, test error 0.21722041994143793\n",
            "Loss: 0.0451678856166593\n",
            "training error 0.1129421615898936, test error 0.21708630638096674\n",
            "Loss: 0.0\n",
            "training error 0.11292047840045863, test error 0.2169997481171508\n",
            "Loss: 0.0\n",
            "training error 0.11276844021260325, test error 0.21720859438642576\n",
            "Loss: 0.0962426321168719\n",
            "training error 0.1129065172167242, test error 0.21701444549224694\n",
            "Loss: 0.006772991777026505\n",
            "training error 0.11298403543429153, test error 0.21699135273937448\n",
            "Loss: 0.0\n",
            "training error 0.11281641133758753, test error 0.21693231377528377\n",
            "Loss: 0.0\n",
            "training error 0.11276189582964244, test error 0.216882076951934\n",
            "Loss: 0.0\n",
            "training error 0.11280816001977002, test error 0.21703571941679084\n",
            "Loss: 0.07084147616811531\n",
            "training error 0.11270229330920517, test error 0.21687609096687235\n",
            "Loss: 0.0\n",
            "training error 0.11266902954186485, test error 0.21675905803925097\n",
            "Loss: 0.0\n",
            "training error 0.1127691854900922, test error 0.216906364388536\n",
            "Loss: 0.06795856681494072\n",
            "training error 0.11268238094663877, test error 0.21690727402799\n",
            "Loss: 0.0683782214592421\n",
            "training error 0.11266416322927271, test error 0.21663418286518454\n",
            "Loss: 0.0\n",
            "training error 0.11264830512846855, test error 0.21666883970600398\n",
            "Loss: 0.015997863477079655\n",
            "training error 0.11257676943517302, test error 0.21663887054904318\n",
            "Loss: 0.0021638708151305863\n",
            "training error 0.112636589136337, test error 0.21650368072058307\n",
            "Loss: 0.0\n",
            "training error 0.11254613294709508, test error 0.21658149379019737\n",
            "Loss: 0.03594076061677054\n",
            "training error 0.11273908743531152, test error 0.2164775327585096\n",
            "Loss: 0.0\n",
            "training error 0.1126125853369421, test error 0.2164865168891457\n",
            "Loss: 0.004150144600045813\n",
            "training error 0.1126107142055011, test error 0.21651042466567305\n",
            "Loss: 0.015194143588170839\n",
            "training error 0.11251183408288343, test error 0.2165919708997185\n",
            "Loss: 0.05286374976223307\n",
            "training error 0.11253309256275068, test error 0.21636757745309182\n",
            "Loss: 0.0\n",
            "training error 0.11256339370342361, test error 0.21660637464947916\n",
            "Loss: 0.11036644177389032\n",
            "training error 0.11241019211831711, test error 0.2164793052826208\n",
            "Loss: 0.05163797221567901\n",
            "training error 0.11242175601854523, test error 0.21637377759710613\n",
            "Loss: 0.002865560583198423\n",
            "training error 0.11245690751987997, test error 0.2162567350428886\n",
            "Loss: 0.0\n",
            "training error 0.11240258630251174, test error 0.2161388314214201\n",
            "Loss: 0.0\n",
            "training error 0.11242799990770451, test error 0.21615689821397452\n",
            "Loss: 0.008358883239822923\n",
            "training error 0.11235687042723902, test error 0.21631283851407856\n",
            "Loss: 0.0805070942200059\n",
            "training error 0.1123492746334578, test error 0.21620138524346233\n",
            "Loss: 0.028941500993062697\n",
            "training error 0.11229260375951274, test error 0.21630755118998565\n",
            "Loss: 0.07806083129808794\n",
            "training error 0.11230398432119104, test error 0.21618501229173204\n",
            "Loss: 0.021366299617819884\n",
            "training error 0.11227582730768587, test error 0.21596659386314987\n",
            "Loss: 0.0\n",
            "training error 0.11229365993102859, test error 0.21591406899289747\n",
            "Loss: 0.0\n",
            "training error 0.11232669965228152, test error 0.2159719250772195\n",
            "Loss: 0.02679588439598035\n",
            "training error 0.11218421491911824, test error 0.2159935496031105\n",
            "Loss: 0.03681122336480769\n",
            "training error 0.11213263098917829, test error 0.216160251386793\n",
            "Loss: 0.11401869041876012\n",
            "training error 0.1122307615491297, test error 0.2162423426899774\n",
            "Loss: 0.15203904896570197\n",
            "training error 0.11215187715436643, test error 0.2163533531490472\n",
            "Loss: 0.20345323405681626\n",
            "training error 0.1120926447351997, test error 0.21631359722006366\n",
            "Loss: 0.18504038621927066\n",
            "training error 0.11209602805986993, test error 0.21624948524111426\n",
            "Loss: 0.1553471016415342\n",
            "training error 0.1120443818983758, test error 0.21612556839207064\n",
            "Loss: 0.09795535796239818\n",
            "training error 0.11201045937994625, test error 0.2159201651778175\n",
            "Loss: 0.0028234310753605385\n",
            "training error 0.11200011903861623, test error 0.21584524180558287\n",
            "Loss: 0.0\n",
            "training error 0.11197520955206067, test error 0.21565171941120936\n",
            "Loss: 0.0\n",
            "training error 0.11193343837408137, test error 0.21576374388014954\n",
            "Loss: 0.051946939837077544\n",
            "training error 0.11187121515387319, test error 0.21573371215382403\n",
            "Loss: 0.038020908360270056\n",
            "training error 0.11193237275014303, test error 0.21589434305957364\n",
            "Loss: 0.11250717083393091\n",
            "training error 0.11200412905270356, test error 0.21615338160448744\n",
            "Loss: 0.23262610409402473\n",
            "training error 0.11182884354665487, test error 0.21597578526233505\n",
            "Loss: 0.1502727879983956\n",
            "training error 0.11179555206442315, test error 0.21602582740594217\n",
            "Loss: 0.17347786317412073\n",
            "training error 0.11172909793220748, test error 0.2160842637311885\n",
            "Loss: 0.2005754098136192\n",
            "training error 0.11172204690669038, test error 0.21602201516734296\n",
            "Loss: 0.1717100875173294\n",
            "training error 0.111652425872953, test error 0.21595801613426002\n",
            "Loss: 0.1420330539848802\n",
            "training error 0.11167090721586735, test error 0.21559255751149867\n",
            "Loss: 0.0\n",
            "training error 0.11154960551486294, test error 0.2155326017021932\n",
            "Loss: 0.0\n",
            "training error 0.11151937679051488, test error 0.2156372676176712\n",
            "Loss: 0.048561523709822474\n",
            "training error 0.11156986773465681, test error 0.21554195880312005\n",
            "Loss: 0.004341385411277265\n",
            "training error 0.11145304368856584, test error 0.21561541725923203\n",
            "Loss: 0.03842367993740492\n",
            "training error 0.11146418572675466, test error 0.215528612978841\n",
            "Loss: 0.0\n",
            "training error 0.11140488404118831, test error 0.21539544978011663\n",
            "Loss: 0.0\n",
            "training error 0.1114466857246188, test error 0.21501666574751296\n",
            "Loss: 0.0\n",
            "training error 0.11133124905334892, test error 0.21485989840596068\n",
            "Loss: 0.0\n",
            "training error 0.11138260090437772, test error 0.21483671788642197\n",
            "Loss: 0.0\n",
            "training error 0.11125947904925117, test error 0.2147637942848582\n",
            "Loss: 0.0\n",
            "training error 0.11123130997301621, test error 0.21454998718847096\n",
            "Loss: 0.0\n",
            "training error 0.11122779929621589, test error 0.21463214413658374\n",
            "Loss: 0.03829268376540629\n",
            "training error 0.11129858878470233, test error 0.21441818842276525\n",
            "Loss: 0.0\n",
            "training error 0.11100842489604688, test error 0.21450191816784894\n",
            "Loss: 0.039049739996221966\n",
            "training error 0.11097765201652963, test error 0.21433003782274723\n",
            "Loss: 0.0\n",
            "training error 0.1108854060212337, test error 0.21436225015606306\n",
            "Loss: 0.015029313503167607\n",
            "training error 0.11088372817503273, test error 0.2143466467822646\n",
            "Loss: 0.007749244896371188\n",
            "training error 0.11095478875219775, test error 0.21405862210028284\n",
            "Loss: 0.0\n",
            "training error 0.11078261293368269, test error 0.21396781866586437\n",
            "Loss: 0.0\n",
            "training error 0.11071409780676573, test error 0.2139190981518708\n",
            "Loss: 0.0\n",
            "training error 0.11077052939861702, test error 0.21385617703535154\n",
            "Loss: 0.0\n",
            "training error 0.11060519574890539, test error 0.21385832134406293\n",
            "Loss: 0.0010026872925283925\n",
            "training error 0.11067827638577715, test error 0.2140845509768889\n",
            "Loss: 0.10678856449379825\n",
            "training error 0.11051805326784081, test error 0.21405215210575132\n",
            "Loss: 0.0916387233310445\n",
            "training error 0.1104367224567162, test error 0.21388573847343134\n",
            "Loss: 0.013823046165706288\n",
            "training error 0.11043027815516475, test error 0.2135915723985175\n",
            "Loss: 0.0\n",
            "training error 0.11038275846231044, test error 0.21354587783987236\n",
            "Loss: 0.0\n",
            "training error 0.11036237972739238, test error 0.21330615558729651\n",
            "Loss: 0.0\n",
            "training error 0.11019431728096782, test error 0.21318156209425312\n",
            "Loss: 0.0\n",
            "training error 0.11016747514742994, test error 0.21317153945634634\n",
            "Loss: 0.0\n",
            "training error 0.11010310471007204, test error 0.21316201883278105\n",
            "Loss: 0.0\n",
            "training error 0.1100672167552746, test error 0.2129845510093197\n",
            "Loss: 0.0\n",
            "training error 0.10995333681397647, test error 0.21278878602725218\n",
            "Loss: 0.0\n",
            "training error 0.10989107528452918, test error 0.21254763370725796\n",
            "Loss: 0.0\n",
            "training error 0.11003631903631579, test error 0.21221632897309575\n",
            "Loss: 0.0\n",
            "training error 0.10986467701062502, test error 0.2122517262275968\n",
            "Loss: 0.01667979776689421\n",
            "training error 0.10970303857861596, test error 0.21231045931850542\n",
            "Loss: 0.04435584474822285\n",
            "training error 0.10976941033706857, test error 0.2121188324870374\n",
            "Loss: 0.0\n",
            "training error 0.10968655134197856, test error 0.2120765046876104\n",
            "Loss: 0.0\n",
            "training error 0.10949782275546724, test error 0.2119618843730158\n",
            "Loss: 0.0\n",
            "training error 0.10951495174748288, test error 0.21161798192070655\n",
            "Loss: 0.0\n",
            "training error 0.10939059511359422, test error 0.21159717942695655\n",
            "Loss: 0.0\n",
            "training error 0.10927483066608829, test error 0.21148965915219806\n",
            "Loss: 0.0\n",
            "training error 0.10926782163816749, test error 0.21155010940591193\n",
            "Loss: 0.02858307775246427\n",
            "training error 0.10916266716315869, test error 0.21145641333334128\n",
            "Loss: 0.0\n",
            "training error 0.10911718133847652, test error 0.21148679621798722\n",
            "Loss: 0.01436839118142963\n",
            "training error 0.10902031557616139, test error 0.21121810908192615\n",
            "Loss: 0.0\n",
            "training error 0.10885728373424582, test error 0.21100577758944702\n",
            "Loss: 0.0\n",
            "training error 0.10885398688289143, test error 0.2107565451817202\n",
            "Loss: 0.0\n",
            "training error 0.10867951974329379, test error 0.21057510764822843\n",
            "Loss: 0.0\n",
            "training error 0.10865821786449663, test error 0.21052188071208527\n",
            "Loss: 0.0\n",
            "training error 0.10849615084903044, test error 0.21039115992631513\n",
            "Loss: 0.0\n",
            "training error 0.1084406527603208, test error 0.21028815329923528\n",
            "Loss: 0.0\n",
            "training error 0.10833855349385264, test error 0.21020463226686922\n",
            "Loss: 0.0\n",
            "training error 0.10828898963553385, test error 0.21011279483386416\n",
            "Loss: 0.0\n",
            "training error 0.10818323711155974, test error 0.21006179281780532\n",
            "Loss: 0.0\n",
            "training error 0.10811858409541293, test error 0.20988198837601554\n",
            "Loss: 0.0\n",
            "training error 0.10798439802221302, test error 0.20972736005598286\n",
            "Loss: 0.0\n",
            "training error 0.10786127325197532, test error 0.20950680243680778\n",
            "Loss: 0.0\n",
            "training error 0.10777681435366912, test error 0.20929689413741237\n",
            "Loss: 0.0\n",
            "training error 0.10771168951616626, test error 0.20900980524887938\n",
            "Loss: 0.0\n",
            "training error 0.10763474449844501, test error 0.20873814236309735\n",
            "Loss: 0.0\n",
            "training error 0.10751501244622859, test error 0.20854729227951926\n",
            "Loss: 0.0\n",
            "training error 0.10744223319482543, test error 0.20850257656790314\n",
            "Loss: 0.0\n",
            "training error 0.10742689466984534, test error 0.20852675759985975\n",
            "Loss: 0.011597473927982271\n",
            "training error 0.10720857057455442, test error 0.20826311363867825\n",
            "Loss: 0.0\n",
            "training error 0.10705897253027852, test error 0.20802860227585435\n",
            "Loss: 0.0\n",
            "training error 0.10694060942566631, test error 0.20780174747730262\n",
            "Loss: 0.0\n",
            "training error 0.10677314440119913, test error 0.20752973421934207\n",
            "Loss: 0.0\n",
            "training error 0.10672907352616215, test error 0.20735741713287761\n",
            "Loss: 0.0\n",
            "training error 0.10662417583449532, test error 0.20742385866187352\n",
            "Loss: 0.032042031538859206\n",
            "training error 0.10643397433028887, test error 0.20707441114282008\n",
            "Loss: 0.0\n",
            "training error 0.10636275138084501, test error 0.20715541139740523\n",
            "Loss: 0.039116496402491485\n",
            "training error 0.10624187062312475, test error 0.20675608138510018\n",
            "Loss: 0.0\n",
            "training error 0.10607172248715697, test error 0.2063739199902396\n",
            "Loss: 0.0\n",
            "training error 0.10599777400163246, test error 0.2063486891806612\n",
            "Loss: 0.0\n",
            "training error 0.1059675115487023, test error 0.20652118625106766\n",
            "Loss: 0.08359494363223696\n",
            "training error 0.10592967938165676, test error 0.20624244390988752\n",
            "Loss: 0.0\n",
            "training error 0.10566564604671494, test error 0.2060417623958931\n",
            "Loss: 0.0\n",
            "training error 0.10552089142167499, test error 0.2058084249382299\n",
            "Loss: 0.0\n",
            "training error 0.10545147315843284, test error 0.2051536980458796\n",
            "Loss: 0.0\n",
            "training error 0.10523473988800659, test error 0.20491028506251133\n",
            "Loss: 0.0\n",
            "training error 0.10511086784261202, test error 0.20482579354621858\n",
            "Loss: 0.0\n",
            "training error 0.10516491773861464, test error 0.20443256177979335\n",
            "Loss: 0.0\n",
            "training error 0.10508080230835223, test error 0.20413444937655723\n",
            "Loss: 0.0\n",
            "training error 0.10489143201694939, test error 0.20428482219667526\n",
            "Loss: 0.0736636175703298\n",
            "training error 0.10462576088459889, test error 0.2042449851057545\n",
            "Loss: 0.05414849357121554\n",
            "training error 0.10455305311955093, test error 0.20409581485921846\n",
            "Loss: 0.0\n",
            "training error 0.1043965820308925, test error 0.20377697753683022\n",
            "Loss: 0.0\n",
            "training error 0.10427628223103709, test error 0.203508037429439\n",
            "Loss: 0.0\n",
            "training error 0.10409576445694779, test error 0.20326540269210958\n",
            "Loss: 0.0\n",
            "training error 0.10406233115649398, test error 0.20300384694073614\n",
            "Loss: 0.0\n",
            "training error 0.10388786258146004, test error 0.20268682813453495\n",
            "Loss: 0.0\n",
            "training error 0.10394571435212231, test error 0.20262301205543615\n",
            "Loss: 0.0\n",
            "training error 0.10390181152053529, test error 0.202810855424771\n",
            "Loss: 0.09270584196205967\n",
            "training error 0.10349091133500261, test error 0.2023803961976632\n",
            "Loss: 0.0\n",
            "training error 0.10357953067983419, test error 0.20165297157136058\n",
            "Loss: 0.0\n",
            "training error 0.1031870205921716, test error 0.20150267945068298\n",
            "Loss: 0.0\n",
            "training error 0.10304749999013338, test error 0.2014031792456353\n",
            "Loss: 0.0\n",
            "training error 0.10290808605830078, test error 0.2012787798377345\n",
            "Loss: 0.0\n",
            "training error 0.10277419799102723, test error 0.20096869638081996\n",
            "Loss: 0.0\n",
            "training error 0.1026435920191769, test error 0.200791602646196\n",
            "Loss: 0.0\n",
            "training error 0.10270328159224351, test error 0.20095446084597374\n",
            "Loss: 0.08110807306254131\n",
            "training error 0.10248043973967152, test error 0.20054674464532254\n",
            "Loss: 0.0\n",
            "training error 0.10219896847046146, test error 0.20027016379428167\n",
            "Loss: 0.0\n",
            "training error 0.1022506385504113, test error 0.19982824350441566\n",
            "Loss: 0.0\n",
            "training error 0.10210996246120695, test error 0.19955128130955585\n",
            "Loss: 0.0\n",
            "training error 0.10200526388178024, test error 0.19953966400779424\n",
            "Loss: 0.0\n",
            "training error 0.10168852597874255, test error 0.19933622113188565\n",
            "Loss: 0.0\n",
            "training error 0.10157377215965085, test error 0.1990596084037455\n",
            "Loss: 0.0\n",
            "training error 0.1014102168350772, test error 0.1988348009302456\n",
            "Loss: 0.0\n",
            "training error 0.10125464843292252, test error 0.19854862362123635\n",
            "Loss: 0.0\n",
            "training error 0.10108255697112509, test error 0.19825862262367763\n",
            "Loss: 0.0\n",
            "training error 0.10093481824949081, test error 0.19816980726225217\n",
            "Loss: 0.0\n",
            "training error 0.10078829784611719, test error 0.19793655537700017\n",
            "Loss: 0.0\n",
            "training error 0.10064934313244822, test error 0.19771406869344002\n",
            "Loss: 0.0\n",
            "training error 0.10062076501393669, test error 0.1973027625228416\n",
            "Loss: 0.0\n",
            "training error 0.10051560660558459, test error 0.1974107239137032\n",
            "Loss: 0.05471864128061554\n",
            "training error 0.10047242266319334, test error 0.19707734034437627\n",
            "Loss: 0.0\n",
            "training error 0.10030034917845974, test error 0.1968291378500145\n",
            "Loss: 0.0\n",
            "training error 0.0999370173329055, test error 0.19668935999987092\n",
            "Loss: 0.0\n",
            "training error 0.09979798259522595, test error 0.19636584675498456\n",
            "Loss: 0.0\n",
            "training error 0.09965519222328778, test error 0.19619634158549834\n",
            "Loss: 0.0\n",
            "training error 0.0997304507450692, test error 0.19588411444636844\n",
            "Loss: 0.0\n",
            "training error 0.09944717961597938, test error 0.196040064785882\n",
            "Loss: 0.07961357150085835\n",
            "training error 0.09931632061341195, test error 0.19558338423249932\n",
            "Loss: 0.0\n",
            "training error 0.0992218548236536, test error 0.19522679125410064\n",
            "Loss: 0.0\n",
            "training error 0.098991436913982, test error 0.19509452372379732\n",
            "Loss: 0.0\n",
            "training error 0.09883375885744188, test error 0.1948546494340853\n",
            "Loss: 0.0\n",
            "training error 0.09879409212184928, test error 0.19463806242403975\n",
            "Loss: 0.0\n",
            "training error 0.09858466937437728, test error 0.19451714822738253\n",
            "Loss: 0.0\n",
            "training error 0.09843436140016977, test error 0.19434218474133513\n",
            "Loss: 0.0\n",
            "training error 0.09823165801449839, test error 0.19422454151927218\n",
            "Loss: 0.0\n",
            "training error 0.09814689424572084, test error 0.19404059182836114\n",
            "Loss: 0.0\n",
            "training error 0.09800327507813159, test error 0.19375789132045715\n",
            "Loss: 0.0\n",
            "training error 0.09790798143543418, test error 0.19373438570061818\n",
            "Loss: 0.0\n",
            "training error 0.09773346585368696, test error 0.19358262315084\n",
            "Loss: 0.0\n",
            "training error 0.09762102062784457, test error 0.19320596937900494\n",
            "Loss: 0.0\n",
            "training error 0.09741726451850578, test error 0.1928378820729719\n",
            "Loss: 0.0\n",
            "training error 0.0972708215424758, test error 0.19278068955103617\n",
            "Loss: 0.0\n",
            "training error 0.09717477544620806, test error 0.19246302131361204\n",
            "Loss: 0.0\n",
            "training error 0.09703187467549539, test error 0.192198673275351\n",
            "Loss: 0.0\n",
            "training error 0.09690437117681273, test error 0.19194742492497197\n",
            "Loss: 0.0\n",
            "training error 0.09668933594564842, test error 0.19173230144671777\n",
            "Loss: 0.0\n",
            "training error 0.0966132204098682, test error 0.19153854489387587\n",
            "Loss: 0.0\n",
            "training error 0.0965298697434514, test error 0.19115680900497387\n",
            "Loss: 0.0\n",
            "training error 0.09629656430375322, test error 0.19118819077723034\n",
            "Loss: 0.016416769258609243\n",
            "training error 0.09613277771233303, test error 0.19093219368636338\n",
            "Loss: 0.0\n",
            "training error 0.09606907508715581, test error 0.19062595142618768\n",
            "Loss: 0.0\n",
            "training error 0.09587349386537286, test error 0.19061081925218154\n",
            "Loss: 0.0\n",
            "training error 0.09575527670679872, test error 0.19041131666467861\n",
            "Loss: 0.0\n",
            "training error 0.0956137074005006, test error 0.19000818250924287\n",
            "Loss: 0.0\n",
            "training error 0.09546702958321134, test error 0.1901538662887224\n",
            "Loss: 0.07667237145034811\n",
            "training error 0.09530216319582516, test error 0.18967279874559345\n",
            "Loss: 0.0\n",
            "training error 0.09517400873548351, test error 0.18947113606504645\n",
            "Loss: 0.0\n",
            "training error 0.0950556676744731, test error 0.18922836407181942\n",
            "Loss: 0.0\n",
            "training error 0.09494700059665304, test error 0.1890737085120919\n",
            "Loss: 0.0\n",
            "training error 0.09476054876429651, test error 0.18866657430059378\n",
            "Loss: 0.0\n",
            "training error 0.094647634169536, test error 0.18853796385639496\n",
            "Loss: 0.0\n",
            "training error 0.09444648627105724, test error 0.1887030222008606\n",
            "Loss: 0.08754647662969628\n",
            "training error 0.09432112930128674, test error 0.18870694046965594\n",
            "Loss: 0.08962471525877369\n",
            "training error 0.09419161353265407, test error 0.1883188285816202\n",
            "Loss: 0.0\n",
            "training error 0.09385830214734948, test error 0.18776645180518275\n",
            "Loss: 0.0\n",
            "training error 0.09381858006440413, test error 0.18738150936299117\n",
            "Loss: 0.0\n",
            "training error 0.09368539155401459, test error 0.18720804458617907\n",
            "Loss: 0.0\n",
            "training error 0.09351480411542769, test error 0.18726014660313034\n",
            "Loss: 0.027831078021489652\n",
            "training error 0.09349062366803362, test error 0.1873532838936435\n",
            "Loss: 0.07758176620320523\n",
            "training error 0.0932257502171683, test error 0.18671785030532081\n",
            "Loss: 0.0\n",
            "training error 0.09307728224357843, test error 0.18629224909192213\n",
            "Loss: 0.0\n",
            "training error 0.09296801717424186, test error 0.186326427623052\n",
            "Loss: 0.01834672741161114\n",
            "training error 0.09291029104579648, test error 0.18661911284791532\n",
            "Loss: 0.1754575177370432\n",
            "training error 0.09268386838394574, test error 0.1860153545817727\n",
            "Loss: 0.0\n",
            "training error 0.09237691587389228, test error 0.1857438443397539\n",
            "Loss: 0.0\n",
            "training error 0.09224878075351928, test error 0.18564399474384233\n",
            "Loss: 0.0\n",
            "training error 0.0920310809606354, test error 0.18520948417458252\n",
            "Loss: 0.0\n",
            "training error 0.09190763686018566, test error 0.18489846556156497\n",
            "Loss: 0.0\n",
            "training error 0.0917695952487816, test error 0.184783743894612\n",
            "Loss: 0.0\n",
            "training error 0.09153481034325686, test error 0.18475797081717105\n",
            "Loss: 0.0\n",
            "training error 0.09134157132957002, test error 0.18456091262702584\n",
            "Loss: 0.0\n",
            "training error 0.09122906716920633, test error 0.18405123393599304\n",
            "Loss: 0.0\n",
            "training error 0.09118056716386556, test error 0.18362780821954508\n",
            "Loss: 0.0\n",
            "training error 0.09089457594701356, test error 0.18356817546268311\n",
            "Loss: 0.0\n",
            "training error 0.09087017912348433, test error 0.1831200603996646\n",
            "Loss: 0.0\n",
            "training error 0.09060193557257053, test error 0.18295009795286515\n",
            "Loss: 0.0\n",
            "training error 0.09081153406255509, test error 0.18217491434017558\n",
            "Loss: 0.0\n",
            "training error 0.09028050852411233, test error 0.18284112785919684\n",
            "Loss: 0.36569992165729204\n",
            "training error 0.09004131370427927, test error 0.18218058556406497\n",
            "Loss: 0.003113065215343269\n",
            "training error 0.08980683916729469, test error 0.1819988698831096\n",
            "Loss: 0.0\n",
            "training error 0.08960786068774416, test error 0.18195569805961018\n",
            "Loss: 0.0\n",
            "training error 0.08936941263718035, test error 0.18140713928812147\n",
            "Loss: 0.0\n",
            "training error 0.0892826245629621, test error 0.18108708025764603\n",
            "Loss: 0.0\n",
            "training error 0.08902049023113515, test error 0.18120862132140553\n",
            "Loss: 0.0671174683398501\n",
            "training error 0.08870525809308873, test error 0.18076866780347853\n",
            "Loss: 0.0\n",
            "training error 0.08849519660663809, test error 0.18023213878868638\n",
            "Loss: 0.0\n",
            "training error 0.08845769709456218, test error 0.17944286001181542\n",
            "Loss: 0.0\n",
            "training error 0.08811402628906526, test error 0.17928525257680797\n",
            "Loss: 0.0\n",
            "training error 0.08789770878515986, test error 0.1789537486082503\n",
            "Loss: 0.0\n",
            "training error 0.08771014438405705, test error 0.1786434176765278\n",
            "Loss: 0.0\n",
            "training error 0.08763704323747352, test error 0.17883096303998663\n",
            "Loss: 0.10498308076394292\n",
            "training error 0.08727247665562592, test error 0.17859579226563915\n",
            "Loss: 0.0\n",
            "training error 0.08708364415970728, test error 0.17819153607855778\n",
            "Loss: 0.0\n",
            "training error 0.08682700878231796, test error 0.1778402436241957\n",
            "Loss: 0.0\n",
            "training error 0.08670452974391835, test error 0.1769282771917387\n",
            "Loss: 0.0\n",
            "training error 0.08634598370454157, test error 0.17640688610654184\n",
            "Loss: 0.0\n",
            "training error 0.08619885919574584, test error 0.17663745538111078\n",
            "Loss: 0.13070310329590384\n",
            "training error 0.08592553839187023, test error 0.17663733953527203\n",
            "Loss: 0.13063743361525493\n",
            "training error 0.08585495792612972, test error 0.17577269071906765\n",
            "Loss: 0.0\n",
            "training error 0.08539893498834886, test error 0.17580744217443545\n",
            "Loss: 0.0197706795211694\n",
            "training error 0.08536236040717186, test error 0.1753924279535865\n",
            "Loss: 0.0\n",
            "training error 0.08503820232200728, test error 0.17524878204393757\n",
            "Loss: 0.0\n",
            "training error 0.08461794407087819, test error 0.17415563342357845\n",
            "Loss: 0.0\n",
            "training error 0.08451426567434217, test error 0.17362653146587176\n",
            "Loss: 0.0\n",
            "training error 0.0842669088380691, test error 0.1733842918421457\n",
            "Loss: 0.0\n",
            "training error 0.0841103070141138, test error 0.17264114868015126\n",
            "Loss: 0.0\n",
            "training error 0.08372541359473955, test error 0.1720364707365772\n",
            "Loss: 0.0\n",
            "training error 0.08342610703334603, test error 0.17180145654060702\n",
            "Loss: 0.0\n",
            "training error 0.08311195517381184, test error 0.17183239315415572\n",
            "Loss: 0.018007189328672624\n",
            "training error 0.08298106797915579, test error 0.17128747969502797\n",
            "Loss: 0.0\n",
            "training error 0.08266405664277324, test error 0.17065304693430186\n",
            "Loss: 0.0\n",
            "training error 0.08214654857151547, test error 0.1700995396749563\n",
            "Loss: 0.0\n",
            "training error 0.08214158881955155, test error 0.16944272701799418\n",
            "Loss: 0.0\n",
            "training error 0.08174179671492922, test error 0.1691464504681659\n",
            "Loss: 0.0\n",
            "training error 0.08132947663497093, test error 0.16881844743272373\n",
            "Loss: 0.0\n",
            "training error 0.08093739291653697, test error 0.16849155620148024\n",
            "Loss: 0.0\n",
            "training error 0.0809348886641305, test error 0.16757921703999043\n",
            "Loss: 0.0\n",
            "training error 0.08046988961032868, test error 0.1674628379768053\n",
            "Loss: 0.0\n",
            "training error 0.08022749139107313, test error 0.16713590855922664\n",
            "Loss: 0.0\n",
            "training error 0.07972744142583901, test error 0.16653728462850728\n",
            "Loss: 0.0\n",
            "training error 0.07939477940137703, test error 0.16636754063193426\n",
            "Loss: 0.0\n",
            "training error 0.07924249327655139, test error 0.1655315010108175\n",
            "Loss: 0.0\n",
            "training error 0.07882441177437627, test error 0.16485091230997112\n",
            "Loss: 0.0\n",
            "training error 0.07839084525515072, test error 0.1641282720096989\n",
            "Loss: 0.0\n",
            "training error 0.07804659740522897, test error 0.16367938985750388\n",
            "Loss: 0.0\n",
            "training error 0.07782413684643748, test error 0.1629532275474198\n",
            "Loss: 0.0\n",
            "training error 0.0777520921996839, test error 0.16286106180717455\n",
            "Loss: 0.0\n",
            "training error 0.07720183145433775, test error 0.16185872504525814\n",
            "Loss: 0.0\n",
            "training error 0.07681007332510424, test error 0.16190407453649228\n",
            "Loss: 0.02801794665159285\n",
            "training error 0.07650745124749826, test error 0.16211845363366378\n",
            "Loss: 0.160466226539846\n",
            "training error 0.07610325216641861, test error 0.16074932932007457\n",
            "Loss: 0.0\n",
            "training error 0.07572389952450177, test error 0.15962217915606516\n",
            "Loss: 0.0\n",
            "training error 0.07531491917684505, test error 0.1590467227235064\n",
            "Loss: 0.0\n",
            "training error 0.0749832475858367, test error 0.15861450426852106\n",
            "Loss: 0.0\n",
            "training error 0.07451659658478922, test error 0.1586354256606127\n",
            "Loss: 0.01319008762037388\n",
            "training error 0.07424035779254887, test error 0.1576566480816206\n",
            "Loss: 0.0\n",
            "training error 0.07389057400208407, test error 0.1569757721974557\n",
            "Loss: 0.0\n",
            "training error 0.07347278988575227, test error 0.15650879283937824\n",
            "Loss: 0.0\n",
            "training error 0.07365851367209961, test error 0.15487672941940547\n",
            "Loss: 0.0\n",
            "training error 0.0729288099780312, test error 0.15488329279144447\n",
            "Loss: 0.004237803873841095\n",
            "training error 0.07281762780735428, test error 0.1545128606810049\n",
            "Loss: 0.0\n",
            "training error 0.07202669621873545, test error 0.15432018940503942\n",
            "Loss: 0.0\n",
            "training error 0.07183856954692647, test error 0.15260364421940562\n",
            "Loss: 0.0\n",
            "training error 0.07142324446619706, test error 0.152368826121082\n",
            "Loss: 0.0\n",
            "training error 0.0712967411122576, test error 0.15207972587396176\n",
            "Loss: 0.0\n",
            "training error 0.07095996702992317, test error 0.15142350880145528\n",
            "Loss: 0.0\n",
            "training error 0.07029990970227151, test error 0.15009592081657022\n",
            "Loss: 0.0\n",
            "training error 0.07033182059890049, test error 0.14983841524069103\n",
            "Loss: 0.0\n",
            "training error 0.06954820115813952, test error 0.14880026422632867\n",
            "Loss: 0.0\n",
            "training error 0.06919071379239566, test error 0.14888106304676677\n",
            "Loss: 0.054300186130862294\n",
            "training error 0.06880858853369157, test error 0.14845356433681287\n",
            "Loss: 0.0\n",
            "training error 0.068602688129448, test error 0.1481257383424927\n",
            "Loss: 0.0\n",
            "training error 0.06817437745398269, test error 0.14651428471481515\n",
            "Loss: 0.0\n",
            "training error 0.06752378433416498, test error 0.14581169159890575\n",
            "Loss: 0.0\n",
            "training error 0.0672254393920887, test error 0.14519084358404277\n",
            "Loss: 0.0\n",
            "training error 0.06694653364394279, test error 0.14448440990749614\n",
            "Loss: 0.0\n",
            "training error 0.06670708520123805, test error 0.1433228019811841\n",
            "Loss: 0.0\n",
            "training error 0.06666049969347491, test error 0.14359559832645072\n",
            "Loss: 0.19033701650796875\n",
            "training error 0.0657675638543824, test error 0.1428256801893926\n",
            "Loss: 0.0\n",
            "training error 0.0653765003360751, test error 0.14146954982033752\n",
            "Loss: 0.0\n",
            "training error 0.06489368278681483, test error 0.14071333686317228\n",
            "Loss: 0.0\n",
            "training error 0.06472874106548132, test error 0.14036821269404176\n",
            "Loss: 0.0\n",
            "training error 0.06415080022901702, test error 0.1394437999322938\n",
            "Loss: 0.0\n",
            "training error 0.0637805520375728, test error 0.13928764352570688\n",
            "Loss: 0.0\n",
            "training error 0.06384207923270141, test error 0.1379974420183059\n",
            "Loss: 0.0\n",
            "training error 0.0632876482778775, test error 0.13723085905736068\n",
            "Loss: 0.0\n",
            "training error 0.06281902793788187, test error 0.1374798386043085\n",
            "Loss: 0.18143116545219495\n",
            "training error 0.06223698299575472, test error 0.13630063290287192\n",
            "Loss: 0.0\n",
            "training error 0.061966118943855376, test error 0.13583285849243712\n",
            "Loss: 0.0\n",
            "training error 0.061667344911673326, test error 0.13581779761996807\n",
            "Loss: 0.0\n",
            "training error 0.06113048583674815, test error 0.1349975626325971\n",
            "Loss: 0.0\n",
            "training error 0.061033290942263126, test error 0.1342287597428296\n",
            "Loss: 0.0\n",
            "training error 0.06044694912112565, test error 0.13288160918498276\n",
            "Loss: 0.0\n",
            "training error 0.060010524660944996, test error 0.13195279266878357\n",
            "Loss: 0.0\n",
            "training error 0.05959328914756929, test error 0.1315994059087231\n",
            "Loss: 0.0\n",
            "training error 0.059347102819715086, test error 0.13040485074950292\n",
            "Loss: 0.0\n",
            "training error 0.058971873117131444, test error 0.12978923782970297\n",
            "Loss: 0.0\n",
            "training error 0.05848936421412313, test error 0.1296814099267642\n",
            "Loss: 0.0\n",
            "training error 0.05814303336205007, test error 0.12877715640744036\n",
            "Loss: 0.0\n",
            "training error 0.05756701067944516, test error 0.12829274799897133\n",
            "Loss: 0.0\n",
            "training error 0.05711309391809514, test error 0.1271176790342334\n",
            "Loss: 0.0\n",
            "training error 0.056781997417068644, test error 0.12687317415230492\n",
            "Loss: 0.0\n",
            "training error 0.05637361753824536, test error 0.12600249602726935\n",
            "Loss: 0.0\n",
            "training error 0.0560221662881258, test error 0.12483807610737933\n",
            "Loss: 0.0\n",
            "training error 0.055638750943785835, test error 0.12353405276838127\n",
            "Loss: 0.0\n",
            "training error 0.0552716581050221, test error 0.1228771671105811\n",
            "Loss: 0.0\n",
            "training error 0.05487838092788681, test error 0.12237093263289506\n",
            "Loss: 0.0\n",
            "training error 0.054767246568990034, test error 0.12137244078669387\n",
            "Loss: 0.0\n",
            "training error 0.054179209467182875, test error 0.12110567086932748\n",
            "Loss: 0.0\n",
            "training error 0.05379349278752215, test error 0.1203458914945025\n",
            "Loss: 0.0\n",
            "training error 0.05344209811888458, test error 0.11988608184864637\n",
            "Loss: 0.0\n",
            "training error 0.05336006737149551, test error 0.1186245776858999\n",
            "Loss: 0.0\n",
            "training error 0.0527067578570831, test error 0.118032698449354\n",
            "Loss: 0.0\n",
            "training error 0.05236955238916446, test error 0.11633964355294174\n",
            "Loss: 0.0\n",
            "training error 0.05209772731103576, test error 0.11638214000417543\n",
            "Loss: 0.036527919405515696\n",
            "training error 0.05160657708937347, test error 0.11592047431000196\n",
            "Loss: 0.0\n",
            "training error 0.051368426438321645, test error 0.11536397058020981\n",
            "Loss: 0.0\n",
            "training error 0.05077723522382288, test error 0.11436520260501462\n",
            "Loss: 0.0\n",
            "training error 0.05058714705706917, test error 0.11412278694748137\n",
            "Loss: 0.0\n",
            "training error 0.05018756190329448, test error 0.11292563283720129\n",
            "Loss: 0.0\n",
            "training error 0.04975774613765297, test error 0.11207380945476116\n",
            "Loss: 0.0\n",
            "training error 0.04955050285127013, test error 0.11025915813507757\n",
            "Loss: 0.0\n",
            "training error 0.04901536128814727, test error 0.11006836737421848\n",
            "Loss: 0.0\n",
            "training error 0.04892984786698974, test error 0.10969291333731765\n",
            "Loss: 0.0\n",
            "training error 0.048508755210365066, test error 0.10917311356870946\n",
            "Loss: 0.0\n",
            "training error 0.04806902206678281, test error 0.10800779917416374\n",
            "Loss: 0.0\n",
            "training error 0.04791379724746746, test error 0.1066752190266488\n",
            "Loss: 0.0\n",
            "training error 0.04740737858080823, test error 0.1064703771433241\n",
            "Loss: 0.0\n",
            "training error 0.04696950674165429, test error 0.10586747772068494\n",
            "Loss: 0.0\n",
            "training error 0.046636038028983674, test error 0.10496373353156237\n",
            "Loss: 0.0\n",
            "training error 0.046430996266032705, test error 0.10396103533367511\n",
            "Loss: 0.0\n",
            "training error 0.04620379788598158, test error 0.1038802203267813\n",
            "Loss: 0.0\n",
            "training error 0.04557251903533688, test error 0.10403663800759194\n",
            "Loss: 0.1505750375948134\n",
            "training error 0.045500940498069437, test error 0.10338867443676807\n",
            "Loss: 0.0\n",
            "training error 0.04538950353181068, test error 0.10160503797334464\n",
            "Loss: 0.0\n",
            "training error 0.044580281733306734, test error 0.10149419580378055\n",
            "Loss: 0.0\n",
            "training error 0.044702713252033996, test error 0.10027942153389685\n",
            "Loss: 0.0\n",
            "training error 0.04401927678458905, test error 0.09965322022068995\n",
            "Loss: 0.0\n",
            "training error 0.04380853818385869, test error 0.09909524683068546\n",
            "Loss: 0.0\n",
            "training error 0.04340158276591707, test error 0.09935739207775938\n",
            "Loss: 0.264538669066372\n",
            "training error 0.04323551441581489, test error 0.09901210615020999\n",
            "Loss: 0.0\n",
            "training error 0.042822071372480085, test error 0.0978690560511199\n",
            "Loss: 0.0\n",
            "training error 0.04243245573959299, test error 0.09749216469595076\n",
            "Loss: 0.0\n",
            "training error 0.04230982613562006, test error 0.09576334127792416\n",
            "Loss: 0.0\n",
            "training error 0.0419582662460105, test error 0.09535104842650988\n",
            "Loss: 0.0\n",
            "training error 0.04172629995650475, test error 0.09473708361071739\n",
            "Loss: 0.0\n",
            "training error 0.04122547456939672, test error 0.09451244990831946\n",
            "Loss: 0.0\n",
            "training error 0.04093008353673617, test error 0.0928353771182904\n",
            "Loss: 0.0\n",
            "training error 0.04066298514053047, test error 0.09297165983735324\n",
            "Loss: 0.14680041520076514\n",
            "training error 0.040510719266423655, test error 0.09181268917263917\n",
            "Loss: 0.0\n",
            "training error 0.040175419047640194, test error 0.09223397110244462\n",
            "Loss: 0.4588493525260917\n",
            "training error 0.040089128299755514, test error 0.09129322777024143\n",
            "Loss: 0.0\n",
            "training error 0.03976367612911077, test error 0.08981201606493798\n",
            "Loss: 0.0\n",
            "training error 0.03939831550146866, test error 0.08996964344868737\n",
            "Loss: 0.1755081231395783\n",
            "training error 0.039394708598410454, test error 0.08909625119656801\n",
            "Loss: 0.0\n",
            "training error 0.03883338234133809, test error 0.08827851717669655\n",
            "Loss: 0.0\n",
            "training error 0.03864611059700805, test error 0.08820340004009324\n",
            "Loss: 0.0\n",
            "training error 0.03827730241844124, test error 0.0876157081717855\n",
            "Loss: 0.0\n",
            "training error 0.03807455546377368, test error 0.08740210414018332\n",
            "Loss: 0.0\n",
            "training error 0.037721327594711654, test error 0.08642698227470047\n",
            "Loss: 0.0\n",
            "training error 0.0377857880125487, test error 0.0864867717492637\n",
            "Loss: 0.06917917644422289\n",
            "training error 0.037315487480913685, test error 0.085476523900318\n",
            "Loss: 0.0\n",
            "training error 0.03717430777944363, test error 0.0848451234005269\n",
            "Loss: 0.0\n",
            "training error 0.036968963379548136, test error 0.08506181109208501\n",
            "Loss: 0.2553920400765852\n",
            "training error 0.036527929370137796, test error 0.0845199930504913\n",
            "Loss: 0.0\n",
            "training error 0.03636619227917934, test error 0.08344098410067702\n",
            "Loss: 0.0\n",
            "training error 0.03612142568804445, test error 0.08345462908954997\n",
            "Loss: 0.016352861870005952\n",
            "training error 0.036010226419610776, test error 0.08300935112667068\n",
            "Loss: 0.0\n",
            "training error 0.03566698922335772, test error 0.08198060265740052\n",
            "Loss: 0.0\n",
            "training error 0.03540088265025939, test error 0.08158404592744288\n",
            "Loss: 0.0\n",
            "training error 0.03514750128618694, test error 0.0809398051459325\n",
            "Loss: 0.0\n",
            "training error 0.034937521471971565, test error 0.08049845242631334\n",
            "Loss: 0.0\n",
            "training error 0.03477045670516384, test error 0.07967774946934987\n",
            "Loss: 0.0\n",
            "training error 0.03481188480688717, test error 0.08021650390493384\n",
            "Loss: 0.6761667330867915\n",
            "training error 0.034396452992573746, test error 0.07962481577949695\n",
            "Loss: 0.0\n",
            "training error 0.0341485577981657, test error 0.07909352317807926\n",
            "Loss: 0.0\n",
            "training error 0.03397421623856344, test error 0.07847927915502026\n",
            "Loss: 0.0\n",
            "training error 0.03377542365016535, test error 0.07827121894972006\n",
            "Loss: 0.0\n",
            "training error 0.03389323405640483, test error 0.07777466829900051\n",
            "Loss: 0.0\n",
            "training error 0.03362790985840791, test error 0.07754056037102429\n",
            "Loss: 0.0\n",
            "training error 0.033276082073584984, test error 0.07564994975416925\n",
            "Loss: 0.0\n",
            "training error 0.03290156216042492, test error 0.0752096741533868\n",
            "Loss: 0.0\n",
            "training error 0.03275639993644489, test error 0.07502641441323275\n",
            "Loss: 0.0\n",
            "training error 0.0325782927625695, test error 0.07496531162907492\n",
            "Loss: 0.0\n",
            "training error 0.03251861756583353, test error 0.07425925971924709\n",
            "Loss: 0.0\n",
            "training error 0.03235620721409974, test error 0.07351244040552034\n",
            "Loss: 0.0\n",
            "training error 0.03212509836344542, test error 0.0731177630778595\n",
            "Loss: 0.0\n",
            "training error 0.031949463347956814, test error 0.07318845098088918\n",
            "Loss: 0.09667678557727655\n",
            "training error 0.03166429432045272, test error 0.07231532324860442\n",
            "Loss: 0.0\n",
            "training error 0.03154897074276768, test error 0.07187830832197943\n",
            "Loss: 0.0\n",
            "training error 0.031498602315216145, test error 0.07149905460388528\n",
            "Loss: 0.0\n",
            "training error 0.03129431208744187, test error 0.07138184769362056\n",
            "Loss: 0.0\n",
            "training error 0.031099447622763475, test error 0.07127108650328053\n",
            "Loss: 0.0\n",
            "training error 0.030885812146434287, test error 0.07091072532808775\n",
            "Loss: 0.0\n",
            "training error 0.030662090707057936, test error 0.07025868191991431\n",
            "Loss: 0.0\n",
            "training error 0.030689783460037808, test error 0.06998178470104997\n",
            "Loss: 0.0\n",
            "training error 0.030368978287749832, test error 0.07029325560539419\n",
            "Loss: 0.44507425135664747\n",
            "training error 0.030334581520327884, test error 0.06991805393309658\n",
            "Loss: 0.0\n",
            "training error 0.030134557570750786, test error 0.06938097884765215\n",
            "Loss: 0.0\n",
            "training error 0.030181956595112597, test error 0.0690682519894445\n",
            "Loss: 0.0\n",
            "training error 0.029992008852138125, test error 0.06891783322796406\n",
            "Loss: 0.0\n",
            "training error 0.029680604894602624, test error 0.06801772367534717\n",
            "Loss: 0.0\n",
            "training error 0.029547469059288803, test error 0.067746081275784\n",
            "Loss: 0.0\n",
            "training error 0.029496442937501918, test error 0.06737109988554608\n",
            "Loss: 0.0\n",
            "training error 0.029482369290198658, test error 0.06657351558488069\n",
            "Loss: 0.0\n",
            "training error 0.029206588800854513, test error 0.06688050038104977\n",
            "Loss: 0.461121503757278\n",
            "training error 0.029031731027678472, test error 0.06666892350478279\n",
            "Loss: 0.1433121250453695\n",
            "training error 0.02879373386103029, test error 0.06646662342589546\n",
            "Loss: 0.0\n",
            "training error 0.02871184632636196, test error 0.06627809653488609\n",
            "Loss: 0.0\n",
            "training error 0.02853628638175655, test error 0.06574029850824746\n",
            "Loss: 0.0\n",
            "training error 0.028475316878996855, test error 0.06493260619498258\n",
            "Loss: 0.0\n",
            "training error 0.028324042368097987, test error 0.06432097017666658\n",
            "Loss: 0.0\n",
            "training error 0.028195668220090894, test error 0.06434699574451774\n",
            "Loss: 0.04046202627181472\n",
            "training error 0.0280700839125615, test error 0.0641333351877278\n",
            "Loss: 0.0\n",
            "training error 0.02796070257583199, test error 0.06468641711336942\n",
            "Loss: 0.8623938300147183\n",
            "training error 0.027830777677640757, test error 0.06414486885532077\n",
            "Loss: 0.017983888658212877\n",
            "training error 0.027715141347687666, test error 0.06368798475352593\n",
            "Loss: 0.0\n",
            "training error 0.02757067322051029, test error 0.06360905493584842\n",
            "Loss: 0.0\n",
            "training error 0.027424304534699177, test error 0.06362639448877344\n",
            "Loss: 0.027259566963389048\n",
            "training error 0.027337422032543687, test error 0.06342308577890093\n",
            "Loss: 0.0\n",
            "training error 0.027325650526574333, test error 0.06296789033055981\n",
            "Loss: 0.0\n",
            "training error 0.027068596228782296, test error 0.06235499544798971\n",
            "Loss: 0.0\n",
            "training error 0.027086378466385296, test error 0.06191997152315357\n",
            "Loss: 0.0\n",
            "training error 0.02687560163245194, test error 0.06203770954288268\n",
            "Loss: 0.19014546814686284\n",
            "training error 0.02690138188298683, test error 0.06132573233876217\n",
            "Loss: 0.0\n",
            "training error 0.026770672478726894, test error 0.06115788513607847\n",
            "Loss: 0.0\n",
            "training error 0.02664060673470913, test error 0.06126088905019095\n",
            "Loss: 0.16842294968717475\n",
            "training error 0.026614676238134957, test error 0.06143724455958423\n",
            "Loss: 0.45678398277535504\n",
            "training error 0.026520379132424318, test error 0.06095992782972092\n",
            "Loss: 0.0\n",
            "training error 0.026324249017720087, test error 0.061007022052722834\n",
            "Loss: 0.07725439428580838\n",
            "training error 0.026251795966000666, test error 0.06073245876268635\n",
            "Loss: 0.0\n",
            "training error 0.026087850367832746, test error 0.06101913447673203\n",
            "Loss: 0.4720304757722227\n",
            "training error 0.02606654675072989, test error 0.06060037841043565\n",
            "Loss: 0.0\n",
            "training error 0.025994599612161825, test error 0.06005739744476811\n",
            "Loss: 0.0\n",
            "training error 0.025835609563072428, test error 0.059824341698326435\n",
            "Loss: 0.0\n",
            "training error 0.02586046058145268, test error 0.05985552904214946\n",
            "Loss: 0.052131528634769\n",
            "training error 0.025663753100473086, test error 0.0590441005774199\n",
            "Loss: 0.0\n",
            "training error 0.02567769048737546, test error 0.05881516937862515\n",
            "Loss: 0.0\n",
            "training error 0.025473462778771057, test error 0.058649993166416295\n",
            "Loss: 0.0\n",
            "training error 0.02538446057483257, test error 0.058499668722080025\n",
            "Loss: 0.0\n",
            "training error 0.025348995311505182, test error 0.05798366236420886\n",
            "Loss: 0.0\n",
            "training error 0.02522324827050416, test error 0.05837438443618313\n",
            "Loss: 0.6738485567193919\n",
            "training error 0.02545090211022942, test error 0.05865989919738414\n",
            "Loss: 1.1662540888287998\n",
            "training error 0.02508505088491957, test error 0.05800637062252556\n",
            "Loss: 0.03916320113424021\n",
            "training error 0.025042439830678786, test error 0.057304386582435404\n",
            "Loss: 0.0\n",
            "training error 0.024955719516599646, test error 0.05722732591687745\n",
            "Loss: 0.0\n",
            "training error 0.024982853081256265, test error 0.05755982169178744\n",
            "Loss: 0.5810087568881572\n",
            "training error 0.024850325540412957, test error 0.05736693729140497\n",
            "Loss: 0.2439592839447169\n",
            "training error 0.024651647608815802, test error 0.056819847406856416\n",
            "Loss: 0.0\n",
            "training error 0.024695450846593192, test error 0.05673703883288349\n",
            "Loss: 0.0\n",
            "training error 0.024529481267581973, test error 0.05644194905335\n",
            "Loss: 0.0\n",
            "training error 0.024583646318345604, test error 0.056418947083631495\n",
            "Loss: 0.0\n",
            "training error 0.024394799543815907, test error 0.05611447601058331\n",
            "Loss: 0.0\n",
            "training error 0.024313702058491024, test error 0.05598048177902033\n",
            "Loss: 0.0\n",
            "training error 0.024596742890107992, test error 0.056233875325395095\n",
            "Loss: 0.45264624083625193\n",
            "training error 0.02436277866850362, test error 0.05644622445821216\n",
            "Loss: 0.8319733314020361\n",
            "training error 0.024090397894953444, test error 0.05547903489056266\n",
            "Loss: 0.0\n",
            "training error 0.024117341489788918, test error 0.055404946448781314\n",
            "Loss: 0.0\n",
            "training error 0.023988568777058523, test error 0.054928184576962254\n",
            "Loss: 0.0\n",
            "training error 0.02388716802897745, test error 0.05474878385061829\n",
            "Loss: 0.0\n",
            "training error 0.023829316209719596, test error 0.05472688421489549\n",
            "Loss: 0.0\n",
            "training error 0.0238555354964256, test error 0.05435920903978272\n",
            "Loss: 0.0\n",
            "training error 0.023801064842876737, test error 0.05482419776210622\n",
            "Loss: 0.855400088664271\n",
            "training error 0.023872535419812706, test error 0.05537616522462963\n",
            "Loss: 1.8708075463398588\n",
            "training error 0.0238041999087598, test error 0.054284194556773836\n",
            "Loss: 0.0\n",
            "training error 0.023678935102681296, test error 0.05390784115432927\n",
            "Loss: 0.0\n",
            "training error 0.023652811381462153, test error 0.05425320386657556\n",
            "Loss: 0.6406539472756378\n",
            "training error 0.02350653254278585, test error 0.05405214331633182\n",
            "Loss: 0.26768306597446667\n",
            "training error 0.023403829216007956, test error 0.053988139359923276\n",
            "Loss: 0.1489545933848868\n",
            "training error 0.023379127948510582, test error 0.05331262281276902\n",
            "Loss: 0.0\n",
            "training error 0.023519314422400798, test error 0.053513121784616015\n",
            "Loss: 0.376081613075252\n",
            "training error 0.02326453904262245, test error 0.05345876826618503\n",
            "Loss: 0.2741291756161779\n",
            "training error 0.02326390353160252, test error 0.05385716763097312\n",
            "Loss: 1.0214181735468397\n",
            "training error 0.023173030852725096, test error 0.05339058652571945\n",
            "Loss: 0.14623874954386995\n",
            "training error 0.023205280248806276, test error 0.05312379048065824\n",
            "Loss: 0.0\n",
            "training error 0.023109234316738912, test error 0.05305190861774131\n",
            "Loss: 0.0\n",
            "training error 0.023126116570095227, test error 0.0530742488020078\n",
            "Loss: 0.04211004815577457\n",
            "training error 0.02306841599077885, test error 0.05357055340217628\n",
            "Loss: 0.9776175786096575\n",
            "training error 0.02305650082110406, test error 0.052758503980348426\n",
            "Loss: 0.0\n",
            "training error 0.022914151623057866, test error 0.05263449439961238\n",
            "Loss: 0.0\n",
            "training error 0.0228490281553393, test error 0.05244200509020151\n",
            "Loss: 0.0\n",
            "training error 0.0228149780856967, test error 0.052519033262861524\n",
            "Loss: 0.14688258491932782\n",
            "training error 0.02299097601538142, test error 0.052604434470347905\n",
            "Loss: 0.3097314449876709\n",
            "training error 0.02276784016299984, test error 0.05228689868130148\n",
            "Loss: 0.0\n",
            "training error 0.022696224899751663, test error 0.052869232688175616\n",
            "Loss: 1.1137283364683226\n",
            "training error 0.022839788624192364, test error 0.05248508544731714\n",
            "Loss: 0.3790371412610405\n",
            "training error 0.022742446914701096, test error 0.05269741373131403\n",
            "Loss: 0.7851202889555875\n",
            "training error 0.02254325148945536, test error 0.05220004744507335\n",
            "Loss: 0.0\n",
            "training error 0.02259937357134404, test error 0.052274993409574456\n",
            "Loss: 0.1435745141418865\n",
            "training error 0.022547019019183392, test error 0.05231849309660709\n",
            "Loss: 0.22690717217905831\n",
            "training error 0.022576958892326107, test error 0.0525181774128449\n",
            "Loss: 0.6094438287748583\n",
            "training error 0.022432615346346732, test error 0.05203382758785927\n",
            "Loss: 0.0\n",
            "training error 0.02257134616807084, test error 0.051147348416913305\n",
            "Loss: 0.0\n",
            "training error 0.022334101470241726, test error 0.05134726059650756\n",
            "Loss: 0.3908554124149699\n",
            "training error 0.022448089657100562, test error 0.05099941834568374\n",
            "Loss: 0.0\n",
            "training error 0.022362416284369514, test error 0.05150660108831109\n",
            "Loss: 0.9944873080503847\n",
            "training error 0.022539809396028072, test error 0.051418151080501635\n",
            "Loss: 0.8210539421835028\n",
            "training error 0.02223807483251769, test error 0.05121209887919909\n",
            "Loss: 0.4170254101208748\n",
            "training error 0.022279818968153436, test error 0.05098120570565982\n",
            "Loss: 0.0\n",
            "training error 0.022250214993283703, test error 0.051065142976978964\n",
            "Loss: 0.16464355865524194\n",
            "training error 0.02222143701346704, test error 0.05075229222781594\n",
            "Loss: 0.0\n",
            "training error 0.022365202521110152, test error 0.0504489242486458\n",
            "Loss: 0.0\n",
            "training error 0.02221362819354214, test error 0.05098696246754548\n",
            "Loss: 1.066500875713161\n",
            "training error 0.022128059628617656, test error 0.05084058136194737\n",
            "Loss: 0.7763438351454877\n",
            "training error 0.022014991417810523, test error 0.05109295757040824\n",
            "Loss: 1.276604667699588\n",
            "training error 0.022069478966793326, test error 0.050701269143268037\n",
            "Loss: 0.5001987621748194\n",
            "training error 0.021995972200653174, test error 0.05089888872705243\n",
            "Loss: 0.891920858785622\n",
            "training error 0.021976718964658193, test error 0.05088906494403001\n",
            "Loss: 0.8724481283583163\n",
            "training error 0.021907885332998887, test error 0.050822177490608446\n",
            "Loss: 0.7398636294463135\n",
            "training error 0.021942201107609954, test error 0.050415497019804516\n",
            "Loss: 0.0\n",
            "training error 0.02196339782006805, test error 0.0507565941720095\n",
            "Loss: 0.6765720311573853\n",
            "training error 0.021844070069051667, test error 0.050770150898631815\n",
            "Loss: 0.7034620301134442\n",
            "training error 0.02184481344608483, test error 0.05071905878417195\n",
            "Loss: 0.6021199478568828\n",
            "training error 0.021817189299656852, test error 0.05045050278862449\n",
            "Loss: 0.06943454074492816\n",
            "training error 0.021897043091889747, test error 0.05027852658055959\n",
            "Loss: 0.0\n",
            "training error 0.021986159316189077, test error 0.05052146228514572\n",
            "Loss: 0.48317984059633723\n",
            "training error 0.021746245462055575, test error 0.05048602984920347\n",
            "Loss: 0.41270753690725304\n",
            "training error 0.02172833884892847, test error 0.050111919820433656\n",
            "Loss: 0.0\n",
            "training error 0.02167205543360525, test error 0.05003721134492107\n",
            "Loss: 0.0\n",
            "training error 0.021744850135379253, test error 0.050406730782580456\n",
            "Loss: 0.7384892717385405\n",
            "training error 0.021685833755359225, test error 0.04954885884410078\n",
            "Loss: 0.0\n",
            "training error 0.021628297960889963, test error 0.049686628394949243\n",
            "Loss: 0.2780478785231688\n",
            "training error 0.02182738240489056, test error 0.050751525406048166\n",
            "Loss: 2.4272336235460656\n",
            "training error 0.021620214785741748, test error 0.05022190647572589\n",
            "Loss: 1.3583514279163822\n",
            "training error 0.021526373480621547, test error 0.049727906615856333\n",
            "Loss: 0.36135599473421376\n",
            "training error 0.021764941818740263, test error 0.04929693927685386\n",
            "Loss: 0.0\n",
            "training error 0.021579168632318305, test error 0.049507079400384686\n",
            "Loss: 0.42627417972274095\n",
            "training error 0.021519040575072954, test error 0.04949295852133561\n",
            "Loss: 0.39762964467409123\n",
            "training error 0.021553631155890214, test error 0.04962681198963162\n",
            "Loss: 0.6691545512089059\n",
            "training error 0.02143144519222232, test error 0.04952447742004825\n",
            "Loss: 0.46156647153392516\n",
            "training error 0.02141907047456585, test error 0.04929090672158781\n",
            "Loss: 0.0\n",
            "training error 0.02144260099915258, test error 0.04943723390359563\n",
            "Loss: 0.29686445582006726\n",
            "training error 0.021426940454882623, test error 0.0490601572402322\n",
            "Loss: 0.0\n",
            "training error 0.021338976168272093, test error 0.049108364140349366\n",
            "Loss: 0.09826079415340416\n",
            "training error 0.021425184346493, test error 0.04869043396591836\n",
            "Loss: 0.0\n",
            "training error 0.021386734284658208, test error 0.048916175475355816\n",
            "Loss: 0.4636259960128397\n",
            "training error 0.021336179325849233, test error 0.04944224075233191\n",
            "Loss: 1.5440543966804388\n",
            "training error 0.021383795420342577, test error 0.048669164500367686\n",
            "Loss: 0.0\n",
            "training error 0.021274211569936027, test error 0.04900825055586972\n",
            "Loss: 0.696716409626208\n",
            "training error 0.021249972931905104, test error 0.048862910885046025\n",
            "Loss: 0.3980885775774379\n",
            "training error 0.021202369446179356, test error 0.04911641213333558\n",
            "Loss: 0.9189548198726749\n",
            "training error 0.021240480274820513, test error 0.049377740737745965\n",
            "Loss: 1.455903845180928\n",
            "training error 0.021225165059672146, test error 0.049113336475104914\n",
            "Loss: 0.9126352985448838\n",
            "training error 0.021176970282204638, test error 0.0490490918714163\n",
            "Loss: 0.780632613994725\n",
            "training error 0.021186164281095213, test error 0.04875337559839381\n",
            "Loss: 0.17302762209012723\n",
            "training error 0.02112405616752099, test error 0.04925618141625762\n",
            "Loss: 1.2061372368237455\n",
            "training error 0.021264445589980006, test error 0.04938457493299428\n",
            "Loss: 1.4699459914114366\n",
            "training error 0.02124312107572282, test error 0.04847866400322435\n",
            "Loss: 0.0\n",
            "training error 0.02117712758177581, test error 0.0491640153913528\n",
            "Loss: 1.4137175646648847\n",
            "training error 0.021187740959807293, test error 0.04862632002430487\n",
            "Loss: 0.30457939408292667\n",
            "training error 0.021128863119125037, test error 0.04827556707404072\n",
            "Loss: 0.0\n",
            "training error 0.02105392205515039, test error 0.04867379721864583\n",
            "Loss: 0.824910340243834\n",
            "training error 0.021093221274627753, test error 0.04833464414178464\n",
            "Loss: 0.12237467382478773\n",
            "training error 0.02104494564959778, test error 0.04831017505519612\n",
            "Loss: 0.07168839902453872\n",
            "training error 0.02100073245720485, test error 0.04798477469585511\n",
            "Loss: 0.0\n",
            "training error 0.020987059540014036, test error 0.048319705407344433\n",
            "Loss: 0.6979937149069304\n",
            "training error 0.020941468862343153, test error 0.048867996219962816\n",
            "Loss: 1.840628677962708\n",
            "training error 0.021012691659896072, test error 0.04865158197348163\n",
            "Loss: 1.3896226081147267\n",
            "training error 0.020977038811685843, test error 0.04860395255083837\n",
            "Loss: 1.2903631597893872\n",
            "training error 0.02089686014122924, test error 0.048151711956337474\n",
            "Loss: 0.34789630990343934\n",
            "training error 0.021021402162819464, test error 0.04768999656818216\n",
            "Loss: 0.0\n",
            "training error 0.021055390551198355, test error 0.048010743839711975\n",
            "Loss: 0.6725671935648991\n",
            "training error 0.020925373782777913, test error 0.048446229307678515\n",
            "Loss: 1.5857261352811625\n",
            "training error 0.02090002225895784, test error 0.04790463597388609\n",
            "Loss: 0.4500721768706084\n",
            "training error 0.020779960910375022, test error 0.04797155936445866\n",
            "Loss: 0.5904022154288757\n",
            "training error 0.020839685124824585, test error 0.04829193771006025\n",
            "Loss: 1.262195817140599\n",
            "training error 0.020872695457978672, test error 0.04844305443150396\n",
            "Loss: 1.5790688142431675\n",
            "training error 0.020893251999256252, test error 0.047645135406540196\n",
            "Loss: 0.0\n",
            "training error 0.020818265317272752, test error 0.047800624206370254\n",
            "Loss: 0.3263476921690378\n",
            "training error 0.020782968029452693, test error 0.04777172627358208\n",
            "Loss: 0.26569526135611365\n",
            "training error 0.020741993493238686, test error 0.04737459734104898\n",
            "Loss: 0.0\n",
            "training error 0.02074524887240989, test error 0.047391489723105897\n",
            "Loss: 0.035657046191461816\n",
            "training error 0.02075958646035575, test error 0.047424443620559587\n",
            "Loss: 0.10521731541435209\n",
            "training error 0.020767434807433007, test error 0.04760504118087961\n",
            "Loss: 0.4864291260813669\n",
            "training error 0.020708188080980103, test error 0.04750326956088139\n",
            "Loss: 0.2716059387399161\n",
            "training error 0.020721035442494234, test error 0.047564209048097564\n",
            "Loss: 0.40023919503435756\n",
            "training error 0.020739625842384646, test error 0.04741345500037801\n",
            "Loss: 0.08202214163277599\n",
            "training error 0.020612470422055443, test error 0.04766713477764214\n",
            "Loss: 0.6174985182189285\n",
            "training error 0.02070734375690071, test error 0.047173978834563514\n",
            "Loss: 0.0\n",
            "training error 0.0207771479107293, test error 0.047623003685512984\n",
            "Loss: 0.9518485869597137\n",
            "training error 0.020572980852903155, test error 0.0471440638997346\n",
            "Loss: 0.0\n",
            "training error 0.020602718861901067, test error 0.04727623558484754\n",
            "Loss: 0.2803570039995762\n",
            "training error 0.020637617625898358, test error 0.04720029239809436\n",
            "Loss: 0.11926951923226792\n",
            "training error 0.020536137529844952, test error 0.0470894563736328\n",
            "Loss: 0.0\n",
            "training error 0.020534053036029926, test error 0.047285574909031416\n",
            "Loss: 0.41648078041611747\n",
            "training error 0.02058438631408048, test error 0.04693221077738553\n",
            "Loss: 0.0\n",
            "training error 0.020473292788894957, test error 0.04720705793528289\n",
            "Loss: 0.5856258491658162\n",
            "training error 0.020519081827751667, test error 0.047063309111868415\n",
            "Loss: 0.2793355188501989\n",
            "training error 0.020516333380440083, test error 0.047104356301756786\n",
            "Loss: 0.3667961119236285\n",
            "training error 0.020474444005573845, test error 0.04701614696980395\n",
            "Loss: 0.17884559671939027\n",
            "training error 0.020529442315078448, test error 0.04722273896936254\n",
            "Loss: 0.6190379425232706\n",
            "training error 0.020601783985208965, test error 0.04794293955343042\n",
            "Loss: 2.1535929360734674\n",
            "training error 0.020525789638446035, test error 0.047648848776610825\n",
            "Loss: 1.5269640772401116\n",
            "training error 0.020573105831690194, test error 0.04729529110007728\n",
            "Loss: 0.7736271457868371\n",
            "training error 0.02042396345186922, test error 0.047076056623592\n",
            "Loss: 0.3064970599590433\n",
            "training error 0.020415574425142094, test error 0.04693346337476585\n",
            "Loss: 0.0026689502999666104\n",
            "training error 0.020421475769373355, test error 0.04678986908923176\n",
            "Loss: 0.0\n",
            "training error 0.020417068811262547, test error 0.04707081084481236\n",
            "Loss: 0.6004328737163611\n",
            "training error 0.020474529488272785, test error 0.047026088960632845\n",
            "Loss: 0.5048526016403265\n",
            "training error 0.0204050654397492, test error 0.04698481398954209\n",
            "Loss: 0.4166391231797517\n",
            "training error 0.02037534643819655, test error 0.04669191039731413\n",
            "Loss: 0.0\n",
            "training error 0.020383523111351814, test error 0.04694473456732636\n",
            "Loss: 0.5414731756762103\n",
            "training error 0.020363263747671816, test error 0.046666228016298446\n",
            "Loss: 0.0\n",
            "training error 0.020451764839039193, test error 0.04659496341507392\n",
            "Loss: 0.0\n",
            "training error 0.020364619077508795, test error 0.0469890234109417\n",
            "Loss: 0.8457137145005289\n",
            "training error 0.020382333764909735, test error 0.046960810393731824\n",
            "Loss: 0.7851642148506199\n",
            "training error 0.02039509042418282, test error 0.04656338006463973\n",
            "Loss: 0.0\n",
            "training error 0.020332672898361638, test error 0.04639021868093788\n",
            "Loss: 0.0\n",
            "training error 0.020303454053370418, test error 0.04655951182987053\n",
            "Loss: 0.3649328538350094\n",
            "training error 0.02036175744435785, test error 0.04690977265946478\n",
            "Loss: 1.1199644953180377\n",
            "training error 0.020334803054057483, test error 0.047058966370647326\n",
            "Loss: 1.4415704618875536\n",
            "training error 0.020346843408733148, test error 0.046943117669214746\n",
            "Loss: 1.1918438929542141\n",
            "training error 0.020324160309412465, test error 0.046826663899772365\n",
            "Loss: 0.9408130231854717\n",
            "training error 0.020326252225056518, test error 0.046620990491909056\n",
            "Loss: 0.49745790714714744\n",
            "training error 0.020294115931298897, test error 0.04668966126774734\n",
            "Loss: 0.6454864739245281\n",
            "training error 0.020360974196620914, test error 0.0467106795661715\n",
            "Loss: 0.6907940819112834\n",
            "training error 0.020361313606358105, test error 0.046862562032975494\n",
            "Loss: 1.0181960022354941\n",
            "training error 0.020311424288358998, test error 0.04671841427539271\n",
            "Loss: 0.7074672286244033\n",
            "training error 0.020269197303534017, test error 0.04654117078751396\n",
            "Loss: 0.3253964108561158\n",
            "training error 0.02029214011601565, test error 0.04678961340955775\n",
            "Loss: 0.860945992444706\n",
            "training error 0.020339714579490704, test error 0.046513614651171466\n",
            "Loss: 0.2659956640477912\n",
            "training error 0.020337321666179936, test error 0.04685524014192761\n",
            "Loss: 1.0024127374523628\n",
            "training error 0.020204545428538962, test error 0.0466280314137118\n",
            "Loss: 0.5126355070872668\n",
            "training error 0.020301494384707137, test error 0.04651292722852802\n",
            "Loss: 0.2645138373545963\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04651292722852802\n",
            "training error 0.12345626668996616, test error 0.23503698342072055\n",
            "training error 0.11942055704508789, test error 0.2287390686921781\n",
            "training error 0.11835688136552407, test error 0.22780826109143448\n",
            "training error 0.11848106252682389, test error 0.22425582220800747\n",
            "training error 0.1179768107716955, test error 0.2241304600319823\n",
            "training error 0.11792140159459968, test error 0.22306379345323152\n",
            "training error 0.11771219884196332, test error 0.2228347957035588\n",
            "training error 0.11770338039126564, test error 0.22340602362688192\n",
            "training error 0.1176049867039552, test error 0.22287456838297146\n",
            "training error 0.11748195881390142, test error 0.22302298188314168\n",
            "training error 0.11759896851344112, test error 0.22345458599807244\n",
            "training error 0.11752865609484073, test error 0.22278446676060368\n",
            "training error 0.11745293073967446, test error 0.22301691407148191\n",
            "training error 0.11771523622021134, test error 0.22394687028661325\n",
            "training error 0.11770199848489282, test error 0.22404729430947276\n",
            "training error 0.11760401257531161, test error 0.2242202582476037\n",
            "training error 0.11731657182784905, test error 0.22334696886011968\n",
            "training error 0.11751193399671224, test error 0.22257899842458978\n",
            "training error 0.11764580252049603, test error 0.2238180109127961\n",
            "training error 0.11757453650883895, test error 0.22256896854181982\n",
            "training error 0.1174512855605303, test error 0.22254022655291042\n",
            "training error 0.11724021327645595, test error 0.2220997992850828\n",
            "training error 0.1172490595245639, test error 0.222201922234179\n",
            "training error 0.11722945210315455, test error 0.22233811076326812\n",
            "training error 0.11738497302176215, test error 0.22250229056970497\n",
            "training error 0.11722788464741624, test error 0.22262208967676322\n",
            "training error 0.1171884480836608, test error 0.2232011121532683\n",
            "training error 0.11763143600421622, test error 0.22317222101181866\n",
            "training error 0.11705925630736508, test error 0.2227795073878697\n",
            "training error 0.11707843251118974, test error 0.2219931440504124\n",
            "training error 0.11708096854912713, test error 0.22237018354012647\n",
            "training error 0.11718215673929616, test error 0.2217386136514542\n",
            "training error 0.11717836383240689, test error 0.22240115447585274\n",
            "training error 0.11693929841946371, test error 0.22212596694399053\n",
            "training error 0.11701669856420154, test error 0.22252417282842277\n",
            "training error 0.11724080403343415, test error 0.2226964676186305\n",
            "training error 0.11691589429915648, test error 0.22246576871231216\n",
            "training error 0.11720575734519498, test error 0.22197733799080446\n",
            "training error 0.11716716539543773, test error 0.222201904858608\n",
            "training error 0.1169342194879028, test error 0.222498888864201\n",
            "training error 0.11699081618646262, test error 0.22217693475649022\n",
            "training error 0.11704379558933209, test error 0.22195188285191345\n",
            "training error 0.11685432067053737, test error 0.22260048804614957\n",
            "training error 0.11679918347116554, test error 0.22200202749841072\n",
            "training error 0.1169118494948366, test error 0.22124087825373304\n",
            "training error 0.11684268463251991, test error 0.22150994658682013\n",
            "training error 0.11670600033648108, test error 0.22154654841695143\n",
            "training error 0.11666748064087168, test error 0.22122635876355684\n",
            "training error 0.11686731981131276, test error 0.22226806722693554\n",
            "training error 0.1167860552742231, test error 0.22162887509558207\n",
            "Loss: 0.18194772733002296\n",
            "training error 0.11671727040536184, test error 0.22206997235276454\n",
            "Loss: 0.3813350244169289\n",
            "training error 0.11666409896441848, test error 0.22243170687172165\n",
            "Loss: 0.5448483240882984\n",
            "training error 0.1169275064084446, test error 0.22313061369929543\n",
            "Loss: 0.8607721730726547\n",
            "training error 0.11674879838568109, test error 0.22328733027658884\n",
            "Loss: 0.9316120938530403\n",
            "training error 0.11665936423346755, test error 0.22294367169410756\n",
            "Loss: 0.7762695820465737\n",
            "training error 0.11675110632837649, test error 0.22221358729484672\n",
            "Loss: 0.44625266935076624\n",
            "training error 0.11665704869461264, test error 0.2221595403664416\n",
            "Loss: 0.4218220686270646\n",
            "training error 0.11659677042459121, test error 0.22131948196054185\n",
            "Loss: 0.042094078438692506\n",
            "training error 0.11645214682109582, test error 0.22160176332595166\n",
            "Loss: 0.16969251064520297\n",
            "training error 0.11680558512155487, test error 0.22233687390887766\n",
            "Loss: 0.5019813875378754\n",
            "training error 0.11644696552841523, test error 0.22224285018025502\n",
            "Loss: 0.45948024565398704\n",
            "training error 0.11646450432000749, test error 0.22231979258646875\n",
            "Loss: 0.4942601907942379\n",
            "training error 0.11681662208246438, test error 0.22218651417259674\n",
            "Loss: 0.43401492227519434\n",
            "training error 0.11646658944186611, test error 0.221929226632841\n",
            "Loss: 0.31771434164198364\n",
            "training error 0.11634453892574269, test error 0.22201199591877308\n",
            "Loss: 0.35512818617420283\n",
            "training error 0.11636816717703956, test error 0.22179600424792026\n",
            "Loss: 0.2574943996489276\n",
            "training error 0.11655394425051936, test error 0.2213628014082842\n",
            "Loss: 0.061675582190989786\n",
            "training error 0.11641091650871514, test error 0.22169693033379442\n",
            "Loss: 0.21271044412050077\n",
            "training error 0.11660885100249306, test error 0.22058360857266116\n",
            "Loss: 0.0\n",
            "training error 0.11625322192838877, test error 0.22120271869651462\n",
            "Loss: 0.28066914303359614\n",
            "training error 0.11625051396406644, test error 0.22133551763701917\n",
            "Loss: 0.3408725921311362\n",
            "training error 0.11634255088463984, test error 0.22102744257350856\n",
            "Loss: 0.201208967302402\n",
            "training error 0.11624157164543836, test error 0.2210385279941774\n",
            "Loss: 0.20623446341272444\n",
            "training error 0.11655353827329971, test error 0.2207648487676622\n",
            "Loss: 0.08216394507905012\n",
            "training error 0.11626307027755486, test error 0.22121868171207948\n",
            "Loss: 0.2879058618760144\n",
            "training error 0.11641657501421106, test error 0.2213882751036836\n",
            "Loss: 0.36478981200336325\n",
            "training error 0.11620133556175342, test error 0.22120318466178496\n",
            "Loss: 0.28088038505349466\n",
            "training error 0.1160946001305369, test error 0.2208914542644864\n",
            "Loss: 0.13955964081702188\n",
            "training error 0.11627148697096208, test error 0.22105392791265965\n",
            "Loss: 0.21321590622340736\n",
            "training error 0.11632228059770698, test error 0.2209166037021105\n",
            "Loss: 0.15096095834321588\n",
            "training error 0.11641700478969666, test error 0.22143485510938243\n",
            "Loss: 0.3859065241653692\n",
            "training error 0.11617457509369122, test error 0.22157090630148374\n",
            "Loss: 0.447584358244546\n",
            "training error 0.1159714440058798, test error 0.2212756263480935\n",
            "Loss: 0.31372130500095796\n",
            "training error 0.1161054764647823, test error 0.22093167086615392\n",
            "Loss: 0.1577915493109261\n",
            "training error 0.11602729113504946, test error 0.22085534924376923\n",
            "Loss: 0.12319168811609771\n",
            "training error 0.11619152119860603, test error 0.22198698358251642\n",
            "Loss: 0.6362100153026518\n",
            "training error 0.11604491860058361, test error 0.22152962054519734\n",
            "Loss: 0.42886775615722517\n",
            "training error 0.1160682314152955, test error 0.22104555715039392\n",
            "Loss: 0.20942108106849489\n",
            "training error 0.11595625142941812, test error 0.221358952460042\n",
            "Loss: 0.3514966014011245\n",
            "training error 0.1159237058103592, test error 0.22075050835524002\n",
            "Loss: 0.07566282175670569\n",
            "training error 0.11605965821171982, test error 0.22007626690369284\n",
            "Loss: 0.0\n",
            "training error 0.1165114237218447, test error 0.22158756725599502\n",
            "Loss: 0.6867166430824412\n",
            "training error 0.11626326100823026, test error 0.22125772389543813\n",
            "Loss: 0.5368398002962849\n",
            "training error 0.11611431143619913, test error 0.2214253924633044\n",
            "Loss: 0.6130263742623043\n",
            "training error 0.11605369908872641, test error 0.22223407899021397\n",
            "Loss: 0.9804837735935434\n",
            "training error 0.11600436760931356, test error 0.22101046573770672\n",
            "Loss: 0.42448867711060156\n",
            "training error 0.11586566407477783, test error 0.22146923935912427\n",
            "Loss: 0.6329498746182383\n",
            "training error 0.11578838573484156, test error 0.22135346763065086\n",
            "Loss: 0.5803445982282884\n",
            "training error 0.115920811192669, test error 0.22139736333544383\n",
            "Loss: 0.6002902767926033\n",
            "training error 0.11590676272167826, test error 0.2209288123605069\n",
            "Loss: 0.38738636783000047\n",
            "training error 0.11587598084301247, test error 0.22078917934326106\n",
            "Loss: 0.32393880975825073\n",
            "training error 0.11587617090783958, test error 0.22074457184069607\n",
            "Loss: 0.30366969887565265\n",
            "training error 0.11569321186735197, test error 0.2209243895273829\n",
            "Loss: 0.38537668582918627\n",
            "training error 0.11587052260574818, test error 0.22101381030725373\n",
            "Loss: 0.4260084091535221\n",
            "training error 0.11586224242996167, test error 0.22092428619038432\n",
            "Loss: 0.38532973074401067\n",
            "training error 0.11578097216904486, test error 0.22057509543597548\n",
            "Loss: 0.22666166565836754\n",
            "training error 0.11565178597274386, test error 0.2204459746211041\n",
            "Loss: 0.16799072549382732\n",
            "training error 0.11573516398438755, test error 0.22083754598686986\n",
            "Loss: 0.3459160289692509\n",
            "training error 0.11560409350401026, test error 0.2207693984755373\n",
            "Loss: 0.31495062216218006\n",
            "training error 0.11557941118084994, test error 0.22060625072232984\n",
            "Loss: 0.2408182518240043\n",
            "training error 0.11560797512622596, test error 0.22047919323625767\n",
            "Loss: 0.18308486336746643\n",
            "training error 0.11571914444722686, test error 0.2204671814937184\n",
            "Loss: 0.17762687250444387\n",
            "training error 0.11563182816300703, test error 0.2205438928888565\n",
            "Loss: 0.2124836047715739\n",
            "training error 0.11549727995800406, test error 0.22045898129321398\n",
            "Loss: 0.17390080034782596\n",
            "training error 0.11566854849515652, test error 0.2205563265136821\n",
            "Loss: 0.21813329385460545\n",
            "training error 0.1158925448806795, test error 0.22113997929384163\n",
            "Loss: 0.4833380741660287\n",
            "training error 0.11551525433993697, test error 0.22042040535027344\n",
            "Loss: 0.15637235737517852\n",
            "training error 0.11547525331663833, test error 0.2204828127981722\n",
            "Loss: 0.18472954862382984\n",
            "training error 0.11544973645790195, test error 0.22064743499926268\n",
            "Loss: 0.25953189028773416\n",
            "training error 0.11552909390261361, test error 0.2200613632943522\n",
            "Loss: 0.0\n",
            "training error 0.11557271810069952, test error 0.22008013583335462\n",
            "Loss: 0.00853059288619118\n",
            "training error 0.1154293899538752, test error 0.22009866069499698\n",
            "Loss: 0.016948636546842977\n",
            "training error 0.11540176339459404, test error 0.22009525063554292\n",
            "Loss: 0.01539904174154838\n",
            "training error 0.11547097020573925, test error 0.22007322378918906\n",
            "Loss: 0.00538963071905485\n",
            "training error 0.11565270396930562, test error 0.22085939771632684\n",
            "Loss: 0.36264176956279925\n",
            "training error 0.11530520379598756, test error 0.22064373531534967\n",
            "Loss: 0.2646407403277262\n",
            "training error 0.11538378730269014, test error 0.22072015389287428\n",
            "Loss: 0.299366771458609\n",
            "training error 0.11546791117662203, test error 0.22042822327954428\n",
            "Loss: 0.16670803983949156\n",
            "training error 0.11527048515849564, test error 0.22038795546526274\n",
            "Loss: 0.14840959177087054\n",
            "training error 0.11527952619047786, test error 0.22057262591497456\n",
            "Loss: 0.2323272986082925\n",
            "training error 0.11539649548694896, test error 0.2212573363686967\n",
            "Loss: 0.5434725371326499\n",
            "training error 0.11534897394240036, test error 0.2202796890336887\n",
            "Loss: 0.09921130000656309\n",
            "training error 0.11537588645397388, test error 0.22010077580789691\n",
            "Loss: 0.017909783414360447\n",
            "training error 0.11526130895774883, test error 0.2202011983849845\n",
            "Loss: 0.06354368097105656\n",
            "training error 0.11540348557742942, test error 0.2204609912407684\n",
            "Loss: 0.18159841438483149\n",
            "training error 0.11526340503765499, test error 0.22011562330809195\n",
            "Loss: 0.024656765243791234\n",
            "training error 0.11542837671029657, test error 0.2202367726166592\n",
            "Loss: 0.07970927730387434\n",
            "training error 0.1151652947836963, test error 0.21988572658710162\n",
            "Loss: 0.0\n",
            "training error 0.11530954281215035, test error 0.21956212994441698\n",
            "Loss: 0.0\n",
            "training error 0.11527106899984378, test error 0.21964018541903982\n",
            "Loss: 0.03555051804362552\n",
            "training error 0.11541336259994556, test error 0.2200860813716597\n",
            "Loss: 0.23863469869569442\n",
            "training error 0.11527187991911124, test error 0.21974871948194666\n",
            "Loss: 0.08498256852258468\n",
            "training error 0.11513879129586052, test error 0.21952498905140877\n",
            "Loss: 0.0\n",
            "training error 0.11521539206172825, test error 0.21924440147422594\n",
            "Loss: 0.0\n",
            "training error 0.11516144982499994, test error 0.21904330427110497\n",
            "Loss: 0.0\n",
            "training error 0.11515132946189405, test error 0.2191425681546761\n",
            "Loss: 0.04531701341039529\n",
            "training error 0.11519871510092804, test error 0.2193926770923909\n",
            "Loss: 0.15949942978104037\n",
            "training error 0.11508058006491836, test error 0.21934678700492327\n",
            "Loss: 0.13854919456597337\n",
            "training error 0.11505508136019568, test error 0.2195949342524259\n",
            "Loss: 0.25183603906842045\n",
            "training error 0.11525276225406673, test error 0.21969441842367393\n",
            "Loss: 0.29725362057317906\n",
            "training error 0.11502650675467525, test error 0.22016127325551166\n",
            "Loss: 0.5103871986075426\n",
            "training error 0.11503615616304078, test error 0.22022696182639326\n",
            "Loss: 0.5403760499445909\n",
            "training error 0.1150926795422857, test error 0.21967522374459786\n",
            "Loss: 0.288490659687457\n",
            "training error 0.11493574121005265, test error 0.21974983572089724\n",
            "Loss: 0.32255331983022106\n",
            "training error 0.11507834150470513, test error 0.22015560307978785\n",
            "Loss: 0.5077985891347891\n",
            "training error 0.115241119706349, test error 0.21997532169125317\n",
            "Loss: 0.4254945948928279\n",
            "training error 0.11490064906523988, test error 0.21987379387763845\n",
            "Loss: 0.37914402784282597\n",
            "training error 0.11489925300015986, test error 0.22006798342691583\n",
            "Loss: 0.46779752488697035\n",
            "training error 0.1149460432235299, test error 0.2200243921790829\n",
            "Loss: 0.4478967806126777\n",
            "training error 0.11494649401329901, test error 0.21993965040683053\n",
            "Loss: 0.40920955731025277\n",
            "training error 0.11500864933118096, test error 0.21965444318129076\n",
            "Loss: 0.27900369391313795\n",
            "training error 0.11539188067548493, test error 0.22039461816062633\n",
            "Loss: 0.6169163189069016\n",
            "training error 0.11487629728618354, test error 0.21972200138682949\n",
            "Loss: 0.30984609092845616\n",
            "training error 0.1148597682561749, test error 0.21949919318352168\n",
            "Loss: 0.20812729881598546\n",
            "training error 0.11482690193784896, test error 0.21963177443990112\n",
            "Loss: 0.26865471681700726\n",
            "training error 0.11487698438019377, test error 0.21986153243355694\n",
            "Loss: 0.3735463018030849\n",
            "training error 0.11482739236127947, test error 0.2195812828077343\n",
            "Loss: 0.24560373503290656\n",
            "training error 0.11485857361337136, test error 0.2199446611155166\n",
            "Loss: 0.41149709981367355\n",
            "training error 0.11496760358813993, test error 0.22046807418415185\n",
            "Loss: 0.6504512510838945\n",
            "training error 0.11493414506595168, test error 0.22078200071808388\n",
            "Loss: 0.7937683613588042\n",
            "training error 0.11503853838096899, test error 0.220518790838732\n",
            "Loss: 0.6736049625150065\n",
            "training error 0.11514327743333849, test error 0.22069789981234073\n",
            "Loss: 0.7553737133128235\n",
            "training error 0.11517678897952954, test error 0.21979233613064852\n",
            "Loss: 0.3419560629967844\n",
            "training error 0.11484360236877238, test error 0.22010181427576272\n",
            "Loss: 0.48324234706926816\n",
            "training error 0.1147455382603389, test error 0.2198621005298162\n",
            "Loss: 0.3738056552040625\n",
            "training error 0.11478217075918241, test error 0.21944324859828693\n",
            "Loss: 0.18258687637717763\n",
            "training error 0.1147301172556249, test error 0.21917250791066836\n",
            "Loss: 0.05898543212419227\n",
            "training error 0.11465725243094405, test error 0.2194706072987407\n",
            "Loss: 0.19507696391709572\n",
            "training error 0.1147559933062093, test error 0.21997727369291853\n",
            "Loss: 0.42638574364164405\n",
            "training error 0.1148174275596639, test error 0.22009888688003346\n",
            "Loss: 0.4819059009546489\n",
            "training error 0.11484851863871516, test error 0.21961269589338606\n",
            "Loss: 0.25994477401434235\n",
            "training error 0.11468073874615872, test error 0.2199213022833528\n",
            "Loss: 0.4008330750713718\n",
            "training error 0.1146262947965672, test error 0.21961809533246116\n",
            "Loss: 0.2624097838867412\n",
            "training error 0.1146647186434442, test error 0.2195125495753808\n",
            "Loss: 0.21422490216593815\n",
            "training error 0.11471461587357538, test error 0.21920066795080945\n",
            "Loss: 0.07184135585798224\n",
            "training error 0.1148012452273419, test error 0.21886476283622402\n",
            "Loss: 0.0\n",
            "training error 0.1147011707366145, test error 0.21927378948660306\n",
            "Loss: 0.1868855658071933\n",
            "training error 0.11458723463331807, test error 0.21936142902591707\n",
            "Loss: 0.2269283475589523\n",
            "training error 0.11504626662424311, test error 0.21978727853100238\n",
            "Loss: 0.4215003287069363\n",
            "training error 0.11458398666869452, test error 0.2197869358492519\n",
            "Loss: 0.4213437563350242\n",
            "training error 0.11456485634655884, test error 0.21961488854034414\n",
            "Loss: 0.3427347986032059\n",
            "training error 0.11457080987114979, test error 0.219663872627332\n",
            "Loss: 0.3651157823454376\n",
            "training error 0.11459172118256578, test error 0.2194337223286715\n",
            "Loss: 0.2599593854553994\n",
            "training error 0.11465722478010705, test error 0.21999094469967545\n",
            "Loss: 0.5145560431279339\n",
            "training error 0.11462159827140873, test error 0.22012650857289046\n",
            "Loss: 0.5764956040962055\n",
            "training error 0.11498645196491854, test error 0.21973905852395983\n",
            "Loss: 0.399468455500096\n",
            "training error 0.1145448902374673, test error 0.22012348734699966\n",
            "Loss: 0.5751151964638268\n",
            "training error 0.11462527789009802, test error 0.22000492877103614\n",
            "Loss: 0.5209454094103227\n",
            "training error 0.11467978873453363, test error 0.22065339123601882\n",
            "Loss: 0.8172299536098659\n",
            "training error 0.11466045891269928, test error 0.22008310791655258\n",
            "Loss: 0.5566657074168813\n",
            "training error 0.11491256018881885, test error 0.21916553200544625\n",
            "Loss: 0.13742238143985563\n",
            "training error 0.11441455733155556, test error 0.2190080750933402\n",
            "Loss: 0.06547982199556213\n",
            "training error 0.11450320924407817, test error 0.21929141259168297\n",
            "Loss: 0.19493761806610443\n",
            "training error 0.11445558725943168, test error 0.2190888089078047\n",
            "Loss: 0.10236735629678417\n",
            "training error 0.1143955505161642, test error 0.21893440975642708\n",
            "Loss: 0.031821897367367846\n",
            "training error 0.11452016280443242, test error 0.21937271597037789\n",
            "Loss: 0.23208538805945533\n",
            "training error 0.11443610460940133, test error 0.21909621465271348\n",
            "Loss: 0.1057510644884685\n",
            "training error 0.11439416684058121, test error 0.21889383085316347\n",
            "Loss: 0.013281268561815551\n",
            "training error 0.11440732412714447, test error 0.21898292165550326\n",
            "Loss: 0.05398713696440627\n",
            "training error 0.11442027508367535, test error 0.21910055998398237\n",
            "Loss: 0.10773646004167414\n",
            "training error 0.11451091119765076, test error 0.2192676298462327\n",
            "Loss: 0.1840712067068262\n",
            "training error 0.11439434435501068, test error 0.21918645264576309\n",
            "Loss: 0.14698108794231057\n",
            "training error 0.11431698848153503, test error 0.21914760491514948\n",
            "Loss: 0.12923143737719744\n",
            "training error 0.11436252681265324, test error 0.21927493552759403\n",
            "Loss: 0.1874091955482715\n",
            "training error 0.11428141275481224, test error 0.2193471295440363\n",
            "Loss: 0.22039486921574536\n",
            "training error 0.11424631019453074, test error 0.21941678334703277\n",
            "Loss: 0.25221991135311317\n",
            "training error 0.11428818044744216, test error 0.2191517374646355\n",
            "Loss: 0.13111961226313085\n",
            "training error 0.11432760100523533, test error 0.21879842645270914\n",
            "Loss: 0.0\n",
            "training error 0.11423548305295778, test error 0.21895434243785233\n",
            "Loss: 0.07126010349844947\n",
            "training error 0.11421870286897362, test error 0.21913667512911225\n",
            "Loss: 0.15459374269140014\n",
            "training error 0.11430499786556075, test error 0.21919936991669825\n",
            "Loss: 0.1832478736202292\n",
            "training error 0.11430515931576, test error 0.2189623060013561\n",
            "Loss: 0.07489978392618557\n",
            "training error 0.11428884598914871, test error 0.21860503558449187\n",
            "Loss: 0.0\n",
            "training error 0.11420605586631272, test error 0.2188530770408383\n",
            "Loss: 0.11346557305198512\n",
            "training error 0.11419958534717406, test error 0.2190581324009978\n",
            "Loss: 0.2072673281722226\n",
            "training error 0.11430819384207898, test error 0.21943760340648782\n",
            "Loss: 0.380854823298038\n",
            "training error 0.1142107876742554, test error 0.2192575810669318\n",
            "Loss: 0.2985043234229323\n",
            "training error 0.1141217916255371, test error 0.21917945376543374\n",
            "Loss: 0.2627653015430331\n",
            "training error 0.11417193992399509, test error 0.2190781631839231\n",
            "Loss: 0.2164303297800041\n",
            "training error 0.11445367536413836, test error 0.21963095012116385\n",
            "Loss: 0.4693005053286958\n",
            "training error 0.11416858689750888, test error 0.21942323419839665\n",
            "Loss: 0.374281686474931\n",
            "training error 0.11410493931850207, test error 0.21955441457004748\n",
            "Loss: 0.4342896233004101\n",
            "training error 0.11455234147388411, test error 0.2197979133310991\n",
            "Loss: 0.5456771585420128\n",
            "training error 0.11414391091187821, test error 0.2193500539223477\n",
            "Loss: 0.340805661618826\n",
            "training error 0.1141456386712106, test error 0.21899686883778796\n",
            "Loss: 0.1792425559861588\n",
            "training error 0.11404284409383339, test error 0.21901308971184033\n",
            "Loss: 0.1866627300040946\n",
            "training error 0.11432632270765285, test error 0.21847381685619213\n",
            "Loss: 0.0\n",
            "training error 0.11405253778902005, test error 0.21880012447111813\n",
            "Loss: 0.1493577672700086\n",
            "training error 0.11405663445714392, test error 0.218820317281555\n",
            "Loss: 0.15860043567186288\n",
            "training error 0.11409984534459801, test error 0.2191671860321362\n",
            "Loss: 0.3173694614400757\n",
            "training error 0.11406694261880007, test error 0.21907492584658023\n",
            "Loss: 0.27514005981950085\n",
            "training error 0.1140997953036098, test error 0.21926276406492193\n",
            "Loss: 0.361117510593556\n",
            "training error 0.11404924385648509, test error 0.219342646622075\n",
            "Loss: 0.39768141481903996\n",
            "training error 0.11409282692996851, test error 0.21909881824781963\n",
            "Loss: 0.28607610770992054\n",
            "training error 0.11398050840214109, test error 0.21893980339937036\n",
            "Loss: 0.2132917115120314\n",
            "training error 0.11398772134345611, test error 0.21925901622975766\n",
            "Loss: 0.3594020486593852\n",
            "training error 0.11445344744397322, test error 0.21918572205048106\n",
            "Loss: 0.32585378171772206\n",
            "training error 0.1140567475989578, test error 0.218618887164126\n",
            "Loss: 0.06640169061054024\n",
            "training error 0.11395525007056924, test error 0.2189777880194612\n",
            "Loss: 0.23067806042900152\n",
            "training error 0.11403000211901854, test error 0.21882076013763238\n",
            "Loss: 0.15880314008915875\n",
            "training error 0.11391867006501703, test error 0.2188428601442688\n",
            "Loss: 0.16891877177189762\n",
            "training error 0.11408072948565191, test error 0.21910348391562912\n",
            "Loss: 0.2882116806937285\n",
            "training error 0.11418442965684514, test error 0.21964925495382628\n",
            "Loss: 0.538022411357364\n",
            "training error 0.11403821597254818, test error 0.21911493773840895\n",
            "Loss: 0.29345433308323177\n",
            "training error 0.11393581983707013, test error 0.2188945003153808\n",
            "Loss: 0.19255554978727663\n",
            "training error 0.11392207866064043, test error 0.21914235875289395\n",
            "Loss: 0.3060055004860729\n",
            "training error 0.11392545810988013, test error 0.21854287428403577\n",
            "Loss: 0.03160901788477055\n",
            "training error 0.11413458402201385, test error 0.21892281469797076\n",
            "Loss: 0.20551563031196984\n",
            "training error 0.11395101318112322, test error 0.21830564970189298\n",
            "Loss: 0.0\n",
            "training error 0.11384159811382849, test error 0.21859110205305582\n",
            "Loss: 0.1307581143926706\n",
            "training error 0.1138503764437852, test error 0.2183924811700419\n",
            "Loss: 0.039775181387891045\n",
            "training error 0.11383569331366093, test error 0.2184800609132745\n",
            "Loss: 0.07989312764908885\n",
            "training error 0.1139550590924891, test error 0.2186853626825181\n",
            "Loss: 0.17393639658140891\n",
            "training error 0.11375811094825534, test error 0.2188369087767179\n",
            "Loss: 0.2433556234345602\n",
            "training error 0.11375621957149146, test error 0.21866595109786433\n",
            "Loss: 0.1650444669954121\n",
            "training error 0.11376222991209083, test error 0.2186353354825221\n",
            "Loss: 0.15102026955293724\n",
            "training error 0.1138422830958097, test error 0.2184798471825905\n",
            "Loss: 0.07979522331895694\n",
            "training error 0.11378435964311892, test error 0.21830895273353013\n",
            "Loss: 0.0015130307629007689\n",
            "training error 0.11376934806529553, test error 0.21844234209903635\n",
            "Loss: 0.06261514410186297\n",
            "training error 0.11371588354762255, test error 0.218623313866008\n",
            "Loss: 0.14551348741949077\n",
            "training error 0.11390481987142571, test error 0.21809752848806113\n",
            "Loss: 0.0\n",
            "training error 0.11369290208764937, test error 0.21811112038266398\n",
            "Loss: 0.006232025964281185\n",
            "training error 0.11385350559748217, test error 0.2181307776634688\n",
            "Loss: 0.015245094998639352\n",
            "training error 0.1139870378049137, test error 0.2183956460111083\n",
            "Loss: 0.13669000520724062\n",
            "training error 0.11380399826194816, test error 0.21879353145696298\n",
            "Loss: 0.31912464745786906\n",
            "training error 0.11379033042653988, test error 0.2182727588221416\n",
            "Loss: 0.08034494260216185\n",
            "training error 0.11376203125692091, test error 0.2183805047719003\n",
            "Loss: 0.12974758852191126\n",
            "training error 0.1136335211296881, test error 0.21840394557065065\n",
            "Loss: 0.1404954401426295\n",
            "training error 0.1136743220804098, test error 0.21843136115848166\n",
            "Loss: 0.15306577416753786\n",
            "training error 0.11363847028220044, test error 0.21856496812128606\n",
            "Loss: 0.21432596529882275\n",
            "training error 0.11370486110393975, test error 0.2185123878199566\n",
            "Loss: 0.1902173466941326\n",
            "training error 0.11370916163314142, test error 0.21828963400276066\n",
            "Loss: 0.08808238957647152\n",
            "training error 0.11365599152716821, test error 0.21819829823673886\n",
            "Loss: 0.046203984692683164\n",
            "training error 0.11364387359307233, test error 0.21792708739178018\n",
            "Loss: 0.0\n",
            "training error 0.1136393427396395, test error 0.2181824385678596\n",
            "Loss: 0.11717275678555517\n",
            "training error 0.11357012875232553, test error 0.21815991324213987\n",
            "Loss: 0.10683658151275921\n",
            "training error 0.11349657986890738, test error 0.21801643493573716\n",
            "Loss: 0.04099882443542313\n",
            "training error 0.11357017636756699, test error 0.21799416497863083\n",
            "Loss: 0.03077982992085726\n",
            "training error 0.11356599445816655, test error 0.2181621073570779\n",
            "Loss: 0.1078433929946554\n",
            "training error 0.11353211031276629, test error 0.2178879429490639\n",
            "Loss: 0.0\n",
            "training error 0.11354368834312557, test error 0.21784646713668965\n",
            "Loss: 0.0\n",
            "training error 0.11380757526461864, test error 0.21813714824293973\n",
            "Loss: 0.13343393173674833\n",
            "training error 0.11343684714519457, test error 0.21820753544895297\n",
            "Loss: 0.16574439650507422\n",
            "training error 0.11348656426666125, test error 0.21827182903978498\n",
            "Loss: 0.19525765493750846\n",
            "training error 0.11348682645751274, test error 0.21841192012150193\n",
            "Loss: 0.25956490928884524\n",
            "training error 0.11357049318948265, test error 0.21792474193831773\n",
            "Loss: 0.03593117788729394\n",
            "training error 0.113409156683525, test error 0.2179921737562258\n",
            "Loss: 0.06688500458660318\n",
            "training error 0.11341578894190617, test error 0.21829571420220442\n",
            "Loss: 0.20622187333103614\n",
            "training error 0.11339322949422821, test error 0.21836211937070532\n",
            "Loss: 0.23670442802825598\n",
            "training error 0.11338055787847344, test error 0.21828077838911247\n",
            "Loss: 0.19936575429992942\n",
            "training error 0.11339961771769276, test error 0.21799514809781306\n",
            "Loss: 0.06825034304096533\n",
            "training error 0.11334971405183707, test error 0.21797401870978533\n",
            "Loss: 0.058551132259432315\n",
            "training error 0.11338184388174151, test error 0.21791258773055766\n",
            "Loss: 0.030351923874216702\n",
            "training error 0.11342460408146625, test error 0.21761940093135784\n",
            "Loss: 0.0\n",
            "training error 0.11338813490826315, test error 0.2177488568766958\n",
            "Loss: 0.05948731812692731\n",
            "training error 0.11334360187018426, test error 0.21791511049553483\n",
            "Loss: 0.13588382419555955\n",
            "training error 0.11331549191787631, test error 0.21801478902282087\n",
            "Loss: 0.1816878870959382\n",
            "training error 0.11343827086595949, test error 0.21798049557307583\n",
            "Loss: 0.16592943467934607\n",
            "training error 0.11332338730005032, test error 0.2176187873620728\n",
            "Loss: 0.0\n",
            "training error 0.11334251598478848, test error 0.21775695296396927\n",
            "Loss: 0.0634897398203993\n",
            "training error 0.11328488408971583, test error 0.21753213874977623\n",
            "Loss: 0.0\n",
            "training error 0.113261545096942, test error 0.2177915095801892\n",
            "Loss: 0.1192333380729993\n",
            "training error 0.11336660243265342, test error 0.21804339863211825\n",
            "Loss: 0.23502728621176416\n",
            "training error 0.11324821580346753, test error 0.21768608464037784\n",
            "Loss: 0.07076926264155681\n",
            "training error 0.1131952165266836, test error 0.217581217927444\n",
            "Loss: 0.022561805326715145\n",
            "training error 0.11319106024734843, test error 0.21764290577082746\n",
            "Loss: 0.05091984186238463\n",
            "training error 0.11314717579635902, test error 0.21756348105614864\n",
            "Loss: 0.014408126795673049\n",
            "training error 0.11344809917011425, test error 0.21723930349300635\n",
            "Loss: 0.0\n",
            "training error 0.11324437409960611, test error 0.21718227753971786\n",
            "Loss: 0.0\n",
            "training error 0.11323629043972584, test error 0.21748918488272523\n",
            "Loss: 0.14131325377193527\n",
            "training error 0.11312539215624895, test error 0.21741783933683248\n",
            "Loss: 0.10846271610331915\n",
            "training error 0.1130677742713096, test error 0.21735502495186576\n",
            "Loss: 0.07954028943097935\n",
            "training error 0.11353755528506176, test error 0.21789252656339173\n",
            "Loss: 0.32702899689591725\n",
            "training error 0.1130600843863638, test error 0.21754293656938423\n",
            "Loss: 0.16606282692674945\n",
            "training error 0.11308444730116464, test error 0.21742931233904356\n",
            "Loss: 0.11374537652157901\n",
            "training error 0.11309378452198518, test error 0.2176268912793947\n",
            "Loss: 0.2047191624995781\n",
            "training error 0.11317888894562188, test error 0.217106762680744\n",
            "Loss: 0.0\n",
            "training error 0.11309312934803904, test error 0.2174311583599184\n",
            "Loss: 0.1494175838508527\n",
            "training error 0.11293383436119477, test error 0.21730360243253471\n",
            "Loss: 0.09066495642984229\n",
            "training error 0.11301677655297951, test error 0.21719847414328583\n",
            "Loss: 0.04224256370894963\n",
            "training error 0.1130310081164015, test error 0.21713401693324763\n",
            "Loss: 0.012553387175562314\n",
            "training error 0.1129656552880047, test error 0.21722795720535323\n",
            "Loss: 0.05582254698692779\n",
            "training error 0.11291291413745828, test error 0.21722944417906176\n",
            "Loss: 0.05650745135845625\n",
            "training error 0.11305734658988613, test error 0.2174054882432789\n",
            "Loss: 0.13759385421547865\n",
            "training error 0.11284328343058857, test error 0.21730933053295085\n",
            "Loss: 0.09330333597425966\n",
            "training error 0.11292607673221952, test error 0.21726115986182426\n",
            "Loss: 0.07111578615692782\n",
            "training error 0.11283392538832798, test error 0.2172590489853889\n",
            "Loss: 0.07014351039300593\n",
            "training error 0.11287754661089594, test error 0.21711756725051562\n",
            "Loss: 0.004976615946095109\n",
            "training error 0.1128957106114536, test error 0.2171695615711721\n",
            "Loss: 0.028925349746211637\n",
            "training error 0.11277500310479073, test error 0.2172706690496939\n",
            "Loss: 0.07549574546921178\n",
            "training error 0.11275122419725021, test error 0.21716959985512296\n",
            "Loss: 0.028942983444224524\n",
            "training error 0.11275704703334913, test error 0.2173367520128993\n",
            "Loss: 0.10593374859237947\n",
            "training error 0.11297319155166252, test error 0.21699283600452005\n",
            "Loss: 0.0\n",
            "training error 0.11288136956725754, test error 0.21677719198063697\n",
            "Loss: 0.0\n",
            "training error 0.11268832735889682, test error 0.21680719838065216\n",
            "Loss: 0.01384204663832378\n",
            "training error 0.1128332151508092, test error 0.2170162618705609\n",
            "Loss: 0.11028369162806584\n",
            "training error 0.11267874134180175, test error 0.21673476998668423\n",
            "Loss: 0.0\n",
            "training error 0.11264096273265789, test error 0.21687565546720253\n",
            "Loss: 0.06500363579269308\n",
            "training error 0.11265974391660512, test error 0.21683057442159584\n",
            "Loss: 0.044203537308518115\n",
            "training error 0.112598725017948, test error 0.21677696143412664\n",
            "Loss: 0.019466856861494186\n",
            "training error 0.11259366925310667, test error 0.21685003709927012\n",
            "Loss: 0.0531834890142413\n",
            "training error 0.11259850269710116, test error 0.21697298690012648\n",
            "Loss: 0.10991171995933247\n",
            "training error 0.11257487075971447, test error 0.21709795298230194\n",
            "Loss: 0.16757024986808755\n",
            "training error 0.11256198254832038, test error 0.21701976830298753\n",
            "Loss: 0.1314963521177548\n",
            "training error 0.11248112659212868, test error 0.21693498203069153\n",
            "Loss: 0.09237652270541741\n",
            "training error 0.11245797739098429, test error 0.21686353921474388\n",
            "Loss: 0.05941327645193617\n",
            "training error 0.1124438544538771, test error 0.2168346770535112\n",
            "Loss: 0.04609646474034168\n",
            "training error 0.11238429925724262, test error 0.216769233084552\n",
            "Loss: 0.01590104710467166\n",
            "training error 0.11245449140375204, test error 0.21681353636548065\n",
            "Loss: 0.03634229007245526\n",
            "training error 0.11240455347157113, test error 0.21664945210047099\n",
            "Loss: 0.0\n",
            "training error 0.11232211567604165, test error 0.21652992990715977\n",
            "Loss: 0.0\n",
            "training error 0.11230326312854298, test error 0.21657182958034915\n",
            "Loss: 0.01935052267709736\n",
            "training error 0.11223640417518664, test error 0.21644025722256824\n",
            "Loss: 0.0\n",
            "training error 0.11235155174304703, test error 0.21639468147702579\n",
            "Loss: 0.0\n",
            "training error 0.11225850304512236, test error 0.2166218061029905\n",
            "Loss: 0.10495850656515593\n",
            "training error 0.11223855356688707, test error 0.21640752230291121\n",
            "Loss: 0.005933984050709995\n",
            "training error 0.11215472941251656, test error 0.2163780090578333\n",
            "Loss: 0.0\n",
            "training error 0.11210711431568787, test error 0.2162144309080705\n",
            "Loss: 0.0\n",
            "training error 0.11217109323719195, test error 0.21599389102684632\n",
            "Loss: 0.0\n",
            "training error 0.1122520831222041, test error 0.21606192408874839\n",
            "Loss: 0.03149767874388587\n",
            "training error 0.11212425767834588, test error 0.2162690113599348\n",
            "Loss: 0.12737412700911666\n",
            "training error 0.11201904587822965, test error 0.21614205986979626\n",
            "Loss: 0.06859862667667471\n",
            "training error 0.11223219522383862, test error 0.21595147419708705\n",
            "Loss: 0.0\n",
            "training error 0.11197558405392828, test error 0.21628739370684694\n",
            "Loss: 0.15555323760063633\n",
            "training error 0.11192836887310867, test error 0.2161890377226701\n",
            "Loss: 0.11000782766883432\n",
            "training error 0.11198954371398842, test error 0.2161384256998681\n",
            "Loss: 0.08657107041114553\n",
            "training error 0.11186022103940758, test error 0.2159772401585692\n",
            "Loss: 0.01193136633030889\n",
            "training error 0.11185243430990656, test error 0.21589858192915168\n",
            "Loss: 0.0\n",
            "training error 0.11196963383974122, test error 0.21567408177062228\n",
            "Loss: 0.0\n",
            "training error 0.11185807518836473, test error 0.21604530717582462\n",
            "Loss: 0.1721233270844058\n",
            "training error 0.11205191542219374, test error 0.216215691876774\n",
            "Loss: 0.25112433617673346\n",
            "training error 0.11181521880869347, test error 0.21581106327365\n",
            "Loss: 0.06351319634845254\n",
            "training error 0.11170240015169058, test error 0.21582423499530212\n",
            "Loss: 0.06962043071987445\n",
            "training error 0.11161539523297506, test error 0.21571220278808048\n",
            "Loss: 0.01767528909604188\n",
            "training error 0.11162613852988586, test error 0.21585725198472577\n",
            "Loss: 0.08492917303726255\n",
            "training error 0.11155855588434517, test error 0.2155114946664067\n",
            "Loss: 0.0\n",
            "training error 0.1115252989127785, test error 0.2152743010582699\n",
            "Loss: 0.0\n",
            "training error 0.11157757818842931, test error 0.21536429849857716\n",
            "Loss: 0.04180593775702235\n",
            "training error 0.11148044648545781, test error 0.21545393837681615\n",
            "Loss: 0.08344577948373733\n",
            "training error 0.11140919998475567, test error 0.2155224858779078\n",
            "Loss: 0.11528771359043954\n",
            "training error 0.11141975208721665, test error 0.21521507201014406\n",
            "Loss: 0.0\n",
            "training error 0.11128424537461354, test error 0.21507764645282804\n",
            "Loss: 0.0\n",
            "training error 0.11127331572862065, test error 0.2148015807446268\n",
            "Loss: 0.0\n",
            "training error 0.11121062547638684, test error 0.2148037416011494\n",
            "Loss: 0.0010059779425697357\n",
            "training error 0.1111301159787835, test error 0.2147874698059869\n",
            "Loss: 0.0\n",
            "training error 0.11111749617769237, test error 0.21480256729671623\n",
            "Loss: 0.007029037002470595\n",
            "training error 0.11105108588935675, test error 0.21468684760954482\n",
            "Loss: 0.0\n",
            "training error 0.11118511763901069, test error 0.21422064060694784\n",
            "Loss: 0.0\n",
            "training error 0.1110601370838599, test error 0.2143774670953312\n",
            "Loss: 0.0732079261545504\n",
            "training error 0.11105288094822875, test error 0.21418564314738373\n",
            "Loss: 0.0\n",
            "training error 0.1110137209839736, test error 0.21434871554719295\n",
            "Loss: 0.07613600865723491\n",
            "training error 0.11083515660784382, test error 0.2143794243854587\n",
            "Loss: 0.09047349543480632\n",
            "training error 0.1108167787146867, test error 0.21435069281349947\n",
            "Loss: 0.07705916404592283\n",
            "training error 0.11067963241469393, test error 0.21425533501547242\n",
            "Loss: 0.03253806700793671\n",
            "training error 0.11067407761494405, test error 0.21393556781048684\n",
            "Loss: 0.0\n",
            "training error 0.11062275881497739, test error 0.21383775048568704\n",
            "Loss: 0.0\n",
            "training error 0.11068320622873153, test error 0.21380894178900656\n",
            "Loss: 0.0\n",
            "training error 0.11048138605303488, test error 0.21356106349575354\n",
            "Loss: 0.0\n",
            "training error 0.11041991712936719, test error 0.2135634800515155\n",
            "Loss: 0.0011315525978217167\n",
            "training error 0.11039303268997326, test error 0.21359532376484366\n",
            "Loss: 0.016042376137903602\n",
            "training error 0.11030545717654901, test error 0.21341685800381033\n",
            "Loss: 0.0\n",
            "training error 0.11040510174655034, test error 0.21330403055525332\n",
            "Loss: 0.0\n",
            "training error 0.1102522324126826, test error 0.2131730380696792\n",
            "Loss: 0.0\n",
            "training error 0.11023922213299303, test error 0.21314268526882985\n",
            "Loss: 0.0\n",
            "training error 0.11023010433947505, test error 0.21333241662399485\n",
            "Loss: 0.08901612313165774\n",
            "training error 0.11000780094836704, test error 0.2130902314761063\n",
            "Loss: 0.0\n",
            "training error 0.10994485800093394, test error 0.21301323345393383\n",
            "Loss: 0.0\n",
            "training error 0.10991055289595089, test error 0.21279479531140164\n",
            "Loss: 0.0\n",
            "training error 0.1098701522728716, test error 0.2128228643448029\n",
            "Loss: 0.013190657863693112\n",
            "training error 0.10981082215815824, test error 0.2126013010564502\n",
            "Loss: 0.0\n",
            "training error 0.10974791427006468, test error 0.21274138201520665\n",
            "Loss: 0.06588904115842897\n",
            "training error 0.10969132598818122, test error 0.21246828909493173\n",
            "Loss: 0.0\n",
            "training error 0.10959273062833211, test error 0.21248971813543988\n",
            "Loss: 0.010085759432354457\n",
            "training error 0.10960835826983831, test error 0.21225260456630787\n",
            "Loss: 0.0\n",
            "training error 0.10955842741158864, test error 0.21235353593536813\n",
            "Loss: 0.04755247610104263\n",
            "training error 0.10931172150303743, test error 0.21225969823224655\n",
            "Loss: 0.003342086639257502\n",
            "training error 0.10934076291095453, test error 0.2120313005337138\n",
            "Loss: 0.0\n",
            "training error 0.10915211956263239, test error 0.2119520161440916\n",
            "Loss: 0.0\n",
            "training error 0.10911246643797362, test error 0.21197531562588842\n",
            "Loss: 0.010992809703203044\n",
            "training error 0.10908840061174013, test error 0.21149399972938546\n",
            "Loss: 0.0\n",
            "training error 0.10896890025534149, test error 0.21145930224832923\n",
            "Loss: 0.0\n",
            "training error 0.10892965489490923, test error 0.21114840913785277\n",
            "Loss: 0.0\n",
            "training error 0.10884307035939071, test error 0.2110883234735955\n",
            "Loss: 0.0\n",
            "training error 0.10865375670186406, test error 0.21100367655173125\n",
            "Loss: 0.0\n",
            "training error 0.10860536692136749, test error 0.2107559678058873\n",
            "Loss: 0.0\n",
            "training error 0.10857840006546114, test error 0.21078349043880182\n",
            "Loss: 0.013059005256677025\n",
            "training error 0.10839733541396353, test error 0.2106753930089484\n",
            "Loss: 0.0\n",
            "training error 0.10842741661079308, test error 0.21057129825751542\n",
            "Loss: 0.0\n",
            "training error 0.10827693103856391, test error 0.21032527333702106\n",
            "Loss: 0.0\n",
            "training error 0.10821270873021499, test error 0.21006756554920372\n",
            "Loss: 0.0\n",
            "training error 0.10810377395194005, test error 0.21015316232303494\n",
            "Loss: 0.0407472584391666\n",
            "training error 0.10795614785276446, test error 0.21015917182951574\n",
            "Loss: 0.04360800777241103\n",
            "training error 0.10794618215697455, test error 0.20997729642475757\n",
            "Loss: 0.0\n",
            "training error 0.10783740255050842, test error 0.20982575181557905\n",
            "Loss: 0.0\n",
            "training error 0.10770809355352373, test error 0.20972889583856322\n",
            "Loss: 0.0\n",
            "training error 0.10768269306572184, test error 0.2094588046738622\n",
            "Loss: 0.0\n",
            "training error 0.10757187266740585, test error 0.20933482914811608\n",
            "Loss: 0.0\n",
            "training error 0.1075377059933406, test error 0.20924280882157625\n",
            "Loss: 0.0\n",
            "training error 0.10747541053044274, test error 0.208822291033867\n",
            "Loss: 0.0\n",
            "training error 0.10733519356666839, test error 0.20888715488633822\n",
            "Loss: 0.031061747359473202\n",
            "training error 0.10715702121712717, test error 0.20893888992848564\n",
            "Loss: 0.055836421505262024\n",
            "training error 0.10702402522668303, test error 0.20863746618652831\n",
            "Loss: 0.0\n",
            "training error 0.10691146951349692, test error 0.20857986392622146\n",
            "Loss: 0.0\n",
            "training error 0.10684961279769266, test error 0.20839013325669387\n",
            "Loss: 0.0\n",
            "training error 0.10681029584360464, test error 0.20817302272930846\n",
            "Loss: 0.0\n",
            "training error 0.10658042065079057, test error 0.20790180255305246\n",
            "Loss: 0.0\n",
            "training error 0.10647166461591785, test error 0.20770344697829357\n",
            "Loss: 0.0\n",
            "training error 0.10651928364392822, test error 0.20729456077507227\n",
            "Loss: 0.0\n",
            "training error 0.10633738537384775, test error 0.2072842051353382\n",
            "Loss: 0.0\n",
            "training error 0.10614418899197962, test error 0.20725948815531506\n",
            "Loss: 0.0\n",
            "training error 0.10605320376643632, test error 0.2072828733608679\n",
            "Loss: 0.011283056694288973\n",
            "training error 0.10594403152629454, test error 0.20715191645019287\n",
            "Loss: 0.0\n",
            "training error 0.10585833836970714, test error 0.2070607382310939\n",
            "Loss: 0.0\n",
            "training error 0.10581414185248919, test error 0.20695490461420446\n",
            "Loss: 0.0\n",
            "training error 0.10560454966735473, test error 0.2064464557368458\n",
            "Loss: 0.0\n",
            "training error 0.10541491318848041, test error 0.20630877789755622\n",
            "Loss: 0.0\n",
            "training error 0.10536291405031255, test error 0.20602420721580195\n",
            "Loss: 0.0\n",
            "training error 0.1052798934989953, test error 0.20601265200224977\n",
            "Loss: 0.0\n",
            "training error 0.1050892211723031, test error 0.2057346593321948\n",
            "Loss: 0.0\n",
            "training error 0.10504077289987687, test error 0.2053017199253721\n",
            "Loss: 0.0\n",
            "training error 0.10477307360393405, test error 0.20552391924707455\n",
            "Loss: 0.10823061871241269\n",
            "training error 0.10473306804727567, test error 0.2054217661334287\n",
            "Loss: 0.05847306496029603\n",
            "training error 0.10460320973150761, test error 0.20517910340253004\n",
            "Loss: 0.0\n",
            "training error 0.1043648424637219, test error 0.2048690976085683\n",
            "Loss: 0.0\n",
            "training error 0.10427369596883168, test error 0.20482688900467153\n",
            "Loss: 0.0\n",
            "training error 0.10433817524975347, test error 0.20429684193351746\n",
            "Loss: 0.0\n",
            "training error 0.1040587778276768, test error 0.20406696644923564\n",
            "Loss: 0.0\n",
            "training error 0.10387145524102395, test error 0.20377984324675508\n",
            "Loss: 0.0\n",
            "training error 0.10392155015767889, test error 0.20350088078431408\n",
            "Loss: 0.0\n",
            "training error 0.10362261210021223, test error 0.20341062982930824\n",
            "Loss: 0.0\n",
            "training error 0.10347398224429831, test error 0.20324471776235467\n",
            "Loss: 0.0\n",
            "training error 0.10342963589886593, test error 0.20283178378212113\n",
            "Loss: 0.0\n",
            "training error 0.10322791394521073, test error 0.20266351767570015\n",
            "Loss: 0.0\n",
            "training error 0.10310407029493417, test error 0.20248136436073724\n",
            "Loss: 0.0\n",
            "training error 0.10302290471904446, test error 0.20247393419673548\n",
            "Loss: 0.0\n",
            "training error 0.10276406211169578, test error 0.20230424740081365\n",
            "Loss: 0.0\n",
            "training error 0.10299222895574793, test error 0.2025397472399048\n",
            "Loss: 0.11640874678453539\n",
            "training error 0.10258368348995692, test error 0.20188342605009468\n",
            "Loss: 0.0\n",
            "training error 0.10249933670278716, test error 0.2017575976287261\n",
            "Loss: 0.0\n",
            "training error 0.10228592714556613, test error 0.2012474214589041\n",
            "Loss: 0.0\n",
            "training error 0.10211425626731618, test error 0.20102500320689295\n",
            "Loss: 0.0\n",
            "training error 0.10198286884580422, test error 0.20091330912112804\n",
            "Loss: 0.0\n",
            "training error 0.10180587659746156, test error 0.20059269039380337\n",
            "Loss: 0.0\n",
            "training error 0.10188833851598386, test error 0.2002142359861086\n",
            "Loss: 0.0\n",
            "training error 0.10166119533654593, test error 0.20007580189482588\n",
            "Loss: 0.0\n",
            "training error 0.10146461879062814, test error 0.19988590285738075\n",
            "Loss: 0.0\n",
            "training error 0.10137221813676588, test error 0.19955950252976876\n",
            "Loss: 0.0\n",
            "training error 0.10109532073659772, test error 0.19931039866273131\n",
            "Loss: 0.0\n",
            "training error 0.10106873708473507, test error 0.1989998866457752\n",
            "Loss: 0.0\n",
            "training error 0.10092239115094521, test error 0.1990805545949529\n",
            "Loss: 0.04053668096872798\n",
            "training error 0.10074171173186258, test error 0.1986814097739426\n",
            "Loss: 0.0\n",
            "training error 0.10053189420360993, test error 0.19840731999969594\n",
            "Loss: 0.0\n",
            "training error 0.10044713821703943, test error 0.19838359791702403\n",
            "Loss: 0.0\n",
            "training error 0.10013335472032556, test error 0.19812174651409828\n",
            "Loss: 0.0\n",
            "training error 0.10006879219885524, test error 0.19782272934166095\n",
            "Loss: 0.0\n",
            "training error 0.09992229116066947, test error 0.19770530638986683\n",
            "Loss: 0.0\n",
            "training error 0.09978428571768724, test error 0.19756878858250634\n",
            "Loss: 0.0\n",
            "training error 0.0995591673857547, test error 0.19740164897186244\n",
            "Loss: 0.0\n",
            "training error 0.09937409783916709, test error 0.19675715926555992\n",
            "Loss: 0.0\n",
            "training error 0.09922253309400676, test error 0.19644224082191\n",
            "Loss: 0.0\n",
            "training error 0.0991426689450715, test error 0.19628771452314223\n",
            "Loss: 0.0\n",
            "training error 0.09884993919821884, test error 0.19623115729509188\n",
            "Loss: 0.0\n",
            "training error 0.09888109129496805, test error 0.19635534795003406\n",
            "Loss: 0.06328793890535422\n",
            "training error 0.09863062949005219, test error 0.1963221063192417\n",
            "Loss: 0.0463479018334878\n",
            "training error 0.09833473282168206, test error 0.19585073432551053\n",
            "Loss: 0.0\n",
            "training error 0.09817157300989489, test error 0.19558982278542053\n",
            "Loss: 0.0\n",
            "training error 0.09815849050250529, test error 0.1949453974147748\n",
            "Loss: 0.0\n",
            "training error 0.09800992548060383, test error 0.19515376898418238\n",
            "Loss: 0.10688714489845985\n",
            "training error 0.09775138300337965, test error 0.19464815703930846\n",
            "Loss: 0.0\n",
            "training error 0.0976044720595545, test error 0.19474429009405764\n",
            "Loss: 0.04938811454031633\n",
            "training error 0.09745396076013765, test error 0.19427798648184472\n",
            "Loss: 0.0\n",
            "training error 0.09717404871141676, test error 0.1941619470062991\n",
            "Loss: 0.0\n",
            "training error 0.09698281048654431, test error 0.19377533666300323\n",
            "Loss: 0.0\n",
            "training error 0.09693323583220283, test error 0.19403416096377618\n",
            "Loss: 0.13356926904639632\n",
            "training error 0.0966556441157751, test error 0.19356367013514622\n",
            "Loss: 0.0\n",
            "training error 0.09647005028788845, test error 0.19344755462561578\n",
            "Loss: 0.0\n",
            "training error 0.09633541404323549, test error 0.19311250768330987\n",
            "Loss: 0.0\n",
            "training error 0.09607613594265846, test error 0.19262590402536323\n",
            "Loss: 0.0\n",
            "training error 0.09589651968238902, test error 0.19241480967123886\n",
            "Loss: 0.0\n",
            "training error 0.095843077076859, test error 0.19227665432132293\n",
            "Loss: 0.0\n",
            "training error 0.0960085396925568, test error 0.19187235414448922\n",
            "Loss: 0.0\n",
            "training error 0.09534740822230325, test error 0.19176205922601083\n",
            "Loss: 0.0\n",
            "training error 0.09524114667885539, test error 0.1909737983029742\n",
            "Loss: 0.0\n",
            "training error 0.09511036457090989, test error 0.19062916111866074\n",
            "Loss: 0.0\n",
            "training error 0.09495051671253024, test error 0.19028582657679532\n",
            "Loss: 0.0\n",
            "training error 0.09469722048230239, test error 0.19017072165825347\n",
            "Loss: 0.0\n",
            "training error 0.09472229201336674, test error 0.18999225396605268\n",
            "Loss: 0.0\n",
            "training error 0.09423044959097039, test error 0.1895871173375728\n",
            "Loss: 0.0\n",
            "training error 0.09413387073174759, test error 0.18940469406643612\n",
            "Loss: 0.0\n",
            "training error 0.09385196649184388, test error 0.18908760727640905\n",
            "Loss: 0.0\n",
            "training error 0.09372830417386856, test error 0.18844479779649695\n",
            "Loss: 0.0\n",
            "training error 0.09347360767897446, test error 0.1881597300422616\n",
            "Loss: 0.0\n",
            "training error 0.09337761292386527, test error 0.18777803533382373\n",
            "Loss: 0.0\n",
            "training error 0.0931499496337223, test error 0.18776153030130663\n",
            "Loss: 0.0\n",
            "training error 0.09297187764370987, test error 0.18765267778294362\n",
            "Loss: 0.0\n",
            "training error 0.09272966986695033, test error 0.18710784446563242\n",
            "Loss: 0.0\n",
            "training error 0.09248289945146677, test error 0.18699896245778944\n",
            "Loss: 0.0\n",
            "training error 0.09229513654895155, test error 0.18666505100688746\n",
            "Loss: 0.0\n",
            "training error 0.09227514297988122, test error 0.18635293646691392\n",
            "Loss: 0.0\n",
            "training error 0.09210712320954323, test error 0.18594370671430183\n",
            "Loss: 0.0\n",
            "training error 0.0917289182451548, test error 0.18568010182134118\n",
            "Loss: 0.0\n",
            "training error 0.09172348844750627, test error 0.1850326490209172\n",
            "Loss: 0.0\n",
            "training error 0.09131587272267178, test error 0.18479582732462194\n",
            "Loss: 0.0\n",
            "training error 0.09132816920410701, test error 0.1847257980286366\n",
            "Loss: 0.0\n",
            "training error 0.09109866641582848, test error 0.18422265998267745\n",
            "Loss: 0.0\n",
            "training error 0.09072277739266, test error 0.18401719298959798\n",
            "Loss: 0.0\n",
            "training error 0.0905924372062246, test error 0.1836639078642767\n",
            "Loss: 0.0\n",
            "training error 0.09018648285650663, test error 0.18357450730494332\n",
            "Loss: 0.0\n",
            "training error 0.09013277468641799, test error 0.18324891910216828\n",
            "Loss: 0.0\n",
            "training error 0.08979119309049487, test error 0.1830482631420185\n",
            "Loss: 0.0\n",
            "training error 0.08970201298916568, test error 0.1826391156198348\n",
            "Loss: 0.0\n",
            "training error 0.08957357966136636, test error 0.1823751576235407\n",
            "Loss: 0.0\n",
            "training error 0.08923291516094718, test error 0.18265884721984454\n",
            "Loss: 0.15555276277783303\n",
            "training error 0.08879011812394179, test error 0.18212952419475875\n",
            "Loss: 0.0\n",
            "training error 0.08878859162650202, test error 0.18125555485001837\n",
            "Loss: 0.0\n",
            "training error 0.08861724062983092, test error 0.18137780532912082\n",
            "Loss: 0.06744647313214891\n",
            "training error 0.08829345703728016, test error 0.18087293039157715\n",
            "Loss: 0.0\n",
            "training error 0.08783928974568356, test error 0.1805473509946985\n",
            "Loss: 0.0\n",
            "training error 0.08767610739023214, test error 0.180274913686831\n",
            "Loss: 0.0\n",
            "training error 0.08741864447042665, test error 0.17969747387336688\n",
            "Loss: 0.0\n",
            "training error 0.08705218705413612, test error 0.1793875830668932\n",
            "Loss: 0.0\n",
            "training error 0.08683957063305923, test error 0.17906911640366838\n",
            "Loss: 0.0\n",
            "training error 0.08681497852821542, test error 0.1791802725310529\n",
            "Loss: 0.062074426688929485\n",
            "training error 0.08636170275820908, test error 0.1782343251210028\n",
            "Loss: 0.0\n",
            "training error 0.08599381042304229, test error 0.17783557865891234\n",
            "Loss: 0.0\n",
            "training error 0.08570207775390673, test error 0.17726809271139052\n",
            "Loss: 0.0\n",
            "training error 0.08562834156170764, test error 0.1764530042705487\n",
            "Loss: 0.0\n",
            "training error 0.08518324283539482, test error 0.1758841319896606\n",
            "Loss: 0.0\n",
            "training error 0.08505655347549879, test error 0.17558612176355956\n",
            "Loss: 0.0\n",
            "training error 0.08499810782868032, test error 0.17572471915754082\n",
            "Loss: 0.07893413932102966\n",
            "training error 0.08438855721007012, test error 0.17441999003767233\n",
            "Loss: 0.0\n",
            "training error 0.08452188553918757, test error 0.17527789378038724\n",
            "Loss: 0.4918609056964174\n",
            "training error 0.08371918026138933, test error 0.17431134451974958\n",
            "Loss: 0.0\n",
            "training error 0.08357825335393824, test error 0.17408776128002745\n",
            "Loss: 0.0\n",
            "training error 0.0832604968154106, test error 0.17353849444324504\n",
            "Loss: 0.0\n",
            "training error 0.08280080012852137, test error 0.17252301970527656\n",
            "Loss: 0.0\n",
            "training error 0.08259678817818715, test error 0.17242584100471484\n",
            "Loss: 0.0\n",
            "training error 0.08219046326042087, test error 0.17197437471405796\n",
            "Loss: 0.0\n",
            "training error 0.0819076444093083, test error 0.17162796898395458\n",
            "Loss: 0.0\n",
            "training error 0.08170533548445391, test error 0.17055165099843184\n",
            "Loss: 0.0\n",
            "training error 0.08127573596113716, test error 0.17048719148643698\n",
            "Loss: 0.0\n",
            "training error 0.08111961492601502, test error 0.17022886078292906\n",
            "Loss: 0.0\n",
            "training error 0.08077206395966839, test error 0.16916675665172962\n",
            "Loss: 0.0\n",
            "training error 0.08039825462185968, test error 0.16936663883899708\n",
            "Loss: 0.1181568951392542\n",
            "training error 0.07998038974180513, test error 0.16867606519133738\n",
            "Loss: 0.0\n",
            "training error 0.07974513603097513, test error 0.16872324489291593\n",
            "Loss: 0.027970596495152655\n",
            "training error 0.07929235640765897, test error 0.16760785777037698\n",
            "Loss: 0.0\n",
            "training error 0.07901022061544047, test error 0.16701469747118167\n",
            "Loss: 0.0\n",
            "training error 0.07893032311268762, test error 0.16544638158224823\n",
            "Loss: 0.0\n",
            "training error 0.07832245066645312, test error 0.16492145018080823\n",
            "Loss: 0.0\n",
            "training error 0.07799354927723925, test error 0.16381236969672347\n",
            "Loss: 0.0\n",
            "training error 0.0776537264369531, test error 0.16335229648122016\n",
            "Loss: 0.0\n",
            "training error 0.07728757107042532, test error 0.16326394508669778\n",
            "Loss: 0.0\n",
            "training error 0.07746144860673466, test error 0.16287791307442864\n",
            "Loss: 0.0\n",
            "training error 0.07655157808259114, test error 0.16219974759050906\n",
            "Loss: 0.0\n",
            "training error 0.07611143697895068, test error 0.16147624639056737\n",
            "Loss: 0.0\n",
            "training error 0.07632821681548628, test error 0.1607368497404095\n",
            "Loss: 0.0\n",
            "training error 0.07577501029113377, test error 0.16002447547138904\n",
            "Loss: 0.0\n",
            "training error 0.07501583317949655, test error 0.15928043553314936\n",
            "Loss: 0.0\n",
            "training error 0.0746498425864605, test error 0.15884329541308517\n",
            "Loss: 0.0\n",
            "training error 0.07428639482877189, test error 0.15797867672812202\n",
            "Loss: 0.0\n",
            "training error 0.07398738493081826, test error 0.15745852853553738\n",
            "Loss: 0.0\n",
            "training error 0.0735789736927963, test error 0.1572486492700095\n",
            "Loss: 0.0\n",
            "training error 0.07329955449372264, test error 0.15647980729571032\n",
            "Loss: 0.0\n",
            "training error 0.07278839089937172, test error 0.15631171498236662\n",
            "Loss: 0.0\n",
            "training error 0.07237711467769035, test error 0.1552108356550571\n",
            "Loss: 0.0\n",
            "training error 0.07199596208766099, test error 0.1542147287962821\n",
            "Loss: 0.0\n",
            "training error 0.07166770279180842, test error 0.15397216166453062\n",
            "Loss: 0.0\n",
            "training error 0.07094930035779763, test error 0.15360301703040363\n",
            "Loss: 0.0\n",
            "training error 0.07058259382932128, test error 0.15274419530406091\n",
            "Loss: 0.0\n",
            "training error 0.0702485811508952, test error 0.15124561236772213\n",
            "Loss: 0.0\n",
            "training error 0.06965343940055446, test error 0.15060689515476627\n",
            "Loss: 0.0\n",
            "training error 0.06938524181825818, test error 0.1496696152831339\n",
            "Loss: 0.0\n",
            "training error 0.06902272670540034, test error 0.1486751185118174\n",
            "Loss: 0.0\n",
            "training error 0.06874013974833358, test error 0.14851906875275725\n",
            "Loss: 0.0\n",
            "training error 0.06815904941195887, test error 0.1477921656518331\n",
            "Loss: 0.0\n",
            "training error 0.06765658921291666, test error 0.14682344231070923\n",
            "Loss: 0.0\n",
            "training error 0.0674499612679696, test error 0.14623579048690805\n",
            "Loss: 0.0\n",
            "training error 0.06698669713174342, test error 0.14563195227603618\n",
            "Loss: 0.0\n",
            "training error 0.0661942001815913, test error 0.14447710610903083\n",
            "Loss: 0.0\n",
            "training error 0.06601064023846619, test error 0.14441030650252681\n",
            "Loss: 0.0\n",
            "training error 0.06573053906400242, test error 0.1429517350250906\n",
            "Loss: 0.0\n",
            "training error 0.06490250689860463, test error 0.14184286795697357\n",
            "Loss: 0.0\n",
            "training error 0.06495595796805034, test error 0.14242801462235904\n",
            "Loss: 0.4125316089653275\n",
            "training error 0.06414888927034904, test error 0.14064999010174264\n",
            "Loss: 0.0\n",
            "training error 0.06391207710233375, test error 0.1402612985670811\n",
            "Loss: 0.0\n",
            "training error 0.06300348162008429, test error 0.13896416968881115\n",
            "Loss: 0.0\n",
            "training error 0.06266671056111624, test error 0.13790312532964732\n",
            "Loss: 0.0\n",
            "training error 0.06287926125971921, test error 0.1375855592263198\n",
            "Loss: 0.0\n",
            "training error 0.06195529988118062, test error 0.13620086521721464\n",
            "Loss: 0.0\n",
            "training error 0.06144162750443596, test error 0.13519227317802512\n",
            "Loss: 0.0\n",
            "training error 0.06098910164847237, test error 0.1340308505687455\n",
            "Loss: 0.0\n",
            "training error 0.06057219421542797, test error 0.1332723061034961\n",
            "Loss: 0.0\n",
            "training error 0.06032454448893476, test error 0.13344941263328225\n",
            "Loss: 0.1328907219843689\n",
            "training error 0.05974177037556327, test error 0.13221731291025413\n",
            "Loss: 0.0\n",
            "training error 0.05923763310864947, test error 0.13183873568540844\n",
            "Loss: 0.0\n",
            "training error 0.058711663805558215, test error 0.13057532811179062\n",
            "Loss: 0.0\n",
            "training error 0.058731405643493134, test error 0.13004701915855696\n",
            "Loss: 0.0\n",
            "training error 0.0579229680999475, test error 0.12907637216508785\n",
            "Loss: 0.0\n",
            "training error 0.05753794683986337, test error 0.12780458207579382\n",
            "Loss: 0.0\n",
            "training error 0.05702670737305667, test error 0.12664376998840193\n",
            "Loss: 0.0\n",
            "training error 0.05677298686368267, test error 0.12648669241549174\n",
            "Loss: 0.0\n",
            "training error 0.056381017445881754, test error 0.12581285818038593\n",
            "Loss: 0.0\n",
            "training error 0.05591430042292694, test error 0.12553278976084278\n",
            "Loss: 0.0\n",
            "training error 0.05537993170254995, test error 0.1243942062832307\n",
            "Loss: 0.0\n",
            "training error 0.05512643198068835, test error 0.1223294501244152\n",
            "Loss: 0.0\n",
            "training error 0.054989943254990306, test error 0.12287441492138326\n",
            "Loss: 0.44548945197888656\n",
            "training error 0.05419146997127529, test error 0.121938933502786\n",
            "Loss: 0.0\n",
            "training error 0.05356583612197903, test error 0.12088297609912625\n",
            "Loss: 0.0\n",
            "training error 0.053404636848281825, test error 0.11964513405282741\n",
            "Loss: 0.0\n",
            "training error 0.053472544041712, test error 0.11796851649286912\n",
            "Loss: 0.0\n",
            "training error 0.05259897249002513, test error 0.11758829409083722\n",
            "Loss: 0.0\n",
            "training error 0.05238331416121238, test error 0.11677835927940992\n",
            "Loss: 0.0\n",
            "training error 0.05144089668341733, test error 0.11524010643012426\n",
            "Loss: 0.0\n",
            "training error 0.051260791268117875, test error 0.11429672715883422\n",
            "Loss: 0.0\n",
            "training error 0.05083555286634821, test error 0.11351893395283769\n",
            "Loss: 0.0\n",
            "training error 0.050481648980112565, test error 0.11279106069519403\n",
            "Loss: 0.0\n",
            "training error 0.05000288025628275, test error 0.1123000093279275\n",
            "Loss: 0.0\n",
            "training error 0.049728386185849495, test error 0.11209543302672974\n",
            "Loss: 0.0\n",
            "training error 0.049336416744001826, test error 0.11095958887791924\n",
            "Loss: 0.0\n",
            "training error 0.049427698766066, test error 0.11008424601469578\n",
            "Loss: 0.0\n",
            "training error 0.0485459306848456, test error 0.10920694000420722\n",
            "Loss: 0.0\n",
            "training error 0.048009478961995936, test error 0.10852281712474136\n",
            "Loss: 0.0\n",
            "training error 0.04769785099072468, test error 0.1071751475388225\n",
            "Loss: 0.0\n",
            "training error 0.047240467760926656, test error 0.10666188361506301\n",
            "Loss: 0.0\n",
            "training error 0.04685742967143737, test error 0.10580765927730089\n",
            "Loss: 0.0\n",
            "training error 0.04654419137267041, test error 0.10597028451320963\n",
            "Loss: 0.15369892597523194\n",
            "training error 0.046134241415340206, test error 0.10431903272804201\n",
            "Loss: 0.0\n",
            "training error 0.04599770410896808, test error 0.10391644923270882\n",
            "Loss: 0.0\n",
            "training error 0.04561060056177996, test error 0.10281104887982967\n",
            "Loss: 0.0\n",
            "training error 0.045286599348717434, test error 0.1019703431011688\n",
            "Loss: 0.0\n",
            "training error 0.045050066418210084, test error 0.1013617031753463\n",
            "Loss: 0.0\n",
            "training error 0.04444330514039572, test error 0.10077889807677173\n",
            "Loss: 0.0\n",
            "training error 0.04411841689674378, test error 0.09995706879007785\n",
            "Loss: 0.0\n",
            "training error 0.043845546159660145, test error 0.09907085525716607\n",
            "Loss: 0.0\n",
            "training error 0.04347080623320378, test error 0.09806574783526685\n",
            "Loss: 0.0\n",
            "training error 0.04317151497291592, test error 0.09820240321076786\n",
            "Loss: 0.1393507708018049\n",
            "training error 0.04279238779377742, test error 0.09719470369022576\n",
            "Loss: 0.0\n",
            "training error 0.042385740941386175, test error 0.0965280132304371\n",
            "Loss: 0.0\n",
            "training error 0.042290043110547765, test error 0.0958697812548567\n",
            "Loss: 0.0\n",
            "training error 0.041691382320093694, test error 0.09449948756816905\n",
            "Loss: 0.0\n",
            "training error 0.04148647235907548, test error 0.09451397378930741\n",
            "Loss: 0.015329417662623968\n",
            "training error 0.04101804180475708, test error 0.09368461904044162\n",
            "Loss: 0.0\n",
            "training error 0.04088251992740279, test error 0.09200043378950856\n",
            "Loss: 0.0\n",
            "training error 0.040851171969313614, test error 0.09207206733207672\n",
            "Loss: 0.07786217914151905\n",
            "training error 0.04038187502659764, test error 0.09075437527046318\n",
            "Loss: 0.0\n",
            "training error 0.04014406252764616, test error 0.09017058926645956\n",
            "Loss: 0.0\n",
            "training error 0.03964555094515483, test error 0.09059432386288514\n",
            "Loss: 0.46992550439415304\n",
            "training error 0.03922723205482232, test error 0.08958032362137938\n",
            "Loss: 0.0\n",
            "training error 0.03904876906166504, test error 0.08896468695718417\n",
            "Loss: 0.0\n",
            "training error 0.038709680354505414, test error 0.08815194308378546\n",
            "Loss: 0.0\n",
            "training error 0.0386031701330799, test error 0.08761103042358993\n",
            "Loss: 0.0\n",
            "training error 0.03819100490789299, test error 0.08678173936135446\n",
            "Loss: 0.0\n",
            "training error 0.03795388575414896, test error 0.08696130995970988\n",
            "Loss: 0.20692210098220976\n",
            "training error 0.037848470397861406, test error 0.08625917432214923\n",
            "Loss: 0.0\n",
            "training error 0.03744198302586933, test error 0.0850360652600069\n",
            "Loss: 0.0\n",
            "training error 0.037296261412600604, test error 0.08540153634271286\n",
            "Loss: 0.42978362367600553\n",
            "training error 0.03694803520600434, test error 0.08373478070046447\n",
            "Loss: 0.0\n",
            "training error 0.03655087816149068, test error 0.08354747187389729\n",
            "Loss: 0.0\n",
            "training error 0.03639967132083671, test error 0.08323097259591117\n",
            "Loss: 0.0\n",
            "training error 0.036078417035306794, test error 0.08197808610500448\n",
            "Loss: 0.0\n",
            "training error 0.03602470837810302, test error 0.08215845284957117\n",
            "Loss: 0.2200182428456099\n",
            "training error 0.0357735748666675, test error 0.0819045390650135\n",
            "Loss: 0.0\n",
            "training error 0.03538113525804254, test error 0.08075047562017074\n",
            "Loss: 0.0\n",
            "training error 0.035206333526295486, test error 0.08046239219605882\n",
            "Loss: 0.0\n",
            "training error 0.03494056552797231, test error 0.08002452751394708\n",
            "Loss: 0.0\n",
            "training error 0.034750716588566294, test error 0.07891959907795487\n",
            "Loss: 0.0\n",
            "training error 0.03467253139638662, test error 0.07922513889272378\n",
            "Loss: 0.38715327794189847\n",
            "training error 0.03432815443960772, test error 0.07861565677827086\n",
            "Loss: 0.0\n",
            "training error 0.03392002874808696, test error 0.07785570252494839\n",
            "Loss: 0.0\n",
            "training error 0.03372603313083756, test error 0.07711078928630101\n",
            "Loss: 0.0\n",
            "training error 0.03361086937092189, test error 0.07716089070565614\n",
            "Loss: 0.06497329338583935\n",
            "training error 0.03335166067376944, test error 0.07643659547811608\n",
            "Loss: 0.0\n",
            "training error 0.03314567909219808, test error 0.07570294558278709\n",
            "Loss: 0.0\n",
            "training error 0.03297947398870898, test error 0.07601175245559438\n",
            "Loss: 0.40791923013032694\n",
            "training error 0.0329392863722456, test error 0.07436240300330783\n",
            "Loss: 0.0\n",
            "training error 0.03253712893520747, test error 0.07404037718929357\n",
            "Loss: 0.0\n",
            "training error 0.032484888224513675, test error 0.07407546539456167\n",
            "Loss: 0.04739063548850897\n",
            "training error 0.03220017088844901, test error 0.07404676276805414\n",
            "Loss: 0.008624454659700298\n",
            "training error 0.032142313051729605, test error 0.07372767997014149\n",
            "Loss: 0.0\n",
            "training error 0.03185364998699309, test error 0.07296743369571299\n",
            "Loss: 0.0\n",
            "training error 0.03155050609953629, test error 0.07292322929026064\n",
            "Loss: 0.0\n",
            "training error 0.03157300905748537, test error 0.07228752929741102\n",
            "Loss: 0.0\n",
            "training error 0.031389489703792836, test error 0.07174083493986562\n",
            "Loss: 0.0\n",
            "training error 0.031119041409833036, test error 0.07134282265942829\n",
            "Loss: 0.0\n",
            "training error 0.03102555064781253, test error 0.07061033793638918\n",
            "Loss: 0.0\n",
            "training error 0.03079618328267681, test error 0.06997165960312333\n",
            "Loss: 0.0\n",
            "training error 0.03058963104058084, test error 0.06985026539318935\n",
            "Loss: 0.0\n",
            "training error 0.03063377894561037, test error 0.06971020652631367\n",
            "Loss: 0.0\n",
            "training error 0.03025137677626278, test error 0.06910741333578972\n",
            "Loss: 0.0\n",
            "training error 0.03016741699837176, test error 0.06835321971905181\n",
            "Loss: 0.0\n",
            "training error 0.02997894312726884, test error 0.06846783969166047\n",
            "Loss: 0.1676877447467362\n",
            "training error 0.02977148064848562, test error 0.06811549116481513\n",
            "Loss: 0.0\n",
            "training error 0.02988457498337125, test error 0.06876938053350724\n",
            "Loss: 0.9599715975179945\n",
            "training error 0.029522381729491547, test error 0.0679476546945549\n",
            "Loss: 0.0\n",
            "training error 0.02932399524892592, test error 0.06759568334583307\n",
            "Loss: 0.0\n",
            "training error 0.029312716784136102, test error 0.0669664823468384\n",
            "Loss: 0.0\n",
            "training error 0.02905333648714256, test error 0.06635076106349629\n",
            "Loss: 0.0\n",
            "training error 0.028967087322956223, test error 0.0660576373094256\n",
            "Loss: 0.0\n",
            "training error 0.028801158270143148, test error 0.06574835225407258\n",
            "Loss: 0.0\n",
            "training error 0.028718568311749838, test error 0.06658613556075296\n",
            "Loss: 1.2742270763576258\n",
            "training error 0.028612159496326034, test error 0.06602700397946544\n",
            "Loss: 0.42381552668584455\n",
            "training error 0.028509100568849238, test error 0.06519746590392511\n",
            "Loss: 0.0\n",
            "training error 0.02843856277840331, test error 0.06477158436512098\n",
            "Loss: 0.0\n",
            "training error 0.028139880079386705, test error 0.06454482428773294\n",
            "Loss: 0.0\n",
            "training error 0.028108066255878836, test error 0.06400946511359162\n",
            "Loss: 0.0\n",
            "training error 0.027905905712077714, test error 0.06370201260572073\n",
            "Loss: 0.0\n",
            "training error 0.027929988962012063, test error 0.06401454373250494\n",
            "Loss: 0.49061421138858474\n",
            "training error 0.027715089009986912, test error 0.06413686635645932\n",
            "Loss: 0.6826373813808573\n",
            "training error 0.02764754201312274, test error 0.06335658476664978\n",
            "Loss: 0.0\n",
            "training error 0.02758543441964488, test error 0.06284259882970819\n",
            "Loss: 0.0\n",
            "training error 0.02734381305724763, test error 0.06253315128228307\n",
            "Loss: 0.0\n",
            "training error 0.027259311564374375, test error 0.06309456241144402\n",
            "Loss: 0.8977816048749476\n",
            "training error 0.02708071381231779, test error 0.06163728290556882\n",
            "Loss: 0.0\n",
            "training error 0.027160178462457028, test error 0.061193758485735696\n",
            "Loss: 0.0\n",
            "training error 0.0268983282055275, test error 0.06138794761526108\n",
            "Loss: 0.317334862787777\n",
            "training error 0.02687655386518577, test error 0.061219161499163156\n",
            "Loss: 0.04151242554153445\n",
            "training error 0.026704883596495615, test error 0.060680200290223286\n",
            "Loss: 0.0\n",
            "training error 0.026557372361590007, test error 0.06087422620863784\n",
            "Loss: 0.31975161170623156\n",
            "training error 0.026392625326414076, test error 0.06028938468851639\n",
            "Loss: 0.0\n",
            "training error 0.026441064203751606, test error 0.06057064599558587\n",
            "Loss: 0.466518788543957\n",
            "training error 0.026284904352341844, test error 0.05993705973061445\n",
            "Loss: 0.0\n",
            "training error 0.026272456561294823, test error 0.060203021318494664\n",
            "Loss: 0.4437347929237223\n",
            "training error 0.026100941166065986, test error 0.05980066408013862\n",
            "Loss: 0.0\n",
            "training error 0.025950413948582374, test error 0.05906505685805986\n",
            "Loss: 0.0\n",
            "training error 0.025815187410846124, test error 0.05912776876278252\n",
            "Loss: 0.10617428994164069\n",
            "training error 0.025775552478917715, test error 0.059034315503842236\n",
            "Loss: 0.0\n",
            "training error 0.025758744672850387, test error 0.05821426334301205\n",
            "Loss: 0.0\n",
            "training error 0.025703256198236983, test error 0.0589220197806524\n",
            "Loss: 1.2157783969026337\n",
            "training error 0.025487004971628462, test error 0.058288196466915104\n",
            "Loss: 0.1270017340379681\n",
            "training error 0.025487333529227742, test error 0.058014868865802136\n",
            "Loss: 0.0\n",
            "training error 0.025550153733715514, test error 0.05878094393421855\n",
            "Loss: 1.3204805654020824\n",
            "training error 0.025277216948788667, test error 0.05845815583347215\n",
            "Loss: 0.7640919928568746\n",
            "training error 0.025253083183124348, test error 0.05787957430595671\n",
            "Loss: 0.0\n",
            "training error 0.025177989598407922, test error 0.05813280658692079\n",
            "Loss: 0.43751579724045087\n",
            "training error 0.025174910905403733, test error 0.05765676749455187\n",
            "Loss: 0.0\n",
            "training error 0.02500663780528414, test error 0.05779853227765234\n",
            "Loss: 0.2458770917288522\n",
            "training error 0.025042669570127678, test error 0.057949532630306846\n",
            "Loss: 0.5077723717040517\n",
            "training error 0.024926992276444647, test error 0.05717005617163851\n",
            "Loss: 0.0\n",
            "training error 0.024857937928150806, test error 0.05755635049523481\n",
            "Loss: 0.6756934476967347\n",
            "training error 0.024734721639524546, test error 0.05692385878620763\n",
            "Loss: 0.0\n",
            "training error 0.024748221120791416, test error 0.056673790471460886\n",
            "Loss: 0.0\n",
            "training error 0.024630344237945693, test error 0.05551357893731959\n",
            "Loss: 0.0\n",
            "training error 0.024542728816805845, test error 0.055294323901052274\n",
            "Loss: 0.0\n",
            "training error 0.02449305888173246, test error 0.05596188483895055\n",
            "Loss: 1.2072865545708744\n",
            "training error 0.024322079559458483, test error 0.05527851216669318\n",
            "Loss: 0.0\n",
            "training error 0.024263586019176428, test error 0.054992541113474305\n",
            "Loss: 0.0\n",
            "training error 0.024347561290233948, test error 0.05504750817915245\n",
            "Loss: 0.09995367474422423\n",
            "training error 0.02411656247860837, test error 0.05489481252914125\n",
            "Loss: 0.0\n",
            "training error 0.024212372625806867, test error 0.05528291618043306\n",
            "Loss: 0.7069951301605704\n",
            "training error 0.024094374366538444, test error 0.05522777581650353\n",
            "Loss: 0.6065478175838912\n",
            "training error 0.024027572240229236, test error 0.0547557500627157\n",
            "Loss: 0.0\n",
            "training error 0.023890122042104507, test error 0.05439816524648004\n",
            "Loss: 0.0\n",
            "training error 0.023812458988620014, test error 0.054671934960630275\n",
            "Loss: 0.5032701248466331\n",
            "training error 0.023957327249971842, test error 0.05421242654940601\n",
            "Loss: 0.0\n",
            "training error 0.023676304436951078, test error 0.0544543160474051\n",
            "Loss: 0.44618828817530876\n",
            "training error 0.023689876415289784, test error 0.053965392683637876\n",
            "Loss: 0.0\n",
            "training error 0.023659512891973433, test error 0.053750220035281696\n",
            "Loss: 0.0\n",
            "training error 0.02368809494495872, test error 0.05396424221179914\n",
            "Loss: 0.3981791635028875\n",
            "training error 0.02349199331530153, test error 0.054054892063586844\n",
            "Loss: 0.5668293601498897\n",
            "training error 0.02357608526465996, test error 0.053631532325726164\n",
            "Loss: 0.0\n",
            "training error 0.023537387067544848, test error 0.05284593676931689\n",
            "Loss: 0.0\n",
            "training error 0.02343431614535799, test error 0.05281778296301657\n",
            "Loss: 0.0\n",
            "training error 0.02346301408804769, test error 0.05334773099171862\n",
            "Loss: 1.003351520969975\n",
            "training error 0.0233111066272715, test error 0.05290065562027798\n",
            "Loss: 0.156902945584525\n",
            "training error 0.023286406071011307, test error 0.0530669819661161\n",
            "Loss: 0.4718089043495466\n",
            "training error 0.023218352386841244, test error 0.05286189244663029\n",
            "Loss: 0.08351256175331834\n",
            "training error 0.02312110322710362, test error 0.053129293803103515\n",
            "Loss: 0.589784013284067\n",
            "training error 0.02313475051649175, test error 0.05226410146527023\n",
            "Loss: 0.0\n",
            "training error 0.023121426879799515, test error 0.05211817536288444\n",
            "Loss: 0.0\n",
            "training error 0.022980816836648404, test error 0.05198243937580904\n",
            "Loss: 0.0\n",
            "training error 0.02293528158682842, test error 0.052216985267374456\n",
            "Loss: 0.45120216438816474\n",
            "training error 0.02291352936968826, test error 0.052012036251472195\n",
            "Loss: 0.05693629621568164\n",
            "training error 0.023185679721259102, test error 0.05224765535866017\n",
            "Loss: 0.5102030340164321\n",
            "training error 0.023014436439378706, test error 0.05207364698593407\n",
            "Loss: 0.1754585033334921\n",
            "training error 0.022849273518983842, test error 0.05274313506730948\n",
            "Loss: 1.4633705163410227\n",
            "training error 0.02278842548605787, test error 0.0520395853632434\n",
            "Loss: 0.10993325461550185\n",
            "training error 0.0227698671661388, test error 0.05177912346908691\n",
            "Loss: 0.0\n",
            "training error 0.022885993903004942, test error 0.05235809275815127\n",
            "Loss: 1.1181519698957754\n",
            "training error 0.022650467091983616, test error 0.05177043653165918\n",
            "Loss: 0.0\n",
            "training error 0.022568209463968536, test error 0.05148938176545604\n",
            "Loss: 0.0\n",
            "training error 0.022570874722994398, test error 0.05157850536123955\n",
            "Loss: 0.17309121362047986\n",
            "training error 0.02248795903937516, test error 0.051346737772797225\n",
            "Loss: 0.0\n",
            "training error 0.02250303577014166, test error 0.05136107584017274\n",
            "Loss: 0.027924008413071633\n",
            "training error 0.022463043179198255, test error 0.05137260360072195\n",
            "Loss: 0.05037482232888024\n",
            "training error 0.022423474149959224, test error 0.05164020389244082\n",
            "Loss: 0.5715380029441164\n",
            "training error 0.022672191076146927, test error 0.052303807075172265\n",
            "Loss: 1.8639339983193226\n",
            "training error 0.022449501262496365, test error 0.05186532790046922\n",
            "Loss: 1.0099767778173119\n",
            "training error 0.022371103999662526, test error 0.051568545974828545\n",
            "Loss: 0.43198109880473456\n",
            "training error 0.02232607163597237, test error 0.05134842162243781\n",
            "Loss: 0.003279370245556912\n",
            "training error 0.02233183163914631, test error 0.05103213450706336\n",
            "Loss: 0.0\n",
            "training error 0.0222089580825181, test error 0.05076559247267203\n",
            "Loss: 0.0\n",
            "training error 0.02224120785049651, test error 0.0511557784543442\n",
            "Loss: 0.7686032264514919\n",
            "training error 0.022265259147075327, test error 0.05033237366314012\n",
            "Loss: 0.0\n",
            "training error 0.022126741784834564, test error 0.05046275636447101\n",
            "Loss: 0.25904341846365586\n",
            "training error 0.022186318465884765, test error 0.05059112912181656\n",
            "Loss: 0.5140934945929931\n",
            "training error 0.022038166629638117, test error 0.05012420936733318\n",
            "Loss: 0.0\n",
            "training error 0.02206172890919241, test error 0.04983417098783798\n",
            "Loss: 0.0\n",
            "training error 0.022226925736262202, test error 0.0503457867085254\n",
            "Loss: 1.0266363632541964\n",
            "training error 0.02213820029154295, test error 0.05046619643607036\n",
            "Loss: 1.268257173148557\n",
            "training error 0.022050713859230627, test error 0.04996195232104438\n",
            "Loss: 0.2564130809712628\n",
            "training error 0.021957698189383108, test error 0.05025027222073062\n",
            "Loss: 0.8349717164838344\n",
            "training error 0.021925092677897707, test error 0.0502030768015039\n",
            "Loss: 0.7402667815141317\n",
            "training error 0.021902663843025763, test error 0.04979202880675615\n",
            "Loss: 0.0\n",
            "training error 0.021902697627195645, test error 0.04973673646313672\n",
            "Loss: 0.0\n",
            "training error 0.022018745903276425, test error 0.04948901141497584\n",
            "Loss: 0.0\n",
            "training error 0.021981109995463013, test error 0.049348752681305626\n",
            "Loss: 0.0\n",
            "training error 0.021801613302170064, test error 0.049251907131718085\n",
            "Loss: 0.0\n",
            "training error 0.021890393390923885, test error 0.04926551759407428\n",
            "Loss: 0.027634386461006244\n",
            "training error 0.021760755173267705, test error 0.04907381689211691\n",
            "Loss: 0.0\n",
            "training error 0.02174737653718687, test error 0.0492359561488187\n",
            "Loss: 0.3303987074374737\n",
            "training error 0.021655417470139344, test error 0.04906317647570005\n",
            "Loss: 0.0\n",
            "training error 0.02170149776682673, test error 0.04930475691272592\n",
            "Loss: 0.4923864583971982\n",
            "training error 0.021629651921394474, test error 0.0492821379749168\n",
            "Loss: 0.44628480042501195\n",
            "training error 0.021613072932461574, test error 0.04931949268335632\n",
            "Loss: 0.5224207360141397\n",
            "training error 0.021668070459897715, test error 0.04901339260769755\n",
            "Loss: 0.0\n",
            "training error 0.021584166581063345, test error 0.04926575125450588\n",
            "Loss: 0.514876921147267\n",
            "training error 0.021626372380517962, test error 0.048994988938041266\n",
            "Loss: 0.0\n",
            "training error 0.02159473896792121, test error 0.049277552395850494\n",
            "Loss: 0.5767190970622726\n",
            "training error 0.021517858577815747, test error 0.04905672030083926\n",
            "Loss: 0.12599525816010537\n",
            "training error 0.021435313281617477, test error 0.04897675043085975\n",
            "Loss: 0.0\n",
            "training error 0.02151413519767256, test error 0.0485432207838777\n",
            "Loss: 0.0\n",
            "training error 0.02166526894978022, test error 0.04885582166862298\n",
            "Loss: 0.6439640380209388\n",
            "training error 0.021381234218045275, test error 0.04830236411455037\n",
            "Loss: 0.0\n",
            "training error 0.021456777943344555, test error 0.048295735394681696\n",
            "Loss: 0.0\n",
            "training error 0.02135876871143754, test error 0.048694376400685704\n",
            "Loss: 0.8254165771496069\n",
            "training error 0.021537626631816967, test error 0.04847779945293537\n",
            "Loss: 0.37697750487866166\n",
            "training error 0.021351841876764525, test error 0.04856578298975214\n",
            "Loss: 0.5591541217119245\n",
            "training error 0.021327376393375327, test error 0.04864638418558939\n",
            "Loss: 0.726045039053913\n",
            "training error 0.021281313181327522, test error 0.048227977220723924\n",
            "Loss: 0.0\n",
            "training error 0.021301479893965934, test error 0.04874023706658442\n",
            "Loss: 1.0621632408841064\n",
            "training error 0.021412888273567673, test error 0.04803248621682514\n",
            "Loss: 0.0\n",
            "training error 0.021308168430090858, test error 0.04760433764936236\n",
            "Loss: 0.0\n",
            "training error 0.02124330697976122, test error 0.04790377440504528\n",
            "Loss: 0.6290114944744518\n",
            "training error 0.02129249043284689, test error 0.04783062678379228\n",
            "Loss: 0.4753540236116516\n",
            "training error 0.02129733787560232, test error 0.04770667608138808\n",
            "Loss: 0.2149771156979785\n",
            "training error 0.021186296273254315, test error 0.048043513109758636\n",
            "Loss: 0.9225534522318002\n",
            "training error 0.021161285776948913, test error 0.04814452760914884\n",
            "Loss: 1.1347494502819133\n",
            "training error 0.021186929760230164, test error 0.04802396415045515\n",
            "Loss: 0.8814879521769958\n",
            "training error 0.0211752155276397, test error 0.04821906602435058\n",
            "Loss: 1.291328490937338\n",
            "training error 0.021111362950286133, test error 0.04792850931030936\n",
            "Loss: 0.68097084625931\n",
            "training error 0.02113614736040983, test error 0.04849940033322408\n",
            "Loss: 1.8802124513410012\n",
            "training error 0.021081683905286835, test error 0.04792770899970384\n",
            "Loss: 0.6792896746580679\n",
            "training error 0.021117226015846775, test error 0.04752609340966834\n",
            "Loss: 0.0\n",
            "training error 0.020974324628933137, test error 0.04753109200364122\n",
            "Loss: 0.010517578059277\n",
            "training error 0.021035332231844808, test error 0.047693733822131615\n",
            "Loss: 0.3527334153435202\n",
            "training error 0.021012589190370478, test error 0.04724851526077464\n",
            "Loss: 0.0\n",
            "training error 0.020925973896530742, test error 0.04746431840164316\n",
            "Loss: 0.45674057624340847\n",
            "training error 0.0212343707176823, test error 0.047194768358761685\n",
            "Loss: 0.0\n",
            "training error 0.02098317239002172, test error 0.047538893910707994\n",
            "Loss: 0.7291603792402679\n",
            "training error 0.02093914607576572, test error 0.04740062041160144\n",
            "Loss: 0.4361755762310793\n",
            "training error 0.0210582009739831, test error 0.04759132356530656\n",
            "Loss: 0.8402524693635005\n",
            "training error 0.020889175282357352, test error 0.04745910032474741\n",
            "Loss: 0.560087431675349\n",
            "training error 0.02092129005820051, test error 0.04741314922684751\n",
            "Loss: 0.46272261879907184\n",
            "training error 0.02103118799542921, test error 0.047457759762371154\n",
            "Loss: 0.5572469423099635\n",
            "training error 0.020923228494863867, test error 0.047042568324235416\n",
            "Loss: 0.0\n",
            "training error 0.020856604779080627, test error 0.04721472900718952\n",
            "Loss: 0.3659678650355547\n",
            "training error 0.020861171496309405, test error 0.04710903405510991\n",
            "Loss: 0.14128848241530267\n",
            "training error 0.02094192717768057, test error 0.047065732006228024\n",
            "Loss: 0.049239832810465956\n",
            "training error 0.020885022188544114, test error 0.04717416049766578\n",
            "Loss: 0.2797299937439268\n",
            "training error 0.020911374394872506, test error 0.046832994044107394\n",
            "Loss: 0.0\n",
            "training error 0.020882482169030676, test error 0.04772099837622663\n",
            "Loss: 1.8961083958948022\n",
            "training error 0.020858694890715655, test error 0.047530682152695417\n",
            "Loss: 1.4897362913226075\n",
            "training error 0.020787101564190214, test error 0.047267185189070464\n",
            "Loss: 0.9271052466860219\n",
            "training error 0.020792386197210657, test error 0.047143779423350136\n",
            "Loss: 0.6636034820879599\n",
            "training error 0.020753751582661215, test error 0.047255294252153114\n",
            "Loss: 0.9017151618536223\n",
            "training error 0.020766209476938594, test error 0.04698795359759559\n",
            "Loss: 0.33087688850781394\n",
            "training error 0.020718889293298553, test error 0.04734501846450936\n",
            "Loss: 1.0932984978917482\n",
            "training error 0.02086166072796076, test error 0.04696904730173234\n",
            "Loss: 0.29050728103527934\n",
            "training error 0.020726299287846032, test error 0.04712588534428283\n",
            "Loss: 0.6253952072754254\n",
            "training error 0.020760997668014605, test error 0.046785664833196836\n",
            "Loss: 0.0\n",
            "training error 0.020798898969302888, test error 0.04656577791567083\n",
            "Loss: 0.0\n",
            "training error 0.02071762564210718, test error 0.04738199684229096\n",
            "Loss: 1.752830003394923\n",
            "training error 0.020722687582578336, test error 0.046684694328848655\n",
            "Loss: 0.25537297668081216\n",
            "training error 0.0207198304319889, test error 0.04670293099585564\n",
            "Loss: 0.29453621591630785\n",
            "training error 0.020741214555629793, test error 0.04703292792231903\n",
            "Loss: 1.0032045582792248\n",
            "training error 0.020669548600891933, test error 0.04648759278432889\n",
            "Loss: 0.0\n",
            "training error 0.020659665707782, test error 0.04638679492407858\n",
            "Loss: 0.0\n",
            "training error 0.020844150661671983, test error 0.04674466134945096\n",
            "Loss: 0.7714834059091569\n",
            "training error 0.02066670722237258, test error 0.046455143536837905\n",
            "Loss: 0.14734497796451418\n",
            "training error 0.02066757686443344, test error 0.04689802071768116\n",
            "Loss: 1.1020933747186268\n",
            "training error 0.020632651255914874, test error 0.04685558816907537\n",
            "Loss: 1.0106178833093837\n",
            "training error 0.0206780264721368, test error 0.047128532740536834\n",
            "Loss: 1.5990279511060468\n",
            "training error 0.020681822453328624, test error 0.04626515409448949\n",
            "Loss: 0.0\n",
            "training error 0.020619057893220983, test error 0.04693183516596684\n",
            "Loss: 1.4410004343998528\n",
            "training error 0.02058949035741088, test error 0.0466526698265222\n",
            "Loss: 0.8375974091457072\n",
            "training error 0.020585880808598318, test error 0.04650921615563717\n",
            "Loss: 0.527528905770458\n",
            "training error 0.0206581621933698, test error 0.046406824171612564\n",
            "Loss: 0.306213347595774\n",
            "training error 0.02057845115217544, test error 0.046683513408089794\n",
            "Loss: 0.9042643903138581\n",
            "training error 0.02065605119080369, test error 0.047079582236376434\n",
            "Loss: 1.7603489231303504\n",
            "training error 0.020654291657347217, test error 0.04688179996114008\n",
            "Loss: 1.3328516433581683\n",
            "training error 0.020517323202618606, test error 0.04631299795538423\n",
            "Loss: 0.10341230204709007\n",
            "training error 0.020587380554181318, test error 0.04679475573446933\n",
            "Loss: 1.1447095559180775\n",
            "training error 0.02055378684807437, test error 0.046228597170885684\n",
            "Loss: 0.0\n",
            "training error 0.020583130515200405, test error 0.04666864350449302\n",
            "Loss: 0.9518920333677627\n",
            "training error 0.02061014421118761, test error 0.04679015443948606\n",
            "Loss: 1.2147400158489807\n",
            "training error 0.020553673754306747, test error 0.04653354788062367\n",
            "Loss: 0.6596581518810263\n",
            "training error 0.02052436843519243, test error 0.04650489801295107\n",
            "Loss: 0.5976838125630879\n",
            "training error 0.020587797597921474, test error 0.046750710546153144\n",
            "Loss: 1.12941643748663\n",
            "training error 0.02067167321283095, test error 0.04633353438086976\n",
            "Loss: 0.22699631052218727\n",
            "training error 0.020567562378338438, test error 0.04665616653129233\n",
            "Loss: 0.9249023041433047\n",
            "training error 0.020486124040063006, test error 0.04660777014423325\n",
            "Loss: 0.8202130208406322\n",
            "training error 0.020536599912520492, test error 0.04650462331252891\n",
            "Loss: 0.5970895907199569\n",
            "training error 0.02046614707376554, test error 0.04664436198600678\n",
            "Loss: 0.8993671462367958\n",
            "training error 0.02058808416140994, test error 0.04715662933722387\n",
            "Loss: 2.007485026871314\n",
            "training error 0.020583493126522752, test error 0.04712816105569259\n",
            "Loss: 1.9459034880111803\n",
            "training error 0.02044166138323969, test error 0.04688374840831266\n",
            "Loss: 1.4171990445766447\n",
            "training error 0.02044620568732956, test error 0.046627651580274786\n",
            "Loss: 0.8632198115681167\n",
            "training error 0.02051591218011801, test error 0.04612593587342446\n",
            "Loss: 0.0\n",
            "training error 0.02097845768535327, test error 0.04589325007704672\n",
            "Loss: 0.0\n",
            "training error 0.020620942066476623, test error 0.04624260429709276\n",
            "Loss: 0.7612322497524859\n",
            "training error 0.02037865800019793, test error 0.04602039165086617\n",
            "Loss: 0.2770376332162039\n",
            "training error 0.020320403608416783, test error 0.04614188638393525\n",
            "Loss: 0.5417709717030705\n",
            "training error 0.020403869795752167, test error 0.04634072758089265\n",
            "Loss: 0.975039909125397\n",
            "training error 0.02041459561982079, test error 0.04617137625374913\n",
            "Loss: 0.6060285036154189\n",
            "training error 0.020413025550152935, test error 0.046135556559043084\n",
            "Loss: 0.5279784752432626\n",
            "training error 0.020349146430806417, test error 0.04621894957989161\n",
            "Loss: 0.7096893384061831\n",
            "training error 0.020478221384096655, test error 0.04615209772263595\n",
            "Loss: 0.5640211690274066\n",
            "training error 0.02034968280606911, test error 0.04673345632410603\n",
            "Loss: 1.8307839293332906\n",
            "training error 0.02037145338981328, test error 0.04671001011593224\n",
            "Loss: 1.7796953528336434\n",
            "training error 0.02049470977632013, test error 0.046622790251827126\n",
            "Loss: 1.589645914280724\n",
            "training error 0.02044887016150135, test error 0.046354676954541305\n",
            "Loss: 1.0054351712287302\n",
            "training error 0.02046810937881228, test error 0.04686260300549394\n",
            "Loss: 2.112190631127331\n",
            "training error 0.020411677096462324, test error 0.046559167650288176\n",
            "Loss: 1.451014195167044\n",
            "training error 0.020362513645240592, test error 0.046272856293455164\n",
            "Loss: 0.8271504322991952\n",
            "training error 0.020347812914706075, test error 0.04618443012871966\n",
            "Loss: 0.6344725012591201\n",
            "training error 0.020383322133043332, test error 0.04597904556055973\n",
            "Loss: 0.18694575644342404\n",
            "training error 0.020368708796720234, test error 0.04622089823614015\n",
            "Loss: 0.7139354012700494\n",
            "training error 0.02038276557356017, test error 0.046587816268462534\n",
            "Loss: 1.5134386652716048\n",
            "training error 0.020425266158757362, test error 0.04645594807817421\n",
            "Loss: 1.226101878125463\n",
            "training error 0.020319280807558873, test error 0.046079772976613795\n",
            "Loss: 0.40642774101624646\n",
            "training error 0.020266886923150467, test error 0.04625588175006806\n",
            "Loss: 0.7901634170875749\n",
            "training error 0.0205788429503198, test error 0.04573920549214066\n",
            "Loss: 0.0\n",
            "training error 0.020348376428130664, test error 0.04655095366738411\n",
            "Loss: 1.7747316913559796\n",
            "training error 0.020427152828454826, test error 0.04703448470005521\n",
            "Loss: 2.8318795527331853\n",
            "training error 0.020404705864228805, test error 0.04628378923960642\n",
            "Loss: 1.190627912326403\n",
            "training error 0.02032524970855854, test error 0.046217179066124166\n",
            "Loss: 1.044997543880899\n",
            "training error 0.02053038310772046, test error 0.046438260234516554\n",
            "Loss: 1.5283491150628103\n",
            "training error 0.020466692856968356, test error 0.04575270690127091\n",
            "Loss: 0.029518241484471908\n",
            "training error 0.020342413068400563, test error 0.04599223545679221\n",
            "Loss: 0.553201486403232\n",
            "training error 0.020216817814718888, test error 0.04588682762437302\n",
            "Loss: 0.3227474781076545\n",
            "training error 0.02027631106389858, test error 0.04608562655070632\n",
            "Loss: 0.7573832007754966\n",
            "training error 0.020281702177328692, test error 0.04619497900116927\n",
            "Loss: 0.9964613598435257\n",
            "training error 0.020246225164821528, test error 0.04607883745851413\n",
            "Loss: 0.7425401528494469\n",
            "training error 0.02028492532146924, test error 0.04565496137635053\n",
            "Loss: 0.0\n",
            "training error 0.02024798963668853, test error 0.04568170125558399\n",
            "Loss: 0.05856949261884292\n",
            "training error 0.02023921956076264, test error 0.04594399402513239\n",
            "Loss: 0.6330804803431178\n",
            "training error 0.02026356420850826, test error 0.046082742881895344\n",
            "Loss: 0.9369879913345258\n",
            "training error 0.020353256208194972, test error 0.04632390901337716\n",
            "Loss: 1.465224406855259\n",
            "training error 0.020222241508161046, test error 0.046136074113538136\n",
            "Loss: 1.0538016519642257\n",
            "training error 0.02028039582528332, test error 0.04614157986485521\n",
            "Loss: 1.0658611327984957\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04614157986485521\n",
            "training error 0.12317939181838716, test error 0.23643276486543133\n",
            "training error 0.11993640250035158, test error 0.22921797295759969\n",
            "training error 0.1187144040760686, test error 0.2271597108314226\n",
            "training error 0.11838525965355981, test error 0.22593259326724635\n",
            "training error 0.11791051412570251, test error 0.22472409391962417\n",
            "training error 0.11844831978085667, test error 0.2231372808236321\n",
            "training error 0.1178059351118697, test error 0.22414942839270816\n",
            "training error 0.11778786940716575, test error 0.2229399044083608\n",
            "training error 0.11757110954952722, test error 0.222485587691558\n",
            "training error 0.11800474578049552, test error 0.22257271545142396\n",
            "training error 0.11763438306017984, test error 0.22341260018566528\n",
            "training error 0.11772408211141076, test error 0.2228916078979272\n",
            "training error 0.11755049111877953, test error 0.22266116322353982\n",
            "training error 0.1176548412397177, test error 0.22293620584635188\n",
            "training error 0.11740727792433865, test error 0.2230398498850464\n",
            "training error 0.11737975974652765, test error 0.22314942682753602\n",
            "training error 0.11738995833750004, test error 0.22294499623414168\n",
            "training error 0.11738100095955781, test error 0.22231422077723303\n",
            "training error 0.11781029143937195, test error 0.2213935461994723\n",
            "training error 0.11735457241869914, test error 0.22211954365400072\n",
            "training error 0.1174933848455651, test error 0.2222929685856786\n",
            "training error 0.11748171873768444, test error 0.22217691482276486\n",
            "training error 0.11739406599410218, test error 0.2231438081004288\n",
            "training error 0.11723127434960061, test error 0.2231029115981529\n",
            "training error 0.11736788123289763, test error 0.2237295315141374\n",
            "training error 0.11746177586115582, test error 0.22421249167207427\n",
            "training error 0.1178109938363092, test error 0.22502745493795617\n",
            "training error 0.1173603540656063, test error 0.22483178629153622\n",
            "training error 0.11730122261432444, test error 0.2243172811269233\n",
            "training error 0.11748197529105085, test error 0.22397302060622826\n",
            "training error 0.11745040833819197, test error 0.22170406326276537\n",
            "training error 0.11714949202488689, test error 0.2219728044345639\n",
            "training error 0.11726788849064482, test error 0.22305374864946548\n",
            "training error 0.11716545562238036, test error 0.2224544226732973\n",
            "training error 0.11727271824487902, test error 0.222047837624664\n",
            "training error 0.11710497845055363, test error 0.22204262075372944\n",
            "training error 0.11698852463454297, test error 0.2232308777959274\n",
            "training error 0.11716836979319242, test error 0.22212913409741566\n",
            "training error 0.11761709506542097, test error 0.22146086731350087\n",
            "training error 0.11712892277147638, test error 0.22180774150584784\n",
            "training error 0.11705258642942308, test error 0.22235130804937356\n",
            "training error 0.11722558473444629, test error 0.22197235039802954\n",
            "training error 0.11710402000621865, test error 0.22260474955705653\n",
            "training error 0.11705742209384618, test error 0.22253221205833112\n",
            "training error 0.11697652860013336, test error 0.22171885644006795\n",
            "training error 0.11682849863365491, test error 0.22239209215173614\n",
            "training error 0.1167105790857529, test error 0.22242361732155624\n",
            "training error 0.11674859590678895, test error 0.22194888951817834\n",
            "training error 0.11667826325185529, test error 0.22173233088183078\n",
            "training error 0.11677978501066942, test error 0.2225408757173809\n",
            "Loss: 0.5182307874841419\n",
            "training error 0.11661067291476113, test error 0.22186962422094048\n",
            "Loss: 0.21503699165612566\n",
            "training error 0.1166585717220288, test error 0.22165396662580078\n",
            "Loss: 0.11762783098197005\n",
            "training error 0.11661253217109993, test error 0.22116866181423725\n",
            "Loss: 0.0\n",
            "training error 0.11676110076208092, test error 0.2215125300872897\n",
            "Loss: 0.1554778467399931\n",
            "training error 0.11690019803273026, test error 0.22159076821902182\n",
            "Loss: 0.19085271906158496\n",
            "training error 0.11660246263603864, test error 0.22126888572944228\n",
            "Loss: 0.045315604110873764\n",
            "training error 0.11648338571371586, test error 0.2216962129840234\n",
            "Loss: 0.23852889711348801\n",
            "training error 0.11675413868816852, test error 0.22192534504396022\n",
            "Loss: 0.3421294967903332\n",
            "training error 0.11662582955683044, test error 0.22260407873067092\n",
            "Loss: 0.6490146048083956\n",
            "training error 0.1165430543572259, test error 0.22198164480815238\n",
            "Loss: 0.3675850761343247\n",
            "training error 0.11649198221541396, test error 0.22243714755555366\n",
            "Loss: 0.573537738534502\n",
            "training error 0.1165064505724358, test error 0.22255290381432868\n",
            "Loss: 0.6258761927375067\n",
            "training error 0.11677136212195183, test error 0.2227837506168109\n",
            "Loss: 0.7302521023209829\n",
            "training error 0.1167086632090463, test error 0.22193435968343841\n",
            "Loss: 0.3462054085421329\n",
            "training error 0.11655370845221764, test error 0.22148791971740994\n",
            "Loss: 0.14435042494440609\n",
            "training error 0.11644205440406816, test error 0.2208661424598811\n",
            "Loss: 0.0\n",
            "training error 0.1163982110161481, test error 0.22095257320604425\n",
            "Loss: 0.039132637171346296\n",
            "training error 0.11629358590300963, test error 0.2215758176870318\n",
            "Loss: 0.3213146294161584\n",
            "training error 0.11658930496602878, test error 0.2215335876236838\n",
            "Loss: 0.30219442254439954\n",
            "training error 0.11635353718286942, test error 0.22074372751160506\n",
            "Loss: 0.0\n",
            "training error 0.11626769513634622, test error 0.22089944639673245\n",
            "Loss: 0.07054283575020914\n",
            "training error 0.11656518525412737, test error 0.22117832988371983\n",
            "Loss: 0.19688096101933006\n",
            "training error 0.11638438898144003, test error 0.2222195844486101\n",
            "Loss: 0.6685838613137651\n",
            "training error 0.11626973165932336, test error 0.22140540152615545\n",
            "Loss: 0.2997475951001194\n",
            "training error 0.1167944648978916, test error 0.22264035732970736\n",
            "Loss: 0.8591998692250913\n",
            "training error 0.11633431099174964, test error 0.22094370830289695\n",
            "Loss: 0.09059409911493788\n",
            "training error 0.11617454767069041, test error 0.2212417446017275\n",
            "Loss: 0.2256087163773346\n",
            "training error 0.11625450493513527, test error 0.2206561821291066\n",
            "Loss: 0.0\n",
            "training error 0.11619165858362873, test error 0.2208086248947891\n",
            "Loss: 0.06908610681630734\n",
            "training error 0.11635174366618968, test error 0.2205097536982973\n",
            "Loss: 0.0\n",
            "training error 0.11621536404762181, test error 0.21997494332478607\n",
            "Loss: 0.0\n",
            "training error 0.11639132978811284, test error 0.22011853616947885\n",
            "Loss: 0.0652769095072614\n",
            "training error 0.11628626330035022, test error 0.22061536757058844\n",
            "Loss: 0.2911350884436059\n",
            "training error 0.11615699134398054, test error 0.2206792121840693\n",
            "Loss: 0.3201586729100425\n",
            "training error 0.11597786788771557, test error 0.2206872139191541\n",
            "Loss: 0.323796239518237\n",
            "training error 0.1160474722312048, test error 0.22073029258885574\n",
            "Loss: 0.3433796834553249\n",
            "training error 0.11618182809640797, test error 0.22040935781317142\n",
            "Loss: 0.19748362327973723\n",
            "training error 0.11615258513294689, test error 0.21997591038325415\n",
            "Loss: 0.00043962210125592094\n",
            "training error 0.11622424398586671, test error 0.2199447992840335\n",
            "Loss: 0.0\n",
            "training error 0.11597630672229599, test error 0.22002685007344855\n",
            "Loss: 0.03730517369910924\n",
            "training error 0.11632243605287021, test error 0.22005208939340262\n",
            "Loss: 0.04878047115384199\n",
            "training error 0.11587958413442143, test error 0.2204177841173083\n",
            "Loss: 0.21504706399719797\n",
            "training error 0.11600276874738537, test error 0.22091805900762085\n",
            "Loss: 0.44250181261640265\n",
            "training error 0.11588863679778295, test error 0.22109827310533775\n",
            "Loss: 0.5244378703470387\n",
            "training error 0.11597647577099823, test error 0.22163036455993743\n",
            "Loss: 0.7663583232660143\n",
            "training error 0.11591027448983629, test error 0.22194219094013382\n",
            "Loss: 0.9081331600484521\n",
            "training error 0.11615753322960097, test error 0.22166130225969252\n",
            "Loss: 0.7804244434269858\n",
            "training error 0.11582055855437838, test error 0.22130869289981367\n",
            "Loss: 0.6201072360974003\n",
            "training error 0.11584247618575196, test error 0.22155732910811937\n",
            "Loss: 0.7331520587597451\n",
            "training error 0.1159099606042061, test error 0.2205226467699889\n",
            "Loss: 0.2627238688236444\n",
            "training error 0.11577340793880295, test error 0.22035457593228827\n",
            "Loss: 0.1863088600360996\n",
            "training error 0.1157366096518773, test error 0.220389254305352\n",
            "Loss: 0.20207571298129778\n",
            "training error 0.11601895595544826, test error 0.22059714913215178\n",
            "Loss: 0.296597078104055\n",
            "training error 0.1157193493417894, test error 0.22033679976243709\n",
            "Loss: 0.17822675493106566\n",
            "training error 0.11576866171935006, test error 0.2210803365502223\n",
            "Loss: 0.5162828445524736\n",
            "training error 0.11566428155924695, test error 0.2210759964145402\n",
            "Loss: 0.514309560484727\n",
            "training error 0.11584712789135984, test error 0.22138535674079607\n",
            "Loss: 0.6549631823311586\n",
            "training error 0.11571522824913145, test error 0.22107982163718498\n",
            "Loss: 0.5160487344307407\n",
            "training error 0.11581240335089918, test error 0.2205584485015121\n",
            "Loss: 0.2790014674028063\n",
            "training error 0.1161579655876591, test error 0.2199885322774974\n",
            "Loss: 0.019883622439031967\n",
            "training error 0.11578202719145711, test error 0.22083028850208178\n",
            "Loss: 0.4025961154483948\n",
            "training error 0.11556160762124089, test error 0.22087192273964396\n",
            "Loss: 0.4215255185066713\n",
            "training error 0.1156060129383286, test error 0.2212442742710494\n",
            "Loss: 0.5908186923473391\n",
            "training error 0.11577212244098158, test error 0.22094175806184727\n",
            "Loss: 0.4532768135728116\n",
            "training error 0.11575188548356989, test error 0.2215956824869356\n",
            "Loss: 0.7505897881086909\n",
            "training error 0.11558205498541475, test error 0.2215522309044916\n",
            "Loss: 0.7308341118729134\n",
            "training error 0.11571872277917356, test error 0.221215526817211\n",
            "Loss: 0.5777483883747214\n",
            "training error 0.11559198840023241, test error 0.22104634449591745\n",
            "Loss: 0.5008280329745096\n",
            "training error 0.1157767803211919, test error 0.22039647273714097\n",
            "Loss: 0.20535764181639493\n",
            "training error 0.11561506987574992, test error 0.22016191056216478\n",
            "Loss: 0.09871171259243638\n",
            "training error 0.11571098864006214, test error 0.22025608821196446\n",
            "Loss: 0.1415304789857741\n",
            "training error 0.11565765081750165, test error 0.2205440375473445\n",
            "Loss: 0.27244938969308574\n",
            "training error 0.11552401919785012, test error 0.22025449563143668\n",
            "Loss: 0.14080639706477438\n",
            "training error 0.11552971406202706, test error 0.22030825036722582\n",
            "Loss: 0.16524650020162124\n",
            "training error 0.11544419348659468, test error 0.22013743338973604\n",
            "Loss: 0.08758293277659757\n",
            "training error 0.1153959008830019, test error 0.22013806668926966\n",
            "Loss: 0.08787086844759262\n",
            "training error 0.11538172617851536, test error 0.2200872320720855\n",
            "Loss: 0.06475842507558394\n",
            "training error 0.11538161786881294, test error 0.22050026884890622\n",
            "Loss: 0.2525495336470396\n",
            "training error 0.11537837547049419, test error 0.22015701741279767\n",
            "Loss: 0.0964869955802472\n",
            "training error 0.11556217629481502, test error 0.22031975583635996\n",
            "Loss: 0.1704775714393092\n",
            "training error 0.11529748405776445, test error 0.21996779748216497\n",
            "Loss: 0.010456350050724872\n",
            "training error 0.1153341376413174, test error 0.2201941437003119\n",
            "Loss: 0.11336681616935795\n",
            "training error 0.11537043872894714, test error 0.2196722391026901\n",
            "Loss: 0.0\n",
            "training error 0.11558186110256123, test error 0.2205627523382819\n",
            "Loss: 0.40538269160879103\n",
            "training error 0.11533529182302729, test error 0.22030017145128838\n",
            "Loss: 0.2858496600040228\n",
            "training error 0.11521016396550636, test error 0.2200986032679374\n",
            "Loss: 0.19409105446772656\n",
            "training error 0.11520906056788141, test error 0.22021361863371075\n",
            "Loss: 0.24644876987280906\n",
            "training error 0.11537102910798054, test error 0.22005279892120788\n",
            "Loss: 0.17323983224839523\n",
            "training error 0.11538786519346368, test error 0.22089657383422462\n",
            "Loss: 0.5573461337379904\n",
            "training error 0.11544547847784346, test error 0.22113123792664233\n",
            "Loss: 0.6641707800275176\n",
            "training error 0.11547771266294547, test error 0.2214030366453754\n",
            "Loss: 0.7878999867052761\n",
            "training error 0.11527970133240172, test error 0.22086542355081265\n",
            "Loss: 0.5431657878102625\n",
            "training error 0.11546758857538811, test error 0.2201393787370163\n",
            "Loss: 0.2126530126129511\n",
            "training error 0.11544369949653467, test error 0.21996760703032847\n",
            "Loss: 0.1344584681454819\n",
            "training error 0.1151830329588913, test error 0.22020426010055585\n",
            "Loss: 0.2421885441869831\n",
            "training error 0.1152670974636243, test error 0.22010964464006477\n",
            "Loss: 0.19911734826456584\n",
            "training error 0.1151689457692295, test error 0.220065303209742\n",
            "Loss: 0.17893208020161033\n",
            "training error 0.11520454719626298, test error 0.21971236261555224\n",
            "Loss: 0.018265172252096562\n",
            "training error 0.11509422058094328, test error 0.2196646011112592\n",
            "Loss: 0.0\n",
            "training error 0.11534387424245393, test error 0.21922505420070162\n",
            "Loss: 0.0\n",
            "training error 0.11507157515849799, test error 0.21925679925157573\n",
            "Loss: 0.014480576132069878\n",
            "training error 0.1152347212741089, test error 0.2193913098521177\n",
            "Loss: 0.07583788815663794\n",
            "training error 0.1150818387692796, test error 0.2197953819182407\n",
            "Loss: 0.26015626709203765\n",
            "training error 0.11526888383464012, test error 0.21981528154476285\n",
            "Loss: 0.2692335263472456\n",
            "training error 0.11504491891198765, test error 0.2200892279958357\n",
            "Loss: 0.39419481422178215\n",
            "training error 0.1151632862781037, test error 0.21958916257482483\n",
            "Loss: 0.16608885122677552\n",
            "training error 0.11520560833314372, test error 0.2200248900345393\n",
            "Loss: 0.36484690892375493\n",
            "training error 0.1149597034544196, test error 0.2200076219889833\n",
            "Loss: 0.3569700512265461\n",
            "training error 0.11496391768322152, test error 0.22008425842549126\n",
            "Loss: 0.3919279335668602\n",
            "training error 0.115110712852017, test error 0.22004264977810598\n",
            "Loss: 0.3729480557709497\n",
            "training error 0.11514953961936526, test error 0.2198915277277048\n",
            "Loss: 0.30401339364842794\n",
            "training error 0.11492932513012928, test error 0.22006428697388317\n",
            "Loss: 0.3828179111376562\n",
            "training error 0.11512725771394616, test error 0.22039582428159785\n",
            "Loss: 0.5340493973943206\n",
            "training error 0.11500075702467646, test error 0.2198914247628651\n",
            "Loss: 0.3039664260059416\n",
            "training error 0.11511096436638425, test error 0.21977592508199362\n",
            "Loss: 0.2512809876136002\n",
            "training error 0.11489317413974137, test error 0.21976509247035225\n",
            "Loss: 0.24633966752551917\n",
            "training error 0.11489166461668925, test error 0.21957134276166113\n",
            "Loss: 0.15796030349819468\n",
            "training error 0.11498372484485539, test error 0.2198671975120988\n",
            "Loss: 0.29291511124878156\n",
            "training error 0.11483636944230624, test error 0.219824142065333\n",
            "Loss: 0.27327527267158036\n",
            "training error 0.1150470398390646, test error 0.22002363608260442\n",
            "Loss: 0.3642749159371572\n",
            "training error 0.11521391594926507, test error 0.2196509662520431\n",
            "Loss: 0.19428073716043492\n",
            "training error 0.11487112441584477, test error 0.22006134424962603\n",
            "Loss: 0.3814755808698722\n",
            "training error 0.11477522414234774, test error 0.22008493305988633\n",
            "Loss: 0.3922356695587714\n",
            "training error 0.11477034169481373, test error 0.21992206008536172\n",
            "Loss: 0.3179407970504977\n",
            "training error 0.11513487642546326, test error 0.22034705994026124\n",
            "Loss: 0.511805433758683\n",
            "training error 0.11481836032487822, test error 0.22004740905154432\n",
            "Loss: 0.37511900902067463\n",
            "training error 0.11496021782290548, test error 0.22017838785133292\n",
            "Loss: 0.4348652822129262\n",
            "training error 0.11481283527184756, test error 0.21986161226396145\n",
            "Loss: 0.29036738778818183\n",
            "training error 0.11477145405499996, test error 0.21950513331262114\n",
            "Loss: 0.12775871486983004\n",
            "training error 0.11473522621553871, test error 0.2197728316356408\n",
            "Loss: 0.24986990512392282\n",
            "training error 0.11478320307258197, test error 0.22001403352903112\n",
            "Loss: 0.3598946895947419\n",
            "training error 0.1148310408870803, test error 0.2191951469408558\n",
            "Loss: 0.0\n",
            "training error 0.1147328404031168, test error 0.21901983514830933\n",
            "Loss: 0.0\n",
            "training error 0.11478161240127917, test error 0.21894473492004313\n",
            "Loss: 0.0\n",
            "training error 0.11468009396941015, test error 0.2189632586355228\n",
            "Loss: 0.008460452582448319\n",
            "training error 0.11482674995822827, test error 0.21871937003100345\n",
            "Loss: 0.0\n",
            "training error 0.11465626722993312, test error 0.21903966385092213\n",
            "Loss: 0.14644053696446502\n",
            "training error 0.11462759473666265, test error 0.219378722152125\n",
            "Loss: 0.30146032380584664\n",
            "training error 0.11469065022325148, test error 0.21978835767367189\n",
            "Loss: 0.4887485011121351\n",
            "training error 0.11533516000289806, test error 0.21985342746633352\n",
            "Loss: 0.5184988577688898\n",
            "training error 0.11497831626374894, test error 0.22043413574469523\n",
            "Loss: 0.7840026758712426\n",
            "training error 0.11472627574071265, test error 0.22031188956852707\n",
            "Loss: 0.7281108835023975\n",
            "training error 0.11464463370178658, test error 0.22028089782805216\n",
            "Loss: 0.7139412466428352\n",
            "training error 0.11457336517842061, test error 0.2196018322052057\n",
            "Loss: 0.4034677742886572\n",
            "training error 0.1144871967673671, test error 0.21964665906329311\n",
            "Loss: 0.4239629220577079\n",
            "training error 0.1146413534733144, test error 0.21954161097301927\n",
            "Loss: 0.3759342128222487\n",
            "training error 0.11453511271018944, test error 0.21945211091949984\n",
            "Loss: 0.33501417290682234\n",
            "training error 0.11451907584348824, test error 0.21886342838011666\n",
            "Loss: 0.06586446783052313\n",
            "training error 0.11452901608135926, test error 0.21883890202570985\n",
            "Loss: 0.05465084994047409\n",
            "training error 0.11458256919331022, test error 0.2189084509341781\n",
            "Loss: 0.08644908914461347\n",
            "training error 0.11456556333677294, test error 0.2192208573557872\n",
            "Loss: 0.229283453364304\n",
            "training error 0.11460722565901114, test error 0.21883484661991806\n",
            "Loss: 0.052796690525513945\n",
            "training error 0.11449606494058007, test error 0.2187735110116514\n",
            "Loss: 0.02475362865221875\n",
            "training error 0.11449807862458798, test error 0.21861455077002598\n",
            "Loss: 0.0\n",
            "training error 0.11436629067937942, test error 0.21897350408937127\n",
            "Loss: 0.16419461471386398\n",
            "training error 0.11448635577446864, test error 0.21899462424959104\n",
            "Loss: 0.17385552710298402\n",
            "training error 0.11444995905808701, test error 0.2190029280640554\n",
            "Loss: 0.17765390851682827\n",
            "training error 0.11435735748684794, test error 0.21913240727695468\n",
            "Loss: 0.23688107909773937\n",
            "training error 0.11442351281130697, test error 0.21903394057891398\n",
            "Loss: 0.19183984204655946\n",
            "training error 0.11431212762021475, test error 0.21924737112983617\n",
            "Loss: 0.28946854524605214\n",
            "training error 0.11435923212806558, test error 0.2190697183119113\n",
            "Loss: 0.20820551069546944\n",
            "training error 0.11464646121303078, test error 0.2187964566354499\n",
            "Loss: 0.08320848945468917\n",
            "training error 0.11431698644250923, test error 0.21869125321328517\n",
            "Loss: 0.03508569900265712\n",
            "training error 0.11460020014816334, test error 0.21879256879769404\n",
            "Loss: 0.08143009101682086\n",
            "training error 0.11429888672126126, test error 0.2189153709217256\n",
            "Loss: 0.13760298691924966\n",
            "training error 0.11435340150575142, test error 0.2194348496231933\n",
            "Loss: 0.3752261001282786\n",
            "training error 0.11439091354487496, test error 0.21967379122882463\n",
            "Loss: 0.48452422543132645\n",
            "training error 0.11430752528370987, test error 0.21987617655071098\n",
            "Loss: 0.5771005526581829\n",
            "training error 0.11422568687402664, test error 0.21927703283858502\n",
            "Loss: 0.3030365848135874\n",
            "training error 0.11421890579190731, test error 0.21911521068603024\n",
            "Loss: 0.22901490968501026\n",
            "training error 0.11426635665310338, test error 0.2191893268793316\n",
            "Loss: 0.26291759047194496\n",
            "training error 0.1142421114490489, test error 0.2189013273428981\n",
            "Loss: 0.13117908751363316\n",
            "training error 0.1141580309393408, test error 0.21885052021846263\n",
            "Loss: 0.10793858304742887\n",
            "training error 0.11416405724329133, test error 0.21900794431742782\n",
            "Loss: 0.17994847370230715\n",
            "training error 0.11445352529588812, test error 0.21956113951057288\n",
            "Loss: 0.4329943899949562\n",
            "training error 0.1141031597331023, test error 0.21938904817227495\n",
            "Loss: 0.3542753213457095\n",
            "training error 0.11412886190894637, test error 0.21899329339731513\n",
            "Loss: 0.17324676054504273\n",
            "training error 0.11413885217196319, test error 0.21897031550702464\n",
            "Loss: 0.16273607394639011\n",
            "training error 0.11416839945386859, test error 0.219147741451403\n",
            "Loss: 0.24389533061681679\n",
            "training error 0.11424015120014083, test error 0.2190372895168575\n",
            "Loss: 0.19337173364832871\n",
            "training error 0.11405601147538792, test error 0.21858041450872628\n",
            "Loss: 0.0\n",
            "training error 0.11407421839086125, test error 0.21869494994772218\n",
            "Loss: 0.052399680572179363\n",
            "training error 0.1140895492955907, test error 0.218786120757369\n",
            "Loss: 0.09411010090041305\n",
            "training error 0.11411301643604597, test error 0.21863590245202968\n",
            "Loss: 0.025385597071037047\n",
            "training error 0.1140795805786976, test error 0.21874432655248502\n",
            "Loss: 0.0749893553487535\n",
            "training error 0.11403700066672758, test error 0.21888870953411216\n",
            "Loss: 0.14104421298624104\n",
            "training error 0.11404598800998078, test error 0.2190676105657465\n",
            "Loss: 0.22289099328283157\n",
            "training error 0.11399951213079806, test error 0.2189647521581438\n",
            "Loss: 0.1758335257444399\n",
            "training error 0.11419264936052817, test error 0.2191345174835707\n",
            "Loss: 0.2535007430056302\n",
            "training error 0.11412307266703779, test error 0.21883754396276717\n",
            "Loss: 0.11763609041495204\n",
            "training error 0.11419528936479408, test error 0.2192351169144333\n",
            "Loss: 0.2995247342624463\n",
            "training error 0.11410059737401752, test error 0.2191047017020487\n",
            "Loss: 0.23986009656939977\n",
            "training error 0.11399644806346469, test error 0.21883024921159244\n",
            "Loss: 0.11429875976201043\n",
            "training error 0.11397710389721098, test error 0.21906708699718416\n",
            "Loss: 0.22265146195816765\n",
            "training error 0.11404901199317163, test error 0.21863657144675472\n",
            "Loss: 0.025691660506121927\n",
            "training error 0.11406967501218722, test error 0.21874482268918724\n",
            "Loss: 0.07521633666514038\n",
            "training error 0.11389212622385504, test error 0.21916610870381092\n",
            "Loss: 0.26795364827221224\n",
            "training error 0.11402986911642758, test error 0.219175166243829\n",
            "Loss: 0.2720974504689444\n",
            "training error 0.11390914652485015, test error 0.21885151230484165\n",
            "Loss: 0.12402657242858162\n",
            "training error 0.1139669484325883, test error 0.21885981637934024\n",
            "Loss: 0.1278256660103505\n",
            "training error 0.11399347730074959, test error 0.2188767499733877\n",
            "Loss: 0.1355727434809051\n",
            "training error 0.11393287044325007, test error 0.2188420785192262\n",
            "Loss: 0.11971063879991917\n",
            "training error 0.11392293646687035, test error 0.21836145925057995\n",
            "Loss: 0.0\n",
            "training error 0.11401005848929195, test error 0.21871313353673325\n",
            "Loss: 0.1610514453238343\n",
            "training error 0.11386453159547215, test error 0.21857984306892034\n",
            "Loss: 0.10001023948542631\n",
            "training error 0.11415019499201444, test error 0.21816317441117386\n",
            "Loss: 0.0\n",
            "training error 0.1138501480109833, test error 0.21817816300322224\n",
            "Loss: 0.006870358431854129\n",
            "training error 0.11383539704941532, test error 0.21852257026789187\n",
            "Loss: 0.164737177888985\n",
            "training error 0.11390695443008762, test error 0.2184298548590814\n",
            "Loss: 0.1222389840207061\n",
            "training error 0.11383798520911623, test error 0.21830287019344777\n",
            "Loss: 0.06403270517627568\n",
            "training error 0.11389568380196106, test error 0.2180651365250486\n",
            "Loss: 0.0\n",
            "training error 0.11385676952449746, test error 0.21834363421925918\n",
            "Loss: 0.12771307630763395\n",
            "training error 0.11383147847949579, test error 0.21830218822034664\n",
            "Loss: 0.10870682910415486\n",
            "training error 0.11378800687355023, test error 0.21824752673672826\n",
            "Loss: 0.08364024372997658\n",
            "training error 0.11384327241957677, test error 0.21839677478704306\n",
            "Loss: 0.1520822022627044\n",
            "training error 0.11376745576061707, test error 0.21833583592936495\n",
            "Loss: 0.1241369476249421\n",
            "training error 0.11373008394737082, test error 0.21846332865097967\n",
            "Loss: 0.18260237848031213\n",
            "training error 0.11378312716593376, test error 0.21871590244143382\n",
            "Loss: 0.2984273078931565\n",
            "training error 0.11382536612457136, test error 0.218961700060099\n",
            "Loss: 0.41114483008950486\n",
            "training error 0.11397701683694997, test error 0.21901463441606175\n",
            "Loss: 0.43541939172109245\n",
            "training error 0.11375568107331993, test error 0.21864645538532101\n",
            "Loss: 0.2665803757244012\n",
            "training error 0.11370924469598102, test error 0.21868453713173303\n",
            "Loss: 0.28404384880353906\n",
            "training error 0.11375063859372839, test error 0.21883429929691622\n",
            "Loss: 0.3527215694010044\n",
            "training error 0.1137586062221502, test error 0.21862115832189755\n",
            "Loss: 0.25497968437750984\n",
            "training error 0.1136563065933241, test error 0.21844822139011147\n",
            "Loss: 0.17567451228905906\n",
            "training error 0.11374575769479173, test error 0.21855674235673708\n",
            "Loss: 0.2254399027384224\n",
            "training error 0.1136832251603898, test error 0.2186180831526111\n",
            "Loss: 0.25356947762211757\n",
            "training error 0.1137765833232809, test error 0.2183794635055324\n",
            "Loss: 0.14414361942156617\n",
            "training error 0.11378861778677271, test error 0.21897067453512306\n",
            "Loss: 0.415260332075329\n",
            "training error 0.1136872050316633, test error 0.21833472133344364\n",
            "Loss: 0.12362581781342197\n",
            "training error 0.11368045611131271, test error 0.21817792361547036\n",
            "Loss: 0.05172174342908953\n",
            "training error 0.11367269137618687, test error 0.2181735964267086\n",
            "Loss: 0.049737387364312546\n",
            "training error 0.11364157636926134, test error 0.21819470102675764\n",
            "Loss: 0.05941550482286839\n",
            "training error 0.1137626581603683, test error 0.21810798960534258\n",
            "Loss: 0.019651504581097434\n",
            "training error 0.11357663554918423, test error 0.21834406894441213\n",
            "Loss: 0.12791243194965052\n",
            "training error 0.11351190463108322, test error 0.21822885639952708\n",
            "Loss: 0.07507842706422352\n",
            "training error 0.11353638982401053, test error 0.21817971404075517\n",
            "Loss: 0.052542794108401125\n",
            "training error 0.11381553298072859, test error 0.21798227378264207\n",
            "Loss: 0.0\n",
            "training error 0.11351125987652275, test error 0.21805816932606825\n",
            "Loss: 0.03481730055805432\n",
            "training error 0.1136313912681126, test error 0.2178566851947845\n",
            "Loss: 0.0\n",
            "training error 0.11354685362970476, test error 0.2180645318759337\n",
            "Loss: 0.0954052343922207\n",
            "training error 0.11351216657709753, test error 0.21784257413166727\n",
            "Loss: 0.0\n",
            "training error 0.11349819850129657, test error 0.21822767534020857\n",
            "Loss: 0.17677958960791162\n",
            "training error 0.11353052148956064, test error 0.21785931423516364\n",
            "Loss: 0.007684495816806525\n",
            "training error 0.1135288154355334, test error 0.21782992687609626\n",
            "Loss: 0.0\n",
            "training error 0.11358970700869894, test error 0.21758398979586474\n",
            "Loss: 0.0\n",
            "training error 0.11343667637219854, test error 0.21765902979006252\n",
            "Loss: 0.03448782893822333\n",
            "training error 0.11370313586706275, test error 0.2178255117841185\n",
            "Loss: 0.11100172787545937\n",
            "training error 0.11348842456219949, test error 0.21773286487722773\n",
            "Loss: 0.06842189147402422\n",
            "training error 0.11342697626395915, test error 0.21796587282554813\n",
            "Loss: 0.1755106292708808\n",
            "training error 0.11350182932649755, test error 0.21821013911773982\n",
            "Loss: 0.287773619034426\n",
            "training error 0.11339558706460526, test error 0.21818064916694796\n",
            "Loss: 0.2742202547361128\n",
            "training error 0.11338242452350007, test error 0.218171272438828\n",
            "Loss: 0.2699107795174793\n",
            "training error 0.11350551811803519, test error 0.2185606597365335\n",
            "Loss: 0.44887031512983455\n",
            "training error 0.11339005978504106, test error 0.2183832035190128\n",
            "Loss: 0.3673127438732493\n",
            "training error 0.11334485295415, test error 0.21821074000326332\n",
            "Loss: 0.2880497815977101\n",
            "training error 0.11345995920564886, test error 0.21799246439500214\n",
            "Loss: 0.18773191884229323\n",
            "training error 0.11365622317775301, test error 0.217565805220308\n",
            "Loss: 0.0\n",
            "training error 0.11338444613379947, test error 0.21743526559535642\n",
            "Loss: 0.0\n",
            "training error 0.11331349106576567, test error 0.21738521721046683\n",
            "Loss: 0.0\n",
            "training error 0.11340244361617144, test error 0.21751942895097118\n",
            "Loss: 0.0617391293789904\n",
            "training error 0.11340768269028509, test error 0.2175618698805207\n",
            "Loss: 0.08126250364248744\n",
            "training error 0.11336635728637844, test error 0.21750977351170941\n",
            "Loss: 0.05729750294933833\n",
            "training error 0.11339384295287541, test error 0.21740844724504546\n",
            "Loss: 0.010686115126290474\n",
            "training error 0.11328737328816323, test error 0.21734066738084856\n",
            "Loss: 0.0\n",
            "training error 0.1132284955238008, test error 0.21738047074352446\n",
            "Loss: 0.018313812668169227\n",
            "training error 0.1132931149306219, test error 0.21747586664354465\n",
            "Loss: 0.06220615052183742\n",
            "training error 0.11339996405589513, test error 0.21784472599684962\n",
            "Loss: 0.23192098472661904\n",
            "training error 0.11327631249565179, test error 0.21772600458046307\n",
            "Loss: 0.1772964094838514\n",
            "training error 0.11327584620016444, test error 0.21764901239800577\n",
            "Loss: 0.14187175408681973\n",
            "training error 0.11322973707390187, test error 0.21770110313666607\n",
            "Loss: 0.16583907658014319\n",
            "training error 0.11322026020169465, test error 0.21770096620276844\n",
            "Loss: 0.16577607231162972\n",
            "training error 0.11318140080095626, test error 0.2177575305940699\n",
            "Loss: 0.19180175447370829\n",
            "training error 0.11330676624159437, test error 0.21747209449763014\n",
            "Loss: 0.060470559129766066\n",
            "training error 0.11317400687113088, test error 0.21755750715667369\n",
            "Loss: 0.09976953620243201\n",
            "training error 0.11337960592661132, test error 0.21739268066283796\n",
            "Loss: 0.02393168412344604\n",
            "training error 0.11307043101906322, test error 0.21743861396497594\n",
            "Loss: 0.04506592590687308\n",
            "training error 0.11317278164740072, test error 0.2173282501433137\n",
            "Loss: 0.0\n",
            "training error 0.11332850300984812, test error 0.21724652375887193\n",
            "Loss: 0.0\n",
            "training error 0.11309585417533874, test error 0.2177897468183602\n",
            "Loss: 0.2500491377671832\n",
            "training error 0.11306623265491994, test error 0.21780383208403786\n",
            "Loss: 0.25653267795644474\n",
            "training error 0.11310517245940975, test error 0.21813623759963763\n",
            "Loss: 0.4095411173314023\n",
            "training error 0.11306088285029757, test error 0.21789799701383097\n",
            "Loss: 0.2998774128520232\n",
            "training error 0.11306892648148249, test error 0.21773326820392247\n",
            "Loss: 0.22405166104788599\n",
            "training error 0.11311891326843758, test error 0.21772941340972654\n",
            "Loss: 0.2222772739924661\n",
            "training error 0.1131156668797558, test error 0.21734144239388903\n",
            "Loss: 0.04369167035438437\n",
            "training error 0.11299628718939095, test error 0.21738367694063487\n",
            "Loss: 0.06313250927558745\n",
            "training error 0.11297836547182079, test error 0.21727586046134825\n",
            "Loss: 0.01350387659546648\n",
            "training error 0.11298903226783932, test error 0.21734063319659006\n",
            "Loss: 0.043319191529422874\n",
            "training error 0.11310886902592619, test error 0.2173454957724571\n",
            "Loss: 0.04555746709899999\n",
            "training error 0.11307032741169597, test error 0.21732307295871098\n",
            "Loss: 0.035236098840418784\n",
            "training error 0.11291796903340284, test error 0.21739005525196192\n",
            "Loss: 0.06606848782044761\n",
            "training error 0.11296130393038559, test error 0.2176343711128368\n",
            "Loss: 0.17852868126688737\n",
            "training error 0.11289940591129348, test error 0.21748764833725212\n",
            "Loss: 0.11099122517965743\n",
            "training error 0.11287881212511462, test error 0.21753518479888656\n",
            "Loss: 0.13287257030405453\n",
            "training error 0.11296850896935225, test error 0.21722303323872041\n",
            "Loss: 0.0\n",
            "training error 0.11282997618073859, test error 0.21707053989424316\n",
            "Loss: 0.0\n",
            "training error 0.11303734025691001, test error 0.21739959912021206\n",
            "Loss: 0.15159091884564546\n",
            "training error 0.11284169081119444, test error 0.21711161433666407\n",
            "Loss: 0.01892216347778586\n",
            "training error 0.11288475187167636, test error 0.2169460139100355\n",
            "Loss: 0.0\n",
            "training error 0.11280002211609895, test error 0.21693595905656418\n",
            "Loss: 0.0\n",
            "training error 0.11286943977723109, test error 0.21670964520909108\n",
            "Loss: 0.0\n",
            "training error 0.11283663133691661, test error 0.21666667327975467\n",
            "Loss: 0.0\n",
            "training error 0.11287022469520548, test error 0.21691719525418146\n",
            "Loss: 0.11562552312940344\n",
            "training error 0.11274997593573546, test error 0.2167945630758029\n",
            "Loss: 0.059026057912969776\n",
            "training error 0.11278096602550665, test error 0.21689625207095367\n",
            "Loss: 0.10595943885776116\n",
            "training error 0.11282761231469203, test error 0.21675026333739925\n",
            "Loss: 0.038580025427648046\n",
            "training error 0.11272349429766534, test error 0.21703195770857714\n",
            "Loss: 0.1685928081569088\n",
            "training error 0.11283146748799208, test error 0.21719470828422335\n",
            "Loss: 0.2437084561624836\n",
            "training error 0.11270203331934077, test error 0.21723273018894254\n",
            "Loss: 0.26125702703572173\n",
            "training error 0.11268544276429836, test error 0.21720218162426555\n",
            "Loss: 0.24715768992282783\n",
            "training error 0.11267242178717829, test error 0.21728134797488582\n",
            "Loss: 0.2836960044785064\n",
            "training error 0.11283572108132149, test error 0.21708682654667152\n",
            "Loss: 0.1939168865044527\n",
            "training error 0.11272831733995504, test error 0.2172227958176227\n",
            "Loss: 0.2566719327203426\n",
            "training error 0.11270589711676575, test error 0.21702298102105108\n",
            "Loss: 0.1644497217328622\n",
            "training error 0.1126223440645454, test error 0.21699741058422906\n",
            "Loss: 0.15264798202136998\n",
            "training error 0.11273375566450759, test error 0.21690247011648903\n",
            "Loss: 0.1088293059403389\n",
            "training error 0.11259890368468405, test error 0.21709230431413867\n",
            "Loss: 0.196445086796726\n",
            "training error 0.11268129242622903, test error 0.2170028766018319\n",
            "Loss: 0.15517075929953883\n",
            "training error 0.11259706867194214, test error 0.21684010880242924\n",
            "Loss: 0.08004716186813532\n",
            "training error 0.11267447495626601, test error 0.2167803339650765\n",
            "Loss: 0.05245877623971662\n",
            "training error 0.11260604440669783, test error 0.21697489544950155\n",
            "Loss: 0.1422563816950717\n",
            "training error 0.11252962968967749, test error 0.21703216098037545\n",
            "Loss: 0.1686866259070996\n",
            "training error 0.11263191821703145, test error 0.21707057285768677\n",
            "Loss: 0.18641518412505498\n",
            "training error 0.11254922375868974, test error 0.2168758417723338\n",
            "Loss: 0.09653930132071942\n",
            "training error 0.11253780066206269, test error 0.2167803027675812\n",
            "Loss: 0.05244437739615471\n",
            "training error 0.1125039933079761, test error 0.21707801774771704\n",
            "Loss: 0.1898512871110869\n",
            "training error 0.1124496472928919, test error 0.2168675777624975\n",
            "Loss: 0.09272514305114221\n",
            "training error 0.11245000014975583, test error 0.21693854849567237\n",
            "Loss: 0.12548086505517198\n",
            "training error 0.11246903328681324, test error 0.2167667337434533\n",
            "Loss: 0.04618175106672062\n",
            "training error 0.112577162953603, test error 0.2169581296717536\n",
            "Loss: 0.13451833066298047\n",
            "training error 0.11258211102823315, test error 0.21669375139737873\n",
            "Loss: 0.012497592368121424\n",
            "training error 0.11238849027072209, test error 0.21674415896198057\n",
            "Loss: 0.03576262147426679\n",
            "training error 0.1123651759020859, test error 0.21654485660137018\n",
            "Loss: 0.0\n",
            "training error 0.11245113195242627, test error 0.21649641267591926\n",
            "Loss: 0.0\n",
            "training error 0.11231364998574553, test error 0.21631117729141436\n",
            "Loss: 0.0\n",
            "training error 0.11234216041707255, test error 0.21651082081925327\n",
            "Loss: 0.0922945963027777\n",
            "training error 0.11238892011853312, test error 0.21647860565278587\n",
            "Loss: 0.07740162273073281\n",
            "training error 0.11227841407138574, test error 0.21640615388007306\n",
            "Loss: 0.04390738835042818\n",
            "training error 0.11228325536141305, test error 0.21634501526068653\n",
            "Loss: 0.015643190377812033\n",
            "training error 0.11228301918444612, test error 0.2164400902389083\n",
            "Loss: 0.05959606392427208\n",
            "training error 0.11219913349557042, test error 0.21647276417003278\n",
            "Loss: 0.07470112300334009\n",
            "training error 0.11229219553579356, test error 0.21649800553705828\n",
            "Loss: 0.08637013028329754\n",
            "training error 0.11216897764639112, test error 0.2164384646897541\n",
            "Loss: 0.05884457748952521\n",
            "training error 0.11217054143782837, test error 0.21635562384064397\n",
            "Loss: 0.02054750465794175\n",
            "training error 0.11224342556777547, test error 0.21621700273594568\n",
            "Loss: 0.0\n",
            "training error 0.11212838967315526, test error 0.21638718503509394\n",
            "Loss: 0.07870902703988047\n",
            "training error 0.11216187078957317, test error 0.2162125982157375\n",
            "Loss: 0.0\n",
            "training error 0.1122690777771529, test error 0.2163553277817378\n",
            "Loss: 0.0660135288961694\n",
            "training error 0.11208176946235494, test error 0.2162314308492496\n",
            "Loss: 0.008710238749976007\n",
            "training error 0.1120894153568781, test error 0.21606094568240164\n",
            "Loss: 0.0\n",
            "training error 0.11207487435014431, test error 0.21590801021813025\n",
            "Loss: 0.0\n",
            "training error 0.11215465581597432, test error 0.21567709182567182\n",
            "Loss: 0.0\n",
            "training error 0.11200646685672416, test error 0.21570807891091595\n",
            "Loss: 0.01436735120166066\n",
            "training error 0.11211303553601579, test error 0.21555175481925742\n",
            "Loss: 0.0\n",
            "training error 0.11204972502672451, test error 0.2156699093876862\n",
            "Loss: 0.054814941556768915\n",
            "training error 0.11193711465962695, test error 0.2156812481810237\n",
            "Loss: 0.06007529925926569\n",
            "training error 0.11202273349276433, test error 0.21578571459126628\n",
            "Loss: 0.10853995236783653\n",
            "training error 0.11190575520620755, test error 0.215848653827995\n",
            "Loss: 0.1377390821923674\n",
            "training error 0.11190875569733635, test error 0.21589387281411415\n",
            "Loss: 0.15871733224515072\n",
            "training error 0.11188888753243066, test error 0.21561533035645775\n",
            "Loss: 0.02949432596994761\n",
            "training error 0.11183060007786924, test error 0.21574772629025557\n",
            "Loss: 0.09091620300769598\n",
            "training error 0.11193420360796866, test error 0.2158410485176561\n",
            "Loss: 0.1342107832252415\n",
            "training error 0.11184906848353096, test error 0.21567332721186233\n",
            "Loss: 0.05640055805011812\n",
            "training error 0.11180590444381974, test error 0.21568705460881926\n",
            "Loss: 0.06276905037274627\n",
            "training error 0.11183182983910121, test error 0.2154760068034047\n",
            "Loss: 0.0\n",
            "training error 0.11179410574235082, test error 0.21564838000929865\n",
            "Loss: 0.07999647313456926\n",
            "training error 0.11177888867328378, test error 0.21538986733254403\n",
            "Loss: 0.0\n",
            "training error 0.11175577814896565, test error 0.21552930410593374\n",
            "Loss: 0.06473692338295756\n",
            "training error 0.11178697802705406, test error 0.21566433973148347\n",
            "Loss: 0.12743050652224142\n",
            "training error 0.11176933066539206, test error 0.21562823341116946\n",
            "Loss: 0.11066726656059345\n",
            "training error 0.1116977815351981, test error 0.21575852220838745\n",
            "Loss: 0.17115701885559442\n",
            "training error 0.11166985760592944, test error 0.21533877023887868\n",
            "Loss: 0.0\n",
            "training error 0.11154500463010385, test error 0.2154088752731895\n",
            "Loss: 0.032555695489966396\n",
            "training error 0.11160454326859418, test error 0.2155949740634017\n",
            "Loss: 0.1189771002401585\n",
            "training error 0.11159127917654493, test error 0.21559736327698173\n",
            "Loss: 0.12008661413649424\n",
            "training error 0.11147369513271943, test error 0.21519198581976712\n",
            "Loss: 0.0\n",
            "training error 0.11164840155732854, test error 0.21490714978072148\n",
            "Loss: 0.0\n",
            "training error 0.1114557688018817, test error 0.21494540561213663\n",
            "Loss: 0.017801097568970192\n",
            "training error 0.11146161747464045, test error 0.21480551955673877\n",
            "Loss: 0.0\n",
            "training error 0.11136096526183269, test error 0.2148899816733032\n",
            "Loss: 0.03932027293280793\n",
            "training error 0.11137635912129512, test error 0.21495470730454325\n",
            "Loss: 0.06945247408556288\n",
            "training error 0.11134954678494534, test error 0.21483049359006792\n",
            "Loss: 0.011626346185455994\n",
            "training error 0.11131314707930368, test error 0.21488764258684773\n",
            "Loss: 0.03823134073948076\n",
            "training error 0.11139342532755693, test error 0.21480773619758017\n",
            "Loss: 0.0010319291822602494\n",
            "training error 0.11117596418264059, test error 0.21474686416088087\n",
            "Loss: 0.0\n",
            "training error 0.11120404357946345, test error 0.21458722007338193\n",
            "Loss: 0.0\n",
            "training error 0.11114558049008963, test error 0.21460396710170035\n",
            "Loss: 0.00780429902240698\n",
            "training error 0.11112108880651857, test error 0.21459350915922876\n",
            "Loss: 0.0029307830376357202\n",
            "training error 0.11111201937996056, test error 0.21448199785186658\n",
            "Loss: 0.0\n",
            "training error 0.1110979179397605, test error 0.2142423068176435\n",
            "Loss: 0.0\n",
            "training error 0.11104039964580197, test error 0.2142935258397581\n",
            "Loss: 0.023907053128491285\n",
            "training error 0.11098622057922505, test error 0.21437826546505426\n",
            "Loss: 0.06346022381400473\n",
            "training error 0.11107860338416208, test error 0.21409328622363946\n",
            "Loss: 0.0\n",
            "training error 0.11092112672811436, test error 0.21406739982025014\n",
            "Loss: 0.0\n",
            "training error 0.11085034774255784, test error 0.21410803869094616\n",
            "Loss: 0.018984147390099793\n",
            "training error 0.11082365451368452, test error 0.213976087237507\n",
            "Loss: 0.0\n",
            "training error 0.11080833934826116, test error 0.2140775844858323\n",
            "Loss: 0.04743392106831834\n",
            "training error 0.11076256095587556, test error 0.21404401844471999\n",
            "Loss: 0.031747102253332216\n",
            "training error 0.11073808259903334, test error 0.2138421257901848\n",
            "Loss: 0.0\n",
            "training error 0.11065919296108137, test error 0.21380697992687822\n",
            "Loss: 0.0\n",
            "training error 0.11070749690422073, test error 0.21363690758056836\n",
            "Loss: 0.0\n",
            "training error 0.11065477307951498, test error 0.21367601557956534\n",
            "Loss: 0.01830582526205493\n",
            "training error 0.11055126361792729, test error 0.2135702352212993\n",
            "Loss: 0.0\n",
            "training error 0.11051801901143067, test error 0.21362946837344055\n",
            "Loss: 0.027734741257301465\n",
            "training error 0.11057265441516487, test error 0.2136355605330791\n",
            "Loss: 0.03058727341480605\n",
            "training error 0.11041738261624008, test error 0.21342510711852203\n",
            "Loss: 0.0\n",
            "training error 0.1104781780915405, test error 0.21328799475135335\n",
            "Loss: 0.0\n",
            "training error 0.11030168396239345, test error 0.2130916623395654\n",
            "Loss: 0.0\n",
            "training error 0.11035117926442528, test error 0.21300012194069673\n",
            "Loss: 0.0\n",
            "training error 0.11023555443928149, test error 0.21294385592001316\n",
            "Loss: 0.0\n",
            "training error 0.11019033104616063, test error 0.21271892696187086\n",
            "Loss: 0.0\n",
            "training error 0.11015473705103951, test error 0.21264008268401002\n",
            "Loss: 0.0\n",
            "training error 0.11005712763587998, test error 0.21266387449078958\n",
            "Loss: 0.011188768589276421\n",
            "training error 0.11007033942004939, test error 0.21272280566215943\n",
            "Loss: 0.03890281507852311\n",
            "training error 0.1102537044583393, test error 0.21292194723788344\n",
            "Loss: 0.13255476122639998\n",
            "training error 0.10992190287281049, test error 0.21281332087968702\n",
            "Loss: 0.08147015063686425\n",
            "training error 0.10985834168304588, test error 0.21269661863991465\n",
            "Loss: 0.02658762881908583\n",
            "training error 0.10984852280433346, test error 0.21251842835202417\n",
            "Loss: 0.0\n",
            "training error 0.10981468940648198, test error 0.21273589019209183\n",
            "Loss: 0.10232610967151334\n",
            "training error 0.10972267544843212, test error 0.21241786401918772\n",
            "Loss: 0.0\n",
            "training error 0.10965481676925173, test error 0.2125729194440522\n",
            "Loss: 0.07299547313519561\n",
            "training error 0.10953878259098904, test error 0.21225788796677103\n",
            "Loss: 0.0\n",
            "training error 0.10963494651087147, test error 0.21190027814804155\n",
            "Loss: 0.0\n",
            "training error 0.10951753063954374, test error 0.2120003811927423\n",
            "Loss: 0.04724063865118033\n",
            "training error 0.1095172060598488, test error 0.21167068420949606\n",
            "Loss: 0.0\n",
            "training error 0.10940457685912988, test error 0.21166127467663137\n",
            "Loss: 0.0\n",
            "training error 0.10940768140063234, test error 0.21126778377925726\n",
            "Loss: 0.0\n",
            "training error 0.10918929445244835, test error 0.21124997574938695\n",
            "Loss: 0.0\n",
            "training error 0.10915756359657193, test error 0.21111689838842437\n",
            "Loss: 0.0\n",
            "training error 0.10907851833572, test error 0.2112432730954734\n",
            "Loss: 0.05986006237004293\n",
            "training error 0.10905743122134824, test error 0.21126255630460472\n",
            "Loss: 0.0689939636723702\n",
            "training error 0.10893960512013899, test error 0.21089170933515994\n",
            "Loss: 0.0\n",
            "training error 0.10882584910815343, test error 0.21081413088746753\n",
            "Loss: 0.0\n",
            "training error 0.10876659537227214, test error 0.21076425371205815\n",
            "Loss: 0.0\n",
            "training error 0.10865895997685884, test error 0.21069054982203977\n",
            "Loss: 0.0\n",
            "training error 0.10861674409088193, test error 0.2105425176960241\n",
            "Loss: 0.0\n",
            "training error 0.10854806747039943, test error 0.21041816361966637\n",
            "Loss: 0.0\n",
            "training error 0.10853422469474992, test error 0.21046082841896321\n",
            "Loss: 0.02027619601032704\n",
            "training error 0.10839798335840627, test error 0.21021639161229447\n",
            "Loss: 0.0\n",
            "training error 0.10828153039211254, test error 0.21004010607690482\n",
            "Loss: 0.0\n",
            "training error 0.10825171738778656, test error 0.21001411731969366\n",
            "Loss: 0.0\n",
            "training error 0.10818819446719638, test error 0.20980024068089267\n",
            "Loss: 0.0\n",
            "training error 0.10802414513888213, test error 0.20973383832413034\n",
            "Loss: 0.0\n",
            "training error 0.10789475179957278, test error 0.20960040961152399\n",
            "Loss: 0.0\n",
            "training error 0.1078180015581547, test error 0.20931399830386196\n",
            "Loss: 0.0\n",
            "training error 0.10774036600106361, test error 0.20919411647448083\n",
            "Loss: 0.0\n",
            "training error 0.10770317026150875, test error 0.20916628796796413\n",
            "Loss: 0.0\n",
            "training error 0.10759574177269607, test error 0.20910860157797106\n",
            "Loss: 0.0\n",
            "training error 0.10746229041572788, test error 0.2089826050852698\n",
            "Loss: 0.0\n",
            "training error 0.10745203544714622, test error 0.20885198569443508\n",
            "Loss: 0.0\n",
            "training error 0.10727908962801538, test error 0.20854938189728453\n",
            "Loss: 0.0\n",
            "training error 0.10725239423025035, test error 0.20852743204966762\n",
            "Loss: 0.0\n",
            "training error 0.10718378117322445, test error 0.20850928296186552\n",
            "Loss: 0.0\n",
            "training error 0.10702084707396506, test error 0.20834083807737647\n",
            "Loss: 0.0\n",
            "training error 0.10692632683574611, test error 0.20801434057407722\n",
            "Loss: 0.0\n",
            "training error 0.10681997224234874, test error 0.20785679417189942\n",
            "Loss: 0.0\n",
            "training error 0.1066760141274012, test error 0.2076906461472898\n",
            "Loss: 0.0\n",
            "training error 0.1065986815147071, test error 0.2072851774741613\n",
            "Loss: 0.0\n",
            "training error 0.10651798746590048, test error 0.20732741149379577\n",
            "Loss: 0.020374838253789385\n",
            "training error 0.10634065694598052, test error 0.2071049223625777\n",
            "Loss: 0.0\n",
            "training error 0.10625103410008827, test error 0.20687660123590176\n",
            "Loss: 0.0\n",
            "training error 0.10613916540691914, test error 0.20670001283348124\n",
            "Loss: 0.0\n",
            "training error 0.10604502094831503, test error 0.20651116351066282\n",
            "Loss: 0.0\n",
            "training error 0.10614069005259155, test error 0.2064806080230817\n",
            "Loss: 0.0\n",
            "training error 0.10592659648589013, test error 0.2059826684582256\n",
            "Loss: 0.0\n",
            "training error 0.10572803551766073, test error 0.20575045166025907\n",
            "Loss: 0.0\n",
            "training error 0.10564155773937203, test error 0.2055025058626761\n",
            "Loss: 0.0\n",
            "training error 0.10554335693130872, test error 0.20528460012819874\n",
            "Loss: 0.0\n",
            "training error 0.10549732785372959, test error 0.20525783630989217\n",
            "Loss: 0.0\n",
            "training error 0.10529377442281304, test error 0.2051344408656141\n",
            "Loss: 0.0\n",
            "training error 0.10516646548481434, test error 0.20495945697091128\n",
            "Loss: 0.0\n",
            "training error 0.10504398113333732, test error 0.20467447775806472\n",
            "Loss: 0.0\n",
            "training error 0.10492879377979197, test error 0.2044625933893533\n",
            "Loss: 0.0\n",
            "training error 0.10490977678320855, test error 0.20429108709745886\n",
            "Loss: 0.0\n",
            "training error 0.1048861833267527, test error 0.20409291619411946\n",
            "Loss: 0.0\n",
            "training error 0.10459703428518208, test error 0.20390723714870757\n",
            "Loss: 0.0\n",
            "training error 0.10454100759621303, test error 0.20375416855572967\n",
            "Loss: 0.0\n",
            "training error 0.10435710433730334, test error 0.20354201085909843\n",
            "Loss: 0.0\n",
            "training error 0.1042430986148537, test error 0.2033120296422454\n",
            "Loss: 0.0\n",
            "training error 0.10415317852601122, test error 0.2031563128865166\n",
            "Loss: 0.0\n",
            "training error 0.10410685667156339, test error 0.20295422208665972\n",
            "Loss: 0.0\n",
            "training error 0.10389560387418016, test error 0.20276509622727223\n",
            "Loss: 0.0\n",
            "training error 0.10374487136035473, test error 0.2026031591578897\n",
            "Loss: 0.0\n",
            "training error 0.10371464140298936, test error 0.2023865119979677\n",
            "Loss: 0.0\n",
            "training error 0.10366572839743338, test error 0.20246205522351562\n",
            "Loss: 0.037326215468680424\n",
            "training error 0.10342400695117519, test error 0.20244988066309424\n",
            "Loss: 0.03131071557138654\n",
            "training error 0.10329848745782517, test error 0.20214407553055128\n",
            "Loss: 0.0\n",
            "training error 0.1031062931962277, test error 0.2019280147537219\n",
            "Loss: 0.0\n",
            "training error 0.10300820638034501, test error 0.20173950875494867\n",
            "Loss: 0.0\n",
            "training error 0.10294152166303433, test error 0.2016189430832619\n",
            "Loss: 0.0\n",
            "training error 0.10288920799459664, test error 0.20120472983984705\n",
            "Loss: 0.0\n",
            "training error 0.10266322739607711, test error 0.2012468038742088\n",
            "Loss: 0.020911056313255294\n",
            "training error 0.10247151380922914, test error 0.200983355319818\n",
            "Loss: 0.0\n",
            "training error 0.10231228311815181, test error 0.20084440733588807\n",
            "Loss: 0.0\n",
            "training error 0.10232263073739434, test error 0.20092381284609018\n",
            "Loss: 0.03953583336244737\n",
            "training error 0.10211582948027621, test error 0.20047973211587597\n",
            "Loss: 0.0\n",
            "training error 0.10193311823363846, test error 0.20045803119920141\n",
            "Loss: 0.0\n",
            "training error 0.10180957108805623, test error 0.20008536060651225\n",
            "Loss: 0.0\n",
            "training error 0.10161125362663527, test error 0.19964873061072025\n",
            "Loss: 0.0\n",
            "training error 0.1015426614173231, test error 0.19960294884842528\n",
            "Loss: 0.0\n",
            "training error 0.10135469257439847, test error 0.19915772180703442\n",
            "Loss: 0.0\n",
            "training error 0.1012969956919455, test error 0.19918732308457424\n",
            "Loss: 0.01486323365784692\n",
            "training error 0.10127392126845064, test error 0.19898380031440815\n",
            "Loss: 0.0\n",
            "training error 0.10099272470461695, test error 0.1986789609925255\n",
            "Loss: 0.0\n",
            "training error 0.10091528696266895, test error 0.19832406468468872\n",
            "Loss: 0.0\n",
            "training error 0.10072446716128397, test error 0.198074482992461\n",
            "Loss: 0.0\n",
            "training error 0.10055614101744043, test error 0.19788646852513883\n",
            "Loss: 0.0\n",
            "training error 0.10042959766532573, test error 0.1975862719130866\n",
            "Loss: 0.0\n",
            "training error 0.10027795319321003, test error 0.1973577121995296\n",
            "Loss: 0.0\n",
            "training error 0.10046001765617756, test error 0.1973464164949157\n",
            "Loss: 0.0\n",
            "training error 0.10003373483785527, test error 0.19702440457833273\n",
            "Loss: 0.0\n",
            "training error 0.10004049924700338, test error 0.19681561386251734\n",
            "Loss: 0.0\n",
            "training error 0.09984279227308408, test error 0.19663601022166458\n",
            "Loss: 0.0\n",
            "training error 0.09967839585952584, test error 0.19637036318148154\n",
            "Loss: 0.0\n",
            "training error 0.09959095359971369, test error 0.19602803471688315\n",
            "Loss: 0.0\n",
            "training error 0.09956292442333034, test error 0.19568725379053423\n",
            "Loss: 0.0\n",
            "training error 0.09928079342509272, test error 0.19566440204820618\n",
            "Loss: 0.0\n",
            "training error 0.0991633366745526, test error 0.19534024063076796\n",
            "Loss: 0.0\n",
            "training error 0.09900705402767022, test error 0.19526120556242596\n",
            "Loss: 0.0\n",
            "training error 0.09890857408689782, test error 0.19523858148822526\n",
            "Loss: 0.0\n",
            "training error 0.09886492651289686, test error 0.19514324283061507\n",
            "Loss: 0.0\n",
            "training error 0.09858175003376744, test error 0.194805073520771\n",
            "Loss: 0.0\n",
            "training error 0.09843982818143221, test error 0.1945585663217482\n",
            "Loss: 0.0\n",
            "training error 0.09828411635615047, test error 0.1944296605901844\n",
            "Loss: 0.0\n",
            "training error 0.0981468185863819, test error 0.19419312195862498\n",
            "Loss: 0.0\n",
            "training error 0.09807191725343525, test error 0.1936308734066333\n",
            "Loss: 0.0\n",
            "training error 0.09793216155007187, test error 0.19347888349409517\n",
            "Loss: 0.0\n",
            "training error 0.0978414555462291, test error 0.19323118459339353\n",
            "Loss: 0.0\n",
            "training error 0.09769346356830699, test error 0.1931518225210522\n",
            "Loss: 0.0\n",
            "training error 0.09761200660111924, test error 0.19325410520237107\n",
            "Loss: 0.052954551494188706\n",
            "training error 0.09742550133257939, test error 0.19308285666218547\n",
            "Loss: 0.0\n",
            "training error 0.0971753478854143, test error 0.1927663382972113\n",
            "Loss: 0.0\n",
            "training error 0.09719574209628873, test error 0.1927844809889457\n",
            "Loss: 0.009411753055377226\n",
            "training error 0.09694348294028744, test error 0.1926259458483294\n",
            "Loss: 0.0\n",
            "training error 0.09709014933662434, test error 0.19206550097096428\n",
            "Loss: 0.0\n",
            "training error 0.09671807575214511, test error 0.1922036538046174\n",
            "Loss: 0.0719300618563512\n",
            "training error 0.09654501701238592, test error 0.19180174851454188\n",
            "Loss: 0.0\n",
            "training error 0.09644121680179087, test error 0.191375278037187\n",
            "Loss: 0.0\n",
            "training error 0.0962727441749426, test error 0.19120970192981224\n",
            "Loss: 0.0\n",
            "training error 0.09626092749814559, test error 0.19120708986997612\n",
            "Loss: 0.0\n",
            "training error 0.09594549461875777, test error 0.19083388179727234\n",
            "Loss: 0.0\n",
            "training error 0.09583759051339716, test error 0.19045265343397164\n",
            "Loss: 0.0\n",
            "training error 0.09563997692511501, test error 0.1902169061105379\n",
            "Loss: 0.0\n",
            "training error 0.09564920808443741, test error 0.19037797041338447\n",
            "Loss: 0.08467402090588383\n",
            "training error 0.09535458313004352, test error 0.19009535016270868\n",
            "Loss: 0.0\n",
            "training error 0.09532419707841984, test error 0.19000031481917168\n",
            "Loss: 0.0\n",
            "training error 0.09518537878881285, test error 0.19008480225460825\n",
            "Loss: 0.044466997603120895\n",
            "training error 0.09506025954541915, test error 0.19011917169746\n",
            "Loss: 0.06255614807872956\n",
            "training error 0.09481686163565434, test error 0.18999323705065743\n",
            "Loss: 0.0\n",
            "training error 0.0946743086852796, test error 0.1894148268603305\n",
            "Loss: 0.0\n",
            "training error 0.09446816832914437, test error 0.18901576563224226\n",
            "Loss: 0.0\n",
            "training error 0.09433024589337512, test error 0.1889331194096399\n",
            "Loss: 0.0\n",
            "training error 0.09418957413154845, test error 0.18866898337026142\n",
            "Loss: 0.0\n",
            "training error 0.09400453444587258, test error 0.1884168948412283\n",
            "Loss: 0.0\n",
            "training error 0.09386479192559187, test error 0.18842066784051126\n",
            "Loss: 0.0020024739745938547\n",
            "training error 0.09361969208583949, test error 0.1881781835836004\n",
            "Loss: 0.0\n",
            "training error 0.09365133981650027, test error 0.18745764458744837\n",
            "Loss: 0.0\n",
            "training error 0.09338320536278388, test error 0.18741673605084022\n",
            "Loss: 0.0\n",
            "training error 0.09336086424615503, test error 0.18711890234147213\n",
            "Loss: 0.0\n",
            "training error 0.09310099681294295, test error 0.1874949225151989\n",
            "Loss: 0.20095253286627202\n",
            "training error 0.09300795707932649, test error 0.1871621058821771\n",
            "Loss: 0.02308881687758113\n",
            "training error 0.09292695901359706, test error 0.18710321787558684\n",
            "Loss: 0.0\n",
            "training error 0.09257225924361218, test error 0.1862495942408946\n",
            "Loss: 0.0\n",
            "training error 0.09255046650028251, test error 0.18602535437814363\n",
            "Loss: 0.0\n",
            "training error 0.09226595958519232, test error 0.18604786163038659\n",
            "Loss: 0.012099023984224466\n",
            "training error 0.09210903041659298, test error 0.18584166161470073\n",
            "Loss: 0.0\n",
            "training error 0.09200724967475427, test error 0.18529943217517547\n",
            "Loss: 0.0\n",
            "training error 0.0918999376636253, test error 0.18543694001085942\n",
            "Loss: 0.07420844957255479\n",
            "training error 0.09172877435294585, test error 0.18535400006911323\n",
            "Loss: 0.029448494956096916\n",
            "training error 0.09152265833904212, test error 0.18482138990215677\n",
            "Loss: 0.0\n",
            "training error 0.09139372621074927, test error 0.18492457505376525\n",
            "Loss: 0.0558296589280749\n",
            "training error 0.09111553462730576, test error 0.1844735353292745\n",
            "Loss: 0.0\n",
            "training error 0.09106400575470085, test error 0.18390637157899217\n",
            "Loss: 0.0\n",
            "training error 0.0909351679354327, test error 0.18403326175343362\n",
            "Loss: 0.06899716053989646\n",
            "training error 0.09067558111245264, test error 0.18372845734524898\n",
            "Loss: 0.0\n",
            "training error 0.09068371761424944, test error 0.1840434809715125\n",
            "Loss: 0.17146153122677976\n",
            "training error 0.0903871506028939, test error 0.18316384615712877\n",
            "Loss: 0.0\n",
            "training error 0.09009348134823889, test error 0.18288568687851073\n",
            "Loss: 0.0\n",
            "training error 0.08999480115687296, test error 0.18251278663714313\n",
            "Loss: 0.0\n",
            "training error 0.08981157870772537, test error 0.18226540565257845\n",
            "Loss: 0.0\n",
            "training error 0.08962352425122812, test error 0.18194651477683363\n",
            "Loss: 0.0\n",
            "training error 0.08948407106565463, test error 0.1815890869589328\n",
            "Loss: 0.0\n",
            "training error 0.08931952151516838, test error 0.1814111203748917\n",
            "Loss: 0.0\n",
            "training error 0.08918137872214082, test error 0.18120259832312646\n",
            "Loss: 0.0\n",
            "training error 0.08908106889335538, test error 0.18104762658773382\n",
            "Loss: 0.0\n",
            "training error 0.08869293291723594, test error 0.180881667216317\n",
            "Loss: 0.0\n",
            "training error 0.08876621606529284, test error 0.1812762562626984\n",
            "Loss: 0.21814761686684836\n",
            "training error 0.08865384250120795, test error 0.18010277109646375\n",
            "Loss: 0.0\n",
            "training error 0.08817214225113312, test error 0.18006874639550918\n",
            "Loss: 0.0\n",
            "training error 0.088091042809079, test error 0.179948640262968\n",
            "Loss: 0.0\n",
            "training error 0.08774475686482629, test error 0.17924116183584607\n",
            "Loss: 0.0\n",
            "training error 0.08765933440882177, test error 0.1787825212562366\n",
            "Loss: 0.0\n",
            "training error 0.08753867709655487, test error 0.17870177107229177\n",
            "Loss: 0.0\n",
            "training error 0.08728023015019366, test error 0.17846501508937063\n",
            "Loss: 0.0\n",
            "training error 0.08724264166735454, test error 0.17788913538222326\n",
            "Loss: 0.0\n",
            "training error 0.0868811882415776, test error 0.17786298325629832\n",
            "Loss: 0.0\n",
            "training error 0.08678298541292052, test error 0.17743960145369966\n",
            "Loss: 0.0\n",
            "training error 0.0865026675502686, test error 0.17713397200484773\n",
            "Loss: 0.0\n",
            "training error 0.08640941988234672, test error 0.17720470329055973\n",
            "Loss: 0.03993095446990225\n",
            "training error 0.08610273135944803, test error 0.17664800651919532\n",
            "Loss: 0.0\n",
            "training error 0.08591064361625483, test error 0.17663397918902254\n",
            "Loss: 0.0\n",
            "training error 0.08566279371123132, test error 0.17644173033231378\n",
            "Loss: 0.0\n",
            "training error 0.0854262629183206, test error 0.17597898769296452\n",
            "Loss: 0.0\n",
            "training error 0.08534646458582537, test error 0.17532942230613266\n",
            "Loss: 0.0\n",
            "training error 0.08493968463584232, test error 0.1748393114552373\n",
            "Loss: 0.0\n",
            "training error 0.08478376426594257, test error 0.1744706344057783\n",
            "Loss: 0.0\n",
            "training error 0.08466437853732485, test error 0.17436471434750123\n",
            "Loss: 0.0\n",
            "training error 0.08429572752725743, test error 0.17394574144627206\n",
            "Loss: 0.0\n",
            "training error 0.08412017896877604, test error 0.1731505741460287\n",
            "Loss: 0.0\n",
            "training error 0.0839008027301022, test error 0.1731218903702044\n",
            "Loss: 0.0\n",
            "training error 0.08353051581425514, test error 0.17270477520285535\n",
            "Loss: 0.0\n",
            "training error 0.08363275566126739, test error 0.17261518284062533\n",
            "Loss: 0.0\n",
            "training error 0.08314270485494643, test error 0.17212096600912127\n",
            "Loss: 0.0\n",
            "training error 0.08284458575602117, test error 0.1719838619482921\n",
            "Loss: 0.0\n",
            "training error 0.08284797255334986, test error 0.17145909002761558\n",
            "Loss: 0.0\n",
            "training error 0.08242994826941252, test error 0.17129646790942804\n",
            "Loss: 0.0\n",
            "training error 0.08206146214768535, test error 0.1703371249330323\n",
            "Loss: 0.0\n",
            "training error 0.08180387032627624, test error 0.17058381572567305\n",
            "Loss: 0.14482503020860626\n",
            "training error 0.08161831857289162, test error 0.16936489200466212\n",
            "Loss: 0.0\n",
            "training error 0.08121650534740629, test error 0.16918670413220005\n",
            "Loss: 0.0\n",
            "training error 0.08102332133369895, test error 0.1682156347304631\n",
            "Loss: 0.0\n",
            "training error 0.08068499358088765, test error 0.16760118060594315\n",
            "Loss: 0.0\n",
            "training error 0.08040471480354143, test error 0.16735082964164583\n",
            "Loss: 0.0\n",
            "training error 0.08021929574273914, test error 0.16742663481851855\n",
            "Loss: 0.04529716227583691\n",
            "training error 0.07983744935665554, test error 0.1667364943871031\n",
            "Loss: 0.0\n",
            "training error 0.07949534786760266, test error 0.16624095283462376\n",
            "Loss: 0.0\n",
            "training error 0.07913828927528144, test error 0.1658103776533941\n",
            "Loss: 0.0\n",
            "training error 0.07890638142810001, test error 0.16502570849362333\n",
            "Loss: 0.0\n",
            "training error 0.07870328550783276, test error 0.1643780032720445\n",
            "Loss: 0.0\n",
            "training error 0.07836169753912317, test error 0.16451396784798153\n",
            "Loss: 0.08271458055857384\n",
            "training error 0.077865406230836, test error 0.1640976527049729\n",
            "Loss: 0.0\n",
            "training error 0.07771483765268115, test error 0.16307302517187797\n",
            "Loss: 0.0\n",
            "training error 0.07736476454464516, test error 0.16272651026754692\n",
            "Loss: 0.0\n",
            "training error 0.07747314972168891, test error 0.1622947328201668\n",
            "Loss: 0.0\n",
            "training error 0.07674839210656437, test error 0.16137671440095955\n",
            "Loss: 0.0\n",
            "training error 0.07624325821884649, test error 0.1614137624466344\n",
            "Loss: 0.022957491613584402\n",
            "training error 0.07601739391548545, test error 0.16033517607985404\n",
            "Loss: 0.0\n",
            "training error 0.07565991707236124, test error 0.1597540563798669\n",
            "Loss: 0.0\n",
            "training error 0.07530471604169339, test error 0.15948449779305704\n",
            "Loss: 0.0\n",
            "training error 0.07514835498881756, test error 0.15992661364933752\n",
            "Loss: 0.2772155679068966\n",
            "training error 0.0746834186665513, test error 0.1594396745632109\n",
            "Loss: 0.0\n",
            "training error 0.07432865422254921, test error 0.15835573534627115\n",
            "Loss: 0.0\n",
            "training error 0.07384633332667466, test error 0.15771181326885558\n",
            "Loss: 0.0\n",
            "training error 0.07372713796654327, test error 0.1570460493032734\n",
            "Loss: 0.0\n",
            "training error 0.07311014611233013, test error 0.15700855136057348\n",
            "Loss: 0.0\n",
            "training error 0.07280036276572086, test error 0.15565070319635024\n",
            "Loss: 0.0\n",
            "training error 0.0725181886062211, test error 0.1551729634867893\n",
            "Loss: 0.0\n",
            "training error 0.0722470183669515, test error 0.15513308627923883\n",
            "Loss: 0.0\n",
            "training error 0.07177882958671296, test error 0.15458658644856238\n",
            "Loss: 0.0\n",
            "training error 0.07187282603366572, test error 0.1535551780745669\n",
            "Loss: 0.0\n",
            "training error 0.07112134829004241, test error 0.15311526279462825\n",
            "Loss: 0.0\n",
            "training error 0.07068554458140315, test error 0.15269421341043166\n",
            "Loss: 0.0\n",
            "training error 0.07036066644515693, test error 0.15192457303261345\n",
            "Loss: 0.0\n",
            "training error 0.07000129243443928, test error 0.15061492708607915\n",
            "Loss: 0.0\n",
            "training error 0.06961539914147094, test error 0.1500027810297429\n",
            "Loss: 0.0\n",
            "training error 0.06984962685784057, test error 0.15005335337155254\n",
            "Loss: 0.033714269470519476\n",
            "training error 0.06911649512725597, test error 0.1485135438718688\n",
            "Loss: 0.0\n",
            "training error 0.06871551081497007, test error 0.147835687605021\n",
            "Loss: 0.0\n",
            "training error 0.06841705580978598, test error 0.14809754284874171\n",
            "Loss: 0.1771258672130127\n",
            "training error 0.06787303762835244, test error 0.14746295882394359\n",
            "Loss: 0.0\n",
            "training error 0.06758878865015575, test error 0.14637580548272047\n",
            "Loss: 0.0\n",
            "training error 0.0671613526687323, test error 0.14558586415896682\n",
            "Loss: 0.0\n",
            "training error 0.06683870267930063, test error 0.14441010448502245\n",
            "Loss: 0.0\n",
            "training error 0.06650985026628418, test error 0.14370909546657215\n",
            "Loss: 0.0\n",
            "training error 0.06607985702669567, test error 0.14369789458883364\n",
            "Loss: 0.0\n",
            "training error 0.06614269263770473, test error 0.14264693018891064\n",
            "Loss: 0.0\n",
            "training error 0.06535635549888165, test error 0.14254052260026115\n",
            "Loss: 0.0\n",
            "training error 0.06509237030636107, test error 0.14228356414497037\n",
            "Loss: 0.0\n",
            "training error 0.06467311362612066, test error 0.1420780525662336\n",
            "Loss: 0.0\n",
            "training error 0.06435667675194641, test error 0.14131502281683173\n",
            "Loss: 0.0\n",
            "training error 0.06406197996628278, test error 0.13979191282267883\n",
            "Loss: 0.0\n",
            "training error 0.06367173616069965, test error 0.13884391116507766\n",
            "Loss: 0.0\n",
            "training error 0.06309963165647771, test error 0.1380847826418717\n",
            "Loss: 0.0\n",
            "training error 0.06262077355088393, test error 0.1382413679320419\n",
            "Loss: 0.11339793362770134\n",
            "training error 0.0623220313370709, test error 0.1372799557970972\n",
            "Loss: 0.0\n",
            "training error 0.06195576448804995, test error 0.1364916901995966\n",
            "Loss: 0.0\n",
            "training error 0.061597847758498823, test error 0.1361706627275357\n",
            "Loss: 0.0\n",
            "training error 0.06138102120500052, test error 0.1349377674783181\n",
            "Loss: 0.0\n",
            "training error 0.060986308853155334, test error 0.13422824996597837\n",
            "Loss: 0.0\n",
            "training error 0.060459671614590586, test error 0.13389551966040608\n",
            "Loss: 0.0\n",
            "training error 0.06077297281891299, test error 0.1337367323009229\n",
            "Loss: 0.0\n",
            "training error 0.05979291735915942, test error 0.13178778419558473\n",
            "Loss: 0.0\n",
            "training error 0.05955782436671744, test error 0.1313661408612241\n",
            "Loss: 0.0\n",
            "training error 0.05942528624936757, test error 0.12996308976121354\n",
            "Loss: 0.0\n",
            "training error 0.0590290070435338, test error 0.13132646161118325\n",
            "Loss: 1.049045427032147\n",
            "training error 0.058418457423470155, test error 0.12983865029793448\n",
            "Loss: 0.0\n",
            "training error 0.0582910166476134, test error 0.12794838502823824\n",
            "Loss: 0.0\n",
            "training error 0.05778694858882938, test error 0.12677163681641268\n",
            "Loss: 0.0\n",
            "training error 0.0575363008021158, test error 0.12691688239276327\n",
            "Loss: 0.11457261261123008\n",
            "training error 0.05728957528182385, test error 0.12549897102426064\n",
            "Loss: 0.0\n",
            "training error 0.05670444332678749, test error 0.1258605814463245\n",
            "Loss: 0.2881381569207919\n",
            "training error 0.05632270640895772, test error 0.12579940324978486\n",
            "Loss: 0.23939019027188202\n",
            "training error 0.05600477604300764, test error 0.12474079108232018\n",
            "Loss: 0.0\n",
            "training error 0.055809606713239826, test error 0.12396741037404693\n",
            "Loss: 0.0\n",
            "training error 0.05522197965688705, test error 0.12257421548600857\n",
            "Loss: 0.0\n",
            "training error 0.054844317948457226, test error 0.1222544655055833\n",
            "Loss: 0.0\n",
            "training error 0.054745267969623666, test error 0.12160434952593123\n",
            "Loss: 0.0\n",
            "training error 0.054278347589407444, test error 0.12176979113826272\n",
            "Loss: 0.13604909115212394\n",
            "training error 0.05375908640371984, test error 0.11985748086152768\n",
            "Loss: 0.0\n",
            "training error 0.05342824780923321, test error 0.11910963573174255\n",
            "Loss: 0.0\n",
            "training error 0.05310613743875338, test error 0.11785706821163418\n",
            "Loss: 0.0\n",
            "training error 0.052961879583050014, test error 0.11819752064073116\n",
            "Loss: 0.28886891067545495\n",
            "training error 0.05233607722360336, test error 0.1167992283151297\n",
            "Loss: 0.0\n",
            "training error 0.05210229677724792, test error 0.11586593630751935\n",
            "Loss: 0.0\n",
            "training error 0.051738863870429946, test error 0.1156605185466041\n",
            "Loss: 0.0\n",
            "training error 0.051332750132692055, test error 0.11505151776239214\n",
            "Loss: 0.0\n",
            "training error 0.051347147352122056, test error 0.11424439025222448\n",
            "Loss: 0.0\n",
            "training error 0.05060030312490566, test error 0.11340583859729567\n",
            "Loss: 0.0\n",
            "training error 0.05036063812560231, test error 0.11331332099688501\n",
            "Loss: 0.0\n",
            "training error 0.049852953831363164, test error 0.11288390547723522\n",
            "Loss: 0.0\n",
            "training error 0.050089351531165116, test error 0.11143575032346593\n",
            "Loss: 0.0\n",
            "training error 0.049346241882455365, test error 0.11062348587431611\n",
            "Loss: 0.0\n",
            "training error 0.04902966948320822, test error 0.11073378562752453\n",
            "Loss: 0.09970735629660776\n",
            "training error 0.04894328041280396, test error 0.11033011896127357\n",
            "Loss: 0.0\n",
            "training error 0.04827414556818596, test error 0.1092974729784901\n",
            "Loss: 0.0\n",
            "training error 0.0481302695023743, test error 0.10756888188459711\n",
            "Loss: 0.0\n",
            "training error 0.04776571797297319, test error 0.10698125599712362\n",
            "Loss: 0.0\n",
            "training error 0.04738490612178979, test error 0.10609827140950633\n",
            "Loss: 0.0\n",
            "training error 0.04728041806466995, test error 0.1059810347649366\n",
            "Loss: 0.0\n",
            "training error 0.04693097650328428, test error 0.10492696381243764\n",
            "Loss: 0.0\n",
            "training error 0.04633543823682675, test error 0.1050988589538948\n",
            "Loss: 0.16382361140689916\n",
            "training error 0.046061748787175415, test error 0.1047831671234718\n",
            "Loss: 0.0\n",
            "training error 0.0456842379323484, test error 0.10340932092341387\n",
            "Loss: 0.0\n",
            "training error 0.04529352160010262, test error 0.10298104136899718\n",
            "Loss: 0.0\n",
            "training error 0.04530459919773587, test error 0.10141088567626527\n",
            "Loss: 0.0\n",
            "training error 0.044982183899055575, test error 0.10092475435824923\n",
            "Loss: 0.0\n",
            "training error 0.04462272990584353, test error 0.10022835038675812\n",
            "Loss: 0.0\n",
            "training error 0.04420656056985207, test error 0.0997718554578296\n",
            "Loss: 0.0\n",
            "training error 0.043954976932001046, test error 0.09921212644609774\n",
            "Loss: 0.0\n",
            "training error 0.04367819128179868, test error 0.09929037642595803\n",
            "Loss: 0.07887138665736426\n",
            "training error 0.04328434016130099, test error 0.09775437456116913\n",
            "Loss: 0.0\n",
            "training error 0.0429022327150699, test error 0.09760743557328101\n",
            "Loss: 0.0\n",
            "training error 0.042868226141047364, test error 0.09668880783834236\n",
            "Loss: 0.0\n",
            "training error 0.042326671551076, test error 0.09652187268981686\n",
            "Loss: 0.0\n",
            "training error 0.042063278298401174, test error 0.09519874501265124\n",
            "Loss: 0.0\n",
            "training error 0.04184724936552153, test error 0.09552769686747493\n",
            "Loss: 0.34554221778866356\n",
            "training error 0.04150977675232702, test error 0.09434372914907177\n",
            "Loss: 0.0\n",
            "training error 0.041257551226470186, test error 0.09366778321930394\n",
            "Loss: 0.0\n",
            "training error 0.04093373997018146, test error 0.09298489760598594\n",
            "Loss: 0.0\n",
            "training error 0.04069823516964054, test error 0.09210709666625716\n",
            "Loss: 0.0\n",
            "training error 0.0406152739996786, test error 0.09136542734019366\n",
            "Loss: 0.0\n",
            "training error 0.040126476797783285, test error 0.09141407987091325\n",
            "Loss: 0.053250482305999824\n",
            "training error 0.04019757960216212, test error 0.09135995495108776\n",
            "Loss: 0.0\n",
            "training error 0.03988735033297948, test error 0.09090855016688595\n",
            "Loss: 0.0\n",
            "training error 0.0394426812068354, test error 0.08966410751536708\n",
            "Loss: 0.0\n",
            "training error 0.03920410327166856, test error 0.08852658211583664\n",
            "Loss: 0.0\n",
            "training error 0.038850787993472254, test error 0.08892586873846015\n",
            "Loss: 0.4510358505663836\n",
            "training error 0.03872134075876926, test error 0.08788724359275915\n",
            "Loss: 0.0\n",
            "training error 0.03844864455472584, test error 0.08799641940694591\n",
            "Loss: 0.12422259445596939\n",
            "training error 0.03812358541443544, test error 0.08734089224985715\n",
            "Loss: 0.0\n",
            "training error 0.037868014638060395, test error 0.08659930828780607\n",
            "Loss: 0.0\n",
            "training error 0.03784653866230737, test error 0.08526245216590567\n",
            "Loss: 0.0\n",
            "training error 0.0374736468829095, test error 0.08516831741761104\n",
            "Loss: 0.0\n",
            "training error 0.03729011879779102, test error 0.0851314485002034\n",
            "Loss: 0.0\n",
            "training error 0.03687959185552644, test error 0.08433428925766293\n",
            "Loss: 0.0\n",
            "training error 0.03668428869556532, test error 0.08403329236401762\n",
            "Loss: 0.0\n",
            "training error 0.036532866250603244, test error 0.08287607817822303\n",
            "Loss: 0.0\n",
            "training error 0.036539898158986756, test error 0.08236489035067594\n",
            "Loss: 0.0\n",
            "training error 0.03594777504334206, test error 0.08338194127632663\n",
            "Loss: 1.2348112421694424\n",
            "training error 0.036300672131456053, test error 0.08232459609651381\n",
            "Loss: 0.0\n",
            "training error 0.03567993009793591, test error 0.08194711680666551\n",
            "Loss: 0.0\n",
            "training error 0.0353887440707787, test error 0.0807448735161058\n",
            "Loss: 0.0\n",
            "training error 0.035271072720596125, test error 0.08076432128786269\n",
            "Loss: 0.024085456958466978\n",
            "training error 0.03493409728150909, test error 0.07999783224674306\n",
            "Loss: 0.0\n",
            "training error 0.03482423512720272, test error 0.08011355241146444\n",
            "Loss: 0.14465412558237745\n",
            "training error 0.03471066951655488, test error 0.08029241910225769\n",
            "Loss: 0.368243547657654\n",
            "training error 0.034418404876693495, test error 0.07873742478620764\n",
            "Loss: 0.0\n",
            "training error 0.034239807602700505, test error 0.07808498892534291\n",
            "Loss: 0.0\n",
            "training error 0.0340023196233026, test error 0.07773984299234801\n",
            "Loss: 0.0\n",
            "training error 0.03368661458525781, test error 0.0774764693250679\n",
            "Loss: 0.0\n",
            "training error 0.033761320582111634, test error 0.07792629731980236\n",
            "Loss: 0.5805995015688126\n",
            "training error 0.033468530514254746, test error 0.07764032713410934\n",
            "Loss: 0.21149364506267698\n",
            "training error 0.033281269278423925, test error 0.07600198282381566\n",
            "Loss: 0.0\n",
            "training error 0.032939449758109626, test error 0.07627181717870771\n",
            "Loss: 0.3550359409932202\n",
            "training error 0.03300566949435087, test error 0.07566589071944607\n",
            "Loss: 0.0\n",
            "training error 0.032692767622892034, test error 0.07500179304130528\n",
            "Loss: 0.0\n",
            "training error 0.03245453313203517, test error 0.07503260955717647\n",
            "Loss: 0.041087705535547414\n",
            "training error 0.032211467682294645, test error 0.07420408564769429\n",
            "Loss: 0.0\n",
            "training error 0.03209669582198104, test error 0.07408937775298347\n",
            "Loss: 0.0\n",
            "training error 0.031864462982049084, test error 0.07391631714464035\n",
            "Loss: 0.0\n",
            "training error 0.03180226830021563, test error 0.07316317715156612\n",
            "Loss: 0.0\n",
            "training error 0.03153841534251645, test error 0.07290400942555614\n",
            "Loss: 0.0\n",
            "training error 0.03163464177884347, test error 0.07164661553681533\n",
            "Loss: 0.0\n",
            "training error 0.031131834537403095, test error 0.07122357542061232\n",
            "Loss: 0.0\n",
            "training error 0.03104809446247297, test error 0.07095038935855487\n",
            "Loss: 0.0\n",
            "training error 0.030803291010861142, test error 0.07059773659071844\n",
            "Loss: 0.0\n",
            "training error 0.030607453945261397, test error 0.07012272613523853\n",
            "Loss: 0.0\n",
            "training error 0.030629465705927388, test error 0.07035694197002258\n",
            "Loss: 0.3340084558782763\n",
            "training error 0.03036385212542842, test error 0.06961093559942282\n",
            "Loss: 0.0\n",
            "training error 0.030221643544874496, test error 0.06978222630830506\n",
            "Loss: 0.2460686778697374\n",
            "training error 0.030348555162509075, test error 0.069601975930344\n",
            "Loss: 0.0\n",
            "training error 0.02987147886333751, test error 0.06853332933535043\n",
            "Loss: 0.0\n",
            "training error 0.030044717797852002, test error 0.06872989924804018\n",
            "Loss: 0.28682381929512335\n",
            "training error 0.029563988563022205, test error 0.06827017911735614\n",
            "Loss: 0.0\n",
            "training error 0.02948567235186487, test error 0.0686303767048495\n",
            "Loss: 0.5276060384640013\n",
            "training error 0.029496053399660806, test error 0.06875905145890547\n",
            "Loss: 0.7160847501351375\n",
            "training error 0.029416251420771193, test error 0.06850201739795082\n",
            "Loss: 0.3395893838159747\n",
            "training error 0.029086863376220295, test error 0.06745267973871381\n",
            "Loss: 0.0\n",
            "training error 0.029090410011693765, test error 0.06645937206619194\n",
            "Loss: 0.0\n",
            "training error 0.028971112027029598, test error 0.06611521644587626\n",
            "Loss: 0.0\n",
            "training error 0.028712959187253428, test error 0.06592267451418839\n",
            "Loss: 0.0\n",
            "training error 0.028551225952242347, test error 0.06604981102632498\n",
            "Loss: 0.19285702995748277\n",
            "training error 0.028475980457976707, test error 0.06583523333800628\n",
            "Loss: 0.0\n",
            "training error 0.028408002708305263, test error 0.06586133911452045\n",
            "Loss: 0.03965319964789327\n",
            "training error 0.028227316682700856, test error 0.0652952074594651\n",
            "Loss: 0.0\n",
            "training error 0.02807073677184898, test error 0.06466549329496295\n",
            "Loss: 0.0\n",
            "training error 0.027907497118819066, test error 0.06417547660618385\n",
            "Loss: 0.0\n",
            "training error 0.027739795792403505, test error 0.06436003433366565\n",
            "Loss: 0.2875829479449754\n",
            "training error 0.027676990105523165, test error 0.06459403869465981\n",
            "Loss: 0.6522150058105414\n",
            "training error 0.027667521812945475, test error 0.0636960642417363\n",
            "Loss: 0.0\n",
            "training error 0.027580591746175907, test error 0.0632644141397297\n",
            "Loss: 0.0\n",
            "training error 0.027456581441252514, test error 0.06417534954616698\n",
            "Loss: 1.4398859435026612\n",
            "training error 0.027280910946461578, test error 0.06398768248969416\n",
            "Loss: 1.1432467364148824\n",
            "training error 0.027127411971225132, test error 0.06324176132702608\n",
            "Loss: 0.0\n",
            "training error 0.027029266685224963, test error 0.06256080515498648\n",
            "Loss: 0.0\n",
            "training error 0.026990258208759794, test error 0.0627401189912529\n",
            "Loss: 0.2866232872517971\n",
            "training error 0.02673781130465308, test error 0.06259408776543589\n",
            "Loss: 0.05320041896352823\n",
            "training error 0.026709532899336794, test error 0.062454664983007974\n",
            "Loss: 0.0\n",
            "training error 0.02666430984247135, test error 0.06172608857206419\n",
            "Loss: 0.0\n",
            "training error 0.02658019075150933, test error 0.06118077455490593\n",
            "Loss: 0.0\n",
            "training error 0.026475448836732, test error 0.06153188113479697\n",
            "Loss: 0.5738838425066728\n",
            "training error 0.026331104716078215, test error 0.061011279043499476\n",
            "Loss: 0.0\n",
            "training error 0.026213642844581365, test error 0.06076931584086529\n",
            "Loss: 0.0\n",
            "training error 0.026162504028824626, test error 0.06076184997852888\n",
            "Loss: 0.0\n",
            "training error 0.026030094240065544, test error 0.06061961365007365\n",
            "Loss: 0.0\n",
            "training error 0.026304181218135925, test error 0.05970716136201819\n",
            "Loss: 0.0\n",
            "training error 0.02588573064077169, test error 0.05965528603686126\n",
            "Loss: 0.0\n",
            "training error 0.02589794068782318, test error 0.06001302480711886\n",
            "Loss: 0.5996765651857805\n",
            "training error 0.025867587385848923, test error 0.05989954516718552\n",
            "Loss: 0.4094509414862779\n",
            "training error 0.02557413340720325, test error 0.05948170314591527\n",
            "Loss: 0.0\n",
            "training error 0.025574233809754675, test error 0.059479873790647016\n",
            "Loss: 0.0\n",
            "training error 0.025439381205864624, test error 0.05878045098536534\n",
            "Loss: 0.0\n",
            "training error 0.025379667755881886, test error 0.05881613631966144\n",
            "Loss: 0.060709527909175165\n",
            "training error 0.02529728882342212, test error 0.05837949434906432\n",
            "Loss: 0.0\n",
            "training error 0.0251565073008206, test error 0.05825674470315528\n",
            "Loss: 0.0\n",
            "training error 0.025141738858368852, test error 0.05845072367319625\n",
            "Loss: 0.33297255284239213\n",
            "training error 0.025097558980937226, test error 0.0582557566708688\n",
            "Loss: 0.0\n",
            "training error 0.02511230150912157, test error 0.058836291396956834\n",
            "Loss: 0.9965276554005253\n",
            "training error 0.025019932355101773, test error 0.058630497377183885\n",
            "Loss: 0.6432681124241224\n",
            "training error 0.024926196813368252, test error 0.05825051375640893\n",
            "Loss: 0.0\n",
            "training error 0.02491928302353428, test error 0.05777131027571624\n",
            "Loss: 0.0\n",
            "training error 0.024902477847721986, test error 0.057104513266963274\n",
            "Loss: 0.0\n",
            "training error 0.025134893167792795, test error 0.05753438001446666\n",
            "Loss: 0.7527719315175041\n",
            "training error 0.024776118611092975, test error 0.05687889295015981\n",
            "Loss: 0.0\n",
            "training error 0.024622831842408925, test error 0.0567230940826374\n",
            "Loss: 0.0\n",
            "training error 0.02450712172780512, test error 0.05688393149597505\n",
            "Loss: 0.2835483782025916\n",
            "training error 0.0245344483938407, test error 0.057086587091858675\n",
            "Loss: 0.6408201370181166\n",
            "training error 0.02440645272855409, test error 0.05689482085237454\n",
            "Loss: 0.30274577315363427\n",
            "training error 0.024401382279312028, test error 0.05674114164506808\n",
            "Loss: 0.031816956960040166\n",
            "training error 0.024397262929149895, test error 0.05609795683472112\n",
            "Loss: 0.0\n",
            "training error 0.02420683560143885, test error 0.05655100630359326\n",
            "Loss: 0.8076042238168046\n",
            "training error 0.024209704462066748, test error 0.05653718675465912\n",
            "Loss: 0.7829695495543243\n",
            "training error 0.02417761445506584, test error 0.05593675328891677\n",
            "Loss: 0.0\n",
            "training error 0.02402227865935515, test error 0.055431744569203086\n",
            "Loss: 0.0\n",
            "training error 0.023950623850453587, test error 0.05539206885559607\n",
            "Loss: 0.0\n",
            "training error 0.024028847757271325, test error 0.055753871309179664\n",
            "Loss: 0.653166529177307\n",
            "training error 0.02385062919958049, test error 0.055388930276105246\n",
            "Loss: 0.0\n",
            "training error 0.023879411892665157, test error 0.05518630477841404\n",
            "Loss: 0.0\n",
            "training error 0.02377615275596661, test error 0.05503344884895393\n",
            "Loss: 0.0\n",
            "training error 0.023753883910645368, test error 0.055158537892956924\n",
            "Loss: 0.227296392683507\n",
            "training error 0.023697885715539362, test error 0.05458416844942577\n",
            "Loss: 0.0\n",
            "training error 0.023757263825303205, test error 0.05502866777064905\n",
            "Loss: 0.8143374422477923\n",
            "training error 0.02352761801518774, test error 0.054745617248910104\n",
            "Loss: 0.2957795347453551\n",
            "training error 0.023492974608605315, test error 0.0543028175622566\n",
            "Loss: 0.0\n",
            "training error 0.023507413227080297, test error 0.054261908172553525\n",
            "Loss: 0.0\n",
            "training error 0.023378363040538447, test error 0.05411600203673812\n",
            "Loss: 0.0\n",
            "training error 0.023430727286261877, test error 0.053662745369324444\n",
            "Loss: 0.0\n",
            "training error 0.023425039801551344, test error 0.05405010390729202\n",
            "Loss: 0.7218388386610597\n",
            "training error 0.02329775006962435, test error 0.05370291282054748\n",
            "Loss: 0.07485165163763075\n",
            "training error 0.02322095982097083, test error 0.05332355222584853\n",
            "Loss: 0.0\n",
            "training error 0.023229393053514992, test error 0.0530505819605994\n",
            "Loss: 0.0\n",
            "training error 0.02312905773579823, test error 0.05292384248034837\n",
            "Loss: 0.0\n",
            "training error 0.02312984055711819, test error 0.05359997068480597\n",
            "Loss: 1.2775493478363042\n",
            "training error 0.02306668264480884, test error 0.053874336405732214\n",
            "Loss: 1.7959654492902377\n",
            "training error 0.02303210397445735, test error 0.053708299776313036\n",
            "Loss: 1.4822379842430067\n",
            "training error 0.022994724467371355, test error 0.05264951259558087\n",
            "Loss: 0.0\n",
            "training error 0.022960597595136245, test error 0.05260187608356801\n",
            "Loss: 0.0\n",
            "training error 0.0229895785137745, test error 0.0525798983683919\n",
            "Loss: 0.0\n",
            "training error 0.022778028297515646, test error 0.05274972657570472\n",
            "Loss: 0.32299074852322196\n",
            "training error 0.022774250943402463, test error 0.05215162882612297\n",
            "Loss: 0.0\n",
            "training error 0.022764927405272632, test error 0.052714114623558656\n",
            "Loss: 1.0785584460095254\n",
            "training error 0.02272348041498279, test error 0.05232901233769536\n",
            "Loss: 0.3401303383328669\n",
            "training error 0.02272417388897208, test error 0.05234020445849628\n",
            "Loss: 0.3615910693835378\n",
            "training error 0.022710749080317703, test error 0.05197768927615108\n",
            "Loss: 0.0\n",
            "training error 0.022651462524381848, test error 0.05196220080338781\n",
            "Loss: 0.0\n",
            "training error 0.02259953991871692, test error 0.05237739890822017\n",
            "Loss: 0.7990387212492678\n",
            "training error 0.022573736629230227, test error 0.052449607161204996\n",
            "Loss: 0.9380017595124857\n",
            "training error 0.022469663065433645, test error 0.05238533881147376\n",
            "Loss: 0.8143188732267159\n",
            "training error 0.022422467569795743, test error 0.05232510809521359\n",
            "Loss: 0.6984063150037301\n",
            "training error 0.0223542381166017, test error 0.05213779345190901\n",
            "Loss: 0.33792380962769375\n",
            "training error 0.02231207636792944, test error 0.0518464910078898\n",
            "Loss: 0.0\n",
            "training error 0.022319907030245226, test error 0.051557223107822646\n",
            "Loss: 0.0\n",
            "training error 0.02228547996304355, test error 0.051433387912804975\n",
            "Loss: 0.0\n",
            "training error 0.022557773478549883, test error 0.05133957496958571\n",
            "Loss: 0.0\n",
            "training error 0.022136604112169445, test error 0.051412997216810724\n",
            "Loss: 0.14301296274561448\n",
            "training error 0.022156388321866533, test error 0.05145740022644324\n",
            "Loss: 0.2295018159525597\n",
            "training error 0.022158387529532992, test error 0.05127128728083926\n",
            "Loss: 0.0\n",
            "training error 0.022134787625630467, test error 0.05131195729333027\n",
            "Loss: 0.07932317413494872\n",
            "training error 0.022126729401612377, test error 0.05070359147440207\n",
            "Loss: 0.0\n",
            "training error 0.022159132931687475, test error 0.050899382800236155\n",
            "Loss: 0.3861488311590833\n",
            "training error 0.02208462017158223, test error 0.05086603187920153\n",
            "Loss: 0.32037258126274004\n",
            "training error 0.02196971805963321, test error 0.050828288930983435\n",
            "Loss: 0.24593416946474544\n",
            "training error 0.02198759464018229, test error 0.05094547371426306\n",
            "Loss: 0.4770514924630209\n",
            "training error 0.022010425317330523, test error 0.05045075494999728\n",
            "Loss: 0.0\n",
            "training error 0.02195741924111729, test error 0.050704244722303414\n",
            "Loss: 0.5024499089406387\n",
            "training error 0.021915825425155053, test error 0.050857683188575954\n",
            "Loss: 0.8065850332308999\n",
            "training error 0.021877485818923674, test error 0.05050113598021582\n",
            "Loss: 0.09986179645571358\n",
            "training error 0.021811916073899585, test error 0.05007920228893597\n",
            "Loss: 0.0\n",
            "training error 0.02175522166754214, test error 0.050390232105143117\n",
            "Loss: 0.6210758198835542\n",
            "training error 0.021784437651577507, test error 0.05060757390597137\n",
            "Loss: 1.0550719517993024\n",
            "training error 0.021758486534935825, test error 0.05044336784638819\n",
            "Loss: 0.7271792297152357\n",
            "training error 0.02179379368795728, test error 0.050030887253100606\n",
            "Loss: 0.0\n",
            "training error 0.0217248397808529, test error 0.050126199119470506\n",
            "Loss: 0.19050604856900577\n",
            "training error 0.021654487428932438, test error 0.049873494107055695\n",
            "Loss: 0.0\n",
            "training error 0.021654055185087107, test error 0.050087114338860504\n",
            "Loss: 0.4283241742522925\n",
            "training error 0.02155711111600598, test error 0.04993041843101887\n",
            "Loss: 0.1141374290740238\n",
            "training error 0.02164851588366612, test error 0.05032016347169008\n",
            "Loss: 0.8956047147520518\n",
            "training error 0.021593496927216033, test error 0.05032621172296872\n",
            "Loss: 0.9077319005186268\n",
            "training error 0.02159656168438114, test error 0.04973752253982747\n",
            "Loss: 0.0\n",
            "training error 0.02163923120348625, test error 0.049543628834396634\n",
            "Loss: 0.0\n",
            "training error 0.02152254950390046, test error 0.04957166684914867\n",
            "Loss: 0.05659257388221928\n",
            "training error 0.021554391899336164, test error 0.049849442823476676\n",
            "Loss: 0.6172619896339215\n",
            "training error 0.021429654819785607, test error 0.04966792030224177\n",
            "Loss: 0.25087275754585026\n",
            "training error 0.02142981341931619, test error 0.049352524861821005\n",
            "Loss: 0.0\n",
            "training error 0.02138262648490703, test error 0.04925722771647821\n",
            "Loss: 0.0\n",
            "training error 0.02140590177509199, test error 0.04942374364595039\n",
            "Loss: 0.3380537987859089\n",
            "training error 0.02138725040542356, test error 0.04956191804100524\n",
            "Loss: 0.6185697787963296\n",
            "training error 0.021419591939315332, test error 0.04971264606157912\n",
            "Loss: 0.9245716135757309\n",
            "training error 0.02138172177204589, test error 0.049749816044912826\n",
            "Loss: 1.000032586628552\n",
            "training error 0.021343505836586757, test error 0.04967119944856857\n",
            "Loss: 0.8404284026562792\n",
            "training error 0.021299792409455932, test error 0.04981735841978224\n",
            "Loss: 1.1371543411417884\n",
            "training error 0.021361721198326366, test error 0.048932078015615076\n",
            "Loss: 0.0\n",
            "training error 0.021178518407573475, test error 0.048924004318066504\n",
            "Loss: 0.0\n",
            "training error 0.02119381718941865, test error 0.04871385430676256\n",
            "Loss: 0.0\n",
            "training error 0.021167776451823272, test error 0.04873225135369981\n",
            "Loss: 0.03776553343819433\n",
            "training error 0.02131224987189894, test error 0.04861015980320223\n",
            "Loss: 0.0\n",
            "training error 0.02121798878536679, test error 0.04869563782431397\n",
            "Loss: 0.1758439417969493\n",
            "training error 0.021125435068376646, test error 0.04882646835587401\n",
            "Loss: 0.44498630234399705\n",
            "training error 0.021155898321423495, test error 0.048305533282906495\n",
            "Loss: 0.0\n",
            "training error 0.021074235858543948, test error 0.048988219600459605\n",
            "Loss: 1.4132673239624305\n",
            "training error 0.021042988648683533, test error 0.04886904725914382\n",
            "Loss: 1.166561960794521\n",
            "training error 0.021093569406171624, test error 0.048996162647268644\n",
            "Loss: 1.4297106716893104\n",
            "training error 0.021025748701868727, test error 0.04831244647249835\n",
            "Loss: 0.014311382406995143\n",
            "training error 0.02095391992671859, test error 0.048491364697981154\n",
            "Loss: 0.38470005907256244\n",
            "training error 0.020969120281519066, test error 0.04852452301127309\n",
            "Loss: 0.45334294745087433\n",
            "training error 0.021050990276172046, test error 0.04786569962748599\n",
            "Loss: 0.0\n",
            "training error 0.020901270116290623, test error 0.04785748404772161\n",
            "Loss: 0.0\n",
            "training error 0.020862751804876706, test error 0.04788104166159267\n",
            "Loss: 0.0492245138661529\n",
            "training error 0.02100423729369885, test error 0.04833082175826116\n",
            "Loss: 0.9890568214316442\n",
            "training error 0.02082692809196697, test error 0.04778239047640881\n",
            "Loss: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04778239047640881\n",
            "training error 0.12319176360009813, test error 0.23685031303664464\n",
            "training error 0.1198886297050329, test error 0.2318960290860955\n",
            "training error 0.11883547047263496, test error 0.22750491954756058\n",
            "training error 0.11836405880644649, test error 0.22520787418746613\n",
            "training error 0.11785321790075354, test error 0.22412518020503744\n",
            "training error 0.11786588924708818, test error 0.22376363205186145\n",
            "training error 0.1177221159783889, test error 0.2233873724699701\n",
            "training error 0.11779871146760441, test error 0.22228066980947406\n",
            "training error 0.11783267919018302, test error 0.2216328917397937\n",
            "training error 0.11770656154329887, test error 0.22185849199588728\n",
            "training error 0.11768063452604331, test error 0.22234891196336948\n",
            "training error 0.11750893047219288, test error 0.22237971917034968\n",
            "training error 0.11782548681548438, test error 0.22277327291776625\n",
            "training error 0.11812302924399663, test error 0.22329757462548797\n",
            "training error 0.11766898236526462, test error 0.22359300442417\n",
            "training error 0.11773230795828107, test error 0.22272057722986915\n",
            "training error 0.11753556358639326, test error 0.22254719946028262\n",
            "training error 0.11736672417496899, test error 0.22218967484286875\n",
            "training error 0.11728956854125921, test error 0.2228759132413699\n",
            "training error 0.11746763895507341, test error 0.22421295114556472\n",
            "training error 0.1173198011666702, test error 0.2233347632499331\n",
            "training error 0.11754116508275851, test error 0.2235086362304951\n",
            "training error 0.11729712089507591, test error 0.22321849460244536\n",
            "training error 0.1172079761870152, test error 0.22306892960542135\n",
            "training error 0.11734213648028027, test error 0.22283731805599882\n",
            "training error 0.11715926375696678, test error 0.22253394915350777\n",
            "training error 0.11722468958723373, test error 0.22205190736287808\n",
            "training error 0.1171280775790519, test error 0.2217522787915671\n",
            "training error 0.11714388409538777, test error 0.22178168311121896\n",
            "training error 0.11726214520019398, test error 0.22174890397540664\n",
            "training error 0.11725276910541726, test error 0.22184219620256376\n",
            "training error 0.11713713151449402, test error 0.22204131681257708\n",
            "training error 0.11701629233680877, test error 0.22185828585897088\n",
            "training error 0.11718021711310339, test error 0.22138724439588134\n",
            "training error 0.11709224051236872, test error 0.22144791437123254\n",
            "training error 0.11707060927139522, test error 0.22147650748727177\n",
            "training error 0.11707831020145182, test error 0.2216968521836741\n",
            "training error 0.11701106380456522, test error 0.22210620323235486\n",
            "training error 0.11689666613974244, test error 0.22244960356638072\n",
            "training error 0.11755069283353493, test error 0.2220599911858691\n",
            "training error 0.11697241019792846, test error 0.22278538118130092\n",
            "training error 0.1168959138320483, test error 0.22326303450576812\n",
            "training error 0.11688209453265891, test error 0.22268739397939188\n",
            "training error 0.11703923980656325, test error 0.22189076615130737\n",
            "training error 0.11700028408930044, test error 0.22293629215678445\n",
            "training error 0.11687386561533791, test error 0.22288343449967893\n",
            "training error 0.1168250789465688, test error 0.22181586995868804\n",
            "training error 0.11710861872643254, test error 0.2213755539560064\n",
            "training error 0.11685400913569735, test error 0.2210875319562901\n",
            "training error 0.11691075604776555, test error 0.22184210715366037\n",
            "Loss: 0.3413015608313197\n",
            "training error 0.1167150020882032, test error 0.2224841597549465\n",
            "Loss: 0.6317080779265849\n",
            "training error 0.11664018314001236, test error 0.22257873533280245\n",
            "Loss: 0.674485514093659\n",
            "training error 0.11670617968508486, test error 0.22197313588460638\n",
            "Loss: 0.40056710592406564\n",
            "training error 0.11664390207483198, test error 0.22219772019249442\n",
            "Loss: 0.5021487310391537\n",
            "training error 0.11684480767066964, test error 0.22164736732189483\n",
            "Loss: 0.25321887699909507\n",
            "training error 0.1165344463009635, test error 0.22173831164980853\n",
            "Loss: 0.294353864173158\n",
            "training error 0.11681598952996243, test error 0.22147899271834512\n",
            "Loss: 0.17706143742759473\n",
            "training error 0.11667585064092012, test error 0.22199861058557444\n",
            "Loss: 0.41208955621452326\n",
            "training error 0.11662180574524038, test error 0.22153842938226662\n",
            "Loss: 0.20394520757762713\n",
            "training error 0.11693087270494208, test error 0.22199548230505584\n",
            "Loss: 0.4106746050904553\n",
            "training error 0.11653737699199719, test error 0.22275669893196515\n",
            "Loss: 0.7549801478651696\n",
            "training error 0.11657600325086101, test error 0.2227607996507399\n",
            "Loss: 0.75683494209009\n",
            "training error 0.11671379581103176, test error 0.22131550716850812\n",
            "Loss: 0.10311536349461026\n",
            "training error 0.1165968431908651, test error 0.2215300109216346\n",
            "Loss: 0.2001374575170356\n",
            "training error 0.11653409860933628, test error 0.22207471031369325\n",
            "Loss: 0.4465101892757506\n",
            "training error 0.11639732737688824, test error 0.2219106408005826\n",
            "Loss: 0.3722999831827778\n",
            "training error 0.11671831990046644, test error 0.22170913672778875\n",
            "Loss: 0.281157768598872\n",
            "training error 0.11653367936382493, test error 0.22142568951879907\n",
            "Loss: 0.15295189173119006\n",
            "training error 0.11636619239824023, test error 0.22075104556370667\n",
            "Loss: 0.0\n",
            "training error 0.11648996591579257, test error 0.22131962582139394\n",
            "Loss: 0.2575662807101864\n",
            "training error 0.11640859832795529, test error 0.2206546601066834\n",
            "Loss: 0.0\n",
            "training error 0.1162426731633265, test error 0.2210250428677635\n",
            "Loss: 0.1678563058224336\n",
            "training error 0.11628158441826561, test error 0.22137612299738743\n",
            "Loss: 0.32696471960085294\n",
            "training error 0.11628497673729624, test error 0.22122204376038837\n",
            "Loss: 0.25713649257652627\n",
            "training error 0.11622774926751551, test error 0.22130696974828123\n",
            "Loss: 0.2956246839665555\n",
            "training error 0.1162643383625486, test error 0.22159336744038075\n",
            "Loss: 0.4254192198993145\n",
            "training error 0.11634951445115758, test error 0.22127397648418293\n",
            "Loss: 0.28067224014218795\n",
            "training error 0.11641698514547898, test error 0.22160535049665636\n",
            "Loss: 0.43084990342525664\n",
            "training error 0.11641712376426148, test error 0.22176415799332466\n",
            "Loss: 0.5028209629041269\n",
            "training error 0.1162100533601544, test error 0.2221152980117984\n",
            "Loss: 0.661956518121487\n",
            "training error 0.11614846330694002, test error 0.22170720962237053\n",
            "Loss: 0.4770121397745575\n",
            "training error 0.11625218638916643, test error 0.2210798223522487\n",
            "Loss: 0.1926821964058023\n",
            "training error 0.11609037812154913, test error 0.22100300366628706\n",
            "Loss: 0.15786820882697228\n",
            "training error 0.11665684391105104, test error 0.22154678792353968\n",
            "Loss: 0.4043095289376408\n",
            "training error 0.11623051502011092, test error 0.2202886770037376\n",
            "Loss: 0.0\n",
            "training error 0.11621199031143337, test error 0.2209601113366559\n",
            "Loss: 0.30479747849541106\n",
            "training error 0.11674849549700721, test error 0.22053559008788676\n",
            "Loss: 0.11208614419384588\n",
            "training error 0.11622928344352994, test error 0.22143757767814426\n",
            "Loss: 0.521543226839194\n",
            "training error 0.11605159626774635, test error 0.22132756008151808\n",
            "Loss: 0.4716007612878048\n",
            "training error 0.11609470781476891, test error 0.2214792582642613\n",
            "Loss: 0.5404641204066474\n",
            "training error 0.11613970995358074, test error 0.2211151326710306\n",
            "Loss: 0.3751693816196333\n",
            "training error 0.11614074462244657, test error 0.22106306448452331\n",
            "Loss: 0.35153303897348387\n",
            "training error 0.11598390229528438, test error 0.2215551194089722\n",
            "Loss: 0.5749012715769775\n",
            "training error 0.11601271165025247, test error 0.22182152970516109\n",
            "Loss: 0.6958381712000028\n",
            "training error 0.11628923394349755, test error 0.22136781323826385\n",
            "Loss: 0.4898736735832854\n",
            "training error 0.11594671618539905, test error 0.22118350294611414\n",
            "Loss: 0.4062060540503065\n",
            "training error 0.11586634426712018, test error 0.2209430734796485\n",
            "Loss: 0.2970631467816176\n",
            "training error 0.11591760680880424, test error 0.22077951831096654\n",
            "Loss: 0.2228173113140164\n",
            "training error 0.11593306249414717, test error 0.22127919291875986\n",
            "Loss: 0.4496444976177516\n",
            "training error 0.11593732133560967, test error 0.22059184863314896\n",
            "Loss: 0.13762469934222032\n",
            "training error 0.11586762128829245, test error 0.220871459501074\n",
            "Loss: 0.264553995812733\n",
            "training error 0.11582326499668336, test error 0.220688743219661\n",
            "Loss: 0.18160997712861615\n",
            "training error 0.11585261763976137, test error 0.22022879322772046\n",
            "Loss: 0.0\n",
            "training error 0.11586047919596851, test error 0.21986487380725447\n",
            "Loss: 0.0\n",
            "training error 0.11582622855366322, test error 0.22035902659597814\n",
            "Loss: 0.22475294946697755\n",
            "training error 0.11577565519398514, test error 0.22074918542671293\n",
            "Loss: 0.4022068664927714\n",
            "training error 0.11568641825994087, test error 0.220486199093131\n",
            "Loss: 0.28259415663696164\n",
            "training error 0.1162671635140687, test error 0.22033203917245914\n",
            "Loss: 0.21247839962568182\n",
            "training error 0.1157217501029235, test error 0.22031622949892793\n",
            "Loss: 0.20528776782648972\n",
            "training error 0.11594544140545661, test error 0.2208886220513479\n",
            "Loss: 0.4656261031450226\n",
            "training error 0.11619483427166775, test error 0.22016858268054434\n",
            "Loss: 0.13813433134213238\n",
            "training error 0.11566819278432247, test error 0.2202819605002395\n",
            "Loss: 0.18970137692420064\n",
            "training error 0.11566173153414537, test error 0.2204477608156645\n",
            "Loss: 0.2651114742962646\n",
            "training error 0.1157707638913676, test error 0.22058367774751042\n",
            "Loss: 0.3269298673357346\n",
            "training error 0.11575910731306942, test error 0.22034251442257285\n",
            "Loss: 0.21724280329431522\n",
            "training error 0.11564447119495852, test error 0.22018053012382063\n",
            "Loss: 0.14356832498987337\n",
            "training error 0.11562545392022723, test error 0.22023304653633644\n",
            "Loss: 0.16745409246441412\n",
            "training error 0.11583221307362991, test error 0.22064773725021153\n",
            "Loss: 0.3560657186392424\n",
            "training error 0.11568963381171327, test error 0.22129604966078645\n",
            "Loss: 0.650934289206484\n",
            "training error 0.11643354391907937, test error 0.2220166916666595\n",
            "Loss: 0.9787001543918317\n",
            "training error 0.11555180497268752, test error 0.22126424906251776\n",
            "Loss: 0.6364705880622212\n",
            "training error 0.11563984773728628, test error 0.22082649284462466\n",
            "Loss: 0.43736819834767626\n",
            "training error 0.11550948138394201, test error 0.22078063432905065\n",
            "Loss: 0.41651060760119485\n",
            "training error 0.11591422664451667, test error 0.220754475949378\n",
            "Loss: 0.4046131274718201\n",
            "training error 0.11547562318035437, test error 0.22026461186302299\n",
            "Loss: 0.1818107862554541\n",
            "training error 0.11545792771544988, test error 0.22032731665004923\n",
            "Loss: 0.21033047925616\n",
            "training error 0.11555635301109969, test error 0.2205714918217697\n",
            "Loss: 0.3213874059458277\n",
            "training error 0.11556384102505132, test error 0.22101299114572964\n",
            "Loss: 0.5221922531753131\n",
            "training error 0.11577905139489043, test error 0.22143792738397608\n",
            "Loss: 0.7154637980510747\n",
            "training error 0.11545825593593573, test error 0.22080069436138144\n",
            "Loss: 0.4256344080443508\n",
            "training error 0.11571212712771234, test error 0.22141021560195992\n",
            "Loss: 0.7028597919921387\n",
            "training error 0.11540156990411712, test error 0.22114918321278917\n",
            "Loss: 0.5841357845367323\n",
            "training error 0.1154577969610945, test error 0.22092518044984946\n",
            "Loss: 0.48225376988799695\n",
            "training error 0.11528804496092368, test error 0.22037094502843044\n",
            "Loss: 0.23017374827214443\n",
            "training error 0.11528986395777614, test error 0.22055470908930286\n",
            "Loss: 0.3137542027987328\n",
            "training error 0.11530206040426462, test error 0.22011822782582346\n",
            "Loss: 0.11523169398632849\n",
            "training error 0.11528369305420134, test error 0.2201576579951867\n",
            "Loss: 0.1331655133729459\n",
            "training error 0.11535742140476395, test error 0.2196376350581557\n",
            "Loss: 0.0\n",
            "training error 0.1153189894601166, test error 0.21940474923433212\n",
            "Loss: 0.0\n",
            "training error 0.1153782355361923, test error 0.21986187619479117\n",
            "Loss: 0.2083487080632107\n",
            "training error 0.11580136367057527, test error 0.22040537286838255\n",
            "Loss: 0.4560628872175121\n",
            "training error 0.11578684784119105, test error 0.22094114418156768\n",
            "Loss: 0.7002560120495049\n",
            "training error 0.11523040522244904, test error 0.22087991505399043\n",
            "Loss: 0.6723490830559786\n",
            "training error 0.11543010184362543, test error 0.22029106383443042\n",
            "Loss: 0.4039632702534046\n",
            "training error 0.11533881099439458, test error 0.22011336059567882\n",
            "Loss: 0.3229699283263443\n",
            "training error 0.11526546543590359, test error 0.2206061318895434\n",
            "Loss: 0.5475645624827274\n",
            "training error 0.11563336254163606, test error 0.22081247850869046\n",
            "Loss: 0.6416129456043862\n",
            "training error 0.11534356268647081, test error 0.22024032547708536\n",
            "Loss: 0.3808378103341781\n",
            "training error 0.11530673697177986, test error 0.22022566561573845\n",
            "Loss: 0.37415615854767825\n",
            "training error 0.115114673407927, test error 0.22001606316799688\n",
            "Loss: 0.27862383827064185\n",
            "training error 0.11514174075442052, test error 0.22035633565799498\n",
            "Loss: 0.4337127737588542\n",
            "training error 0.11538083183367477, test error 0.2202992525507233\n",
            "Loss: 0.4076955122953141\n",
            "training error 0.11511177270761166, test error 0.21997853525930952\n",
            "Loss: 0.2615194187818526\n",
            "training error 0.1151552160669393, test error 0.2199887024172231\n",
            "Loss: 0.2661533922710513\n",
            "training error 0.11547310268647275, test error 0.22080196059602014\n",
            "Loss: 0.6368191055863281\n",
            "training error 0.11517277299645368, test error 0.22085832373197467\n",
            "Loss: 0.6625082194962273\n",
            "training error 0.11509706534804344, test error 0.22058586309513661\n",
            "Loss: 0.5383264787687025\n",
            "training error 0.11511857029413211, test error 0.22023019761554227\n",
            "Loss: 0.3762217472915941\n",
            "training error 0.11503688833467543, test error 0.21989714486366543\n",
            "Loss: 0.22442341428416945\n",
            "training error 0.11498441756961866, test error 0.22008022067649002\n",
            "Loss: 0.3078654607592268\n",
            "training error 0.11509252167567588, test error 0.21998873419309783\n",
            "Loss: 0.2661678750362828\n",
            "training error 0.11501144812224696, test error 0.22010106544262925\n",
            "Loss: 0.3173660600908068\n",
            "training error 0.11513599824493459, test error 0.22073083340581273\n",
            "Loss: 0.604400850988096\n",
            "training error 0.11520763342394305, test error 0.22085944397730484\n",
            "Loss: 0.6630188033983853\n",
            "training error 0.11508424158809345, test error 0.2197481467847896\n",
            "Loss: 0.1565132713197137\n",
            "training error 0.11494280532957078, test error 0.21978152733706172\n",
            "Loss: 0.17172741430824257\n",
            "training error 0.11517217266529801, test error 0.2193920833103196\n",
            "Loss: 0.0\n",
            "training error 0.11482609967684154, test error 0.21979240731162317\n",
            "Loss: 0.1824696658435654\n",
            "training error 0.11503226272650958, test error 0.21951929219193472\n",
            "Loss: 0.05798243933679004\n",
            "training error 0.1149602027907718, test error 0.22049935146634717\n",
            "Loss: 0.5046983187909193\n",
            "training error 0.11488150303134406, test error 0.21983630338208818\n",
            "Loss: 0.20247771253452118\n",
            "training error 0.11490857463987549, test error 0.2199576015160515\n",
            "Loss: 0.2577660037677898\n",
            "training error 0.11485781847382666, test error 0.22013898351753705\n",
            "Loss: 0.34044081990005637\n",
            "training error 0.11481974711853858, test error 0.21986796716136645\n",
            "Loss: 0.21691022021690376\n",
            "training error 0.11481742041675475, test error 0.21979924572463502\n",
            "Loss: 0.1855866484204549\n",
            "training error 0.11487090947052651, test error 0.21999045407788734\n",
            "Loss: 0.27274036443756255\n",
            "training error 0.1148361699927409, test error 0.22006869317996278\n",
            "Loss: 0.30840213531595495\n",
            "training error 0.11497678086153446, test error 0.21924838847316702\n",
            "Loss: 0.0\n",
            "training error 0.11484948591560662, test error 0.21963945497706994\n",
            "Loss: 0.1783668772328495\n",
            "training error 0.11499905231853375, test error 0.21968950555030106\n",
            "Loss: 0.20119512859635424\n",
            "training error 0.11470334533767138, test error 0.22018292884576646\n",
            "Loss: 0.4262473166199765\n",
            "training error 0.11479055501880982, test error 0.2201996868107019\n",
            "Loss: 0.4338906863396552\n",
            "training error 0.1146893520935786, test error 0.21975010899401598\n",
            "Loss: 0.22883658317531808\n",
            "training error 0.1147719598488458, test error 0.2198313404799333\n",
            "Loss: 0.26588656401349553\n",
            "training error 0.11466913935287978, test error 0.21970109102733557\n",
            "Loss: 0.20647930747457188\n",
            "training error 0.11475009964404047, test error 0.21996640950088672\n",
            "Loss: 0.3274920434854556\n",
            "training error 0.11488767228410413, test error 0.21937704433358243\n",
            "Loss: 0.05868041325702844\n",
            "training error 0.11488808273968823, test error 0.21883170869629626\n",
            "Loss: 0.0\n",
            "training error 0.11465333324487739, test error 0.218940220980855\n",
            "Loss: 0.049587093755842915\n",
            "training error 0.11476378428957815, test error 0.21879915789479681\n",
            "Loss: 0.0\n",
            "training error 0.11468902033078995, test error 0.2187945813122716\n",
            "Loss: 0.0\n",
            "training error 0.114849071778728, test error 0.21897464179976409\n",
            "Loss: 0.08229659364162867\n",
            "training error 0.11468109582448223, test error 0.2192183251501221\n",
            "Loss: 0.19367199832325266\n",
            "training error 0.11478646212137752, test error 0.219033455221366\n",
            "Loss: 0.10917725094545805\n",
            "training error 0.11458801354165284, test error 0.21924565143516545\n",
            "Loss: 0.20616146898539967\n",
            "training error 0.11459907674262909, test error 0.21985884769498373\n",
            "Loss: 0.4864226418812345\n",
            "training error 0.11461115503476214, test error 0.21948736194174262\n",
            "Loss: 0.31663518598856744\n",
            "training error 0.11456553017293526, test error 0.21972090453726925\n",
            "Loss: 0.4233757616124656\n",
            "training error 0.11456844608913153, test error 0.2200855556216002\n",
            "Loss: 0.5900394340598636\n",
            "training error 0.11458250259364873, test error 0.21981327128089362\n",
            "Loss: 0.465591955025646\n",
            "training error 0.11451662301575075, test error 0.21972023218892467\n",
            "Loss: 0.42306846499635675\n",
            "training error 0.11452313358317394, test error 0.21994039925275272\n",
            "Loss: 0.5236957577325674\n",
            "training error 0.1145295507142536, test error 0.21996745891337724\n",
            "Loss: 0.5360633677813365\n",
            "training error 0.11457383931314274, test error 0.22037324937020247\n",
            "Loss: 0.7215297785084118\n",
            "training error 0.1145686193720196, test error 0.22049315652285104\n",
            "Loss: 0.7763333078871559\n",
            "training error 0.11460356823859041, test error 0.21999614379537333\n",
            "Loss: 0.5491737847871159\n",
            "training error 0.11454487296598415, test error 0.21979999507607478\n",
            "Loss: 0.45952406945957147\n",
            "training error 0.11450681450965987, test error 0.2197290888178578\n",
            "Loss: 0.427116384684334\n",
            "training error 0.11448210360776988, test error 0.21953160666512525\n",
            "Loss: 0.33685722399208196\n",
            "training error 0.11440487561069247, test error 0.21959622211053428\n",
            "Loss: 0.36638969459601434\n",
            "training error 0.11445571863364927, test error 0.21927565215692849\n",
            "Loss: 0.2198732901754319\n",
            "training error 0.11448652876176371, test error 0.21919709104169685\n",
            "Loss: 0.18396695521940565\n",
            "training error 0.11444392604893332, test error 0.2193187553702411\n",
            "Loss: 0.23957360133217698\n",
            "training error 0.1144250847470766, test error 0.21888995339903222\n",
            "Loss: 0.04358978462291052\n",
            "training error 0.11461381283173763, test error 0.21897024066188542\n",
            "Loss: 0.08028505484927173\n",
            "training error 0.114458430758849, test error 0.21852193659168176\n",
            "Loss: 0.0\n",
            "training error 0.11443033516952626, test error 0.21886116159547167\n",
            "Loss: 0.15523613284820215\n",
            "training error 0.11443652846063383, test error 0.2189401539530309\n",
            "Loss: 0.1913846123973384\n",
            "training error 0.11443874245542449, test error 0.2193803977128884\n",
            "Loss: 0.3928489444108729\n",
            "training error 0.11432717853765051, test error 0.21932649256355854\n",
            "Loss: 0.3681808721017088\n",
            "training error 0.11440349050828924, test error 0.21968964311158592\n",
            "Loss: 0.5343658115597227\n",
            "training error 0.11424664100526562, test error 0.21926821576053027\n",
            "Loss: 0.3415122437995688\n",
            "training error 0.11441321742849803, test error 0.21907468836109875\n",
            "Loss: 0.25295024290847845\n",
            "training error 0.11430308788070577, test error 0.21857844650831523\n",
            "Loss: 0.02586006581988265\n",
            "training error 0.11444004766140303, test error 0.21864602994092305\n",
            "Loss: 0.05678759358296315\n",
            "training error 0.11426201186267564, test error 0.21885939895459738\n",
            "Loss: 0.15442951320085996\n",
            "training error 0.11428372783112992, test error 0.21896288607486136\n",
            "Loss: 0.20178728509236965\n",
            "training error 0.11428353435539514, test error 0.21909438701422526\n",
            "Loss: 0.2619647397749114\n",
            "training error 0.11425881199732835, test error 0.21913518581311364\n",
            "Loss: 0.2806350845122596\n",
            "training error 0.11430438354910355, test error 0.21875190648662288\n",
            "Loss: 0.10523881424813197\n",
            "training error 0.11415383042334346, test error 0.21910587726460884\n",
            "Loss: 0.26722290770202495\n",
            "training error 0.11426075397439757, test error 0.21866239487439443\n",
            "Loss: 0.06427651379234955\n",
            "training error 0.11419236218165542, test error 0.21870508058585847\n",
            "Loss: 0.08381034738811355\n",
            "training error 0.11414883441844859, test error 0.21860744027447618\n",
            "Loss: 0.039128191946313784\n",
            "training error 0.11417901187305868, test error 0.21844537817941007\n",
            "Loss: 0.0\n",
            "training error 0.11409857238818066, test error 0.21851566889442114\n",
            "Loss: 0.03217770757930616\n",
            "training error 0.11409276862355748, test error 0.21856116829032549\n",
            "Loss: 0.053006436611502394\n",
            "training error 0.11419821825682215, test error 0.2187885972645479\n",
            "Loss: 0.15711895028329703\n",
            "training error 0.11425507382295991, test error 0.2190724949380724\n",
            "Loss: 0.28708172445162106\n",
            "training error 0.11405534931372632, test error 0.2186908816559602\n",
            "Loss: 0.11238666553452514\n",
            "training error 0.11408627309330417, test error 0.2186741722582268\n",
            "Loss: 0.10473743172025873\n",
            "training error 0.11419313474631637, test error 0.21885461155144884\n",
            "Loss: 0.18733899313845281\n",
            "training error 0.1139732374779932, test error 0.21879397776283818\n",
            "Loss: 0.15958203663242188\n",
            "training error 0.11414604655486867, test error 0.21880213629254028\n",
            "Loss: 0.16331685115222871\n",
            "training error 0.11405938242135086, test error 0.21899925145982915\n",
            "Loss: 0.2535522999091322\n",
            "training error 0.11419324640489116, test error 0.21933862952055494\n",
            "Loss: 0.4089129047222251\n",
            "training error 0.11399156497737843, test error 0.21920817884287136\n",
            "Loss: 0.34919514883706704\n",
            "training error 0.11396044741245367, test error 0.21915407002946682\n",
            "Loss: 0.3244251977145174\n",
            "training error 0.11404691444846278, test error 0.21883232384070733\n",
            "Loss: 0.17713611728578105\n",
            "training error 0.11405681606228679, test error 0.2187862472004491\n",
            "Loss: 0.1560431371356641\n",
            "training error 0.11399219813647661, test error 0.21868119838789382\n",
            "Loss: 0.10795385576438665\n",
            "training error 0.1139022080602267, test error 0.2188843678120941\n",
            "Loss: 0.20096082432263795\n",
            "training error 0.11402655356203961, test error 0.21914103453578596\n",
            "Loss: 0.3184578049550524\n",
            "training error 0.11396541158163065, test error 0.2187774723262965\n",
            "Loss: 0.1520261722423255\n",
            "training error 0.11402920368410834, test error 0.21881398427991092\n",
            "Loss: 0.1687406268665148\n",
            "training error 0.11388827790402323, test error 0.21887222860563255\n",
            "Loss: 0.19540373423323487\n",
            "training error 0.1139220899591435, test error 0.21865407053066582\n",
            "Loss: 0.09553525599628188\n",
            "training error 0.11403355092053927, test error 0.21874887188840547\n",
            "Loss: 0.13893345399422774\n",
            "training error 0.11416925148820839, test error 0.218767531723612\n",
            "Loss: 0.14747555974259363\n",
            "training error 0.11384000713274954, test error 0.21883236011256893\n",
            "Loss: 0.17715272183100872\n",
            "training error 0.11383470165943779, test error 0.21865953992888126\n",
            "Loss: 0.09803903898359945\n",
            "training error 0.11405404732071046, test error 0.21829524181359045\n",
            "Loss: 0.0\n",
            "training error 0.11389257900437094, test error 0.21810392935401185\n",
            "Loss: 0.0\n",
            "training error 0.11384330631703424, test error 0.21803328396601468\n",
            "Loss: 0.0\n",
            "training error 0.11378297922888254, test error 0.21825493441915603\n",
            "Loss: 0.10165899862146777\n",
            "training error 0.1137860147949945, test error 0.21811487219806988\n",
            "Loss: 0.03742008126974561\n",
            "training error 0.11378229506923462, test error 0.21800485618625742\n",
            "Loss: 0.0\n",
            "training error 0.1140665370078393, test error 0.21783665168455768\n",
            "Loss: 0.0\n",
            "training error 0.11380091191447413, test error 0.21820836687455877\n",
            "Loss: 0.1706394158772495\n",
            "training error 0.11374790159010856, test error 0.21838171823095956\n",
            "Loss: 0.25021801528199994\n",
            "training error 0.11373019207179692, test error 0.2182503096920259\n",
            "Loss: 0.18989366769519567\n",
            "training error 0.11371476495920706, test error 0.21814198255209136\n",
            "Loss: 0.14016505724474548\n",
            "training error 0.113687714446169, test error 0.2182925937686874\n",
            "Loss: 0.20930457781271894\n",
            "training error 0.11371386001427176, test error 0.2185238201282069\n",
            "Loss: 0.31545125135521435\n",
            "training error 0.11404042231511614, test error 0.2183688093683954\n",
            "Loss: 0.24429207836351718\n",
            "training error 0.1136649456231, test error 0.21886876609192307\n",
            "Loss: 0.47380199768216613\n",
            "training error 0.11368722099597742, test error 0.21839035360201953\n",
            "Loss: 0.25418216502135493\n",
            "training error 0.11374155201526599, test error 0.21844011160342502\n",
            "Loss: 0.27702405182998824\n",
            "training error 0.11358794987976085, test error 0.2182185277010682\n",
            "Loss: 0.17530384054171844\n",
            "training error 0.11361397914393169, test error 0.21825076929402884\n",
            "Loss: 0.1901046523937744\n",
            "training error 0.11364440264647073, test error 0.21811584548611965\n",
            "Loss: 0.12816658693701743\n",
            "training error 0.11372419447472439, test error 0.21811088188308858\n",
            "Loss: 0.12588799745600898\n",
            "training error 0.11356978527237431, test error 0.2180098328523966\n",
            "Loss: 0.07950047271645388\n",
            "training error 0.11353700002365776, test error 0.21803465935674696\n",
            "Loss: 0.09089731716773741\n",
            "training error 0.11351373308394154, test error 0.21800010890489432\n",
            "Loss: 0.07503660154184466\n",
            "training error 0.11361381186643287, test error 0.21835676603473458\n",
            "Loss: 0.23876347077260718\n",
            "training error 0.11366282282162832, test error 0.21823069734279552\n",
            "Loss: 0.18089043105953273\n",
            "training error 0.11358234318803861, test error 0.21810338838153617\n",
            "Loss: 0.12244803384360292\n",
            "training error 0.11352501156233344, test error 0.2179907797764182\n",
            "Loss: 0.0707539758202369\n",
            "training error 0.1135324003494175, test error 0.21803827740877235\n",
            "Loss: 0.09255821858051849\n",
            "training error 0.11350352627052883, test error 0.21826394420814918\n",
            "Loss: 0.19615272282564877\n",
            "training error 0.11362744960975069, test error 0.21824407105701327\n",
            "Loss: 0.18702976257896076\n",
            "training error 0.11346028658440147, test error 0.21858880479199855\n",
            "Loss: 0.34528308327563817\n",
            "training error 0.11354016254245265, test error 0.2182174722564964\n",
            "Loss: 0.17481932860874405\n",
            "training error 0.11355195917055554, test error 0.2179947186888502\n",
            "Loss: 0.07256217127382669\n",
            "training error 0.11355927954798774, test error 0.2180689205767855\n",
            "Loss: 0.1066252581609417\n",
            "training error 0.11338513908265042, test error 0.2181381800026079\n",
            "Loss: 0.13841946050789922\n",
            "training error 0.11349592771517975, test error 0.21793751219775614\n",
            "Loss: 0.04630098397973015\n",
            "training error 0.11343060230945341, test error 0.21833293242672416\n",
            "Loss: 0.22782242488978977\n",
            "training error 0.11335680874125907, test error 0.2184805521306353\n",
            "Loss: 0.295588662926205\n",
            "training error 0.11347683830924314, test error 0.21853316594201283\n",
            "Loss: 0.31974153663716365\n",
            "training error 0.1134329979176469, test error 0.21848682269281883\n",
            "Loss: 0.2984672245158526\n",
            "training error 0.11350226674327747, test error 0.21843518819213897\n",
            "Loss: 0.27476391275422785\n",
            "training error 0.11330780201681567, test error 0.21843609929034186\n",
            "Loss: 0.27518216110493654\n",
            "training error 0.11335951943590224, test error 0.2185116396974168\n",
            "Loss: 0.30985970801487017\n",
            "training error 0.11350824135466954, test error 0.21867026841351847\n",
            "Loss: 0.3826797384711478\n",
            "training error 0.11333453260318437, test error 0.21808117473613145\n",
            "Loss: 0.11225064730056022\n",
            "training error 0.11323879096720982, test error 0.21826367202499333\n",
            "Loss: 0.19602777454272857\n",
            "training error 0.11328709815111342, test error 0.2179220201187775\n",
            "Loss: 0.03918919684069433\n",
            "training error 0.113223998370471, test error 0.21785459638999802\n",
            "Loss: 0.008237688791834508\n",
            "training error 0.11322334132051654, test error 0.2177670358198674\n",
            "Loss: 0.0\n",
            "training error 0.11322462186312084, test error 0.21754883328469712\n",
            "Loss: 0.0\n",
            "training error 0.11318388794809237, test error 0.21760132188827952\n",
            "Loss: 0.02412727422616001\n",
            "training error 0.11314513759380074, test error 0.217521662096692\n",
            "Loss: 0.0\n",
            "training error 0.1131521315783001, test error 0.21769634454061923\n",
            "Loss: 0.08030576920177168\n",
            "training error 0.11308356360216476, test error 0.21766902545675776\n",
            "Loss: 0.067746521723544\n",
            "training error 0.11322029054809414, test error 0.2176398235557738\n",
            "Loss: 0.05432169740835491\n",
            "training error 0.11307454143207997, test error 0.21758532863017743\n",
            "Loss: 0.02926905434232907\n",
            "training error 0.11324019745760265, test error 0.21810940994690814\n",
            "Loss: 0.2702019856555271\n",
            "training error 0.11315024123164193, test error 0.21771699040865988\n",
            "Loss: 0.08979717701911305\n",
            "training error 0.1131953399696507, test error 0.2171893214353469\n",
            "Loss: 0.0\n",
            "training error 0.11307960513959768, test error 0.21738634930356548\n",
            "Loss: 0.09071710658539178\n",
            "training error 0.11311664828236044, test error 0.2175093295178768\n",
            "Loss: 0.14734061528212106\n",
            "training error 0.11302135640719214, test error 0.21755266483051772\n",
            "Loss: 0.1672933976539781\n",
            "training error 0.11316741596385124, test error 0.21765118337802275\n",
            "Loss: 0.21265407508230805\n",
            "training error 0.11296465064595268, test error 0.21730334838130946\n",
            "Loss: 0.05250117510797736\n",
            "training error 0.11299116498771167, test error 0.21775696623437704\n",
            "Loss: 0.2613594422040455\n",
            "training error 0.11300400553957075, test error 0.21788396388690717\n",
            "Loss: 0.31983269111464097\n",
            "training error 0.11295509961057144, test error 0.21798781602701672\n",
            "Loss: 0.36764910281628094\n",
            "training error 0.11286847703988544, test error 0.2176952365557396\n",
            "Loss: 0.23293738248697515\n",
            "training error 0.11289948081596779, test error 0.21755217906023233\n",
            "Loss: 0.1670697355134365\n",
            "training error 0.11315889302692948, test error 0.21788168177891756\n",
            "Loss: 0.3187819451688778\n",
            "training error 0.11285198001616542, test error 0.21781305170119042\n",
            "Loss: 0.2871827499259405\n",
            "training error 0.1128936405271967, test error 0.21772301426366375\n",
            "Loss: 0.24572701124982999\n",
            "training error 0.11283486406870817, test error 0.21739565053223936\n",
            "Loss: 0.09499965077881534\n",
            "training error 0.11276528085868333, test error 0.21761409274441848\n",
            "Loss: 0.19557651649924068\n",
            "training error 0.11274206866021332, test error 0.21757047037650334\n",
            "Loss: 0.1754915659009093\n",
            "training error 0.11278737630170041, test error 0.21736714448893804\n",
            "Loss: 0.08187467616547206\n",
            "training error 0.1127716084642037, test error 0.21757028712764498\n",
            "Loss: 0.17540719303343888\n",
            "training error 0.11267991561144759, test error 0.2173622388449466\n",
            "Loss: 0.07961598132768533\n",
            "training error 0.11266652961275074, test error 0.21738534947007487\n",
            "Loss: 0.09025675545761835\n",
            "training error 0.11267831421051575, test error 0.2174129615886469\n",
            "Loss: 0.10297014228048962\n",
            "training error 0.11264805837387148, test error 0.21748136183538216\n",
            "Loss: 0.1344635169469921\n",
            "training error 0.11263002271537645, test error 0.21710181993070846\n",
            "Loss: 0.0\n",
            "training error 0.11267710432007001, test error 0.21687290308111393\n",
            "Loss: 0.0\n",
            "training error 0.11257054995591936, test error 0.2169252462328955\n",
            "Loss: 0.0241354042104458\n",
            "training error 0.11262709873214576, test error 0.21718802554628341\n",
            "Loss: 0.14530282976459308\n",
            "training error 0.11252930762929288, test error 0.21724487220359795\n",
            "Loss: 0.17151479839088157\n",
            "training error 0.11266514357339964, test error 0.21702812511711167\n",
            "Loss: 0.07157281236729318\n",
            "training error 0.11244766188606625, test error 0.21716404898616146\n",
            "Loss: 0.1342472484626711\n",
            "training error 0.11245477529747398, test error 0.21698182311165837\n",
            "Loss: 0.05022297806549503\n",
            "training error 0.11250486441565001, test error 0.21721859357653808\n",
            "Loss: 0.15939773503879096\n",
            "training error 0.11240089651586352, test error 0.2170590928810524\n",
            "Loss: 0.08585203466791036\n",
            "training error 0.11237715652502935, test error 0.21694525474543025\n",
            "Loss: 0.033361320519254\n",
            "training error 0.11231965745622473, test error 0.2166071898221426\n",
            "Loss: 0.0\n",
            "training error 0.1123052612328463, test error 0.21623180118714747\n",
            "Loss: 0.0\n",
            "training error 0.11229823649403185, test error 0.21633823785371076\n",
            "Loss: 0.04922341023796406\n",
            "training error 0.11240537141067292, test error 0.21643681796877948\n",
            "Loss: 0.09481342730646158\n",
            "training error 0.11219063608058034, test error 0.2164047669488898\n",
            "Loss: 0.07999089902259726\n",
            "training error 0.11218900725063255, test error 0.2163741984723912\n",
            "Loss: 0.06585399763676669\n",
            "training error 0.11211405002363092, test error 0.21632006589224925\n",
            "Loss: 0.04081948382115286\n",
            "training error 0.11216539439393346, test error 0.21632369495363704\n",
            "Loss: 0.042497803738883455\n",
            "training error 0.1121260793567595, test error 0.21662714615584439\n",
            "Loss: 0.18283386926734035\n",
            "training error 0.1120336937918952, test error 0.21659675746466753\n",
            "Loss: 0.16878011259970904\n",
            "training error 0.11203123102278764, test error 0.21628431007519833\n",
            "Loss: 0.024283610348985185\n",
            "training error 0.11202512026586726, test error 0.21599777452399618\n",
            "Loss: 0.0\n",
            "training error 0.11210886614970525, test error 0.21608364556090787\n",
            "Loss: 0.039755519287609786\n",
            "training error 0.11203629493301637, test error 0.21611045809512008\n",
            "Loss: 0.05216885746726074\n",
            "training error 0.11205381121411373, test error 0.2160787354680836\n",
            "Loss: 0.037482304744029804\n",
            "training error 0.11188411037014748, test error 0.2162575998840599\n",
            "Loss: 0.12029075791928356\n",
            "training error 0.11182511795946094, test error 0.21615861043703813\n",
            "Loss: 0.07446183804271644\n",
            "training error 0.11180130015825683, test error 0.21619032565411087\n",
            "Loss: 0.08914496019183371\n",
            "training error 0.11179105300792182, test error 0.21641858585997226\n",
            "Loss: 0.19482207022893938\n",
            "training error 0.11179866577014189, test error 0.2159306837750479\n",
            "Loss: 0.0\n",
            "training error 0.1117341255740024, test error 0.21589529572273922\n",
            "Loss: 0.0\n",
            "training error 0.11169476990655046, test error 0.21588197621919175\n",
            "Loss: 0.0\n",
            "training error 0.11173217485453446, test error 0.21582342927675474\n",
            "Loss: 0.0\n",
            "training error 0.11166109604545708, test error 0.21553491659299634\n",
            "Loss: 0.0\n",
            "training error 0.11159939728053708, test error 0.21544976161389998\n",
            "Loss: 0.0\n",
            "training error 0.11161624415413317, test error 0.21527849727086076\n",
            "Loss: 0.0\n",
            "training error 0.11152292841743003, test error 0.21527981236503974\n",
            "Loss: 0.0006108804156745862\n",
            "training error 0.1114984645916491, test error 0.2151639078207218\n",
            "Loss: 0.0\n",
            "training error 0.1115544379659386, test error 0.21519484735119981\n",
            "Loss: 0.014379516895446365\n",
            "training error 0.1114560240561899, test error 0.21497505968331693\n",
            "Loss: 0.0\n",
            "training error 0.11155907553052816, test error 0.2150990359728774\n",
            "Loss: 0.057670080307503646\n",
            "training error 0.11142319867010067, test error 0.21510692532786105\n",
            "Loss: 0.06133997345476594\n",
            "training error 0.11137315135263821, test error 0.21491799072946796\n",
            "Loss: 0.0\n",
            "training error 0.11125365426338694, test error 0.21507084790583836\n",
            "Loss: 0.07112349033766563\n",
            "training error 0.111359050048596, test error 0.2151386303818435\n",
            "Loss: 0.10266225346080571\n",
            "training error 0.1111783270034244, test error 0.2150031771467107\n",
            "Loss: 0.03963670838051936\n",
            "training error 0.11121713226257286, test error 0.2151183849111587\n",
            "Loss: 0.09324216228272508\n",
            "training error 0.11104777031483651, test error 0.21497107718932812\n",
            "Loss: 0.024700798513865863\n",
            "training error 0.11104709007353791, test error 0.21478708085894696\n",
            "Loss: 0.0\n",
            "training error 0.11114588870930772, test error 0.21480503741877194\n",
            "Loss: 0.008360167545062858\n",
            "training error 0.11112252311465227, test error 0.21436036187047855\n",
            "Loss: 0.0\n",
            "training error 0.11101404257924402, test error 0.21456456415661435\n",
            "Loss: 0.09526121543832478\n",
            "training error 0.11084308483161269, test error 0.21447143448349085\n",
            "Loss: 0.051815835746449324\n",
            "training error 0.11079636787244869, test error 0.21433442808394995\n",
            "Loss: 0.0\n",
            "training error 0.11075198756201063, test error 0.21440805200266466\n",
            "Loss: 0.03435001990714781\n",
            "training error 0.11072517303414302, test error 0.2142132340792772\n",
            "Loss: 0.0\n",
            "training error 0.11067707567816829, test error 0.21418049850593118\n",
            "Loss: 0.0\n",
            "training error 0.11065634580030986, test error 0.21424510364793067\n",
            "Loss: 0.03016387694032563\n",
            "training error 0.11064945179691359, test error 0.21413191178805724\n",
            "Loss: 0.0\n",
            "training error 0.1105241031196388, test error 0.21387705264932494\n",
            "Loss: 0.0\n",
            "training error 0.11052279309378842, test error 0.21373475958861748\n",
            "Loss: 0.0\n",
            "training error 0.11060554954955033, test error 0.21385468946010014\n",
            "Loss: 0.05611154297666676\n",
            "training error 0.11054387259956999, test error 0.21380685063103472\n",
            "Loss: 0.03372920836834936\n",
            "training error 0.11040567362473966, test error 0.21360554670205215\n",
            "Loss: 0.0\n",
            "training error 0.11033792425277561, test error 0.21356711252662597\n",
            "Loss: 0.0\n",
            "training error 0.11036086766776922, test error 0.21337345856733647\n",
            "Loss: 0.0\n",
            "training error 0.11028376917159015, test error 0.21328206692035243\n",
            "Loss: 0.0\n",
            "training error 0.1103020693717143, test error 0.2133838897511434\n",
            "Loss: 0.04774092461743429\n",
            "training error 0.11015594518213606, test error 0.21342567296659543\n",
            "Loss: 0.06733151470097454\n",
            "training error 0.11022319961938427, test error 0.2135850615417923\n",
            "Loss: 0.14206286811400126\n",
            "training error 0.1102036965644931, test error 0.21352187094448397\n",
            "Loss: 0.11243515575132257\n",
            "training error 0.1100454817062764, test error 0.21357265627447644\n",
            "Loss: 0.13624650132095795\n",
            "training error 0.11014567991218255, test error 0.21363366620622642\n",
            "Loss: 0.1648517810010297\n",
            "training error 0.10984671057450926, test error 0.21366120792957066\n",
            "Loss: 0.17776506702733563\n",
            "training error 0.10984709486348103, test error 0.21311831638763468\n",
            "Loss: 0.0\n",
            "training error 0.10978419374298685, test error 0.21310398264345187\n",
            "Loss: 0.0\n",
            "training error 0.10962932695778423, test error 0.2132357123422325\n",
            "Loss: 0.06181475219120269\n",
            "training error 0.10959273089721172, test error 0.21311758994627558\n",
            "Loss: 0.006385287902599401\n",
            "training error 0.10958212061846202, test error 0.21299373005478697\n",
            "Loss: 0.0\n",
            "training error 0.10949734277281221, test error 0.2127604167356712\n",
            "Loss: 0.0\n",
            "training error 0.10945894251296834, test error 0.212711947779039\n",
            "Loss: 0.0\n",
            "training error 0.10939466199467941, test error 0.21244014728585453\n",
            "Loss: 0.0\n",
            "training error 0.10924407387571879, test error 0.2123664490558995\n",
            "Loss: 0.0\n",
            "training error 0.10925931806085003, test error 0.21255115941313577\n",
            "Loss: 0.08697718404080401\n",
            "training error 0.10909586549629999, test error 0.21250437220729454\n",
            "Loss: 0.06494582925324899\n",
            "training error 0.10905001023304328, test error 0.21247140669147785\n",
            "Loss: 0.049422889559513905\n",
            "training error 0.10907988581959337, test error 0.21255420613333176\n",
            "Loss: 0.08841183636443262\n",
            "training error 0.10888135550004062, test error 0.21221787503227546\n",
            "Loss: 0.0\n",
            "training error 0.10884881083291367, test error 0.21189091876675148\n",
            "Loss: 0.0\n",
            "training error 0.10875752969539612, test error 0.21193900029698567\n",
            "Loss: 0.02269164271599955\n",
            "training error 0.10872156196129455, test error 0.21192177223003275\n",
            "Loss: 0.014561012553460095\n",
            "training error 0.10864335198889208, test error 0.21186782189449332\n",
            "Loss: 0.0\n",
            "training error 0.10892452066724388, test error 0.2114073517453665\n",
            "Loss: 0.0\n",
            "training error 0.10854966462891993, test error 0.21160491960494301\n",
            "Loss: 0.09345363722945699\n",
            "training error 0.1084204035284643, test error 0.21142976364781924\n",
            "Loss: 0.0106012881140094\n",
            "training error 0.10825251852544301, test error 0.21147939231083498\n",
            "Loss: 0.034076660472637244\n",
            "training error 0.10821809563460248, test error 0.2114530814343108\n",
            "Loss: 0.021631077900896578\n",
            "training error 0.10827307262099309, test error 0.21113709145173387\n",
            "Loss: 0.0\n",
            "training error 0.10809063882139329, test error 0.21120745216149764\n",
            "Loss: 0.03332465616532332\n",
            "training error 0.1080375919307232, test error 0.21118839670585424\n",
            "Loss: 0.024299498381652462\n",
            "training error 0.10810522032191915, test error 0.21161202896282383\n",
            "Loss: 0.22494271746589245\n",
            "training error 0.10804229159362894, test error 0.21167695337989922\n",
            "Loss: 0.2556926044843033\n",
            "training error 0.10791971143931826, test error 0.21160262636069568\n",
            "Loss: 0.22048940134624662\n",
            "training error 0.10769635124630143, test error 0.21087511106059464\n",
            "Loss: 0.0\n",
            "training error 0.1075739830463623, test error 0.21077510807426483\n",
            "Loss: 0.0\n",
            "training error 0.10741444327121848, test error 0.21013319943262868\n",
            "Loss: 0.0\n",
            "training error 0.10744381678016768, test error 0.21019821768436728\n",
            "Loss: 0.03094144662250109\n",
            "training error 0.10722631678117715, test error 0.2099242876737527\n",
            "Loss: 0.0\n",
            "training error 0.1072061146189677, test error 0.20986253896340207\n",
            "Loss: 0.0\n",
            "training error 0.10713109078273135, test error 0.2101339346201785\n",
            "Loss: 0.12932067729523045\n",
            "training error 0.10695318721830432, test error 0.2096367526426447\n",
            "Loss: 0.0\n",
            "training error 0.10692769402779165, test error 0.20979036964174622\n",
            "Loss: 0.07327770401184264\n",
            "training error 0.1068567890352889, test error 0.2094503548562217\n",
            "Loss: 0.0\n",
            "training error 0.1067223534526055, test error 0.20917450356758716\n",
            "Loss: 0.0\n",
            "training error 0.1066733975335191, test error 0.20908839025083298\n",
            "Loss: 0.0\n",
            "training error 0.10671802136819467, test error 0.20890681666873923\n",
            "Loss: 0.0\n",
            "training error 0.10654265090548562, test error 0.2087275111137908\n",
            "Loss: 0.0\n",
            "training error 0.10658216857524688, test error 0.2086857022075999\n",
            "Loss: 0.0\n",
            "training error 0.10631495982224401, test error 0.20868725632542853\n",
            "Loss: 0.0007447169653618246\n",
            "training error 0.10620744282971863, test error 0.2082139224842431\n",
            "Loss: 0.0\n",
            "training error 0.10606997692431666, test error 0.20828325499370817\n",
            "Loss: 0.03329869042272282\n",
            "training error 0.1060213879164554, test error 0.20794576119106403\n",
            "Loss: 0.0\n",
            "training error 0.10589236015519343, test error 0.20816938775619953\n",
            "Loss: 0.10754081441939345\n",
            "training error 0.10581609562344661, test error 0.20790277224488105\n",
            "Loss: 0.0\n",
            "training error 0.10571926290528444, test error 0.20750955891002854\n",
            "Loss: 0.0\n",
            "training error 0.10557086152876119, test error 0.20741050148014742\n",
            "Loss: 0.0\n",
            "training error 0.1056844520621164, test error 0.2077973403189353\n",
            "Loss: 0.18650880067656583\n",
            "training error 0.10548090828838316, test error 0.20712525918178773\n",
            "Loss: 0.0\n",
            "training error 0.10524815970995073, test error 0.20717153889932702\n",
            "Loss: 0.022343830840387824\n",
            "training error 0.1051923988373644, test error 0.20694811447658523\n",
            "Loss: 0.0\n",
            "training error 0.10503298576114138, test error 0.20671226882818722\n",
            "Loss: 0.0\n",
            "training error 0.10496080198432729, test error 0.20651904337401766\n",
            "Loss: 0.0\n",
            "training error 0.10488659502869757, test error 0.2062366396660786\n",
            "Loss: 0.0\n",
            "training error 0.10476489150875243, test error 0.20605865041270843\n",
            "Loss: 0.0\n",
            "training error 0.10470877352075125, test error 0.2063543157923778\n",
            "Loss: 0.14348603132030568\n",
            "training error 0.10461997211701976, test error 0.20588957544313516\n",
            "Loss: 0.0\n",
            "training error 0.10454522767605948, test error 0.20567375587996245\n",
            "Loss: 0.0\n",
            "training error 0.10419147229380506, test error 0.20573920532531959\n",
            "Loss: 0.0318219721699986\n",
            "training error 0.1041719162861778, test error 0.20566737493429108\n",
            "Loss: 0.0\n",
            "training error 0.10397953378849106, test error 0.20553843696696325\n",
            "Loss: 0.0\n",
            "training error 0.10411158586128368, test error 0.20590780940063955\n",
            "Loss: 0.1797096636166673\n",
            "training error 0.10383328091124869, test error 0.20549679084360686\n",
            "Loss: 0.0\n",
            "training error 0.10373506943998592, test error 0.20501869692151467\n",
            "Loss: 0.0\n",
            "training error 0.10360234462599158, test error 0.20485118703633426\n",
            "Loss: 0.0\n",
            "training error 0.10359335850906227, test error 0.20471095520501198\n",
            "Loss: 0.0\n",
            "training error 0.10333056486040715, test error 0.20451471187213696\n",
            "Loss: 0.0\n",
            "training error 0.10328146919845084, test error 0.20414230945749665\n",
            "Loss: 0.0\n",
            "training error 0.10316426147314721, test error 0.20386578987207563\n",
            "Loss: 0.0\n",
            "training error 0.1030821564447137, test error 0.20380886754062608\n",
            "Loss: 0.0\n",
            "training error 0.10306409527508172, test error 0.20375340700892342\n",
            "Loss: 0.0\n",
            "training error 0.10285825047020523, test error 0.20332034413516326\n",
            "Loss: 0.0\n",
            "training error 0.10264929029263074, test error 0.20322924391749606\n",
            "Loss: 0.0\n",
            "training error 0.1026418940485073, test error 0.20320399581421153\n",
            "Loss: 0.0\n",
            "training error 0.1024516832387316, test error 0.20341307686647758\n",
            "Loss: 0.10289219531747218\n",
            "training error 0.1022224900652894, test error 0.20347305664409676\n",
            "Loss: 0.1324092219777251\n",
            "training error 0.10209764373605765, test error 0.20291007082018478\n",
            "Loss: 0.0\n",
            "training error 0.10196374237043711, test error 0.20241086233717867\n",
            "Loss: 0.0\n",
            "training error 0.1018861894332563, test error 0.20227391928489613\n",
            "Loss: 0.0\n",
            "training error 0.10179671363902068, test error 0.20205775779240226\n",
            "Loss: 0.0\n",
            "training error 0.10155453109031795, test error 0.20192709183818355\n",
            "Loss: 0.0\n",
            "training error 0.10142248979671896, test error 0.20170960597211998\n",
            "Loss: 0.0\n",
            "training error 0.10133355250498621, test error 0.20167261854802795\n",
            "Loss: 0.0\n",
            "training error 0.10126034254270631, test error 0.20132287158579973\n",
            "Loss: 0.0\n",
            "training error 0.10092214629238039, test error 0.20134916361972235\n",
            "Loss: 0.013059635855339202\n",
            "training error 0.10091986627310949, test error 0.2010967240152824\n",
            "Loss: 0.0\n",
            "training error 0.10073303660817237, test error 0.2005270708619313\n",
            "Loss: 0.0\n",
            "training error 0.10060160143640488, test error 0.20043249115306083\n",
            "Loss: 0.0\n",
            "training error 0.10036393231409563, test error 0.20014244189054814\n",
            "Loss: 0.0\n",
            "training error 0.10040214651930089, test error 0.19997766791765034\n",
            "Loss: 0.0\n",
            "training error 0.1003885872874691, test error 0.1993770946867929\n",
            "Loss: 0.0\n",
            "training error 0.10000266606660015, test error 0.19924108395981813\n",
            "Loss: 0.0\n",
            "training error 0.10002322836492017, test error 0.19889080794397684\n",
            "Loss: 0.0\n",
            "training error 0.09970830929700428, test error 0.19902339932360258\n",
            "Loss: 0.06666541354847233\n",
            "training error 0.0995269008905128, test error 0.198864919231003\n",
            "Loss: 0.0\n",
            "training error 0.09951991205403728, test error 0.19895351290471908\n",
            "Loss: 0.04454967425058243\n",
            "training error 0.0992904909510206, test error 0.19867208147122198\n",
            "Loss: 0.0\n",
            "training error 0.09916367058965615, test error 0.19867725026426497\n",
            "Loss: 0.0026016705541698215\n",
            "training error 0.09877154252681501, test error 0.1984347140967074\n",
            "Loss: 0.0\n",
            "training error 0.09877035704092409, test error 0.198667222772199\n",
            "Loss: 0.11717137122402299\n",
            "training error 0.09846189805471385, test error 0.19813502251986015\n",
            "Loss: 0.0\n",
            "training error 0.09861523596195132, test error 0.19757561870440538\n",
            "Loss: 0.0\n",
            "training error 0.09818471305268349, test error 0.19747431702900123\n",
            "Loss: 0.0\n",
            "training error 0.09792754322392863, test error 0.19731550685340618\n",
            "Loss: 0.0\n",
            "training error 0.09781334911297505, test error 0.1968933642279237\n",
            "Loss: 0.0\n",
            "training error 0.09764377899868902, test error 0.1964007035235125\n",
            "Loss: 0.0\n",
            "training error 0.09744017491956042, test error 0.19604136036565625\n",
            "Loss: 0.0\n",
            "training error 0.09741300349738977, test error 0.19602186614607395\n",
            "Loss: 0.0\n",
            "training error 0.0971274220771591, test error 0.19577678288937195\n",
            "Loss: 0.0\n",
            "training error 0.09698557520325991, test error 0.1953033238027334\n",
            "Loss: 0.0\n",
            "training error 0.0968311384401629, test error 0.19528380027329728\n",
            "Loss: 0.0\n",
            "training error 0.09651274770069769, test error 0.19485810360575123\n",
            "Loss: 0.0\n",
            "training error 0.09644886673098146, test error 0.19475627711952123\n",
            "Loss: 0.0\n",
            "training error 0.09621613655340097, test error 0.19471488316244567\n",
            "Loss: 0.0\n",
            "training error 0.0960521504640297, test error 0.19459979770603947\n",
            "Loss: 0.0\n",
            "training error 0.09622206625948322, test error 0.19422621747711963\n",
            "Loss: 0.0\n",
            "training error 0.09571421054595174, test error 0.193955661054437\n",
            "Loss: 0.0\n",
            "training error 0.09548400527676841, test error 0.19404202930474965\n",
            "Loss: 0.04452989401964036\n",
            "training error 0.09534596643960809, test error 0.19326887154258007\n",
            "Loss: 0.0\n",
            "training error 0.09513006165197886, test error 0.1928211975287049\n",
            "Loss: 0.0\n",
            "training error 0.094819933768524, test error 0.19285452003304174\n",
            "Loss: 0.017281556573611745\n",
            "training error 0.09467207980690268, test error 0.19278499927254034\n",
            "Loss: 0.0\n",
            "training error 0.0943379456805546, test error 0.19222761981796682\n",
            "Loss: 0.0\n",
            "training error 0.09442473286635951, test error 0.19157349065466986\n",
            "Loss: 0.0\n",
            "training error 0.09398607663891434, test error 0.1912940653833165\n",
            "Loss: 0.0\n",
            "training error 0.09373595815104957, test error 0.19126035135837066\n",
            "Loss: 0.0\n",
            "training error 0.09352553141091537, test error 0.19124122882543312\n",
            "Loss: 0.0\n",
            "training error 0.09331939522891917, test error 0.1905496926738381\n",
            "Loss: 0.0\n",
            "training error 0.0933235469695383, test error 0.19070332061978942\n",
            "Loss: 0.08062356007800808\n",
            "training error 0.09326857406134602, test error 0.1901751296329881\n",
            "Loss: 0.0\n",
            "training error 0.09259640098330531, test error 0.1895156727383283\n",
            "Loss: 0.0\n",
            "training error 0.09258596718989187, test error 0.1899538466828136\n",
            "Loss: 0.23120723376282015\n",
            "training error 0.09257836581448958, test error 0.1897707327071943\n",
            "Loss: 0.13458515867348364\n",
            "training error 0.09193485999049673, test error 0.18835787312970106\n",
            "Loss: 0.0\n",
            "training error 0.09161729192554556, test error 0.18800396209408887\n",
            "Loss: 0.0\n",
            "training error 0.0915295941749099, test error 0.18777914614863866\n",
            "Loss: 0.0\n",
            "training error 0.09152731336334458, test error 0.18709042177731136\n",
            "Loss: 0.0\n",
            "training error 0.09112366233361013, test error 0.1868742627075169\n",
            "Loss: 0.0\n",
            "training error 0.09095269065771978, test error 0.18601306438524923\n",
            "Loss: 0.0\n",
            "training error 0.09061608415051137, test error 0.1859201800254659\n",
            "Loss: 0.0\n",
            "training error 0.09062670420866184, test error 0.18571940415003826\n",
            "Loss: 0.0\n",
            "training error 0.09025250999166642, test error 0.18503169154792365\n",
            "Loss: 0.0\n",
            "training error 0.08980184216537321, test error 0.18484495479937793\n",
            "Loss: 0.0\n",
            "training error 0.08964789003762651, test error 0.183999635792161\n",
            "Loss: 0.0\n",
            "training error 0.08936593418508228, test error 0.18388489240671893\n",
            "Loss: 0.0\n",
            "training error 0.08893960239399401, test error 0.1837574127085096\n",
            "Loss: 0.0\n",
            "training error 0.08889000957765822, test error 0.18320855179780285\n",
            "Loss: 0.0\n",
            "training error 0.08854116310514708, test error 0.1827800666140409\n",
            "Loss: 0.0\n",
            "training error 0.08824104270464116, test error 0.18230751139077372\n",
            "Loss: 0.0\n",
            "training error 0.08795977118353354, test error 0.18172183098037475\n",
            "Loss: 0.0\n",
            "training error 0.08768373136801323, test error 0.1814704942691584\n",
            "Loss: 0.0\n",
            "training error 0.08745911351980333, test error 0.18139438258528537\n",
            "Loss: 0.0\n",
            "training error 0.08713101893518248, test error 0.18069223110720456\n",
            "Loss: 0.0\n",
            "training error 0.08682955635871772, test error 0.17970769504626619\n",
            "Loss: 0.0\n",
            "training error 0.08660841289187668, test error 0.1793877247748517\n",
            "Loss: 0.0\n",
            "training error 0.08619705797050009, test error 0.17885306015712843\n",
            "Loss: 0.0\n",
            "training error 0.08599080921911242, test error 0.17878804457637357\n",
            "Loss: 0.0\n",
            "training error 0.08565301095583, test error 0.1783466574559339\n",
            "Loss: 0.0\n",
            "training error 0.08534122769594231, test error 0.17837733442112869\n",
            "Loss: 0.017200751408741333\n",
            "training error 0.08504100837769459, test error 0.1776064223820363\n",
            "Loss: 0.0\n",
            "training error 0.08479539494712347, test error 0.17657962786103631\n",
            "Loss: 0.0\n",
            "training error 0.0844943382124213, test error 0.17568119208009136\n",
            "Loss: 0.0\n",
            "training error 0.08426587614291704, test error 0.1755849855723142\n",
            "Loss: 0.0\n",
            "training error 0.08368810813340873, test error 0.1749809321904826\n",
            "Loss: 0.0\n",
            "training error 0.0835230373198316, test error 0.17395274430207847\n",
            "Loss: 0.0\n",
            "training error 0.0834277420239896, test error 0.17433356791387294\n",
            "Loss: 0.21892360095978614\n",
            "training error 0.08261884045170079, test error 0.173633134430499\n",
            "Loss: 0.0\n",
            "training error 0.08248609529417626, test error 0.173790570088937\n",
            "Loss: 0.09067143719680981\n",
            "training error 0.08201699519455831, test error 0.17266476638170825\n",
            "Loss: 0.0\n",
            "training error 0.08162379758017882, test error 0.17183224743122624\n",
            "Loss: 0.0\n",
            "training error 0.08134046189817096, test error 0.17136723942606927\n",
            "Loss: 0.0\n",
            "training error 0.08106874083477948, test error 0.17021173549174237\n",
            "Loss: 0.0\n",
            "training error 0.08121713421925325, test error 0.17076795345721596\n",
            "Loss: 0.32678003303747705\n",
            "training error 0.08024120463681092, test error 0.1695876803767475\n",
            "Loss: 0.0\n",
            "training error 0.07998823404819445, test error 0.16885991204800857\n",
            "Loss: 0.0\n",
            "training error 0.07968950458787138, test error 0.16765652812748702\n",
            "Loss: 0.0\n",
            "training error 0.07947342592847507, test error 0.16740793129063475\n",
            "Loss: 0.0\n",
            "training error 0.07905461457217774, test error 0.16611173304842689\n",
            "Loss: 0.0\n",
            "training error 0.07849828785665364, test error 0.16602429317825554\n",
            "Loss: 0.0\n",
            "training error 0.07832252146477292, test error 0.16578158147755717\n",
            "Loss: 0.0\n",
            "training error 0.07792679939067904, test error 0.16487297154318525\n",
            "Loss: 0.0\n",
            "training error 0.07736233289237957, test error 0.1644255824688947\n",
            "Loss: 0.0\n",
            "training error 0.07693183148593782, test error 0.16378033018804633\n",
            "Loss: 0.0\n",
            "training error 0.07668527437438516, test error 0.16283955019406687\n",
            "Loss: 0.0\n",
            "training error 0.07682070585186473, test error 0.16289125838870486\n",
            "Loss: 0.03175407606834657\n",
            "training error 0.07602013370455801, test error 0.16263066338987317\n",
            "Loss: 0.0\n",
            "training error 0.07536509343884763, test error 0.16106908634160158\n",
            "Loss: 0.0\n",
            "training error 0.07512236288557846, test error 0.16081471745500403\n",
            "Loss: 0.0\n",
            "training error 0.07476564243965998, test error 0.15999939252480705\n",
            "Loss: 0.0\n",
            "training error 0.0743749976516959, test error 0.15949955683449482\n",
            "Loss: 0.0\n",
            "training error 0.07384555234842673, test error 0.15888533249022943\n",
            "Loss: 0.0\n",
            "training error 0.0739863351950871, test error 0.15944299994820013\n",
            "Loss: 0.3509873751279091\n",
            "training error 0.07307682381982464, test error 0.15812978339403794\n",
            "Loss: 0.0\n",
            "training error 0.07267065013627468, test error 0.15655114533198836\n",
            "Loss: 0.0\n",
            "training error 0.07229605559475706, test error 0.15562456014364806\n",
            "Loss: 0.0\n",
            "training error 0.0718426373043061, test error 0.15556503277963837\n",
            "Loss: 0.0\n",
            "training error 0.07162293763260048, test error 0.15466009348937212\n",
            "Loss: 0.0\n",
            "training error 0.07091962748944836, test error 0.1530310531332552\n",
            "Loss: 0.0\n",
            "training error 0.07088022996956787, test error 0.15201080710453768\n",
            "Loss: 0.0\n",
            "training error 0.07027494990342767, test error 0.1512417133629877\n",
            "Loss: 0.0\n",
            "training error 0.0698455253920796, test error 0.15091055989914323\n",
            "Loss: 0.0\n",
            "training error 0.06922022057591767, test error 0.1498214988936766\n",
            "Loss: 0.0\n",
            "training error 0.06887544497547651, test error 0.1488399707356953\n",
            "Loss: 0.0\n",
            "training error 0.0684777112090924, test error 0.1480125766690977\n",
            "Loss: 0.0\n",
            "training error 0.06802605889480165, test error 0.14774124210749429\n",
            "Loss: 0.0\n",
            "training error 0.06759228101368156, test error 0.14670614381334707\n",
            "Loss: 0.0\n",
            "training error 0.0672482159873017, test error 0.1456017749053673\n",
            "Loss: 0.0\n",
            "training error 0.06690629063583454, test error 0.1451068298363633\n",
            "Loss: 0.0\n",
            "training error 0.06632397363108287, test error 0.1444342884573558\n",
            "Loss: 0.0\n",
            "training error 0.06593051972743147, test error 0.14375675741980973\n",
            "Loss: 0.0\n",
            "training error 0.06561149063956549, test error 0.14307540232979596\n",
            "Loss: 0.0\n",
            "training error 0.0656486593305889, test error 0.14150493025194918\n",
            "Loss: 0.0\n",
            "training error 0.06542478156393375, test error 0.14176919759756423\n",
            "Loss: 0.18675486793606755\n",
            "training error 0.06442233438090783, test error 0.14168674095832015\n",
            "Loss: 0.12848365498450143\n",
            "training error 0.06387150812076775, test error 0.14034278079870824\n",
            "Loss: 0.0\n",
            "training error 0.06358385020150452, test error 0.13900048699993842\n",
            "Loss: 0.0\n",
            "training error 0.06295633961238949, test error 0.137966911130061\n",
            "Loss: 0.0\n",
            "training error 0.06276033933978857, test error 0.13828667493011274\n",
            "Loss: 0.23176847073882456\n",
            "training error 0.06204566695053165, test error 0.13691716933637316\n",
            "Loss: 0.0\n",
            "training error 0.06164385002425134, test error 0.13598200460729923\n",
            "Loss: 0.0\n",
            "training error 0.06121743206480412, test error 0.1352911597661776\n",
            "Loss: 0.0\n",
            "training error 0.06091990609633289, test error 0.1348659114678815\n",
            "Loss: 0.0\n",
            "training error 0.06039337433919491, test error 0.13369036503592807\n",
            "Loss: 0.0\n",
            "training error 0.05995722932855952, test error 0.1324338818001031\n",
            "Loss: 0.0\n",
            "training error 0.05960657334844289, test error 0.1314968553055199\n",
            "Loss: 0.0\n",
            "training error 0.0594081031085478, test error 0.13038339350753872\n",
            "Loss: 0.0\n",
            "training error 0.05879748619733872, test error 0.13015927917081793\n",
            "Loss: 0.0\n",
            "training error 0.05826440872830926, test error 0.12964824880914863\n",
            "Loss: 0.0\n",
            "training error 0.05801205921122602, test error 0.12844610537567158\n",
            "Loss: 0.0\n",
            "training error 0.05741044689673388, test error 0.12784565307320683\n",
            "Loss: 0.0\n",
            "training error 0.057027568902744706, test error 0.1273482440208464\n",
            "Loss: 0.0\n",
            "training error 0.056567563217599946, test error 0.12578557868402726\n",
            "Loss: 0.0\n",
            "training error 0.056086602262046675, test error 0.1251802567342104\n",
            "Loss: 0.0\n",
            "training error 0.055753244596740095, test error 0.12428272459241621\n",
            "Loss: 0.0\n",
            "training error 0.05540798129487116, test error 0.1239114684486253\n",
            "Loss: 0.0\n",
            "training error 0.05485574027376956, test error 0.12295760920882716\n",
            "Loss: 0.0\n",
            "training error 0.0545291099674458, test error 0.1221175324039737\n",
            "Loss: 0.0\n",
            "training error 0.05416418649323855, test error 0.12054837523682516\n",
            "Loss: 0.0\n",
            "training error 0.053798652113772376, test error 0.12050733358770437\n",
            "Loss: 0.0\n",
            "training error 0.053296473071578455, test error 0.11962282099476382\n",
            "Loss: 0.0\n",
            "training error 0.053049205217775904, test error 0.11847632267222813\n",
            "Loss: 0.0\n",
            "training error 0.05249940544028669, test error 0.11750335630214451\n",
            "Loss: 0.0\n",
            "training error 0.05237169808387057, test error 0.11704455386762798\n",
            "Loss: 0.0\n",
            "training error 0.05180696532596422, test error 0.1169876584781293\n",
            "Loss: 0.0\n",
            "training error 0.05134085894702524, test error 0.11595659711626603\n",
            "Loss: 0.0\n",
            "training error 0.05096246533774967, test error 0.1145028337580581\n",
            "Loss: 0.0\n",
            "training error 0.050678392070690484, test error 0.11394508784299985\n",
            "Loss: 0.0\n",
            "training error 0.05039495395688022, test error 0.1121290162280206\n",
            "Loss: 0.0\n",
            "training error 0.04977594028082791, test error 0.11200409719054463\n",
            "Loss: 0.0\n",
            "training error 0.049722934670924084, test error 0.11092771947436475\n",
            "Loss: 0.0\n",
            "training error 0.04901607180829917, test error 0.11062628231634146\n",
            "Loss: 0.0\n",
            "training error 0.048671878810985655, test error 0.10984805505087311\n",
            "Loss: 0.0\n",
            "training error 0.048587857153717974, test error 0.10982733841024857\n",
            "Loss: 0.0\n",
            "training error 0.047925290852185255, test error 0.1081356985137729\n",
            "Loss: 0.0\n",
            "training error 0.047877873684119256, test error 0.10889934726534264\n",
            "Loss: 0.7061948663257489\n",
            "training error 0.04745606890998299, test error 0.10694842302560763\n",
            "Loss: 0.0\n",
            "training error 0.046897438157285115, test error 0.10593646074586885\n",
            "Loss: 0.0\n",
            "training error 0.04659680098336376, test error 0.10559681472456553\n",
            "Loss: 0.0\n",
            "training error 0.04618287718060615, test error 0.10446675064051238\n",
            "Loss: 0.0\n",
            "training error 0.045771937180553716, test error 0.10333987704503543\n",
            "Loss: 0.0\n",
            "training error 0.04564574581308781, test error 0.10350942607354227\n",
            "Loss: 0.16406931511341316\n",
            "training error 0.04515154354476594, test error 0.10271317504563904\n",
            "Loss: 0.0\n",
            "training error 0.04487663487939879, test error 0.10171686995141835\n",
            "Loss: 0.0\n",
            "training error 0.044536237513141695, test error 0.10034985299248261\n",
            "Loss: 0.0\n",
            "training error 0.044249112267461546, test error 0.10035191091587692\n",
            "Loss: 0.0020507487882959197\n",
            "training error 0.04398840660038018, test error 0.09961714039911178\n",
            "Loss: 0.0\n",
            "training error 0.04352590753759763, test error 0.09875874908012547\n",
            "Loss: 0.0\n",
            "training error 0.043194391780880304, test error 0.09833672587836405\n",
            "Loss: 0.0\n",
            "training error 0.04279358945457298, test error 0.09775382024264327\n",
            "Loss: 0.0\n",
            "training error 0.04293573847922513, test error 0.09569417321297312\n",
            "Loss: 0.0\n",
            "training error 0.042286484970691554, test error 0.09548303190234529\n",
            "Loss: 0.0\n",
            "training error 0.041913014999403204, test error 0.09500500827932369\n",
            "Loss: 0.0\n",
            "training error 0.041527147371834494, test error 0.09456882932702149\n",
            "Loss: 0.0\n",
            "training error 0.04133355610446813, test error 0.09418925830926965\n",
            "Loss: 0.0\n",
            "training error 0.041204922429807736, test error 0.09369757321727441\n",
            "Loss: 0.0\n",
            "training error 0.04113738376795596, test error 0.09222300887605024\n",
            "Loss: 0.0\n",
            "training error 0.04042284305259855, test error 0.09157840052474943\n",
            "Loss: 0.0\n",
            "training error 0.040226647221865856, test error 0.09191159947591866\n",
            "Loss: 0.3638401077764808\n",
            "training error 0.04010046229978865, test error 0.09060244703728566\n",
            "Loss: 0.0\n",
            "training error 0.03954946137445931, test error 0.0896934170908544\n",
            "Loss: 0.0\n",
            "training error 0.03935911797489615, test error 0.08966799978734172\n",
            "Loss: 0.0\n",
            "training error 0.039318044363714326, test error 0.08978537294046614\n",
            "Loss: 0.13089748115580058\n",
            "training error 0.0387412290954505, test error 0.08899208152998703\n",
            "Loss: 0.0\n",
            "training error 0.0385455049232142, test error 0.08747704690709247\n",
            "Loss: 0.0\n",
            "training error 0.03826118755340458, test error 0.08703685563060123\n",
            "Loss: 0.0\n",
            "training error 0.03815180799565946, test error 0.08597645666119964\n",
            "Loss: 0.0\n",
            "training error 0.03795470399823168, test error 0.08614183389820909\n",
            "Loss: 0.1923517709750966\n",
            "training error 0.03742575684924151, test error 0.08564274723805607\n",
            "Loss: 0.0\n",
            "training error 0.03750400655894676, test error 0.08554040162328334\n",
            "Loss: 0.0\n",
            "training error 0.03725656856505025, test error 0.08449785118869611\n",
            "Loss: 0.0\n",
            "training error 0.03687343371870012, test error 0.0845679885624744\n",
            "Loss: 0.08300491999690962\n",
            "training error 0.036485759009637964, test error 0.0836121701002851\n",
            "Loss: 0.0\n",
            "training error 0.03631687200107346, test error 0.08291859839169721\n",
            "Loss: 0.0\n",
            "training error 0.03619871662519853, test error 0.08355293207081979\n",
            "Loss: 0.7650077201330152\n",
            "training error 0.03585664157482814, test error 0.08292744210899793\n",
            "Loss: 0.010665541232302012\n",
            "training error 0.03555717310408182, test error 0.08207539188392822\n",
            "Loss: 0.0\n",
            "training error 0.035593844092536665, test error 0.08105887931895317\n",
            "Loss: 0.0\n",
            "training error 0.03524993735832714, test error 0.0803272378677389\n",
            "Loss: 0.0\n",
            "training error 0.03505682611371308, test error 0.08017273633396595\n",
            "Loss: 0.0\n",
            "training error 0.034675843651183494, test error 0.07957413058374654\n",
            "Loss: 0.0\n",
            "training error 0.034487943655457036, test error 0.07950493768931713\n",
            "Loss: 0.0\n",
            "training error 0.03431827827412518, test error 0.0792395069233504\n",
            "Loss: 0.0\n",
            "training error 0.034190262257698216, test error 0.07864892780319897\n",
            "Loss: 0.0\n",
            "training error 0.03409547418141088, test error 0.07868069417251329\n",
            "Loss: 0.04039008566500968\n",
            "training error 0.0337218019219654, test error 0.07772240276870035\n",
            "Loss: 0.0\n",
            "training error 0.033674040534257876, test error 0.07683052165766056\n",
            "Loss: 0.0\n",
            "training error 0.03346873193782003, test error 0.07716573617720358\n",
            "Loss: 0.43630384424129254\n",
            "training error 0.03346614307849513, test error 0.07586855389475816\n",
            "Loss: 0.0\n",
            "training error 0.03310999809868402, test error 0.07555919818262628\n",
            "Loss: 0.0\n",
            "training error 0.0328224615809717, test error 0.0753095357995221\n",
            "Loss: 0.0\n",
            "training error 0.032826119867199945, test error 0.07576559862390347\n",
            "Loss: 0.6055844316919412\n",
            "training error 0.03269447539565938, test error 0.07516241544793147\n",
            "Loss: 0.0\n",
            "training error 0.032363324012325834, test error 0.07402197714990723\n",
            "Loss: 0.0\n",
            "training error 0.03229558042007758, test error 0.07301528957706062\n",
            "Loss: 0.0\n",
            "training error 0.03211807052733744, test error 0.07269591112897501\n",
            "Loss: 0.0\n",
            "training error 0.03173815853689268, test error 0.07317249122538524\n",
            "Loss: 0.6555803332111809\n",
            "training error 0.03165961464997104, test error 0.0721879495749597\n",
            "Loss: 0.0\n",
            "training error 0.03141014154574499, test error 0.07243637064440335\n",
            "Loss: 0.3441309400063819\n",
            "training error 0.031292684932459416, test error 0.07135068811399349\n",
            "Loss: 0.0\n",
            "training error 0.03112234485851292, test error 0.07170478050070574\n",
            "Loss: 0.49627045803193326\n",
            "training error 0.03092518494991527, test error 0.07093240871403012\n",
            "Loss: 0.0\n",
            "training error 0.030936690067580812, test error 0.07169510192908893\n",
            "Loss: 1.0752394129651899\n",
            "training error 0.030870460859222317, test error 0.0705886117103688\n",
            "Loss: 0.0\n",
            "training error 0.030506297344923744, test error 0.07040864044363424\n",
            "Loss: 0.0\n",
            "training error 0.03048421481823374, test error 0.06962209688077589\n",
            "Loss: 0.0\n",
            "training error 0.030237398611473832, test error 0.06980615382688168\n",
            "Loss: 0.264365703349867\n",
            "training error 0.030044228695284142, test error 0.06917802294652847\n",
            "Loss: 0.0\n",
            "training error 0.029977775481788427, test error 0.06825230185655029\n",
            "Loss: 0.0\n",
            "training error 0.03000491230635152, test error 0.0686413978519019\n",
            "Loss: 0.5700847953368671\n",
            "training error 0.029606928061111697, test error 0.06820979086395373\n",
            "Loss: 0.0\n",
            "training error 0.029574239963289208, test error 0.06759565592407037\n",
            "Loss: 0.0\n",
            "training error 0.029404240140169704, test error 0.06803563429180169\n",
            "Loss: 0.6508974011962376\n",
            "training error 0.02951784470170957, test error 0.06668103241649607\n",
            "Loss: 0.0\n",
            "training error 0.02902614233791795, test error 0.06708604671499416\n",
            "Loss: 0.607390563433885\n",
            "training error 0.029054186740186148, test error 0.06626407555965967\n",
            "Loss: 0.0\n",
            "training error 0.028865658450987385, test error 0.06574725552943213\n",
            "Loss: 0.0\n",
            "training error 0.028726395247907183, test error 0.06608348481149239\n",
            "Loss: 0.5113966801393532\n",
            "training error 0.028784293336442484, test error 0.06586437661269137\n",
            "Loss: 0.17813836078193201\n",
            "training error 0.028590877452786698, test error 0.06471205863609812\n",
            "Loss: 0.0\n",
            "training error 0.028388122992992378, test error 0.06468092247037352\n",
            "Loss: 0.0\n",
            "training error 0.028365962975772922, test error 0.06415774638219718\n",
            "Loss: 0.0\n",
            "training error 0.02813461948701611, test error 0.0640270289394973\n",
            "Loss: 0.0\n",
            "training error 0.028149625474726277, test error 0.0642299539418115\n",
            "Loss: 0.31693646523245356\n",
            "training error 0.027977100091506363, test error 0.06423562090514233\n",
            "Loss: 0.32578735746451315\n",
            "training error 0.027864695610007855, test error 0.0640047044772356\n",
            "Loss: 0.0\n",
            "training error 0.02779006376428126, test error 0.06297037834758643\n",
            "Loss: 0.0\n",
            "training error 0.02764017857314348, test error 0.06295783694746546\n",
            "Loss: 0.0\n",
            "training error 0.027474618032334898, test error 0.06303177817798232\n",
            "Loss: 0.11744563362074967\n",
            "training error 0.02740248079747731, test error 0.06274102334114799\n",
            "Loss: 0.0\n",
            "training error 0.027440190470844148, test error 0.06249095454243294\n",
            "Loss: 0.0\n",
            "training error 0.027200748977413553, test error 0.061743236454166295\n",
            "Loss: 0.0\n",
            "training error 0.027113280213748894, test error 0.0627978413756991\n",
            "Loss: 1.7080493056363721\n",
            "training error 0.026971630496277613, test error 0.06176888393097286\n",
            "Loss: 0.04153892519969116\n",
            "training error 0.026966998709673732, test error 0.06130969260518441\n",
            "Loss: 0.0\n",
            "training error 0.02677464576276433, test error 0.06202727806255\n",
            "Loss: 1.1704274265190273\n",
            "training error 0.026759440906336418, test error 0.06160224493670639\n",
            "Loss: 0.4771714211746714\n",
            "training error 0.026775836087145007, test error 0.06143079462429606\n",
            "Loss: 0.19752507958490373\n",
            "training error 0.026529238401944013, test error 0.060955750224942526\n",
            "Loss: 0.0\n",
            "training error 0.026413636693047242, test error 0.06024797202594081\n",
            "Loss: 0.0\n",
            "training error 0.026683610890978884, test error 0.05969305962549241\n",
            "Loss: 0.0\n",
            "training error 0.02635786772190405, test error 0.05976410578072253\n",
            "Loss: 0.11901912161289552\n",
            "training error 0.026209198116567148, test error 0.059374018487587006\n",
            "Loss: 0.0\n",
            "training error 0.026098729629173662, test error 0.0593664449730248\n",
            "Loss: 0.0\n",
            "training error 0.026012741911110415, test error 0.05964603526807944\n",
            "Loss: 0.4709567756359334\n",
            "training error 0.026081432081914047, test error 0.06039601894056207\n",
            "Loss: 1.7342691953427414\n",
            "training error 0.02599385802273376, test error 0.05979688634707556\n",
            "Loss: 0.7250583629293539\n",
            "training error 0.025772756225933068, test error 0.0587267655222582\n",
            "Loss: 0.0\n",
            "training error 0.025799238695207744, test error 0.0592547461681323\n",
            "Loss: 0.8990460162053182\n",
            "training error 0.02578676872488176, test error 0.058971567733551784\n",
            "Loss: 0.41684947079334567\n",
            "training error 0.02559577420635941, test error 0.05857187112851004\n",
            "Loss: 0.0\n",
            "training error 0.025540809471778385, test error 0.05828155139204298\n",
            "Loss: 0.0\n",
            "training error 0.025375171670122224, test error 0.05829501271145979\n",
            "Loss: 0.02309705060226097\n",
            "training error 0.025278242886565647, test error 0.05805703978337377\n",
            "Loss: 0.0\n",
            "training error 0.025284621864614897, test error 0.05839179335764669\n",
            "Loss: 0.5765942864499607\n",
            "training error 0.02518457642859864, test error 0.058004809243738915\n",
            "Loss: 0.0\n",
            "training error 0.025272924092181206, test error 0.05779318324808983\n",
            "Loss: 0.0\n",
            "training error 0.025008341697858035, test error 0.0570217629801963\n",
            "Loss: 0.0\n",
            "training error 0.024943829974698812, test error 0.05664604390623843\n",
            "Loss: 0.0\n",
            "training error 0.024880288940105872, test error 0.05707649250209555\n",
            "Loss: 0.7598917173626596\n",
            "training error 0.024874789594261166, test error 0.05694727424969705\n",
            "Loss: 0.5317764890293342\n",
            "training error 0.024748417683266483, test error 0.05672284561059617\n",
            "Loss: 0.13558176187000726\n",
            "training error 0.024739810917317636, test error 0.05632790413173709\n",
            "Loss: 0.0\n",
            "training error 0.024680603324999, test error 0.055952611950375875\n",
            "Loss: 0.0\n",
            "training error 0.024508717907054046, test error 0.05605508598063957\n",
            "Loss: 0.1831443192581883\n",
            "training error 0.024501712417180643, test error 0.05616698218115079\n",
            "Loss: 0.38312819241583806\n",
            "training error 0.024491927397130398, test error 0.05636804027561797\n",
            "Loss: 0.7424645798672191\n",
            "training error 0.02436206054273124, test error 0.05561749317970436\n",
            "Loss: 0.0\n",
            "training error 0.024341163988959066, test error 0.05529040077498511\n",
            "Loss: 0.0\n",
            "training error 0.02431444371323465, test error 0.0556285480083715\n",
            "Loss: 0.611583979581809\n",
            "training error 0.024222103840522712, test error 0.0552219358547931\n",
            "Loss: 0.0\n",
            "training error 0.024138327467415767, test error 0.055066223656880055\n",
            "Loss: 0.0\n",
            "training error 0.024098115519926373, test error 0.055243493280800804\n",
            "Loss: 0.3219207930896584\n",
            "training error 0.024130467225867255, test error 0.05501127681763001\n",
            "Loss: 0.0\n",
            "training error 0.023992943107598405, test error 0.05511700192625486\n",
            "Loss: 0.19218806532221855\n",
            "training error 0.024014273769823565, test error 0.05536188612489052\n",
            "Loss: 0.6373407918213392\n",
            "training error 0.023945054036266417, test error 0.05482734198571551\n",
            "Loss: 0.0\n",
            "training error 0.023836848838251077, test error 0.05484531805491408\n",
            "Loss: 0.03278668734889578\n",
            "training error 0.0237838566236387, test error 0.05454816830355934\n",
            "Loss: 0.0\n",
            "training error 0.023755667728320357, test error 0.05478096903013946\n",
            "Loss: 0.426780098801105\n",
            "training error 0.02371743856941618, test error 0.05433198324024624\n",
            "Loss: 0.0\n",
            "training error 0.023668015079880603, test error 0.054805808018092886\n",
            "Loss: 0.8720918133090727\n",
            "training error 0.023682318048418315, test error 0.054153678599842534\n",
            "Loss: 0.0\n",
            "training error 0.023686361009448268, test error 0.05407019651497034\n",
            "Loss: 0.0\n",
            "training error 0.02350979498176437, test error 0.054093592208306625\n",
            "Loss: 0.043269110978383374\n",
            "training error 0.02344080518385513, test error 0.05412188622450574\n",
            "Loss: 0.09559741385642972\n",
            "training error 0.023467230109590908, test error 0.054130004886046044\n",
            "Loss: 0.11061245368166883\n",
            "training error 0.023395678692191207, test error 0.05372911766480545\n",
            "Loss: 0.0\n",
            "training error 0.023316191060315874, test error 0.053293428159273404\n",
            "Loss: 0.0\n",
            "training error 0.023365923627095497, test error 0.053306774860336865\n",
            "Loss: 0.025043802818558447\n",
            "training error 0.023299074009329897, test error 0.05345899726357021\n",
            "Loss: 0.3106745240744946\n",
            "training error 0.023232054100737483, test error 0.053175117690923736\n",
            "Loss: 0.0\n",
            "training error 0.023254277940700965, test error 0.05304322179506169\n",
            "Loss: 0.0\n",
            "training error 0.02311989556122419, test error 0.053055342988045144\n",
            "Loss: 0.022851539882484673\n",
            "training error 0.02315752174009607, test error 0.05236977613538271\n",
            "Loss: 0.0\n",
            "training error 0.023081961151669637, test error 0.05226780399314095\n",
            "Loss: 0.0\n",
            "training error 0.023080298745160495, test error 0.05267923811287819\n",
            "Loss: 0.787165498269693\n",
            "training error 0.02307519844668958, test error 0.05253835629265635\n",
            "Loss: 0.5176270645518288\n",
            "training error 0.02305058043088889, test error 0.052062025828342\n",
            "Loss: 0.0\n",
            "training error 0.022896841436211, test error 0.05229148746439711\n",
            "Loss: 0.44074665248656775\n",
            "training error 0.02286880501668225, test error 0.05272016767035663\n",
            "Loss: 1.2641495054084961\n",
            "training error 0.022937098193532016, test error 0.05241647286239516\n",
            "Loss: 0.680816830335873\n",
            "training error 0.022903761642535717, test error 0.05217186448576472\n",
            "Loss: 0.21097653361565882\n",
            "training error 0.022917050120497967, test error 0.05233355625630608\n",
            "Loss: 0.521551790664776\n",
            "training error 0.022763923126158613, test error 0.05151079034099708\n",
            "Loss: 0.0\n",
            "training error 0.022859685398123133, test error 0.05182054283762461\n",
            "Loss: 0.6013351660438593\n",
            "training error 0.022770837846051772, test error 0.051696938787465424\n",
            "Loss: 0.3613775778551709\n",
            "training error 0.022712188747908847, test error 0.0518057460886702\n",
            "Loss: 0.5726096332837161\n",
            "training error 0.022661464805547378, test error 0.05181070626016526\n",
            "Loss: 0.582239016685171\n",
            "training error 0.022577001522984037, test error 0.05149682129478671\n",
            "Loss: 0.0\n",
            "training error 0.022563045710958383, test error 0.05153416800693862\n",
            "Loss: 0.07252236393024969\n",
            "training error 0.022546815793327988, test error 0.05173974868076567\n",
            "Loss: 0.4717327785890957\n",
            "training error 0.022449372688086548, test error 0.05130862681144499\n",
            "Loss: 0.0\n",
            "training error 0.022636289939897056, test error 0.05076331120731035\n",
            "Loss: 0.0\n",
            "training error 0.022444933515259332, test error 0.05087028083306619\n",
            "Loss: 0.21072231738192837\n",
            "training error 0.022728629376432743, test error 0.0505642630230352\n",
            "Loss: 0.0\n",
            "training error 0.022390768884446032, test error 0.051019709424770826\n",
            "Loss: 0.900727855023109\n",
            "training error 0.02237283132380871, test error 0.05134029946701081\n",
            "Loss: 1.5347528028285096\n",
            "training error 0.02241046076387748, test error 0.050725974336194336\n",
            "Loss: 0.3198134482558679\n",
            "training error 0.022373886128296053, test error 0.050838145052803714\n",
            "Loss: 0.5416513826054237\n",
            "training error 0.022284389724742625, test error 0.050581815805741254\n",
            "Loss: 0.03471381101325388\n",
            "training error 0.022232140302041646, test error 0.05124613970284416\n",
            "Loss: 1.3485347932359337\n",
            "training error 0.02229175424198127, test error 0.051491771898339096\n",
            "Loss: 1.834317005433972\n",
            "training error 0.022323198633933308, test error 0.05068689125327636\n",
            "Loss: 0.24251956403538166\n",
            "training error 0.022213584606381617, test error 0.050980318563356906\n",
            "Loss: 0.8228252830109861\n",
            "training error 0.02229797159935803, test error 0.05042939902896145\n",
            "Loss: 0.0\n",
            "training error 0.022428826288329408, test error 0.05032907527745994\n",
            "Loss: 0.0\n",
            "training error 0.022081645628782558, test error 0.050147715285674535\n",
            "Loss: 0.0\n",
            "training error 0.02209346757244745, test error 0.05022943248097154\n",
            "Loss: 0.16295297768100792\n",
            "training error 0.022126055523927896, test error 0.05069118480074615\n",
            "Loss: 1.083737338731483\n",
            "training error 0.022156911314949377, test error 0.0502086223614449\n",
            "Loss: 0.12145533534957398\n",
            "training error 0.022041810979215856, test error 0.05003686145800975\n",
            "Loss: 0.0\n",
            "training error 0.021948560856385933, test error 0.05012495770118402\n",
            "Loss: 0.1760626878010596\n",
            "training error 0.02202233952806632, test error 0.05073761909899261\n",
            "Loss: 1.4004828052033735\n",
            "training error 0.022020112461239912, test error 0.0502102594112339\n",
            "Loss: 0.3465404267405159\n",
            "training error 0.02198385171768796, test error 0.05059718873753516\n",
            "Loss: 1.1198289884660984\n",
            "training error 0.021981274274274123, test error 0.05044381457672622\n",
            "Loss: 0.8133066440587644\n",
            "training error 0.02189762794867873, test error 0.05022021821080497\n",
            "Loss: 0.3664433528651534\n",
            "training error 0.02198348527048933, test error 0.04963313054592179\n",
            "Loss: 0.0\n",
            "training error 0.02193347672542293, test error 0.049739398922938736\n",
            "Loss: 0.21410774587071746\n",
            "training error 0.02184155795899119, test error 0.049715205121816285\n",
            "Loss: 0.1653624806490006\n",
            "training error 0.021898062715272688, test error 0.04968288278627868\n",
            "Loss: 0.10023998045187721\n",
            "training error 0.021824834590133953, test error 0.049784732813888656\n",
            "Loss: 0.30544570995092446\n",
            "training error 0.022016398764522948, test error 0.049435679491356785\n",
            "Loss: 0.0\n",
            "training error 0.02177322297074981, test error 0.04957168697856084\n",
            "Loss: 0.2751200926202291\n",
            "training error 0.021747995199527814, test error 0.04935691313322687\n",
            "Loss: 0.0\n",
            "training error 0.021765674415998547, test error 0.04937831993353243\n",
            "Loss: 0.043371432584882186\n",
            "training error 0.021744231247039104, test error 0.04929591426706359\n",
            "Loss: 0.0\n",
            "training error 0.02171754634985858, test error 0.04942152430274971\n",
            "Loss: 0.2548082078478453\n",
            "training error 0.021793702146370594, test error 0.049348292382972725\n",
            "Loss: 0.10625244847954907\n",
            "training error 0.021719681088756628, test error 0.049771028564614794\n",
            "Loss: 0.9638005595701937\n",
            "training error 0.021665196965535212, test error 0.04932046654465952\n",
            "Loss: 0.049805907773436964\n",
            "training error 0.021697097802639235, test error 0.04946723628560344\n",
            "Loss: 0.3475379675721202\n",
            "training error 0.02170022688410588, test error 0.04978939333342677\n",
            "Loss: 1.0010546993605374\n",
            "training error 0.02165009817789034, test error 0.049597458905136255\n",
            "Loss: 0.6117031047218724\n",
            "training error 0.021557404141733537, test error 0.04950430638456581\n",
            "Loss: 0.4227370981969125\n",
            "training error 0.021604277629519542, test error 0.049758875027401436\n",
            "Loss: 0.9391463110506981\n",
            "training error 0.0216058333110784, test error 0.04924183442441175\n",
            "Loss: 0.0\n",
            "training error 0.021496362114264717, test error 0.04918649029049087\n",
            "Loss: 0.0\n",
            "training error 0.021447481650720693, test error 0.049359413231422886\n",
            "Loss: 0.35156592777967344\n",
            "training error 0.021504705709810137, test error 0.049315223898752966\n",
            "Loss: 0.26172554191570274\n",
            "training error 0.021479303142295052, test error 0.04936137702574037\n",
            "Loss: 0.3555584759486585\n",
            "training error 0.02142159508453792, test error 0.048829573161661304\n",
            "Loss: 0.0\n",
            "training error 0.021445811411653266, test error 0.04915178060611411\n",
            "Loss: 0.6598612758421218\n",
            "training error 0.021374613100156387, test error 0.04895420682094818\n",
            "Loss: 0.25524216415786505\n",
            "training error 0.02137471456178765, test error 0.04901829966654281\n",
            "Loss: 0.3865004190322985\n",
            "training error 0.02138071498250129, test error 0.04887902326063783\n",
            "Loss: 0.10127079917903181\n",
            "training error 0.02130590308355058, test error 0.048574754574617275\n",
            "Loss: 0.0\n",
            "training error 0.02135985559640848, test error 0.04860805286118257\n",
            "Loss: 0.06855060176196304\n",
            "training error 0.021341762038843328, test error 0.04868647795761648\n",
            "Loss: 0.23000297989685947\n",
            "training error 0.02131290844612228, test error 0.04884195267461182\n",
            "Loss: 0.5500760679790773\n",
            "training error 0.021306039086360872, test error 0.04894491270963621\n",
            "Loss: 0.7620380962508388\n",
            "training error 0.02133714729116007, test error 0.048580638537101935\n",
            "Loss: 0.012113210938857755\n",
            "training error 0.021346477959977923, test error 0.04839791213334721\n",
            "Loss: 0.0\n",
            "training error 0.021327664229339915, test error 0.048871746345581196\n",
            "Loss: 0.9790385397792978\n",
            "training error 0.021308820789371512, test error 0.048666401025388696\n",
            "Loss: 0.5547530465813022\n",
            "training error 0.021346806805082223, test error 0.04913168413434963\n",
            "Loss: 1.5161232554427473\n",
            "training error 0.021281696518967403, test error 0.04922578695801119\n",
            "Loss: 1.7105589645747488\n",
            "training error 0.021310033465184633, test error 0.049092471617083584\n",
            "Loss: 1.4351021627187155\n",
            "training error 0.021328011984812326, test error 0.048575616864352376\n",
            "Loss: 0.3671743742076128\n",
            "training error 0.021201566096308525, test error 0.048426945257443746\n",
            "Loss: 0.05998838135112816\n",
            "training error 0.02120494706811558, test error 0.04871487721646958\n",
            "Loss: 0.6549147869211014\n",
            "training error 0.021282453588682627, test error 0.048001354184686845\n",
            "Loss: 0.0\n",
            "training error 0.021177981098072344, test error 0.04842935188353059\n",
            "Loss: 0.8916367175747064\n",
            "training error 0.021192723421365637, test error 0.04795212160276077\n",
            "Loss: 0.0\n",
            "training error 0.021229666604073397, test error 0.04850574732854236\n",
            "Loss: 1.1545385423566312\n",
            "training error 0.02123581016200733, test error 0.04871420794399627\n",
            "Loss: 1.5892651164607141\n",
            "training error 0.02119380782417577, test error 0.04808546966882616\n",
            "Loss: 0.2780858523217189\n",
            "training error 0.021156162407810503, test error 0.048374977217274115\n",
            "Loss: 0.8818287916774858\n",
            "training error 0.021183753162134618, test error 0.04881915913843133\n",
            "Loss: 1.8081317503595873\n",
            "training error 0.02117650061070274, test error 0.04903051164904546\n",
            "Loss: 2.248889121566222\n",
            "training error 0.021138558194896434, test error 0.04862813648542302\n",
            "Loss: 1.4097705379178205\n",
            "training error 0.021216855232494256, test error 0.048061943754927276\n",
            "Loss: 0.22902459473279624\n",
            "training error 0.021182381701758346, test error 0.04811454777357748\n",
            "Loss: 0.3387257234669594\n",
            "training error 0.021150404624021076, test error 0.0481500475148009\n",
            "Loss: 0.4127573617696445\n",
            "training error 0.02127906966925257, test error 0.047726830402917045\n",
            "Loss: 0.0\n",
            "training error 0.02105089535404535, test error 0.04808400303623104\n",
            "Loss: 0.748368643588293\n",
            "training error 0.02104942436216344, test error 0.04799707531309424\n",
            "Loss: 0.5662326785494498\n",
            "training error 0.021048776550879073, test error 0.04802202642326118\n",
            "Loss: 0.6185116795983436\n",
            "training error 0.021077840377511932, test error 0.04811764223572924\n",
            "Loss: 0.8188514290869531\n",
            "training error 0.021032022317750847, test error 0.04789944829978443\n",
            "Loss: 0.3616789453859015\n",
            "training error 0.021093015690484208, test error 0.048537185627533605\n",
            "Loss: 1.6979028730284895\n",
            "training error 0.0211534095012503, test error 0.04756259744764748\n",
            "Loss: 0.0\n",
            "training error 0.021145154090933142, test error 0.047979193548020674\n",
            "Loss: 0.8758901379003703\n",
            "training error 0.021092373879480007, test error 0.04786417272361279\n",
            "Loss: 0.6340597279138382\n",
            "training error 0.02093143903970649, test error 0.04761229211061134\n",
            "Loss: 0.10448265155946768\n",
            "training error 0.020941192411308627, test error 0.0474612678549485\n",
            "Loss: 0.0\n",
            "training error 0.020997501724924705, test error 0.04767305703426299\n",
            "Loss: 0.44623582320169053\n",
            "training error 0.021017690692645183, test error 0.04761570598547975\n",
            "Loss: 0.32539824052582045\n",
            "training error 0.020956535019368387, test error 0.047432538527701774\n",
            "Loss: 0.0\n",
            "training error 0.021043877755356873, test error 0.047312435907351236\n",
            "Loss: 0.0\n",
            "training error 0.02100844458042045, test error 0.0474437881995512\n",
            "Loss: 0.27762741376746725\n",
            "training error 0.02085068618097539, test error 0.047465484946958465\n",
            "Loss: 0.3234858587854994\n",
            "training error 0.02091114141063696, test error 0.04757334193414672\n",
            "Loss: 0.5514533796281418\n",
            "training error 0.02086839460605833, test error 0.0472155644415502\n",
            "Loss: 0.0\n",
            "training error 0.02096169710331754, test error 0.047135469583353164\n",
            "Loss: 0.0\n",
            "training error 0.020875213306620313, test error 0.04770337777241576\n",
            "Loss: 1.2048425401985696\n",
            "training error 0.020972818770379348, test error 0.047836055702771954\n",
            "Loss: 1.4863246841741784\n",
            "training error 0.020815428494897995, test error 0.04741874570462707\n",
            "Loss: 0.6009829196099714\n",
            "training error 0.02083462585498713, test error 0.04786181770394385\n",
            "Loss: 1.5409799181192563\n",
            "training error 0.02079971367476828, test error 0.04772480968267729\n",
            "Loss: 1.2503112932437332\n",
            "training error 0.020919837023366358, test error 0.047474423319377713\n",
            "Loss: 0.719105461387537\n",
            "training error 0.02081462179784387, test error 0.047370952318080854\n",
            "Loss: 0.4995871194436008\n",
            "training error 0.020839462584784998, test error 0.04749688495098015\n",
            "Loss: 0.7667588141619497\n",
            "training error 0.020845658169949512, test error 0.047455780477030605\n",
            "Loss: 0.6795538402582624\n",
            "training error 0.020852525270898276, test error 0.0470842385691703\n",
            "Loss: 0.0\n",
            "training error 0.020763464877704207, test error 0.04698960923253661\n",
            "Loss: 0.0\n",
            "training error 0.020702436383431576, test error 0.047381810320726116\n",
            "Loss: 0.8346549260467961\n",
            "training error 0.020794238328575104, test error 0.047339966690235505\n",
            "Loss: 0.7456062381048678\n",
            "training error 0.020723586610061094, test error 0.046988056387910704\n",
            "Loss: 0.0\n",
            "training error 0.020743952398690133, test error 0.046976524357047376\n",
            "Loss: 0.0\n",
            "training error 0.02078945453008243, test error 0.0471260134477468\n",
            "Loss: 0.31822084061225997\n",
            "training error 0.020657058241085224, test error 0.047167411839535336\n",
            "Loss: 0.40634654244982027\n",
            "training error 0.02070894176399519, test error 0.04750021942321895\n",
            "Loss: 1.1148016447347198\n",
            "training error 0.02086877766053929, test error 0.04729462308328325\n",
            "Loss: 0.6771440215928903\n",
            "training error 0.020618257721007113, test error 0.04694824568649151\n",
            "Loss: 0.0\n",
            "training error 0.02069070763429785, test error 0.04684568918311304\n",
            "Loss: 0.0\n",
            "training error 0.020778210874980337, test error 0.04711806613658205\n",
            "Loss: 0.5814344035036667\n",
            "training error 0.020687836968449936, test error 0.04683936874283486\n",
            "Loss: 0.0\n",
            "training error 0.020724972430843057, test error 0.046867486649928035\n",
            "Loss: 0.06003049965841445\n",
            "training error 0.020793596697535787, test error 0.046808054992389006\n",
            "Loss: 0.0\n",
            "training error 0.020778861110703612, test error 0.046717444419876825\n",
            "Loss: 0.0\n",
            "training error 0.020689160072095706, test error 0.04653138562890905\n",
            "Loss: 0.0\n",
            "training error 0.020847486324174314, test error 0.04707699521170894\n",
            "Loss: 1.1725625089937353\n",
            "training error 0.020621088474936548, test error 0.04688025671837684\n",
            "Loss: 0.749754353438048\n",
            "training error 0.020733894345664212, test error 0.046760070429251344\n",
            "Loss: 0.4914635514318588\n",
            "training error 0.020602261208581683, test error 0.04702523928407541\n",
            "Loss: 1.0613345132356011\n",
            "training error 0.020712975077538803, test error 0.046973216249189105\n",
            "Loss: 0.9495324807296424\n",
            "training error 0.020668788417176547, test error 0.047179473573403956\n",
            "Loss: 1.3927974328197479\n",
            "training error 0.02059642129165551, test error 0.04720264518702991\n",
            "Loss: 1.4425952484505844\n",
            "training error 0.02067088833240554, test error 0.04693502092374702\n",
            "Loss: 0.8674474000344379\n",
            "training error 0.02064550183440495, test error 0.047174361516253725\n",
            "Loss: 1.3818111768096664\n",
            "training error 0.020631769485625125, test error 0.04698125881050628\n",
            "Loss: 0.9668166454035898\n",
            "training error 0.020638809821956913, test error 0.04657229264547066\n",
            "Loss: 0.08791274106436653\n",
            "training error 0.020589752835521512, test error 0.04672083388031189\n",
            "Loss: 0.4071407907636715\n",
            "training error 0.020624957901505116, test error 0.04727375029974412\n",
            "Loss: 1.5954063280115394\n",
            "training error 0.020514697830354416, test error 0.047281303775125204\n",
            "Loss: 1.6116394044157545\n",
            "training error 0.020625923983416807, test error 0.04747563988774922\n",
            "Loss: 2.0292846346134263\n",
            "training error 0.02059802127853551, test error 0.046933152627297775\n",
            "Loss: 0.8634322682604889\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.046933152627297775\n",
            "training error 0.12312408114550852, test error 0.23706464504867658\n",
            "training error 0.11985625279395781, test error 0.2312052316062369\n",
            "training error 0.11868631857666712, test error 0.22688839569941682\n",
            "training error 0.11889320425466347, test error 0.2253033806911702\n",
            "training error 0.11796518893324721, test error 0.22623622591356618\n",
            "training error 0.11793422521834598, test error 0.22540607477003788\n",
            "training error 0.11788932271590648, test error 0.22419489321502725\n",
            "training error 0.1179433945510415, test error 0.22301801587478376\n",
            "training error 0.11756700256959199, test error 0.22329567030902278\n",
            "training error 0.11765826295316274, test error 0.2223815037103364\n",
            "training error 0.11756008991170877, test error 0.22266509241150267\n",
            "training error 0.11782705895526713, test error 0.22328248293979153\n",
            "training error 0.11750744701399317, test error 0.22398489318904347\n",
            "training error 0.11765482590545687, test error 0.22316898479304037\n",
            "training error 0.11748190393136522, test error 0.2241634716138675\n",
            "training error 0.11759137802442045, test error 0.22379843976658512\n",
            "training error 0.11758240538799258, test error 0.2246497158117895\n",
            "training error 0.11754347277700976, test error 0.2240802146307785\n",
            "training error 0.11753663333554702, test error 0.2237037765304013\n",
            "training error 0.117756734977968, test error 0.22276795723925458\n",
            "training error 0.11752073475031902, test error 0.2222175580950901\n",
            "training error 0.11726471160325348, test error 0.2227286405790363\n",
            "training error 0.11736159469589622, test error 0.22220453383347594\n",
            "training error 0.11740676428501166, test error 0.22262851374671105\n",
            "training error 0.11726759202809973, test error 0.22228381975816291\n",
            "training error 0.11745207211876953, test error 0.221775852697992\n",
            "training error 0.11714815386412124, test error 0.22188934397419746\n",
            "training error 0.11737686542184059, test error 0.22332085044983696\n",
            "training error 0.11734082075068672, test error 0.2230064557609111\n",
            "training error 0.11734384336951288, test error 0.22235305301111896\n",
            "training error 0.11720221340517487, test error 0.22322537246128732\n",
            "training error 0.11700476424959919, test error 0.22229987645392768\n",
            "training error 0.11711288707563437, test error 0.22264694358887846\n",
            "training error 0.11716308905996757, test error 0.22353442378277652\n",
            "training error 0.11753039868768632, test error 0.22372252136055443\n",
            "training error 0.11718728693106234, test error 0.22221244484319305\n",
            "training error 0.11692630047082703, test error 0.22220287131387917\n",
            "training error 0.11702275318687817, test error 0.2220415473900283\n",
            "training error 0.11715355134818099, test error 0.221826086222713\n",
            "training error 0.11689036452420681, test error 0.22158203583145628\n",
            "training error 0.1170492015382632, test error 0.2212415681449116\n",
            "training error 0.116976285897875, test error 0.22069018905428636\n",
            "training error 0.11676941822189975, test error 0.22129594348324097\n",
            "training error 0.1168507508564212, test error 0.22218030309028983\n",
            "training error 0.11676284897647962, test error 0.22216761886350703\n",
            "training error 0.11680355660334953, test error 0.2227237326918481\n",
            "training error 0.1168786961599648, test error 0.22180389471547288\n",
            "training error 0.1168608129063616, test error 0.22271310205893427\n",
            "training error 0.11678075091839674, test error 0.2215920376974287\n",
            "training error 0.11662910651390171, test error 0.22175343253126673\n",
            "Loss: 0.48178103500506886\n",
            "training error 0.1166536490127193, test error 0.22188102332771248\n",
            "Loss: 0.539595474782617\n",
            "training error 0.11685772679075508, test error 0.22165521530015764\n",
            "Loss: 0.43727645982210017\n",
            "training error 0.11676709006207439, test error 0.22077819855245084\n",
            "Loss: 0.039879207381909865\n",
            "training error 0.11717046312341783, test error 0.2209137900892777\n",
            "Loss: 0.10131897387442024\n",
            "training error 0.11661505130783033, test error 0.22090317268472787\n",
            "Loss: 0.09650797407632083\n",
            "training error 0.11667403606666372, test error 0.221448669707981\n",
            "Loss: 0.3436857147773198\n",
            "training error 0.11654203439762761, test error 0.22129047078434566\n",
            "Loss: 0.2720020009188806\n",
            "training error 0.11720730318554384, test error 0.22156624874921332\n",
            "Loss: 0.3969635889484291\n",
            "training error 0.1165783394957625, test error 0.2207362190277823\n",
            "Loss: 0.020857281283404028\n",
            "training error 0.11650121695933335, test error 0.22067531197192589\n",
            "Loss: 0.0\n",
            "training error 0.11648302435500572, test error 0.22048139925328977\n",
            "Loss: 0.0\n",
            "training error 0.1166818577337293, test error 0.22100416329533876\n",
            "Loss: 0.2371011993843597\n",
            "training error 0.1164481256496712, test error 0.2208686365157188\n",
            "Loss: 0.17563262195383622\n",
            "training error 0.11652116490728795, test error 0.22142640099976196\n",
            "Loss: 0.428608376793993\n",
            "training error 0.11631104229404776, test error 0.22085971954266118\n",
            "Loss: 0.17158830207566478\n",
            "training error 0.11659148170375115, test error 0.22063936805076362\n",
            "Loss: 0.07164722194654694\n",
            "training error 0.11624407151339947, test error 0.22076109535435823\n",
            "Loss: 0.12685700563208613\n",
            "training error 0.11637446241269624, test error 0.22060732858171547\n",
            "Loss: 0.05711562465231523\n",
            "training error 0.11649415337594338, test error 0.22031486349351254\n",
            "Loss: 0.0\n",
            "training error 0.11650330428834814, test error 0.22111875345921667\n",
            "Loss: 0.36488231114184533\n",
            "training error 0.11623319995886881, test error 0.22100414757767695\n",
            "Loss: 0.31286317828698174\n",
            "training error 0.11662261581852802, test error 0.22049046930665636\n",
            "Loss: 0.07970674804198552\n",
            "training error 0.11617758261218744, test error 0.22096852915325668\n",
            "Loss: 0.29669612362008824\n",
            "training error 0.11628266607147356, test error 0.22131752858114334\n",
            "Loss: 0.4551055120529002\n",
            "training error 0.11627069464414551, test error 0.22098533579399315\n",
            "Loss: 0.30432458793248074\n",
            "training error 0.11625802232222769, test error 0.2207638375887371\n",
            "Loss: 0.20378747402931552\n",
            "training error 0.11632213519357017, test error 0.22134752637862817\n",
            "Loss: 0.46872138753635273\n",
            "training error 0.11610466026025278, test error 0.22134014977554492\n",
            "Loss: 0.46537317808454937\n",
            "training error 0.11600445094685577, test error 0.2211611969587785\n",
            "Loss: 0.3841472390222478\n",
            "training error 0.1160546150024442, test error 0.22129623627416944\n",
            "Loss: 0.445441022496329\n",
            "training error 0.11607376227992959, test error 0.22174127287997591\n",
            "Loss: 0.6474412864592605\n",
            "training error 0.11610202842068895, test error 0.22168847387025198\n",
            "Loss: 0.623476035596604\n",
            "training error 0.11687561649800765, test error 0.22171797160751033\n",
            "Loss: 0.6368649358236\n",
            "training error 0.11616687105559644, test error 0.2217897065121926\n",
            "Loss: 0.6694251106319493\n",
            "training error 0.11613066312778098, test error 0.2218049149064334\n",
            "Loss: 0.6763281375088637\n",
            "training error 0.1160981628959085, test error 0.2218137276868754\n",
            "Loss: 0.680328221889126\n",
            "training error 0.1162205362520611, test error 0.22078700261670647\n",
            "Loss: 0.2143019838549476\n",
            "training error 0.11614876489891346, test error 0.2212375368216148\n",
            "Loss: 0.4187975851794645\n",
            "training error 0.11608420186067285, test error 0.22168927971796282\n",
            "Loss: 0.6238418065201312\n",
            "training error 0.11606839959204673, test error 0.2207465893767082\n",
            "Loss: 0.1959585823443133\n",
            "training error 0.11602257246172025, test error 0.22140507494565817\n",
            "Loss: 0.4948424427014375\n",
            "training error 0.11585476061923101, test error 0.22082523057037753\n",
            "Loss: 0.23165349299278937\n",
            "training error 0.11597212641830842, test error 0.22057429668268483\n",
            "Loss: 0.11775564528806459\n",
            "training error 0.11593133428776389, test error 0.22068909382676405\n",
            "Loss: 0.16986159141392232\n",
            "training error 0.11582075918454128, test error 0.22038336237642667\n",
            "Loss: 0.03109135799008733\n",
            "training error 0.11578525122376887, test error 0.2206497264191766\n",
            "Loss: 0.15199288888374518\n",
            "training error 0.1157858073781764, test error 0.22089064594788008\n",
            "Loss: 0.2613452607043376\n",
            "training error 0.11588842588243901, test error 0.22037811904059534\n",
            "Loss: 0.028711429669225907\n",
            "training error 0.11581776730247985, test error 0.22024224766849296\n",
            "Loss: 0.0\n",
            "training error 0.11576284420435878, test error 0.22007374466539487\n",
            "Loss: 0.0\n",
            "training error 0.11577991533679151, test error 0.2203709393223307\n",
            "Loss: 0.1350432135317714\n",
            "training error 0.11603018985686132, test error 0.2198799815594096\n",
            "Loss: 0.0\n",
            "training error 0.11597049588895043, test error 0.22056833842505139\n",
            "Loss: 0.3130602707713148\n",
            "training error 0.11600039307027311, test error 0.22086961797788873\n",
            "Loss: 0.4500802717284813\n",
            "training error 0.11565381586550647, test error 0.22048113726740973\n",
            "Loss: 0.2734017456871962\n",
            "training error 0.11569707831778062, test error 0.22062325989265621\n",
            "Loss: 0.3380382006471061\n",
            "training error 0.11564976734120058, test error 0.22099095165263968\n",
            "Loss: 0.5052620458447343\n",
            "training error 0.11580564914523249, test error 0.2207597863896816\n",
            "Loss: 0.40012957252058\n",
            "training error 0.11561902025850976, test error 0.2205136050168911\n",
            "Loss: 0.28816786912013725\n",
            "training error 0.11576951314350141, test error 0.22082530799274758\n",
            "Loss: 0.42992837575919207\n",
            "training error 0.11582622286477201, test error 0.22016259626646625\n",
            "Loss: 0.12853134926258392\n",
            "training error 0.11567930429753834, test error 0.22026455557273084\n",
            "Loss: 0.17490178532570955\n",
            "training error 0.11566325637603497, test error 0.22048351517786866\n",
            "Loss: 0.2744832040546541\n",
            "training error 0.11552719704468355, test error 0.2205473091899003\n",
            "Loss: 0.3034963100132737\n",
            "training error 0.11579563390543472, test error 0.21995415845053062\n",
            "Loss: 0.03373517252227565\n",
            "training error 0.11588538295272698, test error 0.2205794492785589\n",
            "Loss: 0.31811341541354565\n",
            "training error 0.11550684350147866, test error 0.22092792500808425\n",
            "Loss: 0.4765979336738724\n",
            "training error 0.1155891796433058, test error 0.22047952424901138\n",
            "Loss: 0.2726681553044452\n",
            "training error 0.11561387373121641, test error 0.22017438908752834\n",
            "Loss: 0.1338946483580683\n",
            "training error 0.11550961856731254, test error 0.22054769610199598\n",
            "Loss: 0.30367227514340733\n",
            "training error 0.11544876698802196, test error 0.22059425648419057\n",
            "Loss: 0.3248476372042841\n",
            "training error 0.115595853381151, test error 0.2202740225297318\n",
            "Loss: 0.17920729642035838\n",
            "training error 0.11568282556641123, test error 0.22092659763564065\n",
            "Loss: 0.4759942532323036\n",
            "training error 0.11552906089129483, test error 0.2205656457572548\n",
            "Loss: 0.31183566279313624\n",
            "training error 0.11537699874695968, test error 0.22030244155905157\n",
            "Loss: 0.19213208798993797\n",
            "training error 0.11550956923851219, test error 0.220161221919963\n",
            "Loss: 0.1279063053211127\n",
            "training error 0.11553713300654928, test error 0.2199625962723029\n",
            "Loss: 0.037572639540628394\n",
            "training error 0.11536199909220039, test error 0.220150652312409\n",
            "Loss: 0.12309931585392508\n",
            "training error 0.11535349981495677, test error 0.22018170264862008\n",
            "Loss: 0.13722080885700816\n",
            "training error 0.11529450560690847, test error 0.22010154332160545\n",
            "Loss: 0.10076486300594212\n",
            "training error 0.11546774522231396, test error 0.21963596489864406\n",
            "Loss: 0.0\n",
            "training error 0.11529993968834551, test error 0.21988250751726335\n",
            "Loss: 0.11225056822230517\n",
            "training error 0.11541302159706877, test error 0.219509062045234\n",
            "Loss: 0.0\n",
            "training error 0.11538505827211443, test error 0.21953819565041616\n",
            "Loss: 0.01327216512645446\n",
            "training error 0.11526533788774401, test error 0.21959579950687325\n",
            "Loss: 0.03951429650834726\n",
            "training error 0.11541000587883711, test error 0.2197477525793044\n",
            "Loss: 0.10873835086646633\n",
            "training error 0.11541508269906929, test error 0.21989189456614217\n",
            "Loss: 0.17440397099837135\n",
            "training error 0.11533555142920265, test error 0.21996865169683152\n",
            "Loss: 0.20937160740217564\n",
            "training error 0.1152824726696477, test error 0.2197975964995029\n",
            "Loss: 0.13144534971838429\n",
            "training error 0.11536374372356809, test error 0.21976298650075635\n",
            "Loss: 0.1156783474707046\n",
            "training error 0.11522382399242381, test error 0.21957624745916218\n",
            "Loss: 0.030607125419890302\n",
            "training error 0.11521159138589317, test error 0.21977908729561166\n",
            "Loss: 0.12301325870638369\n",
            "training error 0.11520559579172039, test error 0.2197863513439213\n",
            "Loss: 0.12632248350192832\n",
            "training error 0.11530781423309143, test error 0.2200426227542187\n",
            "Loss: 0.24307001451939758\n",
            "training error 0.11517280481529285, test error 0.22055330082861044\n",
            "Loss: 0.47571556893686306\n",
            "training error 0.11507192557879488, test error 0.2200691787323914\n",
            "Loss: 0.25516791058128874\n",
            "training error 0.11512468893093378, test error 0.21979879206338115\n",
            "Loss: 0.1319900032589416\n",
            "training error 0.1151966229308624, test error 0.2201402334678758\n",
            "Loss: 0.28753775209142685\n",
            "training error 0.11554350057658365, test error 0.21996573083917031\n",
            "Loss: 0.20804097547564293\n",
            "training error 0.11517808820260028, test error 0.21953222455211083\n",
            "Loss: 0.010551959295446167\n",
            "training error 0.11512673443786611, test error 0.22023964872318633\n",
            "Loss: 0.33282757037236266\n",
            "training error 0.11501609679388149, test error 0.2199023951069178\n",
            "Loss: 0.17918761896160706\n",
            "training error 0.11499063125091655, test error 0.22005955787984147\n",
            "Loss: 0.2507850151963309\n",
            "training error 0.11542309301893548, test error 0.21981779314822436\n",
            "Loss: 0.1406461765695921\n",
            "training error 0.11532318828584, test error 0.219512910464318\n",
            "Loss: 0.0017531937170023326\n",
            "training error 0.11504382545783925, test error 0.2194190150060416\n",
            "Loss: 0.0\n",
            "training error 0.11500585661770053, test error 0.21937164542748308\n",
            "Loss: 0.0\n",
            "training error 0.11496763561103128, test error 0.219198362090881\n",
            "Loss: 0.0\n",
            "training error 0.11497940149374263, test error 0.21921036719962297\n",
            "Loss: 0.005476824109207357\n",
            "training error 0.11512424769994666, test error 0.21894575309535413\n",
            "Loss: 0.0\n",
            "training error 0.11496005057801646, test error 0.2191293176861334\n",
            "Loss: 0.08384021529721508\n",
            "training error 0.11495689857266411, test error 0.21916495478156237\n",
            "Loss: 0.10011689338991214\n",
            "training error 0.11503837779317723, test error 0.21897385972370217\n",
            "Loss: 0.012837256695186205\n",
            "training error 0.11485678248156696, test error 0.21932529505043422\n",
            "Loss: 0.17334976801983704\n",
            "training error 0.11493016050374441, test error 0.21950510698614162\n",
            "Loss: 0.25547601763431516\n",
            "training error 0.11480059399334143, test error 0.2195770035839382\n",
            "Loss: 0.28831364831687356\n",
            "training error 0.1148229764276745, test error 0.2196342973115546\n",
            "Loss: 0.3144816496625902\n",
            "training error 0.11485255923562666, test error 0.21965600271566543\n",
            "Loss: 0.3243952487180568\n",
            "training error 0.11482795317562536, test error 0.2193487808039947\n",
            "Loss: 0.18407651344807263\n",
            "training error 0.11480172295757272, test error 0.2195901358307315\n",
            "Loss: 0.29431159374748717\n",
            "training error 0.11498845354358797, test error 0.2196277935782118\n",
            "Loss: 0.311511172614809\n",
            "training error 0.11482906870526743, test error 0.21950983314403422\n",
            "Loss: 0.2576346152895814\n",
            "training error 0.11488815425857861, test error 0.2192577130868206\n",
            "Loss: 0.14248277806538923\n",
            "training error 0.11482908172694735, test error 0.21953502660382737\n",
            "Loss: 0.2691413284534372\n",
            "training error 0.11471565735278157, test error 0.21943904808602008\n",
            "Loss: 0.22530466277237426\n",
            "training error 0.11466625122190154, test error 0.2195131133039347\n",
            "Loss: 0.2591327762970774\n",
            "training error 0.11467519308983283, test error 0.21939567028704113\n",
            "Loss: 0.20549254110950876\n",
            "training error 0.1148914421847631, test error 0.21890954790818049\n",
            "Loss: 0.0\n",
            "training error 0.11466571531660115, test error 0.21938473062477695\n",
            "Loss: 0.21706806356194264\n",
            "training error 0.11470114514662282, test error 0.21917350905401287\n",
            "Loss: 0.12058000592238827\n",
            "training error 0.11465316875598477, test error 0.21952183118277036\n",
            "Loss: 0.2796969252554904\n",
            "training error 0.11459426927679578, test error 0.21943704743551548\n",
            "Loss: 0.2409668890076322\n",
            "training error 0.11468653780132107, test error 0.21981793852917597\n",
            "Loss: 0.41496162669729664\n",
            "training error 0.11475570925393307, test error 0.21956309028750448\n",
            "Loss: 0.29854448358648256\n",
            "training error 0.11465963511869141, test error 0.21922742900797573\n",
            "Loss: 0.14521116270751477\n",
            "training error 0.11487382620893163, test error 0.21953081229464497\n",
            "Loss: 0.2837995840752727\n",
            "training error 0.11463909901320629, test error 0.21939337958176117\n",
            "Loss: 0.22101899081332643\n",
            "training error 0.11455314188711269, test error 0.21937037346187743\n",
            "Loss: 0.21050957260677627\n",
            "training error 0.11462254300175498, test error 0.21970121913211066\n",
            "Loss: 0.3616430765560841\n",
            "training error 0.11471775764559462, test error 0.21919985950218562\n",
            "Loss: 0.1326171456563996\n",
            "training error 0.11453279375176942, test error 0.21966309418919816\n",
            "Loss: 0.3442272336763308\n",
            "training error 0.11467023241621672, test error 0.22014576361061844\n",
            "Loss: 0.5647152964549873\n",
            "training error 0.1145178537237241, test error 0.21951091050590127\n",
            "Loss: 0.2747082543759216\n",
            "training error 0.1146228455469106, test error 0.21961081770357252\n",
            "Loss: 0.32034682913244517\n",
            "training error 0.11460023853766546, test error 0.21998857434000382\n",
            "Loss: 0.49290971642586\n",
            "training error 0.11468470982602573, test error 0.22016209179901403\n",
            "Loss: 0.5721741709315165\n",
            "training error 0.11452570242937504, test error 0.21976229940304406\n",
            "Loss: 0.3895451354279267\n",
            "training error 0.11439945854088533, test error 0.2195297165101962\n",
            "Loss: 0.2832990191345308\n",
            "training error 0.11451877772824237, test error 0.21965339186313723\n",
            "Loss: 0.3397951172366076\n",
            "training error 0.11454600527401543, test error 0.21915002275022807\n",
            "Loss: 0.10985123506281891\n",
            "training error 0.1146069409525558, test error 0.21966307098082086\n",
            "Loss: 0.34421663186496865\n",
            "training error 0.1145370064547245, test error 0.2191693931693461\n",
            "Loss: 0.11869982997481099\n",
            "training error 0.114496194327899, test error 0.21932347554820977\n",
            "Loss: 0.18908615178490074\n",
            "training error 0.1144658360308111, test error 0.21913928646113995\n",
            "Loss: 0.10494679430603782\n",
            "training error 0.11441678565689206, test error 0.21891743409156816\n",
            "Loss: 0.0036024848906857088\n",
            "training error 0.11454014741045464, test error 0.21884530786793213\n",
            "Loss: 0.0\n",
            "training error 0.11436362109302584, test error 0.21902793406968135\n",
            "Loss: 0.08344990510804617\n",
            "training error 0.11436257952439184, test error 0.2190433758380347\n",
            "Loss: 0.0905059249532103\n",
            "training error 0.11476523602428723, test error 0.21857108454330218\n",
            "Loss: 0.0\n",
            "training error 0.11436629378038576, test error 0.21886737077117752\n",
            "Loss: 0.13555600389429934\n",
            "training error 0.11435067441179422, test error 0.21857843202061322\n",
            "Loss: 0.003361596217721363\n",
            "training error 0.11435682036363197, test error 0.21871371368125928\n",
            "Loss: 0.06525526386764735\n",
            "training error 0.11428686550091213, test error 0.21896799508997358\n",
            "Loss: 0.18159334639380464\n",
            "training error 0.1143576770062492, test error 0.21873925127809757\n",
            "Loss: 0.07693915009241437\n",
            "training error 0.11441376104795176, test error 0.21903835639637476\n",
            "Loss: 0.2137848444358159\n",
            "training error 0.11421580309149776, test error 0.21872736265486498\n",
            "Loss: 0.07149990214365687\n",
            "training error 0.11425397001064794, test error 0.21883796896851723\n",
            "Loss: 0.12210417758264924\n",
            "training error 0.11425635118687968, test error 0.21897913213533116\n",
            "Loss: 0.18668873464282587\n",
            "training error 0.1144152006472804, test error 0.2188095963165831\n",
            "Loss: 0.10912320528548847\n",
            "training error 0.11439818511808625, test error 0.21889215911222606\n",
            "Loss: 0.1468970928129698\n",
            "training error 0.11419388332611169, test error 0.2187164997038562\n",
            "Loss: 0.06652991673525843\n",
            "training error 0.11417652893132976, test error 0.21899843163627103\n",
            "Loss: 0.19551858557218527\n",
            "training error 0.11417551020857425, test error 0.2188452663647126\n",
            "Loss: 0.12544286083555622\n",
            "training error 0.11421343799651294, test error 0.21901546416915516\n",
            "Loss: 0.20331125994157428\n",
            "training error 0.11415968317674546, test error 0.2189186293431431\n",
            "Loss: 0.15900767503949087\n",
            "training error 0.11416896933253662, test error 0.21874649946535285\n",
            "Loss: 0.08025531941573405\n",
            "training error 0.11412731402348887, test error 0.21885428899182666\n",
            "Loss: 0.12957086666620654\n",
            "training error 0.11413393886727097, test error 0.2186619890776595\n",
            "Loss: 0.0415903752992941\n",
            "training error 0.11424432723399452, test error 0.2184894393036284\n",
            "Loss: 0.0\n",
            "training error 0.11447192708146608, test error 0.2180949360674905\n",
            "Loss: 0.0\n",
            "training error 0.11418441096885877, test error 0.21845984360739343\n",
            "Loss: 0.1673159159413018\n",
            "training error 0.11414076987821489, test error 0.21871727551960363\n",
            "Loss: 0.28535254570081214\n",
            "training error 0.11409257980311933, test error 0.21890581227866354\n",
            "Loss: 0.3717996510116617\n",
            "training error 0.11401389942994826, test error 0.2189338841604909\n",
            "Loss: 0.3846710557006139\n",
            "training error 0.11402931223015572, test error 0.21886943619907495\n",
            "Loss: 0.35512063945619676\n",
            "training error 0.11414917484974933, test error 0.21871441603980393\n",
            "Loss: 0.2840414286931159\n",
            "training error 0.11408391919496325, test error 0.21848766401509304\n",
            "Loss: 0.18007201573950748\n",
            "training error 0.11403247555520499, test error 0.21873655532394426\n",
            "Loss: 0.29419264290262426\n",
            "training error 0.11405155009192211, test error 0.21865774225150733\n",
            "Loss: 0.25805559457954264\n",
            "training error 0.11401650878785873, test error 0.21849747217809046\n",
            "Loss: 0.18456921460816567\n",
            "training error 0.11399184946853749, test error 0.21833864904934533\n",
            "Loss: 0.1117462818024384\n",
            "training error 0.11404103002494004, test error 0.21849221175572678\n",
            "Loss: 0.18215722721472982\n",
            "training error 0.11398428880661973, test error 0.21848456749656162\n",
            "Loss: 0.1786522126999479\n",
            "training error 0.1140737278153695, test error 0.21849987941898788\n",
            "Loss: 0.18567297288005769\n",
            "training error 0.1139392434178801, test error 0.2187914016467446\n",
            "Loss: 0.3193405549950734\n",
            "training error 0.11414983855225277, test error 0.21888004122766894\n",
            "Loss: 0.35998321388603927\n",
            "training error 0.1139451677917995, test error 0.2187294287298215\n",
            "Loss: 0.2909249860504115\n",
            "training error 0.11390754254210053, test error 0.21850960270860284\n",
            "Loss: 0.19013125595177538\n",
            "training error 0.11402290001707278, test error 0.21887668390177423\n",
            "Loss: 0.3584438265186618\n",
            "training error 0.11417358739750938, test error 0.21865490893437037\n",
            "Loss: 0.2567564735691974\n",
            "training error 0.11394729178017109, test error 0.2187678530891458\n",
            "Loss: 0.3085431664708871\n",
            "training error 0.11417449375824881, test error 0.21926495775819538\n",
            "Loss: 0.5364735705476464\n",
            "training error 0.11394683200440094, test error 0.21859005585959987\n",
            "Loss: 0.22702030640278092\n",
            "training error 0.114324826439055, test error 0.21918518132933917\n",
            "Loss: 0.4998948079708132\n",
            "training error 0.11392860004774383, test error 0.21848748207445773\n",
            "Loss: 0.1799885930619416\n",
            "training error 0.11381782409177557, test error 0.21850471767300206\n",
            "Loss: 0.18789138936483596\n",
            "training error 0.11389792180859873, test error 0.21864769553265986\n",
            "Loss: 0.2534490140561063\n",
            "training error 0.11383817832782023, test error 0.21858327808729025\n",
            "Loss: 0.22391258990470675\n",
            "training error 0.11389756872341228, test error 0.21819767063115836\n",
            "Loss: 0.04710543285428859\n",
            "training error 0.11377987528372113, test error 0.21810905821200022\n",
            "Loss: 0.006475228065516703\n",
            "training error 0.11383744628794026, test error 0.21818798232174585\n",
            "Loss: 0.04266318876222641\n",
            "training error 0.11381943184340605, test error 0.21827091764393086\n",
            "Loss: 0.08069035421616189\n",
            "training error 0.11380047373603563, test error 0.21814004938150044\n",
            "Loss: 0.020685172624079762\n",
            "training error 0.11366873681192105, test error 0.2182119839562687\n",
            "Loss: 0.05366832026856283\n",
            "training error 0.11376649820741554, test error 0.21847833446293047\n",
            "Loss: 0.17579426755756078\n",
            "training error 0.11379366604334834, test error 0.21855243333477534\n",
            "Loss: 0.20976977986471024\n",
            "training error 0.11371229003917005, test error 0.21869277360818543\n",
            "Loss: 0.27411802927415074\n",
            "training error 0.11377348210263738, test error 0.21864201859993646\n",
            "Loss: 0.2508460500323828\n",
            "training error 0.11373544938209589, test error 0.21822684105323856\n",
            "Loss: 0.060480535736617824\n",
            "training error 0.11375601391935065, test error 0.2179659358957751\n",
            "Loss: 0.0\n",
            "training error 0.11378867003139972, test error 0.2184408379560732\n",
            "Loss: 0.2178790269894204\n",
            "training error 0.11375926991663232, test error 0.2182259104477696\n",
            "Loss: 0.11927301893577269\n",
            "training error 0.11354431355049024, test error 0.2179849447925256\n",
            "Loss: 0.008721040135184488\n",
            "training error 0.11356906921833375, test error 0.21802478881483772\n",
            "Loss: 0.02700097096399734\n",
            "training error 0.11352565716832008, test error 0.21801350949263143\n",
            "Loss: 0.021826161349847162\n",
            "training error 0.11353173662093499, test error 0.2177933248059817\n",
            "Loss: 0.0\n",
            "training error 0.11360549994922353, test error 0.2180205457665089\n",
            "Loss: 0.10432870737870914\n",
            "training error 0.11348608830431896, test error 0.2176974079792414\n",
            "Loss: 0.0\n",
            "training error 0.11350595181493367, test error 0.21764706638981524\n",
            "Loss: 0.0\n",
            "training error 0.11347932464183458, test error 0.21768770331604487\n",
            "Loss: 0.01867101951047445\n",
            "training error 0.11370876962100596, test error 0.2178617086163066\n",
            "Loss: 0.09861939793249785\n",
            "training error 0.11368474753932573, test error 0.2179238052666064\n",
            "Loss: 0.1271502903216426\n",
            "training error 0.11358876941724841, test error 0.21803534686621315\n",
            "Loss: 0.17839913160258014\n",
            "training error 0.11355802604473564, test error 0.21827803062987494\n",
            "Loss: 0.2899024785979032\n",
            "training error 0.11345775355344516, test error 0.21823797582317522\n",
            "Loss: 0.27149891940267956\n",
            "training error 0.113386519266892, test error 0.21829970135866553\n",
            "Loss: 0.29985929958797897\n",
            "training error 0.11347076459244389, test error 0.21811795405167417\n",
            "Loss: 0.2163537830625062\n",
            "training error 0.11342257926249802, test error 0.21847764668934916\n",
            "Loss: 0.3816179621949578\n",
            "training error 0.11349603387026758, test error 0.2183413617344889\n",
            "Loss: 0.3190005526792383\n",
            "training error 0.11332516217885265, test error 0.21809825959265577\n",
            "Loss: 0.20730497788215008\n",
            "training error 0.11335573275207425, test error 0.21787487302107475\n",
            "Loss: 0.10466790802110548\n",
            "training error 0.11333319857444141, test error 0.21788547456643928\n",
            "Loss: 0.10953888815439239\n",
            "training error 0.1132666586912001, test error 0.21793628213989538\n",
            "Loss: 0.13288290757944576\n",
            "training error 0.11330616987547379, test error 0.21773108304322183\n",
            "Loss: 0.038602244817820264\n",
            "training error 0.1136467942263419, test error 0.21756987876114642\n",
            "Loss: 0.0\n",
            "training error 0.11331237747422115, test error 0.2176006699301593\n",
            "Loss: 0.014152312437842873\n",
            "training error 0.11322889572314156, test error 0.21747791588615734\n",
            "Loss: 0.0\n",
            "training error 0.11328021753957034, test error 0.21778100755141028\n",
            "Loss: 0.1393666405243632\n",
            "training error 0.11338863364659031, test error 0.21751051233329682\n",
            "Loss: 0.014988394111958847\n",
            "training error 0.1131767588094451, test error 0.21782594582692696\n",
            "Loss: 0.1600300147035716\n",
            "training error 0.11312083493858818, test error 0.2179026411628528\n",
            "Loss: 0.19529581887192116\n",
            "training error 0.11321496410425166, test error 0.217880862692382\n",
            "Loss: 0.18528171220639766\n",
            "training error 0.1131754049057485, test error 0.21775811664243033\n",
            "Loss: 0.12884101594006214\n",
            "training error 0.11313257924789644, test error 0.21795831526836723\n",
            "Loss: 0.22089570807795056\n",
            "training error 0.11308853452614309, test error 0.21801136897334508\n",
            "Loss: 0.24529069308674156\n",
            "training error 0.11312393845190118, test error 0.2177860497364071\n",
            "Loss: 0.14168512190961824\n",
            "training error 0.1130367762706654, test error 0.21762054432114356\n",
            "Loss: 0.0655829509883965\n",
            "training error 0.11297331023701632, test error 0.21733849427041957\n",
            "Loss: 0.0\n",
            "training error 0.11316022673262609, test error 0.217419096479254\n",
            "Loss: 0.03708602523682103\n",
            "training error 0.1129930292330196, test error 0.21735521662125576\n",
            "Loss: 0.007694150496595498\n",
            "training error 0.1130994414582658, test error 0.2176424132733454\n",
            "Loss: 0.13983671136863496\n",
            "training error 0.11290846494392728, test error 0.21770567354819145\n",
            "Loss: 0.16894350860598983\n",
            "training error 0.1131163488680959, test error 0.2174058359115224\n",
            "Loss: 0.030984681903167832\n",
            "training error 0.11286519033516426, test error 0.2172287071801474\n",
            "Loss: 0.0\n",
            "training error 0.11283195864679287, test error 0.21734056552901215\n",
            "Loss: 0.05149335477654393\n",
            "training error 0.11309145798299375, test error 0.21738045263678257\n",
            "Loss: 0.06985515800603803\n",
            "training error 0.11287735474943762, test error 0.21706757491360862\n",
            "Loss: 0.0\n",
            "training error 0.11296516945762632, test error 0.21722714055125436\n",
            "Loss: 0.07350966062491526\n",
            "training error 0.11286825705610809, test error 0.21755810747929769\n",
            "Loss: 0.22598150179007348\n",
            "training error 0.1127616910758771, test error 0.21764618159887142\n",
            "Loss: 0.2665560185546312\n",
            "training error 0.11286154235890168, test error 0.21713741304817852\n",
            "Loss: 0.03217345317358955\n",
            "training error 0.11270063620083819, test error 0.2173020288569061\n",
            "Loss: 0.10800965708066546\n",
            "training error 0.11273412613646366, test error 0.21730232454485326\n",
            "Loss: 0.10814587638807716\n",
            "training error 0.11292923186270966, test error 0.2172574775174751\n",
            "Loss: 0.08748547724921618\n",
            "training error 0.11264339235536913, test error 0.21730674993281726\n",
            "Loss: 0.1101845908140886\n",
            "training error 0.11275258301614435, test error 0.217364926548575\n",
            "Loss: 0.1369857451462897\n",
            "training error 0.11259865974311956, test error 0.21707542830216547\n",
            "Loss: 0.0036179464205865486\n",
            "training error 0.11255724491207286, test error 0.21721393658861343\n",
            "Loss: 0.06742677945477116\n",
            "training error 0.11260843191215314, test error 0.21722576556259446\n",
            "Loss: 0.07287622255365278\n",
            "training error 0.1125754494308503, test error 0.2169634391442511\n",
            "Loss: 0.0\n",
            "training error 0.11246008804906138, test error 0.21663369929099205\n",
            "Loss: 0.0\n",
            "training error 0.11269800145400234, test error 0.21664198868775905\n",
            "Loss: 0.0038264576536883865\n",
            "training error 0.11257180065612908, test error 0.21633283810213258\n",
            "Loss: 0.0\n",
            "training error 0.11247851631178121, test error 0.21655999568281847\n",
            "Loss: 0.10500374454416317\n",
            "training error 0.11234861783447225, test error 0.2166541166475204\n",
            "Loss: 0.1485112238189812\n",
            "training error 0.11229799831703846, test error 0.21683081071875318\n",
            "Loss: 0.23018817715760864\n",
            "training error 0.1123722796989278, test error 0.21671517476093055\n",
            "Loss: 0.17673537783360338\n",
            "training error 0.11242430219749605, test error 0.21668241779665665\n",
            "Loss: 0.16159344905326556\n",
            "training error 0.1122160445638552, test error 0.2166274234250965\n",
            "Loss: 0.13617226378956904\n",
            "training error 0.1122230670473691, test error 0.21646990034732524\n",
            "Loss: 0.06335711508020925\n",
            "training error 0.11213786775994156, test error 0.21639685164315445\n",
            "Loss: 0.029590302417070724\n",
            "training error 0.11231584493822201, test error 0.21605005144046902\n",
            "Loss: 0.0\n",
            "training error 0.11211035238206458, test error 0.2160357222818668\n",
            "Loss: 0.0\n",
            "training error 0.11227289850698798, test error 0.21624752659117305\n",
            "Loss: 0.09804133643689372\n",
            "training error 0.1122039228992335, test error 0.2158795301908409\n",
            "Loss: 0.0\n",
            "training error 0.11206137608675042, test error 0.2159606288458561\n",
            "Loss: 0.03756662567473423\n",
            "training error 0.11214719490364645, test error 0.21618278523727064\n",
            "Loss: 0.1404742015890248\n",
            "training error 0.11203785236324414, test error 0.21596528614202953\n",
            "Loss: 0.03972398453564452\n",
            "training error 0.11200795078323854, test error 0.21608185295290114\n",
            "Loss: 0.09372021603037961\n",
            "training error 0.1119780084013665, test error 0.21609774089090902\n",
            "Loss: 0.10107984757758981\n",
            "training error 0.11189131449839344, test error 0.2159933747945319\n",
            "Loss: 0.05273524710303068\n",
            "training error 0.1119277919613022, test error 0.2159061850774419\n",
            "Loss: 0.012347111640176323\n",
            "training error 0.11176237929173564, test error 0.21603832039718648\n",
            "Loss: 0.07355500829799855\n",
            "training error 0.11172359422659885, test error 0.21594832321163865\n",
            "Loss: 0.031866393602442145\n",
            "training error 0.11166253464092096, test error 0.21600183605611867\n",
            "Loss: 0.05665468382742844\n",
            "training error 0.11168542748466077, test error 0.21608600213828472\n",
            "Loss: 0.09564220714268767\n",
            "training error 0.11170840206865386, test error 0.21567739874473957\n",
            "Loss: 0.0\n",
            "training error 0.11154945339116124, test error 0.2156318472391798\n",
            "Loss: 0.0\n",
            "training error 0.11153663962211029, test error 0.21573955468944803\n",
            "Loss: 0.04994969511564751\n",
            "training error 0.11159807178625182, test error 0.21546038063686387\n",
            "Loss: 0.0\n",
            "training error 0.11145987944868853, test error 0.2154145964460023\n",
            "Loss: 0.0\n",
            "training error 0.11140144784331313, test error 0.215632228362837\n",
            "Loss: 0.10102932690043698\n",
            "training error 0.11135857529959307, test error 0.2155584112421031\n",
            "Loss: 0.06676186222915881\n",
            "training error 0.11132168979643452, test error 0.21537638823447938\n",
            "Loss: 0.0\n",
            "training error 0.11128890786357272, test error 0.21540222367410203\n",
            "Loss: 0.011995483736360057\n",
            "training error 0.11133890483274839, test error 0.21532968960292548\n",
            "Loss: 0.0\n",
            "training error 0.1113377918131893, test error 0.2150750822969333\n",
            "Loss: 0.0\n",
            "training error 0.11132445410433953, test error 0.21481255040488362\n",
            "Loss: 0.0\n",
            "training error 0.11130701327707747, test error 0.21466387620711133\n",
            "Loss: 0.0\n",
            "training error 0.11108477084869706, test error 0.2145419805275134\n",
            "Loss: 0.0\n",
            "training error 0.11110575832492642, test error 0.21455316068811336\n",
            "Loss: 0.005211176186814548\n",
            "training error 0.11104480732512653, test error 0.21470794066490836\n",
            "Loss: 0.07735555390460114\n",
            "training error 0.1109049316603068, test error 0.2146445836336268\n",
            "Loss: 0.04782425605520668\n",
            "training error 0.11123529050006425, test error 0.21471993140651743\n",
            "Loss: 0.08294454939146156\n",
            "training error 0.110798915783049, test error 0.2150189502535455\n",
            "Loss: 0.22231999763373533\n",
            "training error 0.11086839060975234, test error 0.21482956114496526\n",
            "Loss: 0.13404398372047766\n",
            "training error 0.1109363309738862, test error 0.2143764642060803\n",
            "Loss: 0.0\n",
            "training error 0.11079021672692439, test error 0.2144877338528606\n",
            "Loss: 0.05190385390130281\n",
            "training error 0.11062752983092793, test error 0.21429187789224294\n",
            "Loss: 0.0\n",
            "training error 0.11086143876840726, test error 0.21431327839149206\n",
            "Loss: 0.009986612399681682\n",
            "training error 0.11065986088300651, test error 0.21470403705656516\n",
            "Loss: 0.1923354111113218\n",
            "training error 0.11054797731138194, test error 0.214667006564524\n",
            "Loss: 0.17505501187016215\n",
            "training error 0.11042038944563932, test error 0.21431828553712898\n",
            "Loss: 0.012323213154785684\n",
            "training error 0.11037259805549286, test error 0.21406174428042563\n",
            "Loss: 0.0\n",
            "training error 0.11033619413761139, test error 0.21392275660030646\n",
            "Loss: 0.0\n",
            "training error 0.1102590801513701, test error 0.21379921143948247\n",
            "Loss: 0.0\n",
            "training error 0.11026181143533959, test error 0.21361809762526424\n",
            "Loss: 0.0\n",
            "training error 0.11017999097799046, test error 0.21369310675916076\n",
            "Loss: 0.035113660654406686\n",
            "training error 0.11014240453066265, test error 0.21346070777191187\n",
            "Loss: 0.0\n",
            "training error 0.11005184033482447, test error 0.21349697616310978\n",
            "Loss: 0.01699066379778902\n",
            "training error 0.10998617492566327, test error 0.21345722792839322\n",
            "Loss: 0.0\n",
            "training error 0.10994795630170921, test error 0.21313259198961887\n",
            "Loss: 0.0\n",
            "training error 0.11008487720940142, test error 0.2129241570352791\n",
            "Loss: 0.0\n",
            "training error 0.11000326236346726, test error 0.21313720188573132\n",
            "Loss: 0.10005668375943078\n",
            "training error 0.10973363216757874, test error 0.2129531586238473\n",
            "Loss: 0.013620619178222881\n",
            "training error 0.10974836970461495, test error 0.212878629702852\n",
            "Loss: 0.0\n",
            "training error 0.10958431677662446, test error 0.2129236433677654\n",
            "Loss: 0.021145224852414657\n",
            "training error 0.10957910820190991, test error 0.2126805278494328\n",
            "Loss: 0.0\n",
            "training error 0.10958257954857534, test error 0.21255509869516173\n",
            "Loss: 0.0\n",
            "training error 0.10958730017805487, test error 0.21258736940541983\n",
            "Loss: 0.015182280009384819\n",
            "training error 0.10936037009543075, test error 0.21248761667585814\n",
            "Loss: 0.0\n",
            "training error 0.10932032197576064, test error 0.21239858635375863\n",
            "Loss: 0.0\n",
            "training error 0.10930739264079363, test error 0.21255177985694268\n",
            "Loss: 0.0721254815363448\n",
            "training error 0.10916877005988725, test error 0.21258916463964322\n",
            "Loss: 0.0897267204816421\n",
            "training error 0.1092091073123456, test error 0.21206694793337602\n",
            "Loss: 0.0\n",
            "training error 0.10920847906289687, test error 0.2117698808188897\n",
            "Loss: 0.0\n",
            "training error 0.10906743703810044, test error 0.2117773717174468\n",
            "Loss: 0.0035372823217860727\n",
            "training error 0.1089718244487774, test error 0.21161797049005956\n",
            "Loss: 0.0\n",
            "training error 0.10900342613875005, test error 0.21147221193746052\n",
            "Loss: 0.0\n",
            "training error 0.10886584020891388, test error 0.2114578189905453\n",
            "Loss: 0.0\n",
            "training error 0.10879835675357803, test error 0.21148368954744287\n",
            "Loss: 0.012234381788789328\n",
            "training error 0.10867325104491567, test error 0.21142435749274144\n",
            "Loss: 0.0\n",
            "training error 0.10869038531921996, test error 0.2111865642800595\n",
            "Loss: 0.0\n",
            "training error 0.10856802646253955, test error 0.2111088896092612\n",
            "Loss: 0.0\n",
            "training error 0.10851568393284801, test error 0.2112025095630268\n",
            "Loss: 0.044346760545654895\n",
            "training error 0.10849518994370934, test error 0.21113258778080893\n",
            "Loss: 0.011225567806083525\n",
            "training error 0.10829830495022005, test error 0.21093846782654058\n",
            "Loss: 0.0\n",
            "training error 0.10824727020294594, test error 0.2109496153114008\n",
            "Loss: 0.00528470931597802\n",
            "training error 0.10828234315233802, test error 0.21085255179012613\n",
            "Loss: 0.0\n",
            "training error 0.10828471303142057, test error 0.2105821734285616\n",
            "Loss: 0.0\n",
            "training error 0.10807823700272957, test error 0.21045078783259663\n",
            "Loss: 0.0\n",
            "training error 0.10797425223139819, test error 0.2105420622172426\n",
            "Loss: 0.04337089235253444\n",
            "training error 0.10794017959332412, test error 0.2105214780914763\n",
            "Loss: 0.033589923614774087\n",
            "training error 0.10790174063473786, test error 0.21018864158553677\n",
            "Loss: 0.0\n",
            "training error 0.10794435016315064, test error 0.21028125489564223\n",
            "Loss: 0.044061995646793584\n",
            "training error 0.10785190328621352, test error 0.21030273992911996\n",
            "Loss: 0.054283781807851206\n",
            "training error 0.10793314937347812, test error 0.2097824679648416\n",
            "Loss: 0.0\n",
            "training error 0.10757564651362217, test error 0.20971799740413452\n",
            "Loss: 0.0\n",
            "training error 0.10762117834537961, test error 0.20960374783029836\n",
            "Loss: 0.0\n",
            "training error 0.10760064031980862, test error 0.20966513638288675\n",
            "Loss: 0.029287907885167108\n",
            "training error 0.10737222071613994, test error 0.20957238312928553\n",
            "Loss: 0.0\n",
            "training error 0.10724380875852899, test error 0.20960175270357112\n",
            "Loss: 0.014014047961397047\n",
            "training error 0.10732585369351826, test error 0.20919102990507937\n",
            "Loss: 0.0\n",
            "training error 0.10719821420847885, test error 0.20930032054254818\n",
            "Loss: 0.05224441866289453\n",
            "training error 0.1070350626593021, test error 0.2094400666376425\n",
            "Loss: 0.11904751971254512\n",
            "training error 0.10695935930584212, test error 0.20918204763024198\n",
            "Loss: 0.0\n",
            "training error 0.1068639846461038, test error 0.20894414921342572\n",
            "Loss: 0.0\n",
            "training error 0.10680404691732977, test error 0.2088516273990173\n",
            "Loss: 0.0\n",
            "training error 0.10681320242941073, test error 0.20907879455774192\n",
            "Loss: 0.10876963783030824\n",
            "training error 0.1066769357532019, test error 0.20870809167706406\n",
            "Loss: 0.0\n",
            "training error 0.1065574259923506, test error 0.20880178526829563\n",
            "Loss: 0.04489216995791079\n",
            "training error 0.10646722416747528, test error 0.20839609334161027\n",
            "Loss: 0.0\n",
            "training error 0.1063634063456701, test error 0.2082143207688055\n",
            "Loss: 0.0\n",
            "training error 0.10643866304326986, test error 0.20809935130570625\n",
            "Loss: 0.0\n",
            "training error 0.10625934734934166, test error 0.20815584056379052\n",
            "Loss: 0.02714533117467166\n",
            "training error 0.10613311852858623, test error 0.20791053019826777\n",
            "Loss: 0.0\n",
            "training error 0.10604919212800214, test error 0.20787630684567837\n",
            "Loss: 0.0\n",
            "training error 0.10602300495742202, test error 0.2081509859049874\n",
            "Loss: 0.1321358183994148\n",
            "training error 0.10578578446729822, test error 0.20773654271909284\n",
            "Loss: 0.0\n",
            "training error 0.10571910780424768, test error 0.20746908278693243\n",
            "Loss: 0.0\n",
            "training error 0.10564776119383129, test error 0.20763444226780756\n",
            "Loss: 0.07970319174974705\n",
            "training error 0.10555493087730056, test error 0.2073534124202301\n",
            "Loss: 0.0\n",
            "training error 0.10553653591955799, test error 0.2070588101424928\n",
            "Loss: 0.0\n",
            "training error 0.10546721387712184, test error 0.2070053894837561\n",
            "Loss: 0.0\n",
            "training error 0.10547077550534192, test error 0.2068571500923816\n",
            "Loss: 0.0\n",
            "training error 0.10524534803913006, test error 0.20680935437166675\n",
            "Loss: 0.0\n",
            "training error 0.10513871788337684, test error 0.20653624842403573\n",
            "Loss: 0.0\n",
            "training error 0.10505572599883034, test error 0.20628106050581957\n",
            "Loss: 0.0\n",
            "training error 0.10498365465153367, test error 0.20635679120957426\n",
            "Loss: 0.03671238821876255\n",
            "training error 0.10489049254868084, test error 0.20631927151656448\n",
            "Loss: 0.018523761052624543\n",
            "training error 0.1048913702617, test error 0.2058794503590697\n",
            "Loss: 0.0\n",
            "training error 0.10485882851226551, test error 0.20588505022754208\n",
            "Loss: 0.0027199744620398647\n",
            "training error 0.10494712769763292, test error 0.20579685385840918\n",
            "Loss: 0.0\n",
            "training error 0.10453014578183764, test error 0.20582365547878675\n",
            "Loss: 0.013023338245976568\n",
            "training error 0.10450188442731422, test error 0.20590588340367658\n",
            "Loss: 0.052979208973913394\n",
            "training error 0.10459709690540991, test error 0.2058967960227354\n",
            "Loss: 0.04856350447173252\n",
            "training error 0.10424012104822233, test error 0.20545996093102067\n",
            "Loss: 0.0\n",
            "training error 0.10421758238016626, test error 0.2053875282104289\n",
            "Loss: 0.0\n",
            "training error 0.10413452430781207, test error 0.20482116278016566\n",
            "Loss: 0.0\n",
            "training error 0.10426061212437417, test error 0.2053538396549284\n",
            "Loss: 0.26006925628796473\n",
            "training error 0.10389185429674641, test error 0.20510912742168916\n",
            "Loss: 0.140593207076245\n",
            "training error 0.10380839025290309, test error 0.2046563840377871\n",
            "Loss: 0.0\n",
            "training error 0.10373919149005807, test error 0.20437684442305615\n",
            "Loss: 0.0\n",
            "training error 0.10359050359772644, test error 0.20427082078340753\n",
            "Loss: 0.0\n",
            "training error 0.10355515754938845, test error 0.2043672219701196\n",
            "Loss: 0.04719283270238073\n",
            "training error 0.103495790279243, test error 0.20433410882200384\n",
            "Loss: 0.03098241753451969\n",
            "training error 0.10336959428644378, test error 0.2038723956096926\n",
            "Loss: 0.0\n",
            "training error 0.10325780120122435, test error 0.20368849451448046\n",
            "Loss: 0.0\n",
            "training error 0.1032582706116792, test error 0.20357887731512175\n",
            "Loss: 0.0\n",
            "training error 0.10318966623547185, test error 0.20333350259501531\n",
            "Loss: 0.0\n",
            "training error 0.10312669644801829, test error 0.20371543058958969\n",
            "Loss: 0.1878332835957064\n",
            "training error 0.10302786387762211, test error 0.20347538199414286\n",
            "Loss: 0.06977669558476673\n",
            "training error 0.10299495766562311, test error 0.2033730559900332\n",
            "Loss: 0.019452473160153083\n",
            "training error 0.10283191725898393, test error 0.2033228017968867\n",
            "Loss: 0.0\n",
            "training error 0.10266636092392983, test error 0.20314539205214346\n",
            "Loss: 0.0\n",
            "training error 0.10273875335806075, test error 0.2031305904238583\n",
            "Loss: 0.0\n",
            "training error 0.10242215931538524, test error 0.20285430045452688\n",
            "Loss: 0.0\n",
            "training error 0.10237531113797604, test error 0.20240108020684486\n",
            "Loss: 0.0\n",
            "training error 0.10229922021136953, test error 0.20232643294022248\n",
            "Loss: 0.0\n",
            "training error 0.10226663169528731, test error 0.20243517689354337\n",
            "Loss: 0.05374678520280174\n",
            "training error 0.10228290849812399, test error 0.20253127836282206\n",
            "Loss: 0.10124501263761854\n",
            "training error 0.10201158039230121, test error 0.2024262769397304\n",
            "Loss: 0.04934797596980456\n",
            "training error 0.10202205241932541, test error 0.20233148056676267\n",
            "Loss: 0.0024947934221142276\n",
            "training error 0.1018365089430025, test error 0.20226378396418224\n",
            "Loss: 0.0\n",
            "training error 0.10187982089465297, test error 0.20188121318211613\n",
            "Loss: 0.0\n",
            "training error 0.1016473079215034, test error 0.202010262132898\n",
            "Loss: 0.06392320946944086\n",
            "training error 0.10165606831552962, test error 0.20205481303045839\n",
            "Loss: 0.08599108634523844\n",
            "training error 0.10146290680772409, test error 0.20195369495930607\n",
            "Loss: 0.03590318090893607\n",
            "training error 0.1013984153648297, test error 0.20164563672257907\n",
            "Loss: 0.0\n",
            "training error 0.10134532703316769, test error 0.20186229959011628\n",
            "Loss: 0.10744733734819878\n",
            "training error 0.1012014152254161, test error 0.20166202823127785\n",
            "Loss: 0.008128868526591226\n",
            "training error 0.10120970084392836, test error 0.2012838274151191\n",
            "Loss: 0.0\n",
            "training error 0.10104614308080605, test error 0.20145112304146473\n",
            "Loss: 0.08311429114500335\n",
            "training error 0.10087396749865762, test error 0.200834375813572\n",
            "Loss: 0.0\n",
            "training error 0.10085972699036086, test error 0.20095155169075934\n",
            "Loss: 0.058344532260812265\n",
            "training error 0.10060193137077161, test error 0.20045094128087665\n",
            "Loss: 0.0\n",
            "training error 0.10050987811160698, test error 0.19994495957234842\n",
            "Loss: 0.0\n",
            "training error 0.1004530896245512, test error 0.19960734841562144\n",
            "Loss: 0.0\n",
            "training error 0.10040196715434943, test error 0.19973456814993246\n",
            "Loss: 0.06373499539009675\n",
            "training error 0.1003224970142834, test error 0.19960351621802563\n",
            "Loss: 0.0\n",
            "training error 0.10018903945663166, test error 0.19927407022704322\n",
            "Loss: 0.0\n",
            "training error 0.10009149524738666, test error 0.19926861967266965\n",
            "Loss: 0.0\n",
            "training error 0.09990858418924653, test error 0.19925128079260748\n",
            "Loss: 0.0\n",
            "training error 0.0998843721713311, test error 0.19916877016880094\n",
            "Loss: 0.0\n",
            "training error 0.09970808814113746, test error 0.19888897949114404\n",
            "Loss: 0.0\n",
            "training error 0.09969073887374573, test error 0.19846214931287814\n",
            "Loss: 0.0\n",
            "training error 0.09954516409350622, test error 0.19841365722612103\n",
            "Loss: 0.0\n",
            "training error 0.0994939631355433, test error 0.19837617976729083\n",
            "Loss: 0.0\n",
            "training error 0.099395091392656, test error 0.1985135521425812\n",
            "Loss: 0.0692484225936374\n",
            "training error 0.09946003570869463, test error 0.1991367986132722\n",
            "Loss: 0.3834224688032739\n",
            "training error 0.09917234749170663, test error 0.19886371037765724\n",
            "Loss: 0.24576066085066905\n",
            "training error 0.09899460974542532, test error 0.1984125819927638\n",
            "Loss: 0.018350099047004242\n",
            "training error 0.09904184175070903, test error 0.19778513825733118\n",
            "Loss: 0.0\n",
            "training error 0.09884948833420715, test error 0.1981003121038108\n",
            "Loss: 0.15935163241109773\n",
            "training error 0.0988357719504491, test error 0.1974777799408012\n",
            "Loss: 0.0\n",
            "training error 0.09867526294401578, test error 0.19723810402623618\n",
            "Loss: 0.0\n",
            "training error 0.09904570160438467, test error 0.19749192740667815\n",
            "Loss: 0.1286888158325672\n",
            "training error 0.09842352296849154, test error 0.19719718916927187\n",
            "Loss: 0.0\n",
            "training error 0.09824117979796218, test error 0.19719750982405415\n",
            "Loss: 0.0001626061627124642\n",
            "training error 0.0983906742423356, test error 0.1970448915093039\n",
            "Loss: 0.0\n",
            "training error 0.09810844508989322, test error 0.19691909854274173\n",
            "Loss: 0.0\n",
            "training error 0.0979543811563992, test error 0.19673217478712235\n",
            "Loss: 0.0\n",
            "training error 0.09790201091709737, test error 0.1964031998134416\n",
            "Loss: 0.0\n",
            "training error 0.09771256578860618, test error 0.19666871965592866\n",
            "Loss: 0.1351911999087907\n",
            "training error 0.09752265014471893, test error 0.1962505299381113\n",
            "Loss: 0.0\n",
            "training error 0.09744559452744082, test error 0.19635634966728002\n",
            "Loss: 0.05392073550176679\n",
            "training error 0.09757184173765748, test error 0.1963764509699524\n",
            "Loss: 0.06416340984192193\n",
            "training error 0.09721753010909147, test error 0.19591087565151058\n",
            "Loss: 0.0\n",
            "training error 0.09713472058155813, test error 0.19551555981088703\n",
            "Loss: 0.0\n",
            "training error 0.0971540012793931, test error 0.19524484379514548\n",
            "Loss: 0.0\n",
            "training error 0.09705939635740783, test error 0.19517676673816078\n",
            "Loss: 0.0\n",
            "training error 0.09699928968273284, test error 0.1947263669365767\n",
            "Loss: 0.0\n",
            "training error 0.09680989231960378, test error 0.19493727706413808\n",
            "Loss: 0.10831102684212279\n",
            "training error 0.09663154581179666, test error 0.19472329090169063\n",
            "Loss: 0.0\n",
            "training error 0.09656052142898154, test error 0.19478256325486829\n",
            "Loss: 0.0304392725200886\n",
            "training error 0.09652692600117249, test error 0.1944683083349564\n",
            "Loss: 0.0\n",
            "training error 0.0963916880169862, test error 0.19457611202938255\n",
            "Loss: 0.05543509651992906\n",
            "training error 0.09637376474638878, test error 0.19452562414733082\n",
            "Loss: 0.02947308631682244\n",
            "training error 0.09609147429122811, test error 0.19397691635713302\n",
            "Loss: 0.0\n",
            "training error 0.09610143972603588, test error 0.19382438551847797\n",
            "Loss: 0.0\n",
            "training error 0.09585624716507694, test error 0.19406062227221943\n",
            "Loss: 0.12188185357044912\n",
            "training error 0.09573641836158887, test error 0.19372523255883337\n",
            "Loss: 0.0\n",
            "training error 0.0957343379006343, test error 0.19380763181537564\n",
            "Loss: 0.042534085753254125\n",
            "training error 0.09569639254412614, test error 0.1938086955025874\n",
            "Loss: 0.043083155793177674\n",
            "training error 0.095475077670512, test error 0.19342078470471835\n",
            "Loss: 0.0\n",
            "training error 0.09524707165093449, test error 0.19347928452405305\n",
            "Loss: 0.030244846449156704\n",
            "training error 0.09507668117179127, test error 0.19302389885830495\n",
            "Loss: 0.0\n",
            "training error 0.09501503316115974, test error 0.19304784880705927\n",
            "Loss: 0.01240776344069161\n",
            "training error 0.09497405158666566, test error 0.19281897636341558\n",
            "Loss: 0.0\n",
            "training error 0.09486830340120486, test error 0.19211052540681434\n",
            "Loss: 0.0\n",
            "training error 0.09474812316830293, test error 0.19214123376168846\n",
            "Loss: 0.015984733168106224\n",
            "training error 0.0945837160616316, test error 0.19202043667716642\n",
            "Loss: 0.0\n",
            "training error 0.09448076376464501, test error 0.19184750000648595\n",
            "Loss: 0.0\n",
            "training error 0.09446177414307813, test error 0.19147336511740548\n",
            "Loss: 0.0\n",
            "training error 0.09427308518075345, test error 0.19134432034260376\n",
            "Loss: 0.0\n",
            "training error 0.09417572973844966, test error 0.1912717875145184\n",
            "Loss: 0.0\n",
            "training error 0.0940554050636268, test error 0.19108526823292296\n",
            "Loss: 0.0\n",
            "training error 0.09399780359666378, test error 0.19160303982030422\n",
            "Loss: 0.2709636342818955\n",
            "training error 0.09376252634874294, test error 0.19169586757711954\n",
            "Loss: 0.31954286682753796\n",
            "training error 0.0936205393036613, test error 0.19192664952668165\n",
            "Loss: 0.4403171953230256\n",
            "training error 0.09354758130196925, test error 0.1910459904832821\n",
            "Loss: 0.0\n",
            "training error 0.0934520123315953, test error 0.19071137847623562\n",
            "Loss: 0.0\n",
            "training error 0.09327781679192604, test error 0.19047742921555585\n",
            "Loss: 0.0\n",
            "training error 0.09307235627943129, test error 0.19051284735569757\n",
            "Loss: 0.018594402647909014\n",
            "training error 0.09310896386883903, test error 0.1905973717012247\n",
            "Loss: 0.06296939546213132\n",
            "training error 0.09287505980753703, test error 0.1899383471699387\n",
            "Loss: 0.0\n",
            "training error 0.09273787832575128, test error 0.18974457261184782\n",
            "Loss: 0.0\n",
            "training error 0.0926343884823288, test error 0.18939104781850638\n",
            "Loss: 0.0\n",
            "training error 0.09261281620031628, test error 0.18928805879508712\n",
            "Loss: 0.0\n",
            "training error 0.0924120502826405, test error 0.18914784976554147\n",
            "Loss: 0.0\n",
            "training error 0.09226935546296332, test error 0.18901596632225826\n",
            "Loss: 0.0\n",
            "training error 0.09231632795152246, test error 0.18900079115243293\n",
            "Loss: 0.0\n",
            "training error 0.09208695752813453, test error 0.1890136790019078\n",
            "Loss: 0.006818939432107207\n",
            "training error 0.09185408810448172, test error 0.18893134270288445\n",
            "Loss: 0.0\n",
            "training error 0.09187003469757088, test error 0.18831618452650029\n",
            "Loss: 0.0\n",
            "training error 0.09168743279749171, test error 0.18805722814304524\n",
            "Loss: 0.0\n",
            "training error 0.09149392322044772, test error 0.1880556136147394\n",
            "Loss: 0.0\n",
            "training error 0.09152611446522019, test error 0.18771517216524927\n",
            "Loss: 0.0\n",
            "training error 0.0913026286969078, test error 0.18776213948889814\n",
            "Loss: 0.025020526101915408\n",
            "training error 0.09128618658461665, test error 0.18746224039362472\n",
            "Loss: 0.0\n",
            "training error 0.09111512919864057, test error 0.1877150512645083\n",
            "Loss: 0.13485962311809985\n",
            "training error 0.09096364536408434, test error 0.18730080775217128\n",
            "Loss: 0.0\n",
            "training error 0.09086344282791892, test error 0.18703390406891932\n",
            "Loss: 0.0\n",
            "training error 0.09070014290678258, test error 0.1868129780563662\n",
            "Loss: 0.0\n",
            "training error 0.09050426598308314, test error 0.1865022410061393\n",
            "Loss: 0.0\n",
            "training error 0.09062012066212773, test error 0.18633352935480213\n",
            "Loss: 0.0\n",
            "training error 0.09030492787668207, test error 0.18673420505527522\n",
            "Loss: 0.21503145561643233\n",
            "training error 0.09014466555096458, test error 0.18650135812514101\n",
            "Loss: 0.09006901276438217\n",
            "training error 0.09013034099155069, test error 0.18601042664637107\n",
            "Loss: 0.0\n",
            "training error 0.09005054964756003, test error 0.18530397222398318\n",
            "Loss: 0.0\n",
            "training error 0.08974730077209829, test error 0.18547716382200957\n",
            "Loss: 0.09346351076437998\n",
            "training error 0.08961812666135931, test error 0.185345323751616\n",
            "Loss: 0.02231551063720527\n",
            "training error 0.08974393522356675, test error 0.18512179033377799\n",
            "Loss: 0.0\n",
            "training error 0.08949599400111051, test error 0.18512711157575176\n",
            "Loss: 0.002874454684231864\n",
            "training error 0.08920254534618234, test error 0.1848247315520105\n",
            "Loss: 0.0\n",
            "training error 0.08917738383037194, test error 0.18455279949418207\n",
            "Loss: 0.0\n",
            "training error 0.08891863865805961, test error 0.18429976673912166\n",
            "Loss: 0.0\n",
            "training error 0.08882426493429231, test error 0.18375624617081043\n",
            "Loss: 0.0\n",
            "training error 0.08884621185262519, test error 0.18364651321038025\n",
            "Loss: 0.0\n",
            "training error 0.08854963013834806, test error 0.1834536798855724\n",
            "Loss: 0.0\n",
            "training error 0.08849809025555806, test error 0.18327756681579285\n",
            "Loss: 0.0\n",
            "training error 0.08831392002632937, test error 0.1830835347332507\n",
            "Loss: 0.0\n",
            "training error 0.08816637882076041, test error 0.18304236325195464\n",
            "Loss: 0.0\n",
            "training error 0.08803964771108343, test error 0.18312174974351672\n",
            "Loss: 0.04337055649397126\n",
            "training error 0.08789239153256698, test error 0.18307859334160645\n",
            "Loss: 0.019793281188107414\n",
            "training error 0.0878143893678829, test error 0.18275330475575555\n",
            "Loss: 0.0\n",
            "training error 0.08767281072333301, test error 0.1823705300897595\n",
            "Loss: 0.0\n",
            "training error 0.08758433689070058, test error 0.1820734102454648\n",
            "Loss: 0.0\n",
            "training error 0.08742841041558334, test error 0.18219989561948224\n",
            "Loss: 0.06946943754551071\n",
            "training error 0.08741078339452078, test error 0.18142590386228336\n",
            "Loss: 0.0\n",
            "training error 0.08732599775916133, test error 0.18185566514931895\n",
            "Loss: 0.23687978281305977\n",
            "training error 0.08696863573283958, test error 0.18171554469843385\n",
            "Loss: 0.15964690266629944\n",
            "training error 0.08678841141479143, test error 0.1813471163338295\n",
            "Loss: 0.0\n",
            "training error 0.08675800957774021, test error 0.18104307104402817\n",
            "Loss: 0.0\n",
            "training error 0.08655900406464374, test error 0.18080424180687607\n",
            "Loss: 0.0\n",
            "training error 0.08655309394703017, test error 0.18054592172604786\n",
            "Loss: 0.0\n",
            "training error 0.08640102697848218, test error 0.18087219591307052\n",
            "Loss: 0.18071534593715466\n",
            "training error 0.086348095278647, test error 0.18105956472459148\n",
            "Loss: 0.284494378844502\n",
            "training error 0.08605561025877555, test error 0.18073234277378433\n",
            "Loss: 0.10325408957136961\n",
            "training error 0.0860482887962878, test error 0.18039463208015985\n",
            "Loss: 0.0\n",
            "training error 0.08582607782873193, test error 0.1799503206936577\n",
            "Loss: 0.0\n",
            "training error 0.08582710320635807, test error 0.17943057561229195\n",
            "Loss: 0.0\n",
            "training error 0.085759157450983, test error 0.1791237379223641\n",
            "Loss: 0.0\n",
            "training error 0.08543282643058242, test error 0.17918664219355973\n",
            "Loss: 0.03511777496676416\n",
            "training error 0.08524305282211694, test error 0.17867951915913569\n",
            "Loss: 0.0\n",
            "training error 0.0851892848613555, test error 0.17850129398100242\n",
            "Loss: 0.0\n",
            "training error 0.08497169364144076, test error 0.17847382174666784\n",
            "Loss: 0.0\n",
            "training error 0.08504247422845461, test error 0.17828414804117237\n",
            "Loss: 0.0\n",
            "training error 0.08473666210779764, test error 0.17838643278724348\n",
            "Loss: 0.05737175581503884\n",
            "training error 0.08461025354739338, test error 0.17773479513079798\n",
            "Loss: 0.0\n",
            "training error 0.08446502861432767, test error 0.17738376755066693\n",
            "Loss: 0.0\n",
            "training error 0.08431766279589886, test error 0.1768778244515958\n",
            "Loss: 0.0\n",
            "training error 0.08421003151239795, test error 0.17665381079935621\n",
            "Loss: 0.0\n",
            "training error 0.08408475356145141, test error 0.17683303139382858\n",
            "Loss: 0.10145300215229636\n",
            "training error 0.08394142869560173, test error 0.17665324364408155\n",
            "Loss: 0.0\n",
            "training error 0.08380131645225529, test error 0.17643827020033878\n",
            "Loss: 0.0\n",
            "training error 0.08366368087873094, test error 0.17646197103746641\n",
            "Loss: 0.013432934419910225\n",
            "training error 0.0836519076006498, test error 0.17617656559304404\n",
            "Loss: 0.0\n",
            "training error 0.08337746048138767, test error 0.17631426583658985\n",
            "Loss: 0.07816036320285047\n",
            "training error 0.08334370236934868, test error 0.17558390369836605\n",
            "Loss: 0.0\n",
            "training error 0.08327034911254197, test error 0.17534052152716229\n",
            "Loss: 0.0\n",
            "training error 0.08296033534189633, test error 0.1756473316575046\n",
            "Loss: 0.1749795926635045\n",
            "training error 0.08293107361989398, test error 0.17588526117990286\n",
            "Loss: 0.3106752780224875\n",
            "training error 0.08268613482324419, test error 0.17535245197136823\n",
            "Loss: 0.0068041569068144625\n",
            "training error 0.0826154729459675, test error 0.1753382250479225\n",
            "Loss: 0.0\n",
            "training error 0.08245335148604278, test error 0.174838499383589\n",
            "Loss: 0.0\n",
            "training error 0.08236615464711443, test error 0.17466223552833637\n",
            "Loss: 0.0\n",
            "training error 0.0822691534268693, test error 0.17429631204126442\n",
            "Loss: 0.0\n",
            "training error 0.08219859958484067, test error 0.17431431926205884\n",
            "Loss: 0.010331383712913755\n",
            "training error 0.0822232918700316, test error 0.17319015130400253\n",
            "Loss: 0.0\n",
            "training error 0.08208210286068572, test error 0.17308036559934548\n",
            "Loss: 0.0\n",
            "training error 0.08172643939080695, test error 0.17302928808460927\n",
            "Loss: 0.0\n",
            "training error 0.08198320124674001, test error 0.17339532606936228\n",
            "Loss: 0.21154683626394277\n",
            "training error 0.08153985484864104, test error 0.17254711020139177\n",
            "Loss: 0.0\n",
            "training error 0.08139988182432233, test error 0.17226823186536766\n",
            "Loss: 0.0\n",
            "training error 0.08126534295307193, test error 0.17199025956052216\n",
            "Loss: 0.0\n",
            "training error 0.08127695054881925, test error 0.17239820952001364\n",
            "Loss: 0.23719364139218602\n",
            "training error 0.08104140971528527, test error 0.17187155443251864\n",
            "Loss: 0.0\n",
            "training error 0.0808342642018779, test error 0.17143983351440578\n",
            "Loss: 0.0\n",
            "training error 0.08107531707900277, test error 0.1718718786036394\n",
            "Loss: 0.2520097461464754\n",
            "training error 0.08068045602242471, test error 0.17153672939522965\n",
            "Loss: 0.056518884110867695\n",
            "training error 0.08055909354440524, test error 0.17086353355392883\n",
            "Loss: 0.0\n",
            "training error 0.08043224144064083, test error 0.17080469456368566\n",
            "Loss: 0.0\n",
            "training error 0.08028846251114057, test error 0.17081843622560472\n",
            "Loss: 0.008045248378074632\n",
            "training error 0.08010092000915685, test error 0.1706348053112468\n",
            "Loss: 0.0\n",
            "training error 0.08023017839453772, test error 0.16995298555757668\n",
            "Loss: 0.0\n",
            "training error 0.07989628831461712, test error 0.17018070850128514\n",
            "Loss: 0.13399172892512023\n",
            "training error 0.07975309248045866, test error 0.1700484172253744\n",
            "Loss: 0.0561518042678788\n",
            "training error 0.07954850814114879, test error 0.17026953780038093\n",
            "Loss: 0.18625871252906379\n",
            "training error 0.07961959314797776, test error 0.17001751975119325\n",
            "Loss: 0.03797179167217557\n",
            "training error 0.07942135051825103, test error 0.16973110177874218\n",
            "Loss: 0.0\n",
            "training error 0.07924892428960577, test error 0.16978602733704742\n",
            "Loss: 0.0323603380462556\n",
            "training error 0.07914334519573167, test error 0.16953134208940857\n",
            "Loss: 0.0\n",
            "training error 0.07905958876988811, test error 0.16873347189989846\n",
            "Loss: 0.0\n",
            "training error 0.07897328523286237, test error 0.16886800532066976\n",
            "Loss: 0.07973131783307608\n",
            "training error 0.07886129837971512, test error 0.16852598328001153\n",
            "Loss: 0.0\n",
            "training error 0.07858619215064794, test error 0.16819318968201288\n",
            "Loss: 0.0\n",
            "training error 0.07849493675147354, test error 0.1677376306974142\n",
            "Loss: 0.0\n",
            "training error 0.07835131347206917, test error 0.16764235061495306\n",
            "Loss: 0.0\n",
            "training error 0.07830760767142962, test error 0.16756944465073897\n",
            "Loss: 0.0\n",
            "training error 0.07821329327645257, test error 0.16777346458820325\n",
            "Loss: 0.12175246978320953\n",
            "training error 0.07814023946869063, test error 0.16708238302794845\n",
            "Loss: 0.0\n",
            "training error 0.07794372804418162, test error 0.1668606946043869\n",
            "Loss: 0.0\n",
            "training error 0.07780370163813558, test error 0.16674480959421425\n",
            "Loss: 0.0\n",
            "training error 0.07768315108303311, test error 0.16646703729835832\n",
            "Loss: 0.0\n",
            "training error 0.07757550319101512, test error 0.16681003219715615\n",
            "Loss: 0.20604373356094552\n",
            "training error 0.07744330896362737, test error 0.16630964793844968\n",
            "Loss: 0.0\n",
            "training error 0.07728990434733775, test error 0.16570340569498898\n",
            "Loss: 0.0\n",
            "training error 0.07717460526946483, test error 0.16587324133988687\n",
            "Loss: 0.1024937563507411\n",
            "training error 0.07703895331223692, test error 0.16544911430626363\n",
            "Loss: 0.0\n",
            "training error 0.07690141354301158, test error 0.16524464074025158\n",
            "Loss: 0.0\n",
            "training error 0.07681882157235478, test error 0.16528942130689034\n",
            "Loss: 0.027099557624477022\n",
            "training error 0.07681569910693152, test error 0.1651233321103979\n",
            "Loss: 0.0\n",
            "training error 0.0765328572815678, test error 0.1649623997151803\n",
            "Loss: 0.0\n",
            "training error 0.07640263292506137, test error 0.16445353157790882\n",
            "Loss: 0.0\n",
            "training error 0.07624680865325412, test error 0.1644652593490192\n",
            "Loss: 0.007131358626266682\n",
            "training error 0.07609641711337303, test error 0.16402148642493652\n",
            "Loss: 0.0\n",
            "training error 0.07609447892753834, test error 0.16367472508047487\n",
            "Loss: 0.0\n",
            "training error 0.07593715587043783, test error 0.1638874267775426\n",
            "Loss: 0.12995390520016414\n",
            "training error 0.07580090203960979, test error 0.1635366602174134\n",
            "Loss: 0.0\n",
            "training error 0.07570429850539453, test error 0.1628988783022989\n",
            "Loss: 0.0\n",
            "training error 0.07564021246722309, test error 0.16281929549671834\n",
            "Loss: 0.0\n",
            "training error 0.07548575868404335, test error 0.16243523355443235\n",
            "Loss: 0.0\n",
            "training error 0.07525456194054511, test error 0.16206411866592232\n",
            "Loss: 0.0\n",
            "training error 0.07519128653695463, test error 0.16177258187961183\n",
            "Loss: 0.0\n",
            "training error 0.07507763106940764, test error 0.16206077811529426\n",
            "Loss: 0.17814899925185923\n",
            "training error 0.07503553659729224, test error 0.16160425816201188\n",
            "Loss: 0.0\n",
            "training error 0.07479709549291684, test error 0.16125876267323574\n",
            "Loss: 0.0\n",
            "training error 0.07482484968894962, test error 0.16110690601751565\n",
            "Loss: 0.0\n",
            "training error 0.07454982524410815, test error 0.16104026934270588\n",
            "Loss: 0.0\n",
            "training error 0.0746381439167264, test error 0.16067782517574436\n",
            "Loss: 0.0\n",
            "training error 0.0743815272015503, test error 0.16063123457793282\n",
            "Loss: 0.0\n",
            "training error 0.07432363434122363, test error 0.16094845400090263\n",
            "Loss: 0.19748302613953328\n",
            "training error 0.07405182536691626, test error 0.16051977958421362\n",
            "Loss: 0.0\n",
            "training error 0.07404531743770186, test error 0.15985371900763903\n",
            "Loss: 0.0\n",
            "training error 0.07395734536538937, test error 0.1601674164766705\n",
            "Loss: 0.1962403320854067\n",
            "training error 0.07368389294339164, test error 0.16016232486869572\n",
            "Loss: 0.1930551650424439\n",
            "training error 0.07367706395621135, test error 0.1593268644148451\n",
            "Loss: 0.0\n",
            "training error 0.07349702604385949, test error 0.1592256026154651\n",
            "Loss: 0.0\n",
            "training error 0.07341990860866013, test error 0.15966814834105683\n",
            "Loss: 0.27793628557368777\n",
            "training error 0.07319678809791139, test error 0.15888713262725176\n",
            "Loss: 0.0\n",
            "training error 0.07310493070616042, test error 0.15870703952185483\n",
            "Loss: 0.0\n",
            "training error 0.07295254924984303, test error 0.15833784789604996\n",
            "Loss: 0.0\n",
            "training error 0.07279217398311554, test error 0.15794884876795362\n",
            "Loss: 0.0\n",
            "training error 0.07260424384416282, test error 0.1576727804909505\n",
            "Loss: 0.0\n",
            "training error 0.07258478876202398, test error 0.1573708496909095\n",
            "Loss: 0.0\n",
            "training error 0.07242832793701731, test error 0.1569056875228094\n",
            "Loss: 0.0\n",
            "training error 0.07228016685060293, test error 0.15688902709669728\n",
            "Loss: 0.0\n",
            "training error 0.07207918455180512, test error 0.15648546114090772\n",
            "Loss: 0.0\n",
            "training error 0.07201664589089599, test error 0.15606464676451165\n",
            "Loss: 0.0\n",
            "training error 0.07183010735070576, test error 0.15610858096837946\n",
            "Loss: 0.028151285238919854\n",
            "training error 0.071744469868646, test error 0.15553061608401167\n",
            "Loss: 0.0\n",
            "training error 0.0715271731378162, test error 0.15560048252665423\n",
            "Loss: 0.04492134372104939\n",
            "training error 0.0715783447528313, test error 0.15550568464887823\n",
            "Loss: 0.0\n",
            "training error 0.07123072657357232, test error 0.15508438400602093\n",
            "Loss: 0.0\n",
            "training error 0.07112844077989285, test error 0.15524195397467386\n",
            "Loss: 0.10160273045081158\n",
            "training error 0.07098689381014997, test error 0.15494974964426342\n",
            "Loss: 0.0\n",
            "training error 0.07081996973676434, test error 0.1543279955560983\n",
            "Loss: 0.0\n",
            "training error 0.07067322696302285, test error 0.15422990040652848\n",
            "Loss: 0.0\n",
            "training error 0.07061527979262092, test error 0.15410858947495823\n",
            "Loss: 0.0\n",
            "training error 0.07040612742720251, test error 0.15367887037843364\n",
            "Loss: 0.0\n",
            "training error 0.07030790505259896, test error 0.15364768298766757\n",
            "Loss: 0.0\n",
            "training error 0.07000873096779076, test error 0.15286513263707513\n",
            "Loss: 0.0\n",
            "training error 0.06985385931443454, test error 0.15293155440644746\n",
            "Loss: 0.0434512228043582\n",
            "training error 0.06980063342142158, test error 0.1519116636987299\n",
            "Loss: 0.0\n",
            "training error 0.06940368905134107, test error 0.15176191352202886\n",
            "Loss: 0.0\n",
            "training error 0.06926574997687895, test error 0.15135608187941807\n",
            "Loss: 0.0\n",
            "training error 0.06905251035169155, test error 0.15084585210095725\n",
            "Loss: 0.0\n",
            "training error 0.06890611742569933, test error 0.15074681514127042\n",
            "Loss: 0.0\n",
            "training error 0.06866124149096982, test error 0.14991772387947616\n",
            "Loss: 0.0\n",
            "training error 0.06851507047768686, test error 0.15000427566361088\n",
            "Loss: 0.05773285632610925\n",
            "training error 0.06831537935579322, test error 0.14972038424956483\n",
            "Loss: 0.0\n",
            "training error 0.06805987051896879, test error 0.14882652784692282\n",
            "Loss: 0.0\n",
            "training error 0.06780489395417016, test error 0.14855301686483446\n",
            "Loss: 0.0\n",
            "training error 0.06752385235990059, test error 0.14776231831217515\n",
            "Loss: 0.0\n",
            "training error 0.06741449539528843, test error 0.14750870482656747\n",
            "Loss: 0.0\n",
            "training error 0.06709923777524585, test error 0.14689345076674698\n",
            "Loss: 0.0\n",
            "training error 0.06690160357394742, test error 0.1466658379072701\n",
            "Loss: 0.0\n",
            "training error 0.06655890898307174, test error 0.14567237871772204\n",
            "Loss: 0.0\n",
            "training error 0.06631485173805478, test error 0.14512775650974039\n",
            "Loss: 0.0\n",
            "training error 0.06594747391064758, test error 0.14484004905973577\n",
            "Loss: 0.0\n",
            "training error 0.06568140462121724, test error 0.14451895568989762\n",
            "Loss: 0.0\n",
            "training error 0.06540618448213457, test error 0.14417844645732977\n",
            "Loss: 0.0\n",
            "training error 0.06504120138638819, test error 0.14353939319986744\n",
            "Loss: 0.0\n",
            "training error 0.06474265976590994, test error 0.14272558941316496\n",
            "Loss: 0.0\n",
            "training error 0.06443451107211444, test error 0.14198489121360763\n",
            "Loss: 0.0\n",
            "training error 0.06402524616991248, test error 0.14110764996449937\n",
            "Loss: 0.0\n",
            "training error 0.06367815222986725, test error 0.14019591293983555\n",
            "Loss: 0.0\n",
            "training error 0.06325581522438678, test error 0.13907154919590822\n",
            "Loss: 0.0\n",
            "training error 0.06274207497642012, test error 0.13820522337951038\n",
            "Loss: 0.0\n",
            "training error 0.06233450420243121, test error 0.1376007914071306\n",
            "Loss: 0.0\n",
            "training error 0.06191124752685777, test error 0.13708856530057595\n",
            "Loss: 0.0\n",
            "training error 0.061526785948099835, test error 0.13636959998291234\n",
            "Loss: 0.0\n",
            "training error 0.06119985132056394, test error 0.13487491109828514\n",
            "Loss: 0.0\n",
            "training error 0.060660287139239884, test error 0.13375962176181397\n",
            "Loss: 0.0\n",
            "training error 0.06012248856407827, test error 0.13281534641648454\n",
            "Loss: 0.0\n",
            "training error 0.05971922279675899, test error 0.1317441735086936\n",
            "Loss: 0.0\n",
            "training error 0.05922140241424094, test error 0.13081115745823854\n",
            "Loss: 0.0\n",
            "training error 0.05871047407777978, test error 0.1298109367340841\n",
            "Loss: 0.0\n",
            "training error 0.05835167446974712, test error 0.12887973280241005\n",
            "Loss: 0.0\n",
            "training error 0.05766054299582498, test error 0.1282429300897837\n",
            "Loss: 0.0\n",
            "training error 0.057199962851208916, test error 0.12693180286544217\n",
            "Loss: 0.0\n",
            "training error 0.056746308141443054, test error 0.12679381060305153\n",
            "Loss: 0.0\n",
            "training error 0.0565247624289711, test error 0.12581922021250108\n",
            "Loss: 0.0\n",
            "training error 0.05566010585273465, test error 0.12391557205448746\n",
            "Loss: 0.0\n",
            "training error 0.055047790040524285, test error 0.12314166092466208\n",
            "Loss: 0.0\n",
            "training error 0.05479991585495662, test error 0.12161085742922767\n",
            "Loss: 0.0\n",
            "training error 0.05431470869348648, test error 0.12022717121497938\n",
            "Loss: 0.0\n",
            "training error 0.0535403444959357, test error 0.11975722433323158\n",
            "Loss: 0.0\n",
            "training error 0.05318066117731205, test error 0.11859043019129831\n",
            "Loss: 0.0\n",
            "training error 0.0524965038223183, test error 0.11760458020372629\n",
            "Loss: 0.0\n",
            "training error 0.052004848634413105, test error 0.11654804545168831\n",
            "Loss: 0.0\n",
            "training error 0.051687402349770074, test error 0.11571213537046134\n",
            "Loss: 0.0\n",
            "training error 0.051045503438513135, test error 0.1144810101713977\n",
            "Loss: 0.0\n",
            "training error 0.050657397963457196, test error 0.11339405884503444\n",
            "Loss: 0.0\n",
            "training error 0.05049969202613506, test error 0.11319940493753379\n",
            "Loss: 0.0\n",
            "training error 0.05003728169729201, test error 0.1110267722222604\n",
            "Loss: 0.0\n",
            "training error 0.04946078982423827, test error 0.11134480286297509\n",
            "Loss: 0.2864450027224352\n",
            "training error 0.049185757924895684, test error 0.11076707945312693\n",
            "Loss: 0.0\n",
            "training error 0.04854782316082439, test error 0.11014129257887233\n",
            "Loss: 0.0\n",
            "training error 0.04839011453033552, test error 0.10838393172473745\n",
            "Loss: 0.0\n",
            "training error 0.04779725002005729, test error 0.1077673343524186\n",
            "Loss: 0.0\n",
            "training error 0.0474490360974224, test error 0.10688775948951822\n",
            "Loss: 0.0\n",
            "training error 0.04711656614357187, test error 0.10629067214884491\n",
            "Loss: 0.0\n",
            "training error 0.046598114052011544, test error 0.10498923459893575\n",
            "Loss: 0.0\n",
            "training error 0.04623115187885245, test error 0.10503929193590787\n",
            "Loss: 0.04767854262710536\n",
            "training error 0.045868412246345816, test error 0.1036061467099159\n",
            "Loss: 0.0\n",
            "training error 0.04548679212870797, test error 0.1028369448584713\n",
            "Loss: 0.0\n",
            "training error 0.045610127091024646, test error 0.10250155414211036\n",
            "Loss: 0.0\n",
            "training error 0.044720007815002655, test error 0.10131666644542656\n",
            "Loss: 0.0\n",
            "training error 0.044716245773204925, test error 0.10038320303446722\n",
            "Loss: 0.0\n",
            "training error 0.04397888603286848, test error 0.09931951381987665\n",
            "Loss: 0.0\n",
            "training error 0.04366111913503611, test error 0.09953646914644242\n",
            "Loss: 0.2184417927772353\n",
            "training error 0.043350135148841944, test error 0.097843032679837\n",
            "Loss: 0.0\n",
            "training error 0.043210044922591104, test error 0.09716317975112693\n",
            "Loss: 0.0\n",
            "training error 0.042586010165754834, test error 0.0967810156811517\n",
            "Loss: 0.0\n",
            "training error 0.042412064089621164, test error 0.09550326677225741\n",
            "Loss: 0.0\n",
            "training error 0.04224775550738603, test error 0.09530620373552308\n",
            "Loss: 0.0\n",
            "training error 0.041892921150984835, test error 0.09481431946500007\n",
            "Loss: 0.0\n",
            "training error 0.041360668389613074, test error 0.09457541369996396\n",
            "Loss: 0.0\n",
            "training error 0.041025232692275086, test error 0.09337918323330195\n",
            "Loss: 0.0\n",
            "training error 0.04078299125827534, test error 0.09267286949702491\n",
            "Loss: 0.0\n",
            "training error 0.04038611820795631, test error 0.09158902745751757\n",
            "Loss: 0.0\n",
            "training error 0.040080500377616186, test error 0.09087684140938979\n",
            "Loss: 0.0\n",
            "training error 0.04008216568457448, test error 0.09104814998294392\n",
            "Loss: 0.1885063024829492\n",
            "training error 0.03951957593245927, test error 0.09050343628118311\n",
            "Loss: 0.0\n",
            "training error 0.03930600324987874, test error 0.08999142462278928\n",
            "Loss: 0.0\n",
            "training error 0.039170451994445625, test error 0.08894750734786917\n",
            "Loss: 0.0\n",
            "training error 0.03860440073242638, test error 0.08807014671795815\n",
            "Loss: 0.0\n",
            "training error 0.03860275923808289, test error 0.0873539962403823\n",
            "Loss: 0.0\n",
            "training error 0.03832479112654971, test error 0.08677576800767386\n",
            "Loss: 0.0\n",
            "training error 0.03797015245653536, test error 0.08556014441047058\n",
            "Loss: 0.0\n",
            "training error 0.0378129539384642, test error 0.08451811277207939\n",
            "Loss: 0.0\n",
            "training error 0.037679819427473324, test error 0.08386792092261172\n",
            "Loss: 0.0\n",
            "training error 0.037146949701442084, test error 0.08380055634370502\n",
            "Loss: 0.0\n",
            "training error 0.036920006387172494, test error 0.08364498244658214\n",
            "Loss: 0.0\n",
            "training error 0.0367673641967977, test error 0.08313550716803608\n",
            "Loss: 0.0\n",
            "training error 0.036427354120471, test error 0.08292778628720666\n",
            "Loss: 0.0\n",
            "training error 0.03617801928549609, test error 0.08162424281442432\n",
            "Loss: 0.0\n",
            "training error 0.035905990665597354, test error 0.08105789621279144\n",
            "Loss: 0.0\n",
            "training error 0.03556790818923534, test error 0.08121239846994677\n",
            "Loss: 0.19060728735140753\n",
            "training error 0.03573312219958892, test error 0.08073671311446223\n",
            "Loss: 0.0\n",
            "training error 0.035568028882619604, test error 0.07918088756030778\n",
            "Loss: 0.0\n",
            "training error 0.03543938980087094, test error 0.08021565916236413\n",
            "Loss: 1.3068451667306968\n",
            "training error 0.03478148044369796, test error 0.07956707266498804\n",
            "Loss: 0.4877251525958526\n",
            "training error 0.03457753739304964, test error 0.07965127373008574\n",
            "Loss: 0.5940652905913613\n",
            "training error 0.034328154728684175, test error 0.07887000765011667\n",
            "Loss: 0.0\n",
            "training error 0.03421646418182222, test error 0.07753256311963411\n",
            "Loss: 0.0\n",
            "training error 0.033868462393880985, test error 0.07713254750319619\n",
            "Loss: 0.0\n",
            "training error 0.03365186037724621, test error 0.07636814494665223\n",
            "Loss: 0.0\n",
            "training error 0.03360431747945535, test error 0.07588150159104921\n",
            "Loss: 0.0\n",
            "training error 0.033405566653895914, test error 0.07612500383238073\n",
            "Loss: 0.32089802682586654\n",
            "training error 0.033165027090335, test error 0.07554132432817548\n",
            "Loss: 0.0\n",
            "training error 0.03288589030544556, test error 0.07539646080511156\n",
            "Loss: 0.0\n",
            "training error 0.03269406773455911, test error 0.07466375798939337\n",
            "Loss: 0.0\n",
            "training error 0.032440503517093724, test error 0.07394275429461757\n",
            "Loss: 0.0\n",
            "training error 0.03241719240514341, test error 0.07292160414732188\n",
            "Loss: 0.0\n",
            "training error 0.03219767152234785, test error 0.07303633356889212\n",
            "Loss: 0.1573325531051939\n",
            "training error 0.03187638539709947, test error 0.07297240404662618\n",
            "Loss: 0.06966371612131539\n",
            "training error 0.03171121135922449, test error 0.07249665502956652\n",
            "Loss: 0.0\n",
            "training error 0.03163321808670757, test error 0.07323787096040746\n",
            "Loss: 1.0224139728083115\n",
            "training error 0.031478300606191584, test error 0.07213895680747733\n",
            "Loss: 0.0\n",
            "training error 0.031556129853169475, test error 0.07099324827276508\n",
            "Loss: 0.0\n",
            "training error 0.03097161180320649, test error 0.07087113071546947\n",
            "Loss: 0.0\n",
            "training error 0.03080497749723022, test error 0.07047629798957697\n",
            "Loss: 0.0\n",
            "training error 0.030704888092462083, test error 0.07055199148553615\n",
            "Loss: 0.10740276960967687\n",
            "training error 0.030510512257807158, test error 0.06949361068890672\n",
            "Loss: 0.0\n",
            "training error 0.030545367895043404, test error 0.06939448272793831\n",
            "Loss: 0.0\n",
            "training error 0.03017434676965788, test error 0.06877822925000951\n",
            "Loss: 0.0\n",
            "training error 0.02998573308615595, test error 0.06846082917404178\n",
            "Loss: 0.0\n",
            "training error 0.029870452590012427, test error 0.06816271743920409\n",
            "Loss: 0.0\n",
            "training error 0.029819818632552144, test error 0.06798036615253719\n",
            "Loss: 0.0\n",
            "training error 0.02965146669163709, test error 0.0672063586187531\n",
            "Loss: 0.0\n",
            "training error 0.029669720644981464, test error 0.06715922163012908\n",
            "Loss: 0.0\n",
            "training error 0.029417696067672527, test error 0.06784093281408571\n",
            "Loss: 1.0150671306333292\n",
            "training error 0.02945351637624111, test error 0.06754048341350079\n",
            "Loss: 0.5676983355636045\n",
            "training error 0.02903787235325581, test error 0.06613038170792539\n",
            "Loss: 0.0\n",
            "training error 0.02895129973092258, test error 0.06592242094486311\n",
            "Loss: 0.0\n",
            "training error 0.02878280549975057, test error 0.06561402460975506\n",
            "Loss: 0.0\n",
            "training error 0.0286445182466465, test error 0.06560787115050454\n",
            "Loss: 0.0\n",
            "training error 0.02862000337913078, test error 0.06625904471355046\n",
            "Loss: 0.9925235366228025\n",
            "training error 0.02840024644966767, test error 0.06535747579404881\n",
            "Loss: 0.0\n",
            "training error 0.028648945240387753, test error 0.06454830061459801\n",
            "Loss: 0.0\n",
            "training error 0.028149677200187257, test error 0.06415625145974084\n",
            "Loss: 0.0\n",
            "training error 0.028049660057720655, test error 0.06439932985123549\n",
            "Loss: 0.37888496594471466\n",
            "training error 0.027966833918023935, test error 0.06453246060821725\n",
            "Loss: 0.5863951523297661\n",
            "training error 0.027947684377543785, test error 0.06373391536414441\n",
            "Loss: 0.0\n",
            "training error 0.02764991943058692, test error 0.06335542747382321\n",
            "Loss: 0.0\n",
            "training error 0.027570333990258353, test error 0.06337253097689098\n",
            "Loss: 0.026996113434551994\n",
            "training error 0.027600783086046146, test error 0.0638002005636265\n",
            "Loss: 0.7020283936795435\n",
            "training error 0.027471342923383792, test error 0.06388730147764465\n",
            "Loss: 0.8395081921611203\n",
            "training error 0.027469839805830766, test error 0.0626693096394017\n",
            "Loss: 0.0\n",
            "training error 0.027185987056146124, test error 0.062745039845803\n",
            "Loss: 0.12084097756468459\n",
            "training error 0.027021021975917672, test error 0.062250072481492294\n",
            "Loss: 0.0\n",
            "training error 0.026829619459898976, test error 0.06180903862725986\n",
            "Loss: 0.0\n",
            "training error 0.02684535319040086, test error 0.061703001558907594\n",
            "Loss: 0.0\n",
            "training error 0.026692185427218882, test error 0.06083539852033327\n",
            "Loss: 0.0\n",
            "training error 0.026867433141268764, test error 0.06024452986251968\n",
            "Loss: 0.0\n",
            "training error 0.02648006262809636, test error 0.060203504209879945\n",
            "Loss: 0.0\n",
            "training error 0.02657874526178838, test error 0.06106176515404464\n",
            "Loss: 1.4255996481079336\n",
            "training error 0.026492576924113588, test error 0.05999232033118832\n",
            "Loss: 0.0\n",
            "training error 0.02664921750005577, test error 0.060680847493981824\n",
            "Loss: 1.1476921695851683\n",
            "training error 0.026249128143180173, test error 0.058847814573267036\n",
            "Loss: 0.0\n",
            "training error 0.02601702124057105, test error 0.05951050764801191\n",
            "Loss: 1.126113313723498\n",
            "training error 0.02590043967483852, test error 0.0592906140351877\n",
            "Loss: 0.7524484386236097\n",
            "training error 0.025872545274796054, test error 0.058726778618472836\n",
            "Loss: 0.0\n",
            "training error 0.025812776898599985, test error 0.058633804916686086\n",
            "Loss: 0.0\n",
            "training error 0.0257036490370933, test error 0.05812354729693534\n",
            "Loss: 0.0\n",
            "training error 0.025555412875165003, test error 0.0584489229813658\n",
            "Loss: 0.5598001146905451\n",
            "training error 0.025524232013120058, test error 0.05806651228642789\n",
            "Loss: 0.0\n",
            "training error 0.025494129006723827, test error 0.05810565795762561\n",
            "Loss: 0.06741522722188975\n",
            "training error 0.02540300479057705, test error 0.05840898336789533\n",
            "Loss: 0.5897910309786036\n",
            "training error 0.025305305707076415, test error 0.05791559413234322\n",
            "Loss: 0.0\n",
            "training error 0.02527750545508475, test error 0.05803349468915719\n",
            "Loss: 0.20357307661309498\n",
            "training error 0.025120161727021462, test error 0.05753038097740286\n",
            "Loss: 0.0\n",
            "training error 0.02505954330424109, test error 0.05709220043281648\n",
            "Loss: 0.0\n",
            "training error 0.024955740202983176, test error 0.05675324514664256\n",
            "Loss: 0.0\n",
            "training error 0.02502689149971613, test error 0.056606665579572016\n",
            "Loss: 0.0\n",
            "training error 0.024760373006968005, test error 0.05645933817679202\n",
            "Loss: 0.0\n",
            "training error 0.024726055418050955, test error 0.05633638411550342\n",
            "Loss: 0.0\n",
            "training error 0.024624222974014228, test error 0.0564809437243197\n",
            "Loss: 0.25660079376037537\n",
            "training error 0.0246255338709637, test error 0.05618481465149305\n",
            "Loss: 0.0\n",
            "training error 0.024540665745570966, test error 0.05638256025745544\n",
            "Loss: 0.35195560791465574\n",
            "training error 0.024418782238853506, test error 0.05623886114223035\n",
            "Loss: 0.09619412482277934\n",
            "training error 0.024461065210201763, test error 0.055207066018490694\n",
            "Loss: 0.0\n",
            "training error 0.024330198439812958, test error 0.055259616451795585\n",
            "Loss: 0.0951878755652169\n",
            "training error 0.024325598722268645, test error 0.05604418959430531\n",
            "Loss: 1.5163341147929055\n",
            "training error 0.024294961728064952, test error 0.05484271692988991\n",
            "Loss: 0.0\n",
            "training error 0.024141927328735404, test error 0.05483940815392703\n",
            "Loss: 0.0\n",
            "training error 0.024079143962596274, test error 0.05465290516913222\n",
            "Loss: 0.0\n",
            "training error 0.02403686650704354, test error 0.054731115403724245\n",
            "Loss: 0.14310352642736834\n",
            "training error 0.02395227177287472, test error 0.054733330207239556\n",
            "Loss: 0.147156016424832\n",
            "training error 0.023905630435588087, test error 0.054851391517073286\n",
            "Loss: 0.3631762068765143\n",
            "training error 0.02381950131697281, test error 0.05447823493509931\n",
            "Loss: 0.0\n",
            "training error 0.023809733492860603, test error 0.05452130216146563\n",
            "Loss: 0.07905400462704382\n",
            "training error 0.023853927458101835, test error 0.05397703990831755\n",
            "Loss: 0.0\n",
            "training error 0.023700544830792113, test error 0.05365928228395751\n",
            "Loss: 0.0\n",
            "training error 0.023842629935655914, test error 0.05379811127989651\n",
            "Loss: 0.25872316965467324\n",
            "training error 0.023572665642265005, test error 0.05413890498581897\n",
            "Loss: 0.8938298863621741\n",
            "training error 0.023551631987486398, test error 0.05347154327463326\n",
            "Loss: 0.0\n",
            "training error 0.02347094285618659, test error 0.05281753999770137\n",
            "Loss: 0.0\n",
            "training error 0.02352422392385075, test error 0.05343865061575208\n",
            "Loss: 1.1759552188112865\n",
            "training error 0.0233390055943676, test error 0.05368364390025714\n",
            "Loss: 1.6398035625920127\n",
            "training error 0.023423871672210418, test error 0.05269366696728758\n",
            "Loss: 0.0\n",
            "training error 0.023223758183133367, test error 0.052752374417982785\n",
            "Loss: 0.11141272580565964\n",
            "training error 0.02321466486336823, test error 0.052776269746817074\n",
            "Loss: 0.1567603552449226\n",
            "training error 0.02320486650854399, test error 0.05237407312301818\n",
            "Loss: 0.0\n",
            "training error 0.023121783081659086, test error 0.05272407003362186\n",
            "Loss: 0.6682636841736533\n",
            "training error 0.022989065833715048, test error 0.05230017949730756\n",
            "Loss: 0.0\n",
            "training error 0.02301145105275698, test error 0.05194545895553763\n",
            "Loss: 0.0\n",
            "training error 0.023007060332688168, test error 0.05228626801870535\n",
            "Loss: 0.6560901954094422\n",
            "training error 0.022938541690316238, test error 0.05182145253908725\n",
            "Loss: 0.0\n",
            "training error 0.02289244779540051, test error 0.05248407877265154\n",
            "Loss: 1.2786716718611757\n",
            "training error 0.02287142836134352, test error 0.05244983276759393\n",
            "Loss: 1.2125870613771683\n",
            "training error 0.02281126555743001, test error 0.05202059080047191\n",
            "Loss: 0.3842776526467473\n",
            "training error 0.022712376933942326, test error 0.05163809908327141\n",
            "Loss: 0.0\n",
            "training error 0.022748005659745718, test error 0.05196543057783287\n",
            "Loss: 0.6338953221992405\n",
            "training error 0.022779907993561405, test error 0.05165154169437417\n",
            "Loss: 0.026032350805715865\n",
            "training error 0.02269615725240083, test error 0.05160932370497148\n",
            "Loss: 0.0\n",
            "training error 0.02262500489459544, test error 0.05116464805729436\n",
            "Loss: 0.0\n",
            "training error 0.022513856872483078, test error 0.051140510740989284\n",
            "Loss: 0.0\n",
            "training error 0.022452799149137115, test error 0.050833219495530026\n",
            "Loss: 0.0\n",
            "training error 0.022430229011629502, test error 0.05098578782410004\n",
            "Loss: 0.3001350889912269\n",
            "training error 0.022375296402118248, test error 0.05093490089558121\n",
            "Loss: 0.20002943165959852\n",
            "training error 0.0223901092653761, test error 0.05067778134917464\n",
            "Loss: 0.0\n",
            "training error 0.022325615367036047, test error 0.051005322023154845\n",
            "Loss: 0.6463200741236408\n",
            "training error 0.022319942025325848, test error 0.05064597777623827\n",
            "Loss: 0.0\n",
            "training error 0.022319526652211416, test error 0.050882725644590544\n",
            "Loss: 0.4674564076899923\n",
            "training error 0.022271186131644957, test error 0.050446906828301046\n",
            "Loss: 0.0\n",
            "training error 0.022241415549103364, test error 0.0500527521309159\n",
            "Loss: 0.0\n",
            "training error 0.022200635303075617, test error 0.050637791836394656\n",
            "Loss: 1.1688462283723222\n",
            "training error 0.022190732119176056, test error 0.05067062395154675\n",
            "Loss: 1.2344412531298365\n",
            "training error 0.022265648777590824, test error 0.050495048479769954\n",
            "Loss: 0.8836603983277458\n",
            "training error 0.02241945383083414, test error 0.050734895814946925\n",
            "Loss: 1.3628495037532273\n",
            "training error 0.022168157676534177, test error 0.05001716207834372\n",
            "Loss: 0.0\n",
            "training error 0.021984287312057475, test error 0.05017999521128763\n",
            "Loss: 0.3255545220435696\n",
            "training error 0.022016701082853574, test error 0.050059548659121315\n",
            "Loss: 0.08474407386649396\n",
            "training error 0.02205140446852849, test error 0.05052371832262007\n",
            "Loss: 1.0127648655533728\n",
            "training error 0.021955640826210078, test error 0.050448675627135835\n",
            "Loss: 0.8627309724534626\n",
            "training error 0.022006637914186614, test error 0.049698477396688576\n",
            "Loss: 0.0\n",
            "training error 0.02201532951519764, test error 0.049884188777381246\n",
            "Loss: 0.3736761977843672\n",
            "training error 0.02190065708041561, test error 0.0500049466570292\n",
            "Loss: 0.6166572426241856\n",
            "training error 0.02184927881098204, test error 0.04982417500814191\n",
            "Loss: 0.2529204475421487\n",
            "training error 0.02179244712209921, test error 0.049673561800631615\n",
            "Loss: 0.0\n",
            "training error 0.021793899145099573, test error 0.050158989561086\n",
            "Loss: 0.9772356619053957\n",
            "training error 0.021915305716477197, test error 0.05012983120493515\n",
            "Loss: 0.9185357114813053\n",
            "training error 0.021705670604413266, test error 0.05002445358341552\n",
            "Loss: 0.7063954547737783\n",
            "training error 0.021728881941355672, test error 0.04985423284674391\n",
            "Loss: 0.36371671280073237\n",
            "training error 0.02173904233616369, test error 0.04970771328869376\n",
            "Loss: 0.06875184066568174\n",
            "training error 0.02163667241650006, test error 0.049298060803703365\n",
            "Loss: 0.0\n",
            "training error 0.0217416780156867, test error 0.04920667512674383\n",
            "Loss: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04920667512674383\n",
            "training error 0.1237913309912479, test error 0.23502684585411643\n",
            "training error 0.11969682456201318, test error 0.22808970709073476\n",
            "training error 0.11823404619729738, test error 0.22709082352639184\n",
            "training error 0.11819014570594798, test error 0.22552964281427\n",
            "training error 0.11784380101281629, test error 0.22390224996821964\n",
            "training error 0.11772299380750557, test error 0.2243466660453418\n",
            "training error 0.11785615041918826, test error 0.22455716575688656\n",
            "training error 0.11775823647682725, test error 0.2249239487490388\n",
            "training error 0.11797025489893187, test error 0.2242089933350878\n",
            "training error 0.11759554589159976, test error 0.2247418513017679\n",
            "training error 0.11841413400058758, test error 0.22325507892840873\n",
            "training error 0.117577577210957, test error 0.22244229212559166\n",
            "training error 0.11760488656522104, test error 0.2231507468645046\n",
            "training error 0.11752029787477923, test error 0.223181162604346\n",
            "training error 0.11757673022383588, test error 0.2227386120498948\n",
            "training error 0.11757069495114184, test error 0.22254235644646012\n",
            "training error 0.11760124357772615, test error 0.22311131671033466\n",
            "training error 0.11761958844868427, test error 0.2238577003115431\n",
            "training error 0.11757959057537509, test error 0.22304173023540133\n",
            "training error 0.11764382835681295, test error 0.22316194854463228\n",
            "training error 0.1173533221686936, test error 0.22216684879835505\n",
            "training error 0.11738551461507721, test error 0.22287731651717718\n",
            "training error 0.11722805435532871, test error 0.22282245184840568\n",
            "training error 0.11752038157950112, test error 0.22307869785531428\n",
            "training error 0.11740229913235686, test error 0.22285011802439642\n",
            "training error 0.11780869136008935, test error 0.22415488855410826\n",
            "training error 0.11764431481712238, test error 0.22287262799127094\n",
            "training error 0.11735211959151334, test error 0.22254698439596263\n",
            "training error 0.11718669143009086, test error 0.22213006751255765\n",
            "training error 0.11708331509713797, test error 0.2220718416513911\n",
            "training error 0.11767235998805502, test error 0.22216457016117178\n",
            "training error 0.11727587388206952, test error 0.22146729054950787\n",
            "training error 0.11700483646568388, test error 0.22193508945200488\n",
            "training error 0.116985339081143, test error 0.2223661832752666\n",
            "training error 0.1169738927430752, test error 0.22189298727945417\n",
            "training error 0.11733890860494037, test error 0.2212600408867722\n",
            "training error 0.1173252187649353, test error 0.22271155970195522\n",
            "training error 0.11779461590384638, test error 0.22357712415961767\n",
            "training error 0.11685583739314805, test error 0.22274524150769331\n",
            "training error 0.11696219067442928, test error 0.2221276267379967\n",
            "training error 0.11710661563752446, test error 0.2231911063284201\n",
            "training error 0.11697998268004793, test error 0.22271773358717192\n",
            "training error 0.11679949525359841, test error 0.2217077172095883\n",
            "training error 0.11751432318357054, test error 0.222571507874502\n",
            "training error 0.11685344766505053, test error 0.22227962370584886\n",
            "training error 0.11687379768039116, test error 0.2224930927626537\n",
            "training error 0.11688813190147002, test error 0.22244011529091126\n",
            "training error 0.11671217539211062, test error 0.22250830284085812\n",
            "training error 0.11661991834241175, test error 0.2221258152140951\n",
            "training error 0.11678972297693847, test error 0.22186130857048975\n",
            "Loss: 0.27174707249792984\n",
            "training error 0.1165861234145651, test error 0.22169900367561438\n",
            "Loss: 0.19839225694928686\n",
            "training error 0.1169423978771744, test error 0.221785364934691\n",
            "Loss: 0.23742382303346687\n",
            "training error 0.11741462500254786, test error 0.2220025249302802\n",
            "Loss: 0.3355707793111895\n",
            "training error 0.11656824516165025, test error 0.2211495534487213\n",
            "Loss: 0.0\n",
            "training error 0.11670465111493226, test error 0.22178844834164144\n",
            "Loss: 0.28889721139240265\n",
            "training error 0.11684730382521168, test error 0.2222499949893541\n",
            "Loss: 0.4976006161766744\n",
            "training error 0.11671746787705793, test error 0.22126503265983888\n",
            "Loss: 0.05221770033749795\n",
            "training error 0.11651542771530757, test error 0.2212156294051245\n",
            "Loss: 0.029878403719463265\n",
            "training error 0.11649134610916131, test error 0.22127299985849824\n",
            "Loss: 0.05582032966011674\n",
            "training error 0.1167401766776946, test error 0.22166725677853177\n",
            "Loss: 0.23409648436414354\n",
            "training error 0.11656872868148406, test error 0.22108719420849524\n",
            "Loss: 0.0\n",
            "training error 0.11712435374725085, test error 0.2203843943892299\n",
            "Loss: 0.0\n",
            "training error 0.11630021213091069, test error 0.22096225603752173\n",
            "Loss: 0.2622062464510355\n",
            "training error 0.11639545630793863, test error 0.22164012449139195\n",
            "Loss: 0.5697908446022915\n",
            "training error 0.11635895433275044, test error 0.22102925984314242\n",
            "Loss: 0.2926093999076951\n",
            "training error 0.11631068516417077, test error 0.22093511541003688\n",
            "Loss: 0.2498911151732175\n",
            "training error 0.11634915880330157, test error 0.22179388931900282\n",
            "Loss: 0.6395620405333924\n",
            "training error 0.11641939941418021, test error 0.22167629996562827\n",
            "Loss: 0.586205561414066\n",
            "training error 0.11639220170139955, test error 0.2220955929652097\n",
            "Loss: 0.7764608654447613\n",
            "training error 0.1163445255560707, test error 0.22204211599894955\n",
            "Loss: 0.752195551011603\n",
            "training error 0.1164985744783891, test error 0.2212424382804084\n",
            "Loss: 0.3893396778644309\n",
            "training error 0.11633860868299495, test error 0.22125269013124232\n",
            "Loss: 0.3939914822094437\n",
            "training error 0.11631348293798857, test error 0.22195001692134117\n",
            "Loss: 0.7104053517265507\n",
            "training error 0.11623164888643948, test error 0.2209622617312974\n",
            "Loss: 0.26220883001675244\n",
            "training error 0.11632905093509452, test error 0.22193262879306136\n",
            "Loss: 0.7025154426756108\n",
            "training error 0.11621660863236222, test error 0.22169697975463798\n",
            "Loss: 0.595589070199698\n",
            "training error 0.11641270433113694, test error 0.2227985397940191\n",
            "Loss: 1.0954248423440838\n",
            "training error 0.1162090912261879, test error 0.22195580261415546\n",
            "Loss: 0.7130306250950902\n",
            "training error 0.116177049839944, test error 0.22150306591412255\n",
            "Loss: 0.5076001538098618\n",
            "training error 0.1163915700940574, test error 0.22168395650865133\n",
            "Loss: 0.5896797379973284\n",
            "training error 0.11606054882835445, test error 0.2217265375514512\n",
            "Loss: 0.6090009984331513\n",
            "training error 0.11618996422282503, test error 0.2212088446126875\n",
            "Loss: 0.37409646256598705\n",
            "training error 0.11599251518918027, test error 0.2210522657187055\n",
            "Loss: 0.3030483765996905\n",
            "training error 0.11601543817177185, test error 0.22069805286039265\n",
            "Loss: 0.14232335825410392\n",
            "training error 0.11619126663567524, test error 0.22025712254554963\n",
            "Loss: 0.0\n",
            "training error 0.11603460142858996, test error 0.22054632229144783\n",
            "Loss: 0.1313009734059234\n",
            "training error 0.11596063678216334, test error 0.2207241690373728\n",
            "Loss: 0.21204603348370377\n",
            "training error 0.11595418707454412, test error 0.2208479868682733\n",
            "Loss: 0.26826116490352714\n",
            "training error 0.1160781677582, test error 0.22032584318308962\n",
            "Loss: 0.031200188554980635\n",
            "training error 0.11584893098915898, test error 0.2204769376907121\n",
            "Loss: 0.09979933571366839\n",
            "training error 0.11590310087843216, test error 0.22056219542436376\n",
            "Loss: 0.13850761114480026\n",
            "training error 0.11615014336184024, test error 0.22138430880549684\n",
            "Loss: 0.511759277938495\n",
            "training error 0.11603875563696552, test error 0.22152003371352996\n",
            "Loss: 0.5733803989558472\n",
            "training error 0.11616786274249381, test error 0.22044019710146526\n",
            "Loss: 0.08311856334080048\n",
            "training error 0.11596552036532454, test error 0.22095501946853507\n",
            "Loss: 0.31685555269211907\n",
            "training error 0.11584010658586391, test error 0.22075266795256554\n",
            "Loss: 0.2249849636138057\n",
            "training error 0.11589448792343163, test error 0.22062160642902295\n",
            "Loss: 0.16548108831211383\n",
            "training error 0.11577161317897229, test error 0.2202898430495961\n",
            "Loss: 0.014855594074925094\n",
            "training error 0.11597980557219503, test error 0.22043934075055283\n",
            "Loss: 0.08272976732706105\n",
            "training error 0.11591882932066554, test error 0.22088773766417572\n",
            "Loss: 0.28630861573870625\n",
            "training error 0.11583653909469516, test error 0.22039506645452137\n",
            "Loss: 0.06262858035077645\n",
            "training error 0.11569107431675638, test error 0.22067463532963028\n",
            "Loss: 0.1895569955946863\n",
            "training error 0.1160901031569542, test error 0.22030681110663755\n",
            "Loss: 0.022559343604267035\n",
            "training error 0.11580331606023118, test error 0.21976865205380497\n",
            "Loss: 0.0\n",
            "training error 0.11565707188759689, test error 0.2201609389492042\n",
            "Loss: 0.17849993242129436\n",
            "training error 0.11572906788302101, test error 0.22040841473326372\n",
            "Loss: 0.29110734105159963\n",
            "training error 0.11558817658611739, test error 0.2207151008213217\n",
            "Loss: 0.43065685604926074\n",
            "training error 0.11593841309020175, test error 0.22085046025937197\n",
            "Loss: 0.4922486421321537\n",
            "training error 0.11579677821456413, test error 0.22003254381730863\n",
            "Loss: 0.12007707242935872\n",
            "training error 0.1155812525004549, test error 0.22027620002288778\n",
            "Loss: 0.230946481374672\n",
            "training error 0.11581105101011509, test error 0.2204376591066238\n",
            "Loss: 0.304414231314043\n",
            "training error 0.11558726482224144, test error 0.22040899187113921\n",
            "Loss: 0.2913699526070124\n",
            "training error 0.11572273989281838, test error 0.2202653162937864\n",
            "Loss: 0.22599412397534824\n",
            "training error 0.1155430630593554, test error 0.220497769069694\n",
            "Loss: 0.3317657041053135\n",
            "training error 0.1155967724979115, test error 0.22021013475166568\n",
            "Loss: 0.20088520074856842\n",
            "training error 0.11548427348184613, test error 0.2205233314097656\n",
            "Loss: 0.3433971810392178\n",
            "training error 0.11554888127581306, test error 0.22012458107405708\n",
            "Loss: 0.16195622848200752\n",
            "training error 0.11561770403660172, test error 0.21976176682636064\n",
            "Loss: 0.0\n",
            "training error 0.11538265077275968, test error 0.2199500820627165\n",
            "Loss: 0.08569062720753529\n",
            "training error 0.1156675550571965, test error 0.21950489268522927\n",
            "Loss: 0.0\n",
            "training error 0.11565548198158697, test error 0.21944861134046567\n",
            "Loss: 0.0\n",
            "training error 0.11553267969664426, test error 0.22008465539588348\n",
            "Loss: 0.28983735715284453\n",
            "training error 0.11550752087640673, test error 0.21985487058652955\n",
            "Loss: 0.18512728040624982\n",
            "training error 0.11530349166605558, test error 0.2201757568370666\n",
            "Loss: 0.3313511496652044\n",
            "training error 0.11537392545514953, test error 0.22012735071861958\n",
            "Loss: 0.3092930841566588\n",
            "training error 0.11545354305867092, test error 0.22012242259265197\n",
            "Loss: 0.3070473985095745\n",
            "training error 0.11561506363599694, test error 0.22069673040679694\n",
            "Loss: 0.5687523191453936\n",
            "training error 0.11531497562474147, test error 0.22054104534031946\n",
            "Loss: 0.4978085726680348\n",
            "training error 0.11552480877675603, test error 0.22132076783647486\n",
            "Loss: 0.8531184064339392\n",
            "training error 0.1154279592700028, test error 0.22018769909755082\n",
            "Loss: 0.3367930890838311\n",
            "training error 0.11530113443955245, test error 0.21996296019483902\n",
            "Loss: 0.2343823691713265\n",
            "training error 0.11547860236283095, test error 0.22034898981193568\n",
            "Loss: 0.41029125952094514\n",
            "training error 0.115210080030681, test error 0.22008523125092172\n",
            "Loss: 0.2900997671242411\n",
            "training error 0.1151774513135574, test error 0.22022298298700713\n",
            "Loss: 0.3528715182161912\n",
            "training error 0.11530063245590921, test error 0.22056093188299558\n",
            "Loss: 0.5068706225733077\n",
            "training error 0.11529730464207072, test error 0.22070466274642453\n",
            "Loss: 0.5723669875541626\n",
            "training error 0.11532682745609618, test error 0.22031179514465904\n",
            "Loss: 0.39334211272550323\n",
            "training error 0.11570871554348124, test error 0.21984390737163312\n",
            "Loss: 0.1801314798725917\n",
            "training error 0.11531046306190115, test error 0.21975950607610295\n",
            "Loss: 0.14167086031586784\n",
            "training error 0.11525443884742846, test error 0.21980246047758478\n",
            "Loss: 0.16124464627853552\n",
            "training error 0.11537236004689336, test error 0.2195444799672897\n",
            "Loss: 0.04368613965630708\n",
            "training error 0.11500782496239956, test error 0.2201613414899116\n",
            "Loss: 0.32478225544119166\n",
            "training error 0.11523880409817615, test error 0.22052348293249327\n",
            "Loss: 0.48980560207783075\n",
            "training error 0.11523653390641876, test error 0.2207465457853289\n",
            "Loss: 0.5914525669290072\n",
            "training error 0.11517582440029697, test error 0.2208597592349689\n",
            "Loss: 0.6430425263953321\n",
            "training error 0.11508350124889417, test error 0.22019276904038046\n",
            "Loss: 0.33910339890930175\n",
            "training error 0.11531414406650595, test error 0.22038508656076966\n",
            "Loss: 0.4267400985513925\n",
            "training error 0.11533613445143913, test error 0.21999655478836327\n",
            "Loss: 0.24969100717957549\n",
            "training error 0.11505518205367726, test error 0.22020033879325016\n",
            "Loss: 0.34255284104678374\n",
            "training error 0.11513789788610906, test error 0.21969761737563778\n",
            "Loss: 0.11346895004307189\n",
            "training error 0.11511247177537104, test error 0.2194291751428333\n",
            "Loss: 0.0\n",
            "training error 0.11504304127057224, test error 0.21950749694541774\n",
            "Loss: 0.03569343162022065\n",
            "training error 0.11498651709938953, test error 0.21954331980996203\n",
            "Loss: 0.05201891091028976\n",
            "training error 0.11505101500071749, test error 0.21955997025569296\n",
            "Loss: 0.05960698379079421\n",
            "training error 0.11516789583711244, test error 0.21918766122228547\n",
            "Loss: 0.0\n",
            "training error 0.11507424113390713, test error 0.21912651655432444\n",
            "Loss: 0.0\n",
            "training error 0.11498251963391046, test error 0.21922755140832947\n",
            "Loss: 0.04610799988689074\n",
            "training error 0.11492518839648441, test error 0.21913675475515693\n",
            "Loss: 0.004672278368444971\n",
            "training error 0.11493761460421796, test error 0.2192225906303486\n",
            "Loss: 0.0438441123123301\n",
            "training error 0.11488510549128868, test error 0.21957288864432054\n",
            "Loss: 0.20370519141867938\n",
            "training error 0.1149244629613886, test error 0.21973767306571992\n",
            "Loss: 0.2789057759899016\n",
            "training error 0.11493531411429299, test error 0.21973715811547276\n",
            "Loss: 0.27867077465129064\n",
            "training error 0.11491568471625585, test error 0.2201640011517758\n",
            "Loss: 0.47346373855861046\n",
            "training error 0.11484839701707703, test error 0.2200363266868055\n",
            "Loss: 0.4151985559700755\n",
            "training error 0.11491614449972788, test error 0.21960833773259233\n",
            "Loss: 0.21988264398318247\n",
            "training error 0.1149196815584045, test error 0.21982619206668183\n",
            "Loss: 0.31930207414396783\n",
            "training error 0.11495765701299643, test error 0.21986362975090593\n",
            "Loss: 0.33638703712006723\n",
            "training error 0.11475068258974663, test error 0.21993550614924165\n",
            "Loss: 0.369188360969841\n",
            "training error 0.11474085491935956, test error 0.2199509738246703\n",
            "Loss: 0.3762471485925678\n",
            "training error 0.11496388483187543, test error 0.21963590756967508\n",
            "Loss: 0.23246434222594647\n",
            "training error 0.11489143884161174, test error 0.2196657123037477\n",
            "Loss: 0.24606595217315785\n",
            "training error 0.11472177488773509, test error 0.21955407999532658\n",
            "Loss: 0.19512172589852828\n",
            "training error 0.11489362311469198, test error 0.2198284454063265\n",
            "Loss: 0.32033040228978127\n",
            "training error 0.11472207449197719, test error 0.21965286661655384\n",
            "Loss: 0.24020372819595348\n",
            "training error 0.11469416585846035, test error 0.21955385466296826\n",
            "Loss: 0.19501889381692283\n",
            "training error 0.11470201160279482, test error 0.21967570730005034\n",
            "Loss: 0.2506272423628664\n",
            "training error 0.1147550150110327, test error 0.21974363790670925\n",
            "Loss: 0.28162787511469833\n",
            "training error 0.11473563529524704, test error 0.2196193821663388\n",
            "Loss: 0.22492285268094214\n",
            "training error 0.1147837310485982, test error 0.21968815333139494\n",
            "Loss: 0.2563070804492362\n",
            "training error 0.1146515014506464, test error 0.2195907072765557\n",
            "Loss: 0.21183685549812648\n",
            "training error 0.1145875688497836, test error 0.21955865757677598\n",
            "Loss: 0.1972107389131894\n",
            "training error 0.11463738296692459, test error 0.21942740425124627\n",
            "Loss: 0.13731231694509294\n",
            "training error 0.11462351553099297, test error 0.21976165591316305\n",
            "Loss: 0.2898505250874761\n",
            "training error 0.11465946424998621, test error 0.219650340623517\n",
            "Loss: 0.23905097266614383\n",
            "training error 0.1146409048281441, test error 0.22002737780197615\n",
            "Loss: 0.41111466645724626\n",
            "training error 0.11479355537816091, test error 0.22052979590229282\n",
            "Loss: 0.64039686754227\n",
            "training error 0.1146714359185396, test error 0.2200878101788513\n",
            "Loss: 0.43869342681241985\n",
            "training error 0.11461402601780113, test error 0.220130273826196\n",
            "Loss: 0.45807202508176825\n",
            "training error 0.1145501134977438, test error 0.219845685009904\n",
            "Loss: 0.32819782237594186\n",
            "training error 0.11457630428939534, test error 0.21993515990911058\n",
            "Loss: 0.3690303517354776\n",
            "training error 0.11454861340085573, test error 0.2197297935989186\n",
            "Loss: 0.27530992327191584\n",
            "training error 0.11457172122279001, test error 0.21994961752111988\n",
            "Loss: 0.37562818947627363\n",
            "training error 0.11456392437566956, test error 0.2195734458923718\n",
            "Loss: 0.2039594956717794\n",
            "training error 0.11464332460224813, test error 0.21973912030560938\n",
            "Loss: 0.279566234574391\n",
            "training error 0.11448428447925932, test error 0.22001437316391342\n",
            "Loss: 0.40517990408015514\n",
            "training error 0.1147514500034595, test error 0.22043122166082676\n",
            "Loss: 0.595411786313349\n",
            "training error 0.11463426384103477, test error 0.2193874827845462\n",
            "Loss: 0.11909386153960977\n",
            "training error 0.11445406839865833, test error 0.2195418152077587\n",
            "Loss: 0.18952459974477254\n",
            "training error 0.114563357766241, test error 0.21913335178301926\n",
            "Loss: 0.003119306965815305\n",
            "training error 0.11447498180147486, test error 0.2191266605612963\n",
            "Loss: 6.571864241688985e-05\n",
            "training error 0.11450510432678157, test error 0.21892690755678432\n",
            "Loss: 0.0\n",
            "training error 0.11436496204043085, test error 0.21906593656396398\n",
            "Loss: 0.06350475998186944\n",
            "training error 0.11453549668523856, test error 0.21904364597994957\n",
            "Loss: 0.05332301290328356\n",
            "training error 0.11436016443153511, test error 0.21938960787578848\n",
            "Loss: 0.21134922343164497\n",
            "training error 0.11440003995279392, test error 0.2197267257110788\n",
            "Loss: 0.36533570186525477\n",
            "training error 0.11438539729116533, test error 0.21941441974125442\n",
            "Loss: 0.2226826249503544\n",
            "training error 0.11439626459588675, test error 0.21938324875778437\n",
            "Loss: 0.20844454712889426\n",
            "training error 0.11437520349603449, test error 0.21911193548104155\n",
            "Loss: 0.08451584427064951\n",
            "training error 0.11436522847600886, test error 0.21906538686186722\n",
            "Loss: 0.06325367065580512\n",
            "training error 0.11428723465258651, test error 0.2193197122192743\n",
            "Loss: 0.17942274290247973\n",
            "training error 0.11447780837350718, test error 0.2193773212450555\n",
            "Loss: 0.20573701665902444\n",
            "training error 0.11437163746481467, test error 0.21933572115064126\n",
            "Loss: 0.18673519779697223\n",
            "training error 0.11444381575997249, test error 0.21921998386871688\n",
            "Loss: 0.13386947963742735\n",
            "training error 0.11442327116817534, test error 0.21967026786371815\n",
            "Loss: 0.33954725585343404\n",
            "training error 0.1142287464874479, test error 0.21947869710056572\n",
            "Loss: 0.25204281645383464\n",
            "training error 0.11436633028947935, test error 0.21889253288832353\n",
            "Loss: 0.0\n",
            "training error 0.11419477508822974, test error 0.21889219721048522\n",
            "Loss: 0.0\n",
            "training error 0.11444154458330028, test error 0.21855421621918697\n",
            "Loss: 0.0\n",
            "training error 0.11422189624760469, test error 0.21905972353997852\n",
            "Loss: 0.23129607359511084\n",
            "training error 0.11424085610270995, test error 0.2186617379057156\n",
            "Loss: 0.04919680269210858\n",
            "training error 0.114255332092542, test error 0.2187890266847866\n",
            "Loss: 0.10743808546074263\n",
            "training error 0.11422324764155299, test error 0.21895494563772527\n",
            "Loss: 0.18335469590593512\n",
            "training error 0.11414282495990455, test error 0.21904665795629943\n",
            "Loss: 0.22531788479367432\n",
            "training error 0.11416935861572879, test error 0.21905816778169462\n",
            "Loss: 0.23058423270234663\n",
            "training error 0.11418106712148957, test error 0.21909064529966515\n",
            "Loss: 0.2454443980802523\n",
            "training error 0.11415525213686888, test error 0.21933493884495275\n",
            "Loss: 0.3572214891442771\n",
            "training error 0.11416169437797732, test error 0.21932751156384342\n",
            "Loss: 0.35382311905660657\n",
            "training error 0.11449095322549863, test error 0.21881630287719686\n",
            "Loss: 0.1199183719919894\n",
            "training error 0.11410921969951483, test error 0.21892228397426844\n",
            "Loss: 0.16841027432403788\n",
            "training error 0.11408402574481459, test error 0.2187751228917916\n",
            "Loss: 0.10107637199874286\n",
            "training error 0.11408204600610863, test error 0.2189951550724826\n",
            "Loss: 0.2017526181482543\n",
            "training error 0.11403780890316811, test error 0.2189520613049526\n",
            "Loss: 0.18203496260471574\n",
            "training error 0.11408076973886802, test error 0.21928307853485382\n",
            "Loss: 0.3334926812557537\n",
            "training error 0.11430254922796598, test error 0.21861894342140242\n",
            "Loss: 0.02961608489426837\n",
            "training error 0.11411001893748964, test error 0.21839157767304512\n",
            "Loss: 0.0\n",
            "training error 0.11402701664202516, test error 0.21839617232514597\n",
            "Loss: 0.002103859567204047\n",
            "training error 0.11403471187300744, test error 0.21846452784435383\n",
            "Loss: 0.03340338125030762\n",
            "training error 0.11408970495028269, test error 0.2186033428633569\n",
            "Loss: 0.09696582284359767\n",
            "training error 0.11394557975257487, test error 0.21869133065648405\n",
            "Loss: 0.1372548276049823\n",
            "training error 0.11401645191108874, test error 0.21890178797872012\n",
            "Loss: 0.233621786660132\n",
            "training error 0.114159234888097, test error 0.21868986273063484\n",
            "Loss: 0.13658267446388095\n",
            "training error 0.11413128174921544, test error 0.21825255970587898\n",
            "Loss: 0.0\n",
            "training error 0.11402288644257182, test error 0.2185102035997407\n",
            "Loss: 0.11804850958399005\n",
            "training error 0.1141568372960992, test error 0.2190423658450874\n",
            "Loss: 0.3618771483242966\n",
            "training error 0.1140618028748417, test error 0.219229065051723\n",
            "Loss: 0.4474198823418041\n",
            "training error 0.1139706111022336, test error 0.2191267371486599\n",
            "Loss: 0.40053479508281864\n",
            "training error 0.1142655351748715, test error 0.21960359609484162\n",
            "Loss: 0.6190243041288124\n",
            "training error 0.11389154005847339, test error 0.21887608583385346\n",
            "Loss: 0.28569017876114433\n",
            "training error 0.1139608682413809, test error 0.218745558064926\n",
            "Loss: 0.2258843423011303\n",
            "training error 0.11392338753363465, test error 0.21888062345913273\n",
            "Loss: 0.2877692495795392\n",
            "training error 0.11393322388594904, test error 0.21902860552791234\n",
            "Loss: 0.3555723804931299\n",
            "training error 0.11386760148775016, test error 0.21910170368791657\n",
            "Loss: 0.38906484450029755\n",
            "training error 0.11393971026053062, test error 0.21880882519703093\n",
            "Loss: 0.25487237900054804\n",
            "training error 0.11389638950836259, test error 0.21874600372486874\n",
            "Loss: 0.22608853690180286\n",
            "training error 0.11394807573761041, test error 0.2183331958865389\n",
            "Loss: 0.03694627030657038\n",
            "training error 0.11389245579768896, test error 0.2184430205763244\n",
            "Loss: 0.08726627110449137\n",
            "training error 0.11370042490994729, test error 0.21879896364871934\n",
            "Loss: 0.2503539677045197\n",
            "training error 0.1138298127862602, test error 0.21883396254267132\n",
            "Loss: 0.2663899280612503\n",
            "training error 0.11375314692684241, test error 0.21893504350649762\n",
            "Loss: 0.31270368674638505\n",
            "training error 0.11390879991581178, test error 0.21856611203465573\n",
            "Loss: 0.1436649032658721\n",
            "training error 0.11388934611706258, test error 0.21897234490404824\n",
            "Loss: 0.3297946191967993\n",
            "training error 0.11372552962851235, test error 0.2188171802698892\n",
            "Loss: 0.25870054617966876\n",
            "training error 0.11389223818447064, test error 0.21881168093611372\n",
            "Loss: 0.2561808351701389\n",
            "training error 0.1137458210115065, test error 0.21871711356957257\n",
            "Loss: 0.2128515075926929\n",
            "training error 0.1137061730148019, test error 0.21865917217310252\n",
            "Loss: 0.18630364187779413\n",
            "training error 0.11371881959042139, test error 0.21866631480872942\n",
            "Loss: 0.18957628877664945\n",
            "training error 0.11370735264968422, test error 0.21885003978315717\n",
            "Loss: 0.27375627487868925\n",
            "training error 0.11369056272822638, test error 0.21875815520398642\n",
            "Loss: 0.2316561596293676\n",
            "training error 0.11373573163793434, test error 0.21838811923894252\n",
            "Loss: 0.062111314179413846\n",
            "training error 0.11378152927486317, test error 0.21812679764817597\n",
            "Loss: 0.0\n",
            "training error 0.11368390634591131, test error 0.21821423544640886\n",
            "Loss: 0.040085766249564614\n",
            "training error 0.11364503569318428, test error 0.21830230908159529\n",
            "Loss: 0.08046303127891008\n",
            "training error 0.11368391986769313, test error 0.21818389629120066\n",
            "Loss: 0.02617681258805238\n",
            "training error 0.1136105884372762, test error 0.21837742557433462\n",
            "Loss: 0.11490010803849593\n",
            "training error 0.11357159192055735, test error 0.2181988759195134\n",
            "Loss: 0.0330442073668058\n",
            "training error 0.11356159748010602, test error 0.21807339069206916\n",
            "Loss: 0.0\n",
            "training error 0.11349596962473066, test error 0.21816458834758354\n",
            "Loss: 0.041819708138146616\n",
            "training error 0.11377980614405517, test error 0.2179823104409558\n",
            "Loss: 0.0\n",
            "training error 0.11358096916172894, test error 0.21828284167529755\n",
            "Loss: 0.13786955176948723\n",
            "training error 0.11363434134786056, test error 0.21867139362695037\n",
            "Loss: 0.3161188559753336\n",
            "training error 0.11351466836693909, test error 0.2183432683378733\n",
            "Loss: 0.16559045373327752\n",
            "training error 0.11353055108428757, test error 0.21861848738307704\n",
            "Loss: 0.29184796731180906\n",
            "training error 0.11351170235649778, test error 0.21866148720572895\n",
            "Loss: 0.31157425728685073\n",
            "training error 0.11347661389881342, test error 0.21841640779761773\n",
            "Loss: 0.1991433872701842\n",
            "training error 0.113443025742249, test error 0.21846503090786826\n",
            "Loss: 0.22144937629844375\n",
            "training error 0.11341878740043819, test error 0.2184913620292454\n",
            "Loss: 0.23352885252929667\n",
            "training error 0.11353485142387702, test error 0.2182508782801814\n",
            "Loss: 0.12320625406818664\n",
            "training error 0.11339040853300326, test error 0.2182101334954149\n",
            "Loss: 0.1045144690861477\n",
            "training error 0.11361294625254295, test error 0.21810335716123114\n",
            "Loss: 0.05553052448634688\n",
            "training error 0.11338050990052129, test error 0.2180960748494806\n",
            "Loss: 0.05218974342213745\n",
            "training error 0.11349018504843339, test error 0.21850292717575956\n",
            "Loss: 0.238834396126264\n",
            "training error 0.11337640837327496, test error 0.21835683163372424\n",
            "Loss: 0.17181265397674395\n",
            "training error 0.1134607764807788, test error 0.21810204071767816\n",
            "Loss: 0.0549266022917827\n",
            "training error 0.11339500517179822, test error 0.2182313175544972\n",
            "Loss: 0.11423271596566753\n",
            "training error 0.11339705875752154, test error 0.21840633222877842\n",
            "Loss: 0.19452119163470005\n",
            "training error 0.11343427059314157, test error 0.21792498663241464\n",
            "Loss: 0.0\n",
            "training error 0.1133158205136191, test error 0.21784209195572132\n",
            "Loss: 0.0\n",
            "training error 0.11338063046592406, test error 0.21801648331776854\n",
            "Loss: 0.0800540246752135\n",
            "training error 0.11326146954417056, test error 0.2179705434622348\n",
            "Loss: 0.05896542094334656\n",
            "training error 0.11330852910348288, test error 0.21785458255405668\n",
            "Loss: 0.00573378552475301\n",
            "training error 0.1133229999894865, test error 0.21780499603725711\n",
            "Loss: 0.0\n",
            "training error 0.11321819614816542, test error 0.21767243492625338\n",
            "Loss: 0.0\n",
            "training error 0.11322179186848094, test error 0.2176671511503005\n",
            "Loss: 0.0\n",
            "training error 0.11314887337667594, test error 0.21766871070968205\n",
            "Loss: 0.0007164881670629342\n",
            "training error 0.11331449744629332, test error 0.2179198020724426\n",
            "Loss: 0.11607214079245587\n",
            "training error 0.1132247568488275, test error 0.2179122357019278\n",
            "Loss: 0.11259602118744994\n",
            "training error 0.11319157735548939, test error 0.2176933428653748\n",
            "Loss: 0.012032920418114657\n",
            "training error 0.11308078773451347, test error 0.21767342755890515\n",
            "Loss: 0.002883489112370796\n",
            "training error 0.11328120669405614, test error 0.21776841419064122\n",
            "Loss: 0.04652196705179357\n",
            "training error 0.11322004546135503, test error 0.21732445459099284\n",
            "Loss: 0.0\n",
            "training error 0.11339023189649582, test error 0.2176368645913099\n",
            "Loss: 0.1437528054102355\n",
            "training error 0.113025573131758, test error 0.21741545493465705\n",
            "Loss: 0.04187303441551826\n",
            "training error 0.11310992325588966, test error 0.21759357090764994\n",
            "Loss: 0.12383158497444313\n",
            "training error 0.11311743994384257, test error 0.21728504506338547\n",
            "Loss: 0.0\n",
            "training error 0.11299369633384417, test error 0.21738336438083247\n",
            "Loss: 0.045249003408542876\n",
            "training error 0.11313636621410486, test error 0.2174638568730364\n",
            "Loss: 0.08229365697891566\n",
            "training error 0.1130142755201615, test error 0.21731473539782867\n",
            "Loss: 0.013664232821231082\n",
            "training error 0.11299165372763126, test error 0.2172455188144442\n",
            "Loss: 0.0\n",
            "training error 0.11299007249020977, test error 0.21719824010323194\n",
            "Loss: 0.0\n",
            "training error 0.11305062227322327, test error 0.2174266308456893\n",
            "Loss: 0.10515312755241535\n",
            "training error 0.1129073239562374, test error 0.21727108257969024\n",
            "Loss: 0.03353732351776273\n",
            "training error 0.1129045766887324, test error 0.21731223713769815\n",
            "Loss: 0.05248524776813035\n",
            "training error 0.11297708346219365, test error 0.2171463193074461\n",
            "Loss: 0.0\n",
            "training error 0.11300587122983723, test error 0.21730199126947372\n",
            "Loss: 0.07168989210781795\n",
            "training error 0.11291580786128513, test error 0.21705442895848695\n",
            "Loss: 0.0\n",
            "training error 0.11285986284011662, test error 0.21697022891292767\n",
            "Loss: 0.0\n",
            "training error 0.11291442995755174, test error 0.2172551850576512\n",
            "Loss: 0.1313342139846796\n",
            "training error 0.11280396859718145, test error 0.21730315132921765\n",
            "Loss: 0.15344151958451846\n",
            "training error 0.11290838433830165, test error 0.21747412722427487\n",
            "Loss: 0.23224306572926512\n",
            "training error 0.11280289700145099, test error 0.21733658350619464\n",
            "Loss: 0.1688501667267861\n",
            "training error 0.11274749980667532, test error 0.2172209647043616\n",
            "Loss: 0.11556230211406948\n",
            "training error 0.11279225627225407, test error 0.2171655851646886\n",
            "Loss: 0.09003827517706231\n",
            "training error 0.11281426528025006, test error 0.21721782414328106\n",
            "Loss: 0.11411484036030206\n",
            "training error 0.1127898407814443, test error 0.2168068471369402\n",
            "Loss: 0.0\n",
            "training error 0.11265821040985009, test error 0.21690133798872535\n",
            "Loss: 0.0435829647600805\n",
            "training error 0.11267884736355586, test error 0.2167940638350706\n",
            "Loss: 0.0\n",
            "training error 0.11268634821537733, test error 0.21688611097011815\n",
            "Loss: 0.0424583281567914\n",
            "training error 0.11270499224308375, test error 0.2170302112448449\n",
            "Loss: 0.10892706451313128\n",
            "training error 0.11266355467477021, test error 0.21727847751080587\n",
            "Loss: 0.22344416040089854\n",
            "training error 0.11263186769723683, test error 0.2174605887984876\n",
            "Loss: 0.307446131884892\n",
            "training error 0.11272722020205864, test error 0.2170388501047792\n",
            "Loss: 0.11291188761275439\n",
            "training error 0.11251475781764055, test error 0.2171504446407932\n",
            "Loss: 0.16438679150998503\n",
            "training error 0.11250273763875351, test error 0.21706407381853157\n",
            "Loss: 0.12454676049911129\n",
            "training error 0.1125435172484009, test error 0.2168738283378936\n",
            "Loss: 0.036792752260805806\n",
            "training error 0.11268889009234573, test error 0.21687561766911656\n",
            "Loss: 0.03761811213982558\n",
            "training error 0.11259839514794352, test error 0.217308553617719\n",
            "Loss: 0.23731728329969837\n",
            "training error 0.11237043713454839, test error 0.21703135992953593\n",
            "Loss: 0.10945691513299938\n",
            "training error 0.11242242951448857, test error 0.21696404845909176\n",
            "Loss: 0.07840833877743592\n",
            "training error 0.11237982047450774, test error 0.2170624659698908\n",
            "Loss: 0.12380511259033611\n",
            "training error 0.11233592627289031, test error 0.2171177661901001\n",
            "Loss: 0.1493132926719598\n",
            "training error 0.11230656910776976, test error 0.21686621374307313\n",
            "Loss: 0.033280389105772024\n",
            "training error 0.11230927296652439, test error 0.21669043901087462\n",
            "Loss: 0.0\n",
            "training error 0.1123799677023714, test error 0.2171450396194172\n",
            "Loss: 0.2097926473441536\n",
            "training error 0.11225100057964053, test error 0.2170919504723251\n",
            "Loss: 0.18529265217388513\n",
            "training error 0.11222232159410139, test error 0.21678648433136968\n",
            "Loss: 0.04432374632377112\n",
            "training error 0.11225855890984283, test error 0.21651264674458537\n",
            "Loss: 0.0\n",
            "training error 0.11210914358544498, test error 0.2164821527256373\n",
            "Loss: 0.0\n",
            "training error 0.11210738984935631, test error 0.216295606873968\n",
            "Loss: 0.0\n",
            "training error 0.11205703836056156, test error 0.21632073794876128\n",
            "Loss: 0.011618855859563126\n",
            "training error 0.11222924046244574, test error 0.21585884627139196\n",
            "Loss: 0.0\n",
            "training error 0.1119796000765604, test error 0.2161650848505076\n",
            "Loss: 0.14186983040325174\n",
            "training error 0.11194241817989121, test error 0.21616681492440437\n",
            "Loss: 0.14267131430194535\n",
            "training error 0.11194687910662296, test error 0.21609076327536192\n",
            "Loss: 0.10743919370270749\n",
            "training error 0.11186790571366981, test error 0.21591263475820383\n",
            "Loss: 0.024918361114667498\n",
            "training error 0.11187533102125495, test error 0.21572987945608366\n",
            "Loss: 0.0\n",
            "training error 0.111800482040746, test error 0.21565191557582744\n",
            "Loss: 0.0\n",
            "training error 0.11190666361716219, test error 0.21578582605484564\n",
            "Loss: 0.06209565941515116\n",
            "training error 0.11174581249913096, test error 0.215715648837843\n",
            "Loss: 0.029553765773604468\n",
            "training error 0.11173229692635876, test error 0.21558459804553504\n",
            "Loss: 0.0\n",
            "training error 0.1117567207554709, test error 0.21557881027378406\n",
            "Loss: 0.0\n",
            "training error 0.11166893422366496, test error 0.21516561640796245\n",
            "Loss: 0.0\n",
            "training error 0.11174331084190454, test error 0.21545134070237013\n",
            "Loss: 0.1327927292369635\n",
            "training error 0.11150221608682068, test error 0.21553691534656752\n",
            "Loss: 0.1725642529710969\n",
            "training error 0.11151267321607262, test error 0.2154301971591271\n",
            "Loss: 0.12296609262281155\n",
            "training error 0.11147688151621829, test error 0.2154854335055847\n",
            "Loss: 0.14863764153463244\n",
            "training error 0.11141247535291232, test error 0.21557258713912789\n",
            "Loss: 0.18914301362806807\n",
            "training error 0.111453542097078, test error 0.21549126097070498\n",
            "Loss: 0.15134600415203092\n",
            "training error 0.11134341957653311, test error 0.2153348910240215\n",
            "Loss: 0.0786717779936108\n",
            "training error 0.11152078851130065, test error 0.21516636248475773\n",
            "Loss: 0.0003467453618899441\n",
            "training error 0.11125766014988747, test error 0.21493733228064\n",
            "Loss: 0.0\n",
            "training error 0.1111620512351054, test error 0.21512428861120744\n",
            "Loss: 0.0869817860786215\n",
            "training error 0.11123005652396394, test error 0.21502298332185749\n",
            "Loss: 0.03984930877696247\n",
            "training error 0.11111251067467535, test error 0.21489416205017126\n",
            "Loss: 0.0\n",
            "training error 0.11115979070909605, test error 0.21497617719281822\n",
            "Loss: 0.038165365622089276\n",
            "training error 0.11097781817922255, test error 0.214812806932873\n",
            "Loss: 0.0\n",
            "training error 0.11103749325631658, test error 0.21481333674601985\n",
            "Loss: 0.00024663945992209335\n",
            "training error 0.11094571546037682, test error 0.21486763882417767\n",
            "Loss: 0.025525429366890506\n",
            "training error 0.11088081741013828, test error 0.21463832307735\n",
            "Loss: 0.0\n",
            "training error 0.11083998730764573, test error 0.21456064934093788\n",
            "Loss: 0.0\n",
            "training error 0.11078568271818988, test error 0.21464252397758216\n",
            "Loss: 0.038159204353527265\n",
            "training error 0.11077509478775112, test error 0.21455819909582552\n",
            "Loss: 0.0\n",
            "training error 0.11072290514137625, test error 0.214477578497218\n",
            "Loss: 0.0\n",
            "training error 0.11064176942529347, test error 0.21431991037967485\n",
            "Loss: 0.0\n",
            "training error 0.11056352439883789, test error 0.21416616230817376\n",
            "Loss: 0.0\n",
            "training error 0.1104874163891795, test error 0.21403576520390796\n",
            "Loss: 0.0\n",
            "training error 0.11037689543159551, test error 0.21379877036586145\n",
            "Loss: 0.0\n",
            "training error 0.11034040749761964, test error 0.2138071949818225\n",
            "Loss: 0.003940441727801058\n",
            "training error 0.11027864558932536, test error 0.2136325797823779\n",
            "Loss: 0.0\n",
            "training error 0.11024322244660985, test error 0.21363006258220998\n",
            "Loss: 0.0\n",
            "training error 0.11018911269808875, test error 0.2133244144183399\n",
            "Loss: 0.0\n",
            "training error 0.11022472356687299, test error 0.21313153779851549\n",
            "Loss: 0.0\n",
            "training error 0.11009762899992705, test error 0.21308015053650334\n",
            "Loss: 0.0\n",
            "training error 0.11010091976596093, test error 0.21274105517134337\n",
            "Loss: 0.0\n",
            "training error 0.11003612756530984, test error 0.2126867123822165\n",
            "Loss: 0.0\n",
            "training error 0.10992422892769602, test error 0.21285233006680418\n",
            "Loss: 0.0778693143227649\n",
            "training error 0.109871081397583, test error 0.21268911406908236\n",
            "Loss: 0.001129213404515994\n",
            "training error 0.10972126976823819, test error 0.21268018766016517\n",
            "Loss: 0.0\n",
            "training error 0.10966247962358751, test error 0.21257394122746318\n",
            "Loss: 0.0\n",
            "training error 0.10968144599857568, test error 0.21256080314448614\n",
            "Loss: 0.0\n",
            "training error 0.10960077066016441, test error 0.2124515662558171\n",
            "Loss: 0.0\n",
            "training error 0.10944354142049861, test error 0.21241957652765892\n",
            "Loss: 0.0\n",
            "training error 0.10946731054729039, test error 0.2121450422690668\n",
            "Loss: 0.0\n",
            "training error 0.10937247415227763, test error 0.21208812239874836\n",
            "Loss: 0.0\n",
            "training error 0.10932489143964351, test error 0.21195426771130596\n",
            "Loss: 0.0\n",
            "training error 0.1093543372631949, test error 0.21219801943491287\n",
            "Loss: 0.11500203616514604\n",
            "training error 0.1091572272074231, test error 0.21205428894164027\n",
            "Loss: 0.04719000537916074\n",
            "training error 0.10905266807672083, test error 0.21200104217538843\n",
            "Loss: 0.022068186966706094\n",
            "training error 0.1088977505894888, test error 0.2118022209687973\n",
            "Loss: 0.0\n",
            "training error 0.10900166227660442, test error 0.21156153040884043\n",
            "Loss: 0.0\n",
            "training error 0.10892044605562688, test error 0.21143151530906046\n",
            "Loss: 0.0\n",
            "training error 0.10888393072317747, test error 0.21112149458230925\n",
            "Loss: 0.0\n",
            "training error 0.10860531993515388, test error 0.21098602898015595\n",
            "Loss: 0.0\n",
            "training error 0.10877503016271187, test error 0.21083164577787597\n",
            "Loss: 0.0\n",
            "training error 0.10842235091667325, test error 0.2106776340812857\n",
            "Loss: 0.0\n",
            "training error 0.10834506652828711, test error 0.2104190414092744\n",
            "Loss: 0.0\n",
            "training error 0.10825917229624414, test error 0.21030514534840353\n",
            "Loss: 0.0\n",
            "training error 0.10828329587327576, test error 0.21016449727036676\n",
            "Loss: 0.0\n",
            "training error 0.10806821630855647, test error 0.2100499235672111\n",
            "Loss: 0.0\n",
            "training error 0.10800198602861676, test error 0.20985566119843338\n",
            "Loss: 0.0\n",
            "training error 0.10805146679907303, test error 0.20967136119097354\n",
            "Loss: 0.0\n",
            "training error 0.10787561293255041, test error 0.20964454797942728\n",
            "Loss: 0.0\n",
            "training error 0.10767960942698138, test error 0.2095731700987906\n",
            "Loss: 0.0\n",
            "training error 0.10763950779622476, test error 0.20963337415097497\n",
            "Loss: 0.028726984544813483\n",
            "training error 0.10750932133090878, test error 0.2094219295778901\n",
            "Loss: 0.0\n",
            "training error 0.10754023321658919, test error 0.20894671295443745\n",
            "Loss: 0.0\n",
            "training error 0.10735004997351692, test error 0.20878913433506946\n",
            "Loss: 0.0\n",
            "training error 0.10726323824861471, test error 0.2088462481557095\n",
            "Loss: 0.027354785880961963\n",
            "training error 0.10707564553445197, test error 0.20857369016735208\n",
            "Loss: 0.0\n",
            "training error 0.10700527654621844, test error 0.2083667239636079\n",
            "Loss: 0.0\n",
            "training error 0.10689764912903467, test error 0.2082337343066338\n",
            "Loss: 0.0\n",
            "training error 0.10675037041150297, test error 0.2080461293913724\n",
            "Loss: 0.0\n",
            "training error 0.10661059430550512, test error 0.20797561954058363\n",
            "Loss: 0.0\n",
            "training error 0.10663230404562941, test error 0.20772346349316012\n",
            "Loss: 0.0\n",
            "training error 0.10644177745831551, test error 0.20775353040313166\n",
            "Loss: 0.014474489047078265\n",
            "training error 0.10630572404820852, test error 0.20760511139157686\n",
            "Loss: 0.0\n",
            "training error 0.1061609647135467, test error 0.2073538298607242\n",
            "Loss: 0.0\n",
            "training error 0.10612886675865824, test error 0.20748968974041207\n",
            "Loss: 0.06552079591639615\n",
            "training error 0.10598263405442356, test error 0.2073942870828119\n",
            "Loss: 0.019511200788957517\n",
            "training error 0.10587326411437778, test error 0.20729279530571282\n",
            "Loss: 0.0\n",
            "training error 0.10571271207568506, test error 0.20656387863815845\n",
            "Loss: 0.0\n",
            "training error 0.10555457551629172, test error 0.20647852111223128\n",
            "Loss: 0.0\n",
            "training error 0.10554896021939508, test error 0.20654104467383183\n",
            "Loss: 0.03028090343912826\n",
            "training error 0.10528480654871461, test error 0.2064403615285061\n",
            "Loss: 0.0\n",
            "training error 0.10518641283223636, test error 0.2060393213509205\n",
            "Loss: 0.0\n",
            "training error 0.10518639606090927, test error 0.2059792675910563\n",
            "Loss: 0.0\n",
            "training error 0.1048789563616924, test error 0.20579332383925375\n",
            "Loss: 0.0\n",
            "training error 0.10473090298461563, test error 0.205349357767765\n",
            "Loss: 0.0\n",
            "training error 0.10458311164681683, test error 0.20518087045984038\n",
            "Loss: 0.0\n",
            "training error 0.10447792926001635, test error 0.20492541896292887\n",
            "Loss: 0.0\n",
            "training error 0.10440955508819387, test error 0.20491725487966136\n",
            "Loss: 0.0\n",
            "training error 0.10424935420269102, test error 0.2047404730271806\n",
            "Loss: 0.0\n",
            "training error 0.10419604941853972, test error 0.20426065755148717\n",
            "Loss: 0.0\n",
            "training error 0.10395570408499027, test error 0.20428166219770988\n",
            "Loss: 0.010283255950760406\n",
            "training error 0.10379255768490409, test error 0.20404314717689145\n",
            "Loss: 0.0\n",
            "training error 0.10370836936158959, test error 0.2036887999033848\n",
            "Loss: 0.0\n",
            "training error 0.10372040111786371, test error 0.20342495521060058\n",
            "Loss: 0.0\n",
            "training error 0.10349026485899289, test error 0.20355554409803236\n",
            "Loss: 0.06419511671840183\n",
            "training error 0.10332198931208009, test error 0.20323750254753087\n",
            "Loss: 0.0\n",
            "training error 0.10329335351493152, test error 0.20303935927314928\n",
            "Loss: 0.0\n",
            "training error 0.10290815161485678, test error 0.20268659251948062\n",
            "Loss: 0.0\n",
            "training error 0.10283940946856093, test error 0.20231058517245218\n",
            "Loss: 0.0\n",
            "training error 0.10276369721976535, test error 0.20197373482654263\n",
            "Loss: 0.0\n",
            "training error 0.10258364555098404, test error 0.20182592384725442\n",
            "Loss: 0.0\n",
            "training error 0.1024481485071065, test error 0.20155166146568193\n",
            "Loss: 0.0\n",
            "training error 0.10235536220344194, test error 0.20139642692527412\n",
            "Loss: 0.0\n",
            "training error 0.10225374397896654, test error 0.20143086434222748\n",
            "Loss: 0.017099318731284008\n",
            "training error 0.10195893715121161, test error 0.20116360791446625\n",
            "Loss: 0.0\n",
            "training error 0.10180352240911532, test error 0.2008760245152235\n",
            "Loss: 0.0\n",
            "training error 0.10166959807164255, test error 0.20080737642297966\n",
            "Loss: 0.0\n",
            "training error 0.10153999248355619, test error 0.2005964132635886\n",
            "Loss: 0.0\n",
            "training error 0.10170079537027245, test error 0.20043960637537372\n",
            "Loss: 0.0\n",
            "training error 0.10125657245144166, test error 0.20014692906427473\n",
            "Loss: 0.0\n",
            "training error 0.10125540944489757, test error 0.20009373299252423\n",
            "Loss: 0.0\n",
            "training error 0.1009752140843585, test error 0.2000551407928395\n",
            "Loss: 0.0\n",
            "training error 0.1008518438494837, test error 0.19987493131187228\n",
            "Loss: 0.0\n",
            "training error 0.10072076754031589, test error 0.19987805605890968\n",
            "Loss: 0.0015633511500912078\n",
            "training error 0.10053588066083842, test error 0.19950560640189682\n",
            "Loss: 0.0\n",
            "training error 0.10038489157101385, test error 0.19921112374473307\n",
            "Loss: 0.0\n",
            "training error 0.10024687196540952, test error 0.19855026178914417\n",
            "Loss: 0.0\n",
            "training error 0.10004472073147183, test error 0.19830601379752905\n",
            "Loss: 0.0\n",
            "training error 0.100158673044266, test error 0.19797147452236666\n",
            "Loss: 0.0\n",
            "training error 0.0997325573394146, test error 0.19824156685117666\n",
            "Loss: 0.13642992227118622\n",
            "training error 0.09953999089067198, test error 0.19796439644527344\n",
            "Loss: 0.0\n",
            "training error 0.09953628843857319, test error 0.1982704152162095\n",
            "Loss: 0.15458273125423805\n",
            "training error 0.09946055311760026, test error 0.19790115447230022\n",
            "Loss: 0.0\n",
            "training error 0.09899403809909588, test error 0.19699308050850306\n",
            "Loss: 0.0\n",
            "training error 0.09893009532181307, test error 0.19690606653506404\n",
            "Loss: 0.0\n",
            "training error 0.09873023960391773, test error 0.19680074412169887\n",
            "Loss: 0.0\n",
            "training error 0.09850365234147929, test error 0.19642603223175617\n",
            "Loss: 0.0\n",
            "training error 0.09835337371297138, test error 0.19606142862728224\n",
            "Loss: 0.0\n",
            "training error 0.09817983544339116, test error 0.1957364605265256\n",
            "Loss: 0.0\n",
            "training error 0.09799842563296232, test error 0.1954623321304729\n",
            "Loss: 0.0\n",
            "training error 0.09783577234508749, test error 0.1955712325353362\n",
            "Loss: 0.055714266619211195\n",
            "training error 0.09767600908228763, test error 0.19506381715763316\n",
            "Loss: 0.0\n",
            "training error 0.09743865562408549, test error 0.19465255768303083\n",
            "Loss: 0.0\n",
            "training error 0.097287580447425, test error 0.19437861219287994\n",
            "Loss: 0.0\n",
            "training error 0.09710165176419767, test error 0.19443150420511865\n",
            "Loss: 0.02721081894865307\n",
            "training error 0.09706826304219786, test error 0.19427074475882958\n",
            "Loss: 0.0\n",
            "training error 0.09671357003420925, test error 0.19396329780888988\n",
            "Loss: 0.0\n",
            "training error 0.09662573533912319, test error 0.19377166647955296\n",
            "Loss: 0.0\n",
            "training error 0.09676132748732429, test error 0.19325994849657435\n",
            "Loss: 0.0\n",
            "training error 0.09620806449121885, test error 0.19311921439218888\n",
            "Loss: 0.0\n",
            "training error 0.09604205659109495, test error 0.19293870689902018\n",
            "Loss: 0.0\n",
            "training error 0.09585512259329473, test error 0.19247462170707771\n",
            "Loss: 0.0\n",
            "training error 0.09567151152466413, test error 0.19220611444356742\n",
            "Loss: 0.0\n",
            "training error 0.09562656902549646, test error 0.19235235807661238\n",
            "Loss: 0.07608687864502084\n",
            "training error 0.0953733790001625, test error 0.19175265259241103\n",
            "Loss: 0.0\n",
            "training error 0.09517128426778347, test error 0.19135299896966085\n",
            "Loss: 0.0\n",
            "training error 0.09496094356529321, test error 0.19089439013200613\n",
            "Loss: 0.0\n",
            "training error 0.09483551847965777, test error 0.19072231764052122\n",
            "Loss: 0.0\n",
            "training error 0.09459745644355502, test error 0.19087215150405815\n",
            "Loss: 0.07856126403589236\n",
            "training error 0.09430408609431673, test error 0.19017901606246523\n",
            "Loss: 0.0\n",
            "training error 0.09418839600110446, test error 0.19004466440423548\n",
            "Loss: 0.0\n",
            "training error 0.093960316568847, test error 0.18928103748297553\n",
            "Loss: 0.0\n",
            "training error 0.09386248271984791, test error 0.18923807398190498\n",
            "Loss: 0.0\n",
            "training error 0.09371326824026625, test error 0.1891689429345193\n",
            "Loss: 0.0\n",
            "training error 0.09336322996423858, test error 0.18874375175724098\n",
            "Loss: 0.0\n",
            "training error 0.0933743451674274, test error 0.18776121373541435\n",
            "Loss: 0.0\n",
            "training error 0.09296544061129644, test error 0.18775490692424424\n",
            "Loss: 0.0\n",
            "training error 0.09284698235947161, test error 0.18737999075403106\n",
            "Loss: 0.0\n",
            "training error 0.09259518612534827, test error 0.18760074268973853\n",
            "Loss: 0.11780976977271429\n",
            "training error 0.09247861159762913, test error 0.18744381293830345\n",
            "Loss: 0.03406029854926551\n",
            "training error 0.09215251931550966, test error 0.18702644860005302\n",
            "Loss: 0.0\n",
            "training error 0.09184566889208637, test error 0.18696739080600724\n",
            "Loss: 0.0\n",
            "training error 0.09166270497064866, test error 0.18635551996073013\n",
            "Loss: 0.0\n",
            "training error 0.09158906188412239, test error 0.18592484247610574\n",
            "Loss: 0.0\n",
            "training error 0.0914066431157774, test error 0.18549636633145614\n",
            "Loss: 0.0\n",
            "training error 0.09111671139027987, test error 0.18496616882388706\n",
            "Loss: 0.0\n",
            "training error 0.09097923586481436, test error 0.18461223418251319\n",
            "Loss: 0.0\n",
            "training error 0.09076154959112724, test error 0.1847125388304353\n",
            "Loss: 0.05433261146872148\n",
            "training error 0.09039329047140805, test error 0.18419366980988927\n",
            "Loss: 0.0\n",
            "training error 0.09019782935938842, test error 0.1841057758899073\n",
            "Loss: 0.0\n",
            "training error 0.08988271544487968, test error 0.18350473899976885\n",
            "Loss: 0.0\n",
            "training error 0.08972065141865408, test error 0.1833847433913549\n",
            "Loss: 0.0\n",
            "training error 0.08944000040603586, test error 0.18291235523010135\n",
            "Loss: 0.0\n",
            "training error 0.08927663916545635, test error 0.18285886463448128\n",
            "Loss: 0.0\n",
            "training error 0.08901229323676785, test error 0.18249131582187014\n",
            "Loss: 0.0\n",
            "training error 0.08871103416797188, test error 0.18210519505012668\n",
            "Loss: 0.0\n",
            "training error 0.08843163899932228, test error 0.1818219251639266\n",
            "Loss: 0.0\n",
            "training error 0.08823584263796012, test error 0.1814363085773311\n",
            "Loss: 0.0\n",
            "training error 0.08791406384169413, test error 0.18119713103595636\n",
            "Loss: 0.0\n",
            "training error 0.08765589831074427, test error 0.1807287286586248\n",
            "Loss: 0.0\n",
            "training error 0.087576912683274, test error 0.1800881111947053\n",
            "Loss: 0.0\n",
            "training error 0.08721062382773054, test error 0.1795719210500149\n",
            "Loss: 0.0\n",
            "training error 0.08697073073671907, test error 0.17901325266557125\n",
            "Loss: 0.0\n",
            "training error 0.08676217604983702, test error 0.17883216713363867\n",
            "Loss: 0.0\n",
            "training error 0.08648555139759549, test error 0.17817915325835756\n",
            "Loss: 0.0\n",
            "training error 0.08615318845054365, test error 0.1783798435965759\n",
            "Loss: 0.11263401725079003\n",
            "training error 0.08588874819624122, test error 0.17809845431947227\n",
            "Loss: 0.0\n",
            "training error 0.0856064284826863, test error 0.17763875495218476\n",
            "Loss: 0.0\n",
            "training error 0.08535500231228603, test error 0.17701835599992413\n",
            "Loss: 0.0\n",
            "training error 0.08503594513462745, test error 0.17633116914251978\n",
            "Loss: 0.0\n",
            "training error 0.08491739704591787, test error 0.1756057077021607\n",
            "Loss: 0.0\n",
            "training error 0.08441099407116447, test error 0.17529794217187028\n",
            "Loss: 0.0\n",
            "training error 0.08428301662530564, test error 0.17479286785076498\n",
            "Loss: 0.0\n",
            "training error 0.08392805893787496, test error 0.17461196247590186\n",
            "Loss: 0.0\n",
            "training error 0.08367498006228286, test error 0.17422005648073055\n",
            "Loss: 0.0\n",
            "training error 0.0834775547203116, test error 0.17337759566473354\n",
            "Loss: 0.0\n",
            "training error 0.08318993565944205, test error 0.17250103615835502\n",
            "Loss: 0.0\n",
            "training error 0.0830034110595807, test error 0.17261576755734573\n",
            "Loss: 0.06651055642667991\n",
            "training error 0.08244124588600613, test error 0.17227803898714025\n",
            "Loss: 0.0\n",
            "training error 0.08247138757417063, test error 0.1718257014248219\n",
            "Loss: 0.0\n",
            "training error 0.08191861821998235, test error 0.17078627786626197\n",
            "Loss: 0.0\n",
            "training error 0.08145160212217752, test error 0.17045717985688275\n",
            "Loss: 0.0\n",
            "training error 0.08118907589083994, test error 0.16979448833155786\n",
            "Loss: 0.0\n",
            "training error 0.08093034863039224, test error 0.16927690381347055\n",
            "Loss: 0.0\n",
            "training error 0.08070735920173383, test error 0.16876772786449212\n",
            "Loss: 0.0\n",
            "training error 0.08035919795640298, test error 0.16850012038177853\n",
            "Loss: 0.0\n",
            "training error 0.07990463413499212, test error 0.1683702624388462\n",
            "Loss: 0.0\n",
            "training error 0.07976206790183277, test error 0.1671643106491115\n",
            "Loss: 0.0\n",
            "training error 0.07957074480952549, test error 0.16641138573472045\n",
            "Loss: 0.0\n",
            "training error 0.07898235843806627, test error 0.1662491346196834\n",
            "Loss: 0.0\n",
            "training error 0.0787572338547583, test error 0.16529753538696387\n",
            "Loss: 0.0\n",
            "training error 0.07835345655502733, test error 0.1647907404109222\n",
            "Loss: 0.0\n",
            "training error 0.07812751720006667, test error 0.1640626551357178\n",
            "Loss: 0.0\n",
            "training error 0.07761938754969247, test error 0.16367458529261783\n",
            "Loss: 0.0\n",
            "training error 0.07726886651362253, test error 0.16314598213676954\n",
            "Loss: 0.0\n",
            "training error 0.07728233766961601, test error 0.16206081349687707\n",
            "Loss: 0.0\n",
            "training error 0.07665194463531387, test error 0.16184927671837704\n",
            "Loss: 0.0\n",
            "training error 0.07622529616210846, test error 0.16135721664750347\n",
            "Loss: 0.0\n",
            "training error 0.07620393838052925, test error 0.16076235322343593\n",
            "Loss: 0.0\n",
            "training error 0.07527917545680679, test error 0.16100380760698402\n",
            "Loss: 0.15019336225596813\n",
            "training error 0.07515261102821827, test error 0.16029160258993722\n",
            "Loss: 0.0\n",
            "training error 0.07457356158623862, test error 0.1596478316895718\n",
            "Loss: 0.0\n",
            "training error 0.07432551227197512, test error 0.15952577021511838\n",
            "Loss: 0.0\n",
            "training error 0.07402366162308603, test error 0.1577192882557525\n",
            "Loss: 0.0\n",
            "training error 0.07348232895841303, test error 0.15693835459057426\n",
            "Loss: 0.0\n",
            "training error 0.07306738885987933, test error 0.15633066482916189\n",
            "Loss: 0.0\n",
            "training error 0.0727040930164048, test error 0.156106458561941\n",
            "Loss: 0.0\n",
            "training error 0.07230389815218181, test error 0.15613385662002738\n",
            "Loss: 0.01755088055854781\n",
            "training error 0.0721182579126739, test error 0.15406544213566253\n",
            "Loss: 0.0\n",
            "training error 0.0717899103959099, test error 0.15315027489693983\n",
            "Loss: 0.0\n",
            "training error 0.07126120356145885, test error 0.15282950113233298\n",
            "Loss: 0.0\n",
            "training error 0.07072804417015852, test error 0.15171787462783334\n",
            "Loss: 0.0\n",
            "training error 0.07037602723799773, test error 0.15272200274191042\n",
            "Loss: 0.6618390328365864\n",
            "training error 0.06980140191984817, test error 0.15129675686027955\n",
            "Loss: 0.0\n",
            "training error 0.0697240282867634, test error 0.15156175731140276\n",
            "Loss: 0.17515276376209865\n",
            "training error 0.06901400504215124, test error 0.1502261841951402\n",
            "Loss: 0.0\n",
            "training error 0.06854502984277394, test error 0.1485692960499059\n",
            "Loss: 0.0\n",
            "training error 0.06813197024336579, test error 0.14785027283357993\n",
            "Loss: 0.0\n",
            "training error 0.06770350966828799, test error 0.1474978189101038\n",
            "Loss: 0.0\n",
            "training error 0.06711636048076876, test error 0.14673573911062285\n",
            "Loss: 0.0\n",
            "training error 0.06695077415976745, test error 0.14556489096052\n",
            "Loss: 0.0\n",
            "training error 0.06637064840964861, test error 0.1443180585651625\n",
            "Loss: 0.0\n",
            "training error 0.06608435995587121, test error 0.14366420366611432\n",
            "Loss: 0.0\n",
            "training error 0.06556375975905919, test error 0.14234499690383884\n",
            "Loss: 0.0\n",
            "training error 0.06514735842339452, test error 0.14148121326779506\n",
            "Loss: 0.0\n",
            "training error 0.0646197522786829, test error 0.14108057237399182\n",
            "Loss: 0.0\n",
            "training error 0.06423733834333933, test error 0.13989493752667786\n",
            "Loss: 0.0\n",
            "training error 0.0637481941553607, test error 0.139640246482042\n",
            "Loss: 0.0\n",
            "training error 0.06320980141053865, test error 0.13845725411496534\n",
            "Loss: 0.0\n",
            "training error 0.06283948475730394, test error 0.13834372175669624\n",
            "Loss: 0.0\n",
            "training error 0.0626344836513191, test error 0.1381611856336863\n",
            "Loss: 0.0\n",
            "training error 0.06196776093639137, test error 0.13664526246660097\n",
            "Loss: 0.0\n",
            "training error 0.06176834296794141, test error 0.13586094920662226\n",
            "Loss: 0.0\n",
            "training error 0.06108285355528099, test error 0.1351689553055926\n",
            "Loss: 0.0\n",
            "training error 0.06080463061670149, test error 0.1334167020903149\n",
            "Loss: 0.0\n",
            "training error 0.060415006983560254, test error 0.13333598974478245\n",
            "Loss: 0.0\n",
            "training error 0.05979453855605152, test error 0.13209116611664887\n",
            "Loss: 0.0\n",
            "training error 0.059361815257610195, test error 0.13100775054549985\n",
            "Loss: 0.0\n",
            "training error 0.0589133772775587, test error 0.1303534844256404\n",
            "Loss: 0.0\n",
            "training error 0.05852791288474436, test error 0.1298856628628312\n",
            "Loss: 0.0\n",
            "training error 0.05791816100645693, test error 0.1289501278880995\n",
            "Loss: 0.0\n",
            "training error 0.05756301552822166, test error 0.1276064511743528\n",
            "Loss: 0.0\n",
            "training error 0.0573303371926521, test error 0.12637853874706692\n",
            "Loss: 0.0\n",
            "training error 0.056764107871846325, test error 0.12665910256233429\n",
            "Loss: 0.22200273721226793\n",
            "training error 0.05649699861713241, test error 0.1264660352489752\n",
            "Loss: 0.0692336711404673\n",
            "training error 0.05573968088527606, test error 0.1245470099722036\n",
            "Loss: 0.0\n",
            "training error 0.05562931329662333, test error 0.1242052769516078\n",
            "Loss: 0.0\n",
            "training error 0.05523571947904035, test error 0.1233958053082801\n",
            "Loss: 0.0\n",
            "training error 0.05463677860325364, test error 0.12267671288429403\n",
            "Loss: 0.0\n",
            "training error 0.05409966393077875, test error 0.1207575612121501\n",
            "Loss: 0.0\n",
            "training error 0.05373191733499077, test error 0.12097473866114242\n",
            "Loss: 0.1798458388959867\n",
            "training error 0.05344243681664437, test error 0.12007741975979819\n",
            "Loss: 0.0\n",
            "training error 0.05303426376139664, test error 0.1178976231904906\n",
            "Loss: 0.0\n",
            "training error 0.05253224965433486, test error 0.11800712574183193\n",
            "Loss: 0.09287935445858597\n",
            "training error 0.05201385047532206, test error 0.11674213553733757\n",
            "Loss: 0.0\n",
            "training error 0.05170070879078485, test error 0.11611782921653682\n",
            "Loss: 0.0\n",
            "training error 0.05126026068158098, test error 0.11406768515817226\n",
            "Loss: 0.0\n",
            "training error 0.05086338743474777, test error 0.11437062639983449\n",
            "Loss: 0.2655802484657688\n",
            "training error 0.05037450490454642, test error 0.11347101015932269\n",
            "Loss: 0.0\n",
            "training error 0.049985358783183734, test error 0.1126901984549081\n",
            "Loss: 0.0\n",
            "training error 0.04951246007968047, test error 0.11167687791551092\n",
            "Loss: 0.0\n",
            "training error 0.04911645796042022, test error 0.11141286486677866\n",
            "Loss: 0.0\n",
            "training error 0.04876080121740021, test error 0.1104950456109431\n",
            "Loss: 0.0\n",
            "training error 0.04860735055756363, test error 0.11008732962643643\n",
            "Loss: 0.0\n",
            "training error 0.04813342279294152, test error 0.10797563552829283\n",
            "Loss: 0.0\n",
            "training error 0.047653860791755, test error 0.10739608466536009\n",
            "Loss: 0.0\n",
            "training error 0.047216359994564916, test error 0.10660352824863764\n",
            "Loss: 0.0\n",
            "training error 0.04721729341894787, test error 0.10591339873173178\n",
            "Loss: 0.0\n",
            "training error 0.046550835368250415, test error 0.10546881647399073\n",
            "Loss: 0.0\n",
            "training error 0.04618183032115897, test error 0.10482943566217529\n",
            "Loss: 0.0\n",
            "training error 0.04585860278413876, test error 0.10363583642395645\n",
            "Loss: 0.0\n",
            "training error 0.045597401621064605, test error 0.10394397553204479\n",
            "Loss: 0.2973287221109455\n",
            "training error 0.04529097339086548, test error 0.10363092984729225\n",
            "Loss: 0.0\n",
            "training error 0.04481617547956779, test error 0.10238133450008899\n",
            "Loss: 0.0\n",
            "training error 0.044523748823623185, test error 0.10068071413574936\n",
            "Loss: 0.0\n",
            "training error 0.04391607492825739, test error 0.09954335428033184\n",
            "Loss: 0.0\n",
            "training error 0.04378992066125298, test error 0.0997529979389711\n",
            "Loss: 0.21060537908825783\n",
            "training error 0.043464336438233504, test error 0.10021906732536022\n",
            "Loss: 0.6788128146912209\n",
            "training error 0.04339701896497316, test error 0.09732099933723685\n",
            "Loss: 0.0\n",
            "training error 0.042730017722073514, test error 0.09669807111072812\n",
            "Loss: 0.0\n",
            "training error 0.04239728951947848, test error 0.0958067609661177\n",
            "Loss: 0.0\n",
            "training error 0.04233399262420058, test error 0.09565736774636023\n",
            "Loss: 0.0\n",
            "training error 0.04167915535542643, test error 0.09471344053463708\n",
            "Loss: 0.0\n",
            "training error 0.04150999477012121, test error 0.09418651417930242\n",
            "Loss: 0.0\n",
            "training error 0.041140121478164364, test error 0.09419689999815642\n",
            "Loss: 0.011026864030894146\n",
            "training error 0.04092199964634451, test error 0.0921535538508361\n",
            "Loss: 0.0\n",
            "training error 0.04070321333556686, test error 0.09191545100018544\n",
            "Loss: 0.0\n",
            "training error 0.04012305108537792, test error 0.09190107594046674\n",
            "Loss: 0.0\n",
            "training error 0.04018333561737508, test error 0.08952988679365899\n",
            "Loss: 0.0\n",
            "training error 0.03980286528605517, test error 0.09050265240312681\n",
            "Loss: 1.086526124745113\n",
            "training error 0.03931796055211936, test error 0.0891938792698386\n",
            "Loss: 0.0\n",
            "training error 0.039080507996642935, test error 0.08925404886742207\n",
            "Loss: 0.06745933473915056\n",
            "training error 0.03868901931560044, test error 0.08825564608512808\n",
            "Loss: 0.0\n",
            "training error 0.0384746603217631, test error 0.08757234829110731\n",
            "Loss: 0.0\n",
            "training error 0.03817297220066036, test error 0.08712310849729575\n",
            "Loss: 0.0\n",
            "training error 0.037930738603176896, test error 0.08660520570048152\n",
            "Loss: 0.0\n",
            "training error 0.03756045392086871, test error 0.0862507550267803\n",
            "Loss: 0.0\n",
            "training error 0.03727521276912661, test error 0.08520142795927621\n",
            "Loss: 0.0\n",
            "training error 0.03731759878939831, test error 0.08419536647025969\n",
            "Loss: 0.0\n",
            "training error 0.037144180324810885, test error 0.08394274430045597\n",
            "Loss: 0.0\n",
            "training error 0.036694303959336594, test error 0.08286001778879767\n",
            "Loss: 0.0\n",
            "training error 0.03634642478717322, test error 0.08237507717519922\n",
            "Loss: 0.0\n",
            "training error 0.036066685454589874, test error 0.08262932647577152\n",
            "Loss: 0.3086483306492749\n",
            "training error 0.03580152468109628, test error 0.08238622116039171\n",
            "Loss: 0.013528345677649156\n",
            "training error 0.03562935946462792, test error 0.08175797198354912\n",
            "Loss: 0.0\n",
            "training error 0.035440790097018386, test error 0.08112357499773919\n",
            "Loss: 0.0\n",
            "training error 0.03509278436240135, test error 0.08044889832251631\n",
            "Loss: 0.0\n",
            "training error 0.03500019778500302, test error 0.0805177455442905\n",
            "Loss: 0.08557882483137824\n",
            "training error 0.03479066787033309, test error 0.07982853710882844\n",
            "Loss: 0.0\n",
            "training error 0.034511076621268046, test error 0.07957587924421976\n",
            "Loss: 0.0\n",
            "training error 0.034299988906097464, test error 0.07865086025775432\n",
            "Loss: 0.0\n",
            "training error 0.03397067434023666, test error 0.077871065548024\n",
            "Loss: 0.0\n",
            "training error 0.03383854876661658, test error 0.07775482789098304\n",
            "Loss: 0.0\n",
            "training error 0.0337908091875714, test error 0.07741509466504311\n",
            "Loss: 0.0\n",
            "training error 0.03348657712194278, test error 0.07642704375867762\n",
            "Loss: 0.0\n",
            "training error 0.03318746365752479, test error 0.07624519152270809\n",
            "Loss: 0.0\n",
            "training error 0.03352682859870874, test error 0.07697115374127447\n",
            "Loss: 0.9521416420734896\n",
            "training error 0.0327954966962347, test error 0.07531157274722881\n",
            "Loss: 0.0\n",
            "training error 0.03273304866426242, test error 0.07479721372029277\n",
            "Loss: 0.0\n",
            "training error 0.0322720562724158, test error 0.073598607621395\n",
            "Loss: 0.0\n",
            "training error 0.03212698516446282, test error 0.07339754125058054\n",
            "Loss: 0.0\n",
            "training error 0.031920459252234086, test error 0.07272430200201192\n",
            "Loss: 0.0\n",
            "training error 0.03174165635843717, test error 0.0723564413889012\n",
            "Loss: 0.0\n",
            "training error 0.03181587152449471, test error 0.07297494997442854\n",
            "Loss: 0.8548079115762164\n",
            "training error 0.03160012789647493, test error 0.07187584204948663\n",
            "Loss: 0.0\n",
            "training error 0.031210773188582373, test error 0.07170203604755793\n",
            "Loss: 0.0\n",
            "training error 0.031184647817855047, test error 0.07174174109031722\n",
            "Loss: 0.055375056201967254\n",
            "training error 0.03115840003938964, test error 0.07121885806248983\n",
            "Loss: 0.0\n",
            "training error 0.03062749587804169, test error 0.07061129774455657\n",
            "Loss: 0.0\n",
            "training error 0.030801411207188475, test error 0.06936155755559299\n",
            "Loss: 0.0\n",
            "training error 0.030773779291879872, test error 0.06931552478014513\n",
            "Loss: 0.0\n",
            "training error 0.030682228784237483, test error 0.06828676231330884\n",
            "Loss: 0.0\n",
            "training error 0.030044371279283222, test error 0.06857447341899457\n",
            "Loss: 0.4213277887823663\n",
            "training error 0.029949921593631273, test error 0.06888146892236782\n",
            "Loss: 0.8708958938928646\n",
            "training error 0.029954384261605797, test error 0.06802841368533659\n",
            "Loss: 0.0\n",
            "training error 0.029568772348585265, test error 0.06806272770387606\n",
            "Loss: 0.05044071540192263\n",
            "training error 0.02955707770188071, test error 0.06702217422363937\n",
            "Loss: 0.0\n",
            "training error 0.029424686752486013, test error 0.06699731224732759\n",
            "Loss: 0.0\n",
            "training error 0.02921012331038625, test error 0.06633754008512201\n",
            "Loss: 0.0\n",
            "training error 0.029107663766749454, test error 0.06644551586196717\n",
            "Loss: 0.1627672306006689\n",
            "training error 0.02890389259240358, test error 0.06608974188808314\n",
            "Loss: 0.0\n",
            "training error 0.02876227052637983, test error 0.06569233268730726\n",
            "Loss: 0.0\n",
            "training error 0.028792958015679843, test error 0.06665344495044938\n",
            "Loss: 1.4630508977615087\n",
            "training error 0.0286659966091161, test error 0.06536870249967289\n",
            "Loss: 0.0\n",
            "training error 0.028439695593810474, test error 0.0647234708282158\n",
            "Loss: 0.0\n",
            "training error 0.028378433699980988, test error 0.06444857545012514\n",
            "Loss: 0.0\n",
            "training error 0.02823896586964115, test error 0.0640620811858295\n",
            "Loss: 0.0\n",
            "training error 0.028302676205128587, test error 0.06374815842488239\n",
            "Loss: 0.0\n",
            "training error 0.027925707973869413, test error 0.06388588555909978\n",
            "Loss: 0.21604880457790632\n",
            "training error 0.027793420530039987, test error 0.06310200506375346\n",
            "Loss: 0.0\n",
            "training error 0.02760318299408972, test error 0.06293511520931726\n",
            "Loss: 0.0\n",
            "training error 0.027535477233195552, test error 0.06246035502562302\n",
            "Loss: 0.0\n",
            "training error 0.027398773628213267, test error 0.061972826700808316\n",
            "Loss: 0.0\n",
            "training error 0.0273281851344234, test error 0.06248988386216414\n",
            "Loss: 0.834328832299458\n",
            "training error 0.027122915594641306, test error 0.062273644622409995\n",
            "Loss: 0.48540293805536816\n",
            "training error 0.027093148625050762, test error 0.06223498011186549\n",
            "Loss: 0.4230134802835295\n",
            "training error 0.026995336228018637, test error 0.06207619480243663\n",
            "Loss: 0.1667958476823328\n",
            "training error 0.026934289555865788, test error 0.06181250149575589\n",
            "Loss: 0.0\n",
            "training error 0.026738086814119, test error 0.06096036612035348\n",
            "Loss: 0.0\n",
            "training error 0.026724794748148376, test error 0.060229246490859624\n",
            "Loss: 0.0\n",
            "training error 0.02661785401467583, test error 0.06023732111586177\n",
            "Loss: 0.013406485175559979\n",
            "training error 0.026517068297071573, test error 0.06052875475623551\n",
            "Loss: 0.49728044567407537\n",
            "training error 0.02637337303992125, test error 0.060891700702731165\n",
            "Loss: 1.0998879289849217\n",
            "training error 0.026339612451600217, test error 0.060017868251747465\n",
            "Loss: 0.0\n",
            "training error 0.02612742815884727, test error 0.06000474305360223\n",
            "Loss: 0.0\n",
            "training error 0.02612704119617457, test error 0.0597325261649495\n",
            "Loss: 0.0\n",
            "training error 0.025980764373159083, test error 0.059755004302209286\n",
            "Loss: 0.03763131865159863\n",
            "training error 0.026047842890918067, test error 0.059765343958121706\n",
            "Loss: 0.054941244375927845\n",
            "training error 0.025978206914912937, test error 0.05911796209237169\n",
            "Loss: 0.0\n",
            "training error 0.025769283061124474, test error 0.058925453248601295\n",
            "Loss: 0.0\n",
            "training error 0.02565883126664633, test error 0.05898377516362105\n",
            "Loss: 0.09897575971744565\n",
            "training error 0.025594746356893232, test error 0.05865744680018533\n",
            "Loss: 0.0\n",
            "training error 0.02557904315385188, test error 0.05879949077080126\n",
            "Loss: 0.24215846131148133\n",
            "training error 0.025341220994794314, test error 0.058506403091438834\n",
            "Loss: 0.0\n",
            "training error 0.025328374237169125, test error 0.058141119289425114\n",
            "Loss: 0.0\n",
            "training error 0.025255215653874435, test error 0.05761237729065937\n",
            "Loss: 0.0\n",
            "training error 0.025105631909871813, test error 0.057563117477718306\n",
            "Loss: 0.0\n",
            "training error 0.025131934169567768, test error 0.0574986848426111\n",
            "Loss: 0.0\n",
            "training error 0.02509662230177023, test error 0.05740306413467794\n",
            "Loss: 0.0\n",
            "training error 0.02494242956944247, test error 0.057376676725769904\n",
            "Loss: 0.0\n",
            "training error 0.024865195318675936, test error 0.05684039525225173\n",
            "Loss: 0.0\n",
            "training error 0.024869170405756785, test error 0.057023098889047115\n",
            "Loss: 0.32143273456239907\n",
            "training error 0.024680176992878503, test error 0.05679774033191506\n",
            "Loss: 0.0\n",
            "training error 0.024669898483278437, test error 0.05658903775689045\n",
            "Loss: 0.0\n",
            "training error 0.02465081013133594, test error 0.05674764598120912\n",
            "Loss: 0.28028082930136033\n",
            "training error 0.024521297946490665, test error 0.05661531016638801\n",
            "Loss: 0.04642667650656129\n",
            "training error 0.024725724467270276, test error 0.05741295350157585\n",
            "Loss: 1.4559635175720675\n",
            "training error 0.024539797601620235, test error 0.05523373514141435\n",
            "Loss: 0.0\n",
            "training error 0.024342271438692886, test error 0.05527908720217053\n",
            "Loss: 0.08210934972994188\n",
            "training error 0.024248880105120618, test error 0.055650763828030345\n",
            "Loss: 0.7550253220215408\n",
            "training error 0.024261912009822185, test error 0.05560528026867134\n",
            "Loss: 0.6726778956840818\n",
            "training error 0.024097009810671737, test error 0.055634642430943855\n",
            "Loss: 0.7258377303346775\n",
            "training error 0.024184431409330263, test error 0.0546092624894371\n",
            "Loss: 0.0\n",
            "training error 0.023960779461837615, test error 0.055084394497985405\n",
            "Loss: 0.8700575449818837\n",
            "training error 0.023961141520426, test error 0.054494476861426666\n",
            "Loss: 0.0\n",
            "training error 0.02417404093311994, test error 0.0537645255586433\n",
            "Loss: 0.0\n",
            "training error 0.02374105523011312, test error 0.05395295615625293\n",
            "Loss: 0.35047384060722386\n",
            "training error 0.023772765316438068, test error 0.054250443945352486\n",
            "Loss: 0.9037899649633863\n",
            "training error 0.023709119203829416, test error 0.054211796885282715\n",
            "Loss: 0.8319078834826854\n",
            "training error 0.023633882666197977, test error 0.0545118464785178\n",
            "Loss: 1.3899888673980065\n",
            "training error 0.023673212164990905, test error 0.05343997521909438\n",
            "Loss: 0.0\n",
            "training error 0.023609835430389997, test error 0.054452703415707675\n",
            "Loss: 1.8950760969878688\n",
            "training error 0.023629280444457845, test error 0.05359995624106597\n",
            "Loss: 0.2993658236473573\n",
            "training error 0.023405317729406124, test error 0.05325200925605588\n",
            "Loss: 0.0\n",
            "training error 0.023344975974067428, test error 0.05296610409346507\n",
            "Loss: 0.0\n",
            "training error 0.023295626089676953, test error 0.053462666997671215\n",
            "Loss: 0.9375107206863964\n",
            "training error 0.02336696156669277, test error 0.05337641393510598\n",
            "Loss: 0.7746649459376309\n",
            "training error 0.023155395183833735, test error 0.0527282675968986\n",
            "Loss: 0.0\n",
            "training error 0.0232940216090294, test error 0.05324406292925028\n",
            "Loss: 0.9782140697184971\n",
            "training error 0.023090343843529777, test error 0.05287128828805031\n",
            "Loss: 0.27124102055671173\n",
            "training error 0.02306524647663227, test error 0.05275824210813259\n",
            "Loss: 0.056847138356874716\n",
            "training error 0.02333622760805409, test error 0.052148231832233126\n",
            "Loss: 0.0\n",
            "training error 0.0229583134938835, test error 0.05228048920496331\n",
            "Loss: 0.2536181344665156\n",
            "training error 0.02308922512700473, test error 0.05237758596330138\n",
            "Loss: 0.43981190351018995\n",
            "training error 0.022905933210474565, test error 0.052654573074366176\n",
            "Loss: 0.9709653124232664\n",
            "training error 0.022951396458981324, test error 0.05232113782787219\n",
            "Loss: 0.33156636296955977\n",
            "training error 0.02300163454370967, test error 0.051886797134675776\n",
            "Loss: 0.0\n",
            "training error 0.022875225587916836, test error 0.05186021504082394\n",
            "Loss: 0.0\n",
            "training error 0.022782628219634886, test error 0.052367889677575864\n",
            "Loss: 0.9789289079350727\n",
            "training error 0.022714125840947213, test error 0.0523357573624833\n",
            "Loss: 0.9169694365613656\n",
            "training error 0.022671937178717037, test error 0.05219968483514499\n",
            "Loss: 0.6545861679397635\n",
            "training error 0.022824127358305912, test error 0.05160436522894135\n",
            "Loss: 0.0\n",
            "training error 0.022605766333507145, test error 0.05197359330844679\n",
            "Loss: 0.7154977643216043\n",
            "training error 0.022698827499159913, test error 0.05235948365836513\n",
            "Loss: 1.463284018849409\n",
            "training error 0.022572346083572396, test error 0.051874451484949485\n",
            "Loss: 0.5233787002512313\n",
            "training error 0.02251602536169211, test error 0.05168675682386765\n",
            "Loss: 0.15966012673689356\n",
            "training error 0.022549048026550365, test error 0.05157083511642266\n",
            "Loss: 0.0\n",
            "training error 0.02258654279260051, test error 0.05189813639369109\n",
            "Loss: 0.6346635196609496\n",
            "training error 0.02248642354293456, test error 0.05136100855353961\n",
            "Loss: 0.0\n",
            "training error 0.022495271629657067, test error 0.0517039103943768\n",
            "Loss: 0.6676306608732974\n",
            "training error 0.02259544407591173, test error 0.05112840002682807\n",
            "Loss: 0.0\n",
            "training error 0.022494903808408115, test error 0.050580392229970975\n",
            "Loss: 0.0\n",
            "training error 0.022365605817357966, test error 0.050895624171010956\n",
            "Loss: 0.6232295305396818\n",
            "training error 0.022261334603555706, test error 0.05072509275448065\n",
            "Loss: 0.2860802736597501\n",
            "training error 0.02218348076442692, test error 0.050866945835946406\n",
            "Loss: 0.5665310080486874\n",
            "training error 0.022316419598398803, test error 0.050771019709701576\n",
            "Loss: 0.37688019275115003\n",
            "training error 0.02213493034308796, test error 0.05055134897882773\n",
            "Loss: 0.0\n",
            "training error 0.022085138631999193, test error 0.05007442894742269\n",
            "Loss: 0.0\n",
            "training error 0.02222378129493097, test error 0.05011577370366338\n",
            "Loss: 0.08256660557046658\n",
            "training error 0.022069402932836, test error 0.05016430224246606\n",
            "Loss: 0.1794794207992556\n",
            "training error 0.022079620130421092, test error 0.04983933523295816\n",
            "Loss: 0.0\n",
            "training error 0.02197243328623215, test error 0.05021747251294357\n",
            "Loss: 0.7587125274001405\n",
            "training error 0.02192147465016743, test error 0.05006247592770017\n",
            "Loss: 0.447720046222555\n",
            "training error 0.021957926285689797, test error 0.050425817472343405\n",
            "Loss: 1.1767457102786816\n",
            "training error 0.021889762295717957, test error 0.050259284323280425\n",
            "Loss: 0.8426057216841754\n",
            "training error 0.021965680288477108, test error 0.050029680856012865\n",
            "Loss: 0.38191846292692233\n",
            "training error 0.02186090917029465, test error 0.04987555085817087\n",
            "Loss: 0.07266474370781761\n",
            "training error 0.02188728727520956, test error 0.05053592229930518\n",
            "Loss: 1.397665243910362\n",
            "training error 0.021868679405060282, test error 0.05014402736114354\n",
            "Loss: 0.611348700301062\n",
            "training error 0.021853459452978705, test error 0.04980564183419423\n",
            "Loss: 0.0\n",
            "training error 0.02182072009316488, test error 0.04998960227026527\n",
            "Loss: 0.369356621652317\n",
            "training error 0.02174226644864907, test error 0.04973705273333379\n",
            "Loss: 0.0\n",
            "training error 0.021866316163232116, test error 0.04911504731211192\n",
            "Loss: 0.0\n",
            "training error 0.02171849534561317, test error 0.04943836522123428\n",
            "Loss: 0.6582868729979374\n",
            "training error 0.02171417119821355, test error 0.049308686827257024\n",
            "Loss: 0.39425700623798576\n",
            "training error 0.021590665286334344, test error 0.04952706598939714\n",
            "Loss: 0.8388848221339673\n",
            "training error 0.02165289403482228, test error 0.049230989052658145\n",
            "Loss: 0.23606154710480443\n",
            "training error 0.0216115952305768, test error 0.04908578567394499\n",
            "Loss: 0.0\n",
            "training error 0.021832091850293806, test error 0.04869670535554155\n",
            "Loss: 0.0\n",
            "training error 0.021548036761103406, test error 0.04899955383254826\n",
            "Loss: 0.6219075290526899\n",
            "training error 0.021563621328930326, test error 0.04886154900595193\n",
            "Loss: 0.33851088940584084\n",
            "training error 0.02157899276062078, test error 0.04933997997334172\n",
            "Loss: 1.320981805860444\n",
            "training error 0.021520148590145883, test error 0.04865864904997024\n",
            "Loss: 0.0\n",
            "training error 0.021476233176446258, test error 0.04893647165751649\n",
            "Loss: 0.57096243518997\n",
            "training error 0.021442960168797057, test error 0.04882617808863921\n",
            "Loss: 0.34429447167125815\n",
            "training error 0.02158616132858744, test error 0.04838692486739929\n",
            "Loss: 0.0\n",
            "training error 0.021616817522581207, test error 0.04834128425451401\n",
            "Loss: 0.0\n",
            "training error 0.021507268921815013, test error 0.048356451562910824\n",
            "Loss: 0.031375476739414765\n",
            "training error 0.021454947033530337, test error 0.048539489179392645\n",
            "Loss: 0.4100117072502574\n",
            "training error 0.021504937789758264, test error 0.04814573411998359\n",
            "Loss: 0.0\n",
            "training error 0.0214400683526436, test error 0.048331658497158196\n",
            "Loss: 0.38616999111753536\n",
            "training error 0.021446878444137524, test error 0.04916006469159499\n",
            "Loss: 2.106792201119201\n",
            "training error 0.02152214945686932, test error 0.04806230608306025\n",
            "Loss: 0.0\n",
            "training error 0.02138543484380576, test error 0.04890893245261622\n",
            "Loss: 1.7615184092349745\n",
            "training error 0.021305753197953997, test error 0.04875132570844243\n",
            "Loss: 1.4335966821721557\n",
            "training error 0.021421830864287544, test error 0.04832257247729583\n",
            "Loss: 0.5415187398328136\n",
            "training error 0.02126667618112506, test error 0.04804606878874647\n",
            "Loss: 0.0\n",
            "training error 0.021302150449906725, test error 0.04838923792719717\n",
            "Loss: 0.7142501917473787\n",
            "training error 0.021236527668557936, test error 0.048974272752748134\n",
            "Loss: 1.9319040816489608\n",
            "training error 0.021350950334863308, test error 0.048122344564720525\n",
            "Loss: 0.15875549841430914\n",
            "training error 0.021228861628127028, test error 0.04837448951140231\n",
            "Loss: 0.68355378688707\n",
            "training error 0.021381463066753245, test error 0.048024435448584084\n",
            "Loss: 0.0\n",
            "training error 0.021198498878305196, test error 0.047975310716077565\n",
            "Loss: 0.0\n",
            "training error 0.021240553548377845, test error 0.04826940196708571\n",
            "Loss: 0.6130054117806649\n",
            "training error 0.02117263446599811, test error 0.048644836894348356\n",
            "Loss: 1.3955640271578584\n",
            "training error 0.021266813622991026, test error 0.048162931181477485\n",
            "Loss: 0.39107712404464756\n",
            "training error 0.021100448591398178, test error 0.04829637028861042\n",
            "Loss: 0.6692183286376441\n",
            "training error 0.021228379831470058, test error 0.04883503855339379\n",
            "Loss: 1.7920214053519734\n",
            "training error 0.021137932008443414, test error 0.048118960417106\n",
            "Loss: 0.29942422234336963\n",
            "training error 0.021061934931347552, test error 0.04789807078428183\n",
            "Loss: 0.0\n",
            "training error 0.02111971136370124, test error 0.048014397752417406\n",
            "Loss: 0.24286357723983798\n",
            "training error 0.021040656955583003, test error 0.047909824535970515\n",
            "Loss: 0.024539092068276425\n",
            "training error 0.02102335897958701, test error 0.047974000822515614\n",
            "Loss: 0.1585242098283146\n",
            "training error 0.02101339812029786, test error 0.047915189696417594\n",
            "Loss: 0.035740295705988245\n",
            "training error 0.02110809897600327, test error 0.04824310014406907\n",
            "Loss: 0.720340828216548\n",
            "training error 0.02116993382990252, test error 0.04874885140585457\n",
            "Loss: 1.7762315008560403\n",
            "training error 0.02096579210926901, test error 0.048210043818680874\n",
            "Loss: 0.65132693089891\n",
            "training error 0.020932457329306375, test error 0.047662450754134444\n",
            "Loss: 0.0\n",
            "training error 0.020916253681095138, test error 0.04782491446654251\n",
            "Loss: 0.34086311097625277\n",
            "training error 0.020991063692719962, test error 0.04780973984859327\n",
            "Loss: 0.3090254322393404\n",
            "training error 0.020888077026106813, test error 0.04742951175323336\n",
            "Loss: 0.0\n",
            "training error 0.021034978533915095, test error 0.04775716823368899\n",
            "Loss: 0.6908282804182431\n",
            "training error 0.0210311294857006, test error 0.047951029247235925\n",
            "Loss: 1.0995632776401365\n",
            "training error 0.02087188458105695, test error 0.04784895735259975\n",
            "Loss: 0.884355718331431\n",
            "training error 0.02091511223907829, test error 0.047774896431575876\n",
            "Loss: 0.7282062698420466\n",
            "training error 0.02092325041618321, test error 0.04732963854092129\n",
            "Loss: 0.0\n",
            "training error 0.020782146399851653, test error 0.0476417511504797\n",
            "Loss: 0.6594443126552996\n",
            "training error 0.020782788047489772, test error 0.04773080213316865\n",
            "Loss: 0.8475948784196108\n",
            "training error 0.020820748642930754, test error 0.0472851914468354\n",
            "Loss: 0.0\n",
            "training error 0.020818553534024592, test error 0.04726083379452255\n",
            "Loss: 0.0\n",
            "training error 0.020832391949776267, test error 0.04765521527723823\n",
            "Loss: 0.8344784699109375\n",
            "training error 0.020781925701662266, test error 0.047546189328230945\n",
            "Loss: 0.6037886147947535\n",
            "training error 0.020981608874531626, test error 0.04762466418180364\n",
            "Loss: 0.7698348887853479\n",
            "training error 0.020765592829452176, test error 0.047366185075350224\n",
            "Loss: 0.22291456237466534\n",
            "training error 0.020800506896572497, test error 0.04772944529590646\n",
            "Loss: 0.9915430257140923\n",
            "training error 0.020777206487489, test error 0.04741026124405175\n",
            "Loss: 0.31617607547695936\n",
            "training error 0.020749286773195177, test error 0.04748627115924911\n",
            "Loss: 0.477006744541808\n",
            "training error 0.020805568880362908, test error 0.04722958487343169\n",
            "Loss: 0.0\n",
            "training error 0.0207895333534243, test error 0.04703299217937114\n",
            "Loss: 0.0\n",
            "training error 0.020853165234636532, test error 0.04676434304848232\n",
            "Loss: 0.0\n",
            "training error 0.02073167709343394, test error 0.04728692573835933\n",
            "Loss: 1.1174810888185283\n",
            "training error 0.020770397704319796, test error 0.04715694686199005\n",
            "Loss: 0.8395366809722971\n",
            "training error 0.020757884727093723, test error 0.04743745670187228\n",
            "Loss: 1.4393736969470883\n",
            "training error 0.02070565605594176, test error 0.047626859037632634\n",
            "Loss: 1.8443881233531023\n",
            "training error 0.02069502495526897, test error 0.04687177081049913\n",
            "Loss: 0.2297215250205431\n",
            "training error 0.0207531093441371, test error 0.046973022052090516\n",
            "Loss: 0.4462352938259917\n",
            "training error 0.020685816607492462, test error 0.046896142033573174\n",
            "Loss: 0.2818364944295437\n",
            "training error 0.02068102184180977, test error 0.047210219445230614\n",
            "Loss: 0.9534537805567789\n",
            "training error 0.020709985934422755, test error 0.04676291307694157\n",
            "Loss: 0.0\n",
            "training error 0.020614713831461635, test error 0.047088204068706965\n",
            "Loss: 0.6956174676931992\n",
            "training error 0.020591184016208363, test error 0.0471113504195533\n",
            "Loss: 0.7451147066873887\n",
            "training error 0.020615746052129548, test error 0.04725031806244479\n",
            "Loss: 1.0422896124997028\n",
            "training error 0.02070388447422369, test error 0.04750021355607615\n",
            "Loss: 1.5766778214211463\n",
            "training error 0.020655376144994, test error 0.04694288595820259\n",
            "Loss: 0.38486242498387835\n",
            "training error 0.02060097345125216, test error 0.04679149320055646\n",
            "Loss: 0.06111707277061118\n",
            "training error 0.020649223853213675, test error 0.04658212104957813\n",
            "Loss: 0.0\n",
            "training error 0.020575579206636437, test error 0.0466574738108359\n",
            "Loss: 0.16176326788033268\n",
            "training error 0.020534089665864178, test error 0.04665205398969575\n",
            "Loss: 0.15012828643674592\n",
            "training error 0.020575796655220767, test error 0.04720842456907406\n",
            "Loss: 1.3445148168099497\n",
            "training error 0.020587182555896453, test error 0.04661318832939709\n",
            "Loss: 0.06669357066393378\n",
            "training error 0.020532409631538892, test error 0.046909459284218885\n",
            "Loss: 0.7027121721064677\n",
            "training error 0.02058085691807224, test error 0.04708719310323797\n",
            "Loss: 1.0842616056969234\n",
            "training error 0.020614135642089755, test error 0.04692030635021854\n",
            "Loss: 0.7259980718363312\n",
            "training error 0.020616844627832785, test error 0.046841730987938424\n",
            "Loss: 0.5573166968588339\n",
            "training error 0.020638171139131013, test error 0.04728208136145916\n",
            "Loss: 1.5026372696426815\n",
            "training error 0.020564665851861445, test error 0.046892080462302387\n",
            "Loss: 0.6654042489700362\n",
            "training error 0.020541289768069654, test error 0.046957297904004915\n",
            "Loss: 0.8054095562275432\n",
            "training error 0.020500638118076963, test error 0.04666062778471068\n",
            "Loss: 0.1685340498965182\n",
            "training error 0.020593499877045087, test error 0.04653240377740724\n",
            "Loss: 0.0\n",
            "training error 0.020574560393110966, test error 0.046729265712819344\n",
            "Loss: 0.4230641863115725\n",
            "training error 0.020679759120601007, test error 0.0468670892714482\n",
            "Loss: 0.7192525355921076\n",
            "training error 0.02056739187417387, test error 0.04702396176568866\n",
            "Loss: 1.0563778106818633\n",
            "training error 0.02057787363402113, test error 0.04723851438863583\n",
            "Loss: 1.517459993269088\n",
            "training error 0.02058410308604089, test error 0.046584073324069476\n",
            "Loss: 0.11103992587488953\n",
            "training error 0.020751336955582074, test error 0.046632611376875285\n",
            "Loss: 0.21535014599158853\n",
            "training error 0.020477417609575846, test error 0.04661984137603853\n",
            "Loss: 0.18790690257386444\n",
            "training error 0.02046882708171581, test error 0.046628212315979106\n",
            "Loss: 0.205896387880955\n",
            "training error 0.020518413684916602, test error 0.046472307024328585\n",
            "Loss: 0.0\n",
            "training error 0.02058110601474758, test error 0.04696432544373719\n",
            "Loss: 1.0587346549226107\n",
            "training error 0.020466928379612316, test error 0.047081870232308254\n",
            "Loss: 1.3116697814476108\n",
            "training error 0.020447972138780975, test error 0.04675611560154777\n",
            "Loss: 0.6107047301753488\n",
            "training error 0.0205245055051312, test error 0.04649456037957361\n",
            "Loss: 0.04788519587242135\n",
            "training error 0.020432078994667913, test error 0.04636224624883747\n",
            "Loss: 0.0\n",
            "training error 0.02043511944578533, test error 0.046318629456331355\n",
            "Loss: 0.0\n",
            "training error 0.020413114728555955, test error 0.04661203546801826\n",
            "Loss: 0.6334514106543843\n",
            "training error 0.02042499541558204, test error 0.04689359785585328\n",
            "Loss: 1.2413329286091956\n",
            "training error 0.020391389719710065, test error 0.046788152469898044\n",
            "Loss: 1.0136807135223025\n",
            "training error 0.02046814767509751, test error 0.04667920658720795\n",
            "Loss: 0.7784710711627119\n",
            "training error 0.020363178942421668, test error 0.046320708365237384\n",
            "Loss: 0.004488278108460975\n",
            "training error 0.020507983477191325, test error 0.04705631450616456\n",
            "Loss: 1.592631428200364\n",
            "training error 0.02036278599301178, test error 0.04671762606934279\n",
            "Loss: 0.861417139701004\n",
            "training error 0.020461097396882514, test error 0.0462853459831737\n",
            "Loss: 0.0\n",
            "training error 0.020444077593666572, test error 0.04693742034030925\n",
            "Loss: 1.4088138335891287\n",
            "training error 0.020413004466803362, test error 0.04631836626061035\n",
            "Loss: 0.07134067324170434\n",
            "training error 0.020467722516394747, test error 0.046730041101194525\n",
            "Loss: 0.9607687024365985\n",
            "training error 0.02042893723067504, test error 0.0470623631894564\n",
            "Loss: 1.6787542358766672\n",
            "training error 0.02045042361705292, test error 0.04641410150068435\n",
            "Loss: 0.278177714297434\n",
            "training error 0.020550763487243842, test error 0.046903429598558886\n",
            "Loss: 1.335376461504434\n",
            "training error 0.020396277091903097, test error 0.046893526755288246\n",
            "Loss: 1.3139812595019507\n",
            "training error 0.020449042996353327, test error 0.04619302571561241\n",
            "Loss: 0.0\n",
            "training error 0.020347180873043394, test error 0.04636118504622936\n",
            "Loss: 0.36403618947202787\n",
            "training error 0.020589372160850817, test error 0.04659763379910326\n",
            "Loss: 0.8759072981748828\n",
            "training error 0.02036690591379571, test error 0.04669035877076967\n",
            "Loss: 1.0766410025164763\n",
            "training error 0.02040492422505548, test error 0.04619098054532898\n",
            "Loss: 0.0\n",
            "training error 0.020529338475358063, test error 0.0459332739795384\n",
            "Loss: 0.0\n",
            "training error 0.02039529815912381, test error 0.04585285262700065\n",
            "Loss: 0.0\n",
            "training error 0.020451272532148915, test error 0.0465680385106977\n",
            "Loss: 1.5597413088229706\n",
            "training error 0.020402350022196633, test error 0.04641191904596768\n",
            "Loss: 1.2192620239243723\n",
            "training error 0.02030181179821362, test error 0.04657161727621007\n",
            "Loss: 1.5675462005741547\n",
            "training error 0.020390034757819423, test error 0.046323551660579415\n",
            "Loss: 1.0265425303148668\n",
            "training error 0.020286407801130453, test error 0.04619302658461625\n",
            "Loss: 0.7418817764356156\n",
            "training error 0.0202802542987239, test error 0.04645172001607574\n",
            "Loss: 1.306063537522295\n",
            "training error 0.020260525583649637, test error 0.04622364923659549\n",
            "Loss: 0.8086663933674076\n",
            "training error 0.020310966850000327, test error 0.04618241121243566\n",
            "Loss: 0.7187308238287171\n",
            "training error 0.02033737169895086, test error 0.04642942980301453\n",
            "Loss: 1.2574510482568302\n",
            "training error 0.020379216893899328, test error 0.04594779500142686\n",
            "Loss: 0.2070588174710286\n",
            "training error 0.02040420318346863, test error 0.04603462036643924\n",
            "Loss: 0.39641533519672034\n",
            "training error 0.02032913452499077, test error 0.04632415577149947\n",
            "Loss: 1.0278600294134854\n",
            "training error 0.02036785782938015, test error 0.0456799883926632\n",
            "Loss: 0.0\n",
            "training error 0.020229982198345965, test error 0.04585262762443982\n",
            "Loss: 0.3779318643704954\n",
            "training error 0.020315741414085178, test error 0.045456515918802405\n",
            "Loss: 0.0\n",
            "training error 0.020327806852936506, test error 0.046207316634227974\n",
            "Loss: 1.6516899728230339\n",
            "training error 0.0202338759374335, test error 0.04589049230688702\n",
            "Loss: 0.9547066670481552\n",
            "training error 0.0203069698538348, test error 0.045940268165212385\n",
            "Loss: 1.0642088084227286\n",
            "training error 0.020277828517442184, test error 0.04576670441477373\n",
            "Loss: 0.6823851095966171\n",
            "training error 0.020328070017879406, test error 0.04566712968713632\n",
            "Loss: 0.46333020487123733\n",
            "training error 0.020183145804855643, test error 0.04577143648976154\n",
            "Loss: 0.6927952232891554\n",
            "training error 0.020217159137708846, test error 0.045636645252393256\n",
            "Loss: 0.396267355625346\n",
            "training error 0.020280051279609, test error 0.04556395446121027\n",
            "Loss: 0.2363545472771733\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04556395446121027\n",
            "training error 0.1231028210068331, test error 0.23702980197935242\n",
            "training error 0.11989027972281796, test error 0.22807449653977754\n",
            "training error 0.11812392473049808, test error 0.2256719555869147\n",
            "training error 0.11785747472497124, test error 0.22419634373757139\n",
            "training error 0.11802181195886487, test error 0.22517986038270416\n",
            "training error 0.11771182560886605, test error 0.22425168539585355\n",
            "training error 0.11774736824639058, test error 0.22312976953745073\n",
            "training error 0.11776713349562613, test error 0.22378180281422086\n",
            "training error 0.11762392076674778, test error 0.22364262363182527\n",
            "training error 0.11757280887438958, test error 0.2233885031179479\n",
            "training error 0.11776428693744925, test error 0.22358639285605456\n",
            "training error 0.11760429725046041, test error 0.2232118897041749\n",
            "training error 0.11776577770503922, test error 0.22300972139905847\n",
            "training error 0.11758667755010661, test error 0.22315204829790525\n",
            "training error 0.11750850344811103, test error 0.22270541234279223\n",
            "training error 0.11746240857221388, test error 0.22296626910324824\n",
            "training error 0.11787371177739865, test error 0.22318023326377154\n",
            "training error 0.11745199632930582, test error 0.22273135888417692\n",
            "training error 0.11737330073495397, test error 0.22218568122661997\n",
            "training error 0.11734622549539658, test error 0.22185188203249345\n",
            "training error 0.11749524526300117, test error 0.22212771453767582\n",
            "training error 0.1175288321682383, test error 0.22280314157358452\n",
            "training error 0.11726556732666081, test error 0.22278581822412988\n",
            "training error 0.11721178166003898, test error 0.2223983121062243\n",
            "training error 0.11721581690853049, test error 0.22230330740776738\n",
            "training error 0.11724997462604145, test error 0.22262441138725408\n",
            "training error 0.11746097420138696, test error 0.22281217098522768\n",
            "training error 0.11722961426604138, test error 0.2229640311932359\n",
            "training error 0.11723847221900703, test error 0.22211229594868268\n",
            "training error 0.11724119764758924, test error 0.22236122710502867\n",
            "training error 0.11706322655351939, test error 0.22215544542163307\n",
            "training error 0.11717312821082415, test error 0.22247325947567817\n",
            "training error 0.11709114746606243, test error 0.22212225570018027\n",
            "training error 0.11755881927143011, test error 0.2212983392710453\n",
            "training error 0.1171684828239933, test error 0.22152643700579994\n",
            "training error 0.11710004416367274, test error 0.22091724573446758\n",
            "training error 0.11709511507142387, test error 0.2218396724984873\n",
            "training error 0.11711830397656446, test error 0.2220559898502447\n",
            "training error 0.11708973579170072, test error 0.22152460023414458\n",
            "training error 0.11682289372670934, test error 0.22189671562193894\n",
            "training error 0.11709094857866109, test error 0.22177113277915309\n",
            "training error 0.1169388677636451, test error 0.22128089542406712\n",
            "training error 0.11699378316791187, test error 0.22234249376657356\n",
            "training error 0.11677851725995139, test error 0.22248343985604865\n",
            "training error 0.11705913107726483, test error 0.22187229352644294\n",
            "training error 0.11680658241055768, test error 0.22237083784400796\n",
            "training error 0.11729283147077246, test error 0.2216421697291009\n",
            "training error 0.11684628022167938, test error 0.22160393799329964\n",
            "training error 0.11701601061628589, test error 0.2205797068496321\n",
            "training error 0.11682545155994113, test error 0.22105864338120243\n",
            "Loss: 0.21712628890961927\n",
            "training error 0.11666388471891753, test error 0.221133019658489\n",
            "Loss: 0.25084483824890924\n",
            "training error 0.11675521481208716, test error 0.22119230774753681\n",
            "Loss: 0.2777231444605732\n",
            "training error 0.11678594021505853, test error 0.2214203827204978\n",
            "Loss: 0.38112112980492885\n",
            "training error 0.11685764723619889, test error 0.22101703138730006\n",
            "Loss: 0.19826145564971753\n",
            "training error 0.11661160023412828, test error 0.22137134337700004\n",
            "Loss: 0.35888910121164574\n",
            "training error 0.11653747288597899, test error 0.2212913161610595\n",
            "Loss: 0.3226086939686068\n",
            "training error 0.11644210530201875, test error 0.22131828193416367\n",
            "Loss: 0.3348336504205518\n",
            "training error 0.11653180467237241, test error 0.22162800732338198\n",
            "Loss: 0.47524792226898427\n",
            "training error 0.11676644066324973, test error 0.22225714668687682\n",
            "Loss: 0.7604687943429944\n",
            "training error 0.11650161737321227, test error 0.2211648073904221\n",
            "Loss: 0.2652558338872346\n",
            "training error 0.11642168192428438, test error 0.22107783852389234\n",
            "Loss: 0.2258284233734198\n",
            "training error 0.116528104757222, test error 0.2216733602580325\n",
            "Loss: 0.4958087142376666\n",
            "training error 0.11689628159420251, test error 0.2219109214073465\n",
            "Loss: 0.6035072657984308\n",
            "training error 0.11642837635607103, test error 0.2214928484840694\n",
            "Loss: 0.4139735461067495\n",
            "training error 0.1164899464015979, test error 0.22187716489858345\n",
            "Loss: 0.5882037234893112\n",
            "training error 0.11637939588644308, test error 0.22148018490999485\n",
            "Loss: 0.40823250389783183\n",
            "training error 0.11644476712537916, test error 0.22158802949021658\n",
            "Loss: 0.4571239371860436\n",
            "training error 0.11638245403526368, test error 0.22118503968635642\n",
            "Loss: 0.2744281626672729\n",
            "training error 0.11634608306475926, test error 0.22114218831277627\n",
            "Loss: 0.2550014555634528\n",
            "training error 0.11632796656931757, test error 0.22188928259339244\n",
            "Loss: 0.5936972908632487\n",
            "training error 0.1162467378384529, test error 0.22161492838782984\n",
            "Loss: 0.46931857557659384\n",
            "training error 0.11627134366419609, test error 0.22136853837618267\n",
            "Loss: 0.3576174516762398\n",
            "training error 0.11628042230188193, test error 0.22204154295713333\n",
            "Loss: 0.6627246578479351\n",
            "training error 0.11629518524294287, test error 0.22151322129818693\n",
            "Loss: 0.4232095789261425\n",
            "training error 0.11621802265534911, test error 0.22210856240954363\n",
            "Loss: 0.6931079842960042\n",
            "training error 0.11640660480290418, test error 0.22094272666898931\n",
            "Loss: 0.16457534763372195\n",
            "training error 0.11613638589351502, test error 0.22100137180425808\n",
            "Loss: 0.19116217019610193\n",
            "training error 0.11637632581780606, test error 0.2215371823250917\n",
            "Loss: 0.4340723311017536\n",
            "training error 0.11611069475370174, test error 0.22173287374635192\n",
            "Loss: 0.5227892054031624\n",
            "training error 0.11608466386109279, test error 0.22132602877558935\n",
            "Loss: 0.3383456876502322\n",
            "training error 0.11615707057284257, test error 0.2213916905022016\n",
            "Loss: 0.36811348793885923\n",
            "training error 0.11628897392260747, test error 0.22133698128536983\n",
            "Loss: 0.3433110173883591\n",
            "training error 0.1165953051251622, test error 0.22032832338034147\n",
            "Loss: 0.0\n",
            "training error 0.11602840125944043, test error 0.22075966157648003\n",
            "Loss: 0.19577065241582758\n",
            "training error 0.11611105612258676, test error 0.22066805197942457\n",
            "Loss: 0.15419197762269743\n",
            "training error 0.11604937885346162, test error 0.22082212908090354\n",
            "Loss: 0.22412266066658137\n",
            "training error 0.11623099116652742, test error 0.22062759284658773\n",
            "Loss: 0.13582886741694278\n",
            "training error 0.11617273038695934, test error 0.22055757474401347\n",
            "Loss: 0.10404988344427935\n",
            "training error 0.11606663985889126, test error 0.22146123383151353\n",
            "Loss: 0.5141919267530382\n",
            "training error 0.11609785303455392, test error 0.22086295383621285\n",
            "Loss: 0.24265171525337248\n",
            "training error 0.11581098222241071, test error 0.22083479203753964\n",
            "Loss: 0.22986997287854916\n",
            "training error 0.11581940439237906, test error 0.2207002511740834\n",
            "Loss: 0.16880616528809345\n",
            "training error 0.11589360825267896, test error 0.22078882674427192\n",
            "Loss: 0.20900779203747444\n",
            "training error 0.1159267718674604, test error 0.22105227765530364\n",
            "Loss: 0.3285797594494655\n",
            "training error 0.11601066817514306, test error 0.2208577419091611\n",
            "Loss: 0.24028618776612554\n",
            "training error 0.11601770703260064, test error 0.22047424580688638\n",
            "Loss: 0.06622953613322213\n",
            "training error 0.11594561366397664, test error 0.2204022107845299\n",
            "Loss: 0.03353513658834739\n",
            "training error 0.11581837793525575, test error 0.22079456711287326\n",
            "Loss: 0.2116131622927675\n",
            "training error 0.11578399030347264, test error 0.22069366174299673\n",
            "Loss: 0.16581543264622134\n",
            "training error 0.115869252126733, test error 0.2203714011409968\n",
            "Loss: 0.019551621867952562\n",
            "training error 0.11575660255499917, test error 0.22051388579178455\n",
            "Loss: 0.08422086121118166\n",
            "training error 0.11576161909327194, test error 0.22032431452714574\n",
            "Loss: 0.0\n",
            "training error 0.11567728618817794, test error 0.22041511995232205\n",
            "Loss: 0.04121443671398772\n",
            "training error 0.11569596379340427, test error 0.22003961266360014\n",
            "Loss: 0.0\n",
            "training error 0.11572254771781035, test error 0.21987668579457628\n",
            "Loss: 0.0\n",
            "training error 0.11569441453783778, test error 0.21975974824648115\n",
            "Loss: 0.0\n",
            "training error 0.1157388860607689, test error 0.22006041486582034\n",
            "Loss: 0.1368160555963005\n",
            "training error 0.11573702742391714, test error 0.21949530038560222\n",
            "Loss: 0.0\n",
            "training error 0.11580015113200107, test error 0.22005866325835047\n",
            "Loss: 0.25666284050662735\n",
            "training error 0.11569926525119523, test error 0.22049805892776048\n",
            "Loss: 0.45684738597895347\n",
            "training error 0.1155766128240374, test error 0.22039323611652226\n",
            "Loss: 0.40909109641189545\n",
            "training error 0.11565590162540233, test error 0.22066629943493934\n",
            "Loss: 0.5334961829615237\n",
            "training error 0.11554881030352816, test error 0.22040494286931292\n",
            "Loss: 0.414424583174533\n",
            "training error 0.11584720343151585, test error 0.22075030652483033\n",
            "Loss: 0.571769025133273\n",
            "training error 0.11549368948587795, test error 0.22019540431423745\n",
            "Loss: 0.3189607829440222\n",
            "training error 0.11580109666377596, test error 0.22034313331149705\n",
            "Loss: 0.386264728404373\n",
            "training error 0.11550251133757665, test error 0.22022480795135913\n",
            "Loss: 0.3323568042119085\n",
            "training error 0.11548962663226328, test error 0.220032218960514\n",
            "Loss: 0.24461506645860887\n",
            "training error 0.11552561616444249, test error 0.2200891231185893\n",
            "Loss: 0.2705400671193736\n",
            "training error 0.11544431146123353, test error 0.21988882508785546\n",
            "Loss: 0.17928616310320944\n",
            "training error 0.11553107242652068, test error 0.21997897247257833\n",
            "Loss: 0.22035646600468972\n",
            "training error 0.11543342334035209, test error 0.2198469406947174\n",
            "Loss: 0.16020402646317322\n",
            "training error 0.11555421156416529, test error 0.22080417654583598\n",
            "Loss: 0.5963117014051722\n",
            "training error 0.11546973271331483, test error 0.22016724257727185\n",
            "Loss: 0.3061305597382713\n",
            "training error 0.11538020381668078, test error 0.22005353994486015\n",
            "Loss: 0.25432870693689047\n",
            "training error 0.11532740592483004, test error 0.22069331386195257\n",
            "Loss: 0.5458037025146911\n",
            "training error 0.11533320827123526, test error 0.2204563677619629\n",
            "Loss: 0.43785328190275585\n",
            "training error 0.11538113250935833, test error 0.22020346625727608\n",
            "Loss: 0.3226337285717529\n",
            "training error 0.11537526813276788, test error 0.22036710462678652\n",
            "Loss: 0.3971858348004398\n",
            "training error 0.11540119219367508, test error 0.2203472185996283\n",
            "Loss: 0.3881259473571763\n",
            "training error 0.115403886704525, test error 0.22113393716931795\n",
            "Loss: 0.7465475483242834\n",
            "training error 0.11528827260461065, test error 0.22014306577116674\n",
            "Loss: 0.29511583365409155\n",
            "training error 0.1153410668044818, test error 0.22015873320275667\n",
            "Loss: 0.3022537685266835\n",
            "training error 0.11520142768554445, test error 0.22035230350466994\n",
            "Loss: 0.39044258239797625\n",
            "training error 0.11525897356538628, test error 0.2206438390557636\n",
            "Loss: 0.5232634448863571\n",
            "training error 0.11531368420530973, test error 0.22027054377152402\n",
            "Loss: 0.353193614879177\n",
            "training error 0.11518131016840055, test error 0.22048577594304575\n",
            "Loss: 0.4512513733567314\n",
            "training error 0.11513632876306928, test error 0.22014288695207967\n",
            "Loss: 0.29503436535534\n",
            "training error 0.11527964680814627, test error 0.22014301365647698\n",
            "Loss: 0.2950920906902743\n",
            "training error 0.11524467357595909, test error 0.21977273832507258\n",
            "Loss: 0.12639812286776575\n",
            "training error 0.11507004059541716, test error 0.21979138253960392\n",
            "Loss: 0.1348922521263729\n",
            "training error 0.11523369241643616, test error 0.2196464959554862\n",
            "Loss: 0.068883283431731\n",
            "training error 0.11508651157055895, test error 0.21963480954669234\n",
            "Loss: 0.06355906520323362\n",
            "training error 0.11511651024921557, test error 0.21990195125668\n",
            "Loss: 0.1852663224968243\n",
            "training error 0.11519911669171817, test error 0.21941064372410596\n",
            "Loss: 0.0\n",
            "training error 0.11518732101058524, test error 0.21955315368222772\n",
            "Loss: 0.06495125108922917\n",
            "training error 0.11525667559409791, test error 0.2199555632470328\n",
            "Loss: 0.24835601121158124\n",
            "training error 0.11506995456211254, test error 0.21991919978658875\n",
            "Loss: 0.23178276762283456\n",
            "training error 0.11519057093505095, test error 0.21965081426366617\n",
            "Loss: 0.10946166306418093\n",
            "training error 0.11501725451580666, test error 0.21977391162353127\n",
            "Loss: 0.16556530406159897\n",
            "training error 0.11508177144239734, test error 0.2199711595043744\n",
            "Loss: 0.25546426132965205\n",
            "training error 0.11496430167278146, test error 0.21988030965997338\n",
            "Loss: 0.2140579544800847\n",
            "training error 0.11508396795310294, test error 0.2201332836420198\n",
            "Loss: 0.3293549964798137\n",
            "training error 0.11509718319201835, test error 0.22030216148440157\n",
            "Loss: 0.406323843348555\n",
            "training error 0.11500072054871935, test error 0.22053410921151084\n",
            "Loss: 0.5120378247545521\n",
            "training error 0.11502165258132499, test error 0.22069577923629355\n",
            "Loss: 0.5857215905184399\n",
            "training error 0.11513612951948081, test error 0.22101422437443996\n",
            "Loss: 0.7308581858728846\n",
            "training error 0.11506591943796013, test error 0.2213342327029037\n",
            "Loss: 0.8767072308563773\n",
            "training error 0.11526983212048707, test error 0.22137837667461663\n",
            "Loss: 0.8968265700842526\n",
            "training error 0.11498146104973414, test error 0.2207865306180635\n",
            "Loss: 0.6270830214087697\n",
            "training error 0.11504092407361084, test error 0.22049010695114604\n",
            "Loss: 0.49198307279816333\n",
            "training error 0.11490568948186372, test error 0.22010396172118585\n",
            "Loss: 0.31599105007489303\n",
            "training error 0.11486856505798729, test error 0.2197837459610509\n",
            "Loss: 0.17004746470463683\n",
            "training error 0.11516528917380817, test error 0.21919569135996284\n",
            "Loss: 0.0\n",
            "training error 0.11497146677843464, test error 0.21937727809177548\n",
            "Loss: 0.08284229068828974\n",
            "training error 0.11503803554903994, test error 0.21986138725687795\n",
            "Loss: 0.30369935320577746\n",
            "training error 0.11500457965754608, test error 0.21947068228227412\n",
            "Loss: 0.12545452905809995\n",
            "training error 0.11479479255240067, test error 0.21951466771311592\n",
            "Loss: 0.14552126968101486\n",
            "training error 0.11475135108830771, test error 0.2195972151564357\n",
            "Loss: 0.18318051508297017\n",
            "training error 0.11487980189955344, test error 0.21945717569505893\n",
            "Loss: 0.11929264369832104\n",
            "training error 0.11488721482625396, test error 0.21964400261632633\n",
            "Loss: 0.20452557875660915\n",
            "training error 0.11483906596873991, test error 0.21933203301470183\n",
            "Loss: 0.06220088264194956\n",
            "training error 0.11468122765064662, test error 0.21952679875679343\n",
            "Loss: 0.1510556137195529\n",
            "training error 0.11488248712064424, test error 0.21900999119889264\n",
            "Loss: 0.0\n",
            "training error 0.11479322351788626, test error 0.21901573394608684\n",
            "Loss: 0.002622139365771048\n",
            "training error 0.11472874288966843, test error 0.21899059801487028\n",
            "Loss: 0.0\n",
            "training error 0.11502336718799942, test error 0.21909085573047646\n",
            "Loss: 0.04578174429177295\n",
            "training error 0.11484743251188072, test error 0.21884804586585924\n",
            "Loss: 0.0\n",
            "training error 0.11475996403438363, test error 0.21905875800504632\n",
            "Loss: 0.09628239464209987\n",
            "training error 0.11493070213850944, test error 0.21874335815147095\n",
            "Loss: 0.0\n",
            "training error 0.11476322213602397, test error 0.21944567778728716\n",
            "Loss: 0.32107015351290347\n",
            "training error 0.11478311604458484, test error 0.21965300559098774\n",
            "Loss: 0.4158514558814108\n",
            "training error 0.11477624174165357, test error 0.21998206536583617\n",
            "Loss: 0.5662833490502894\n",
            "training error 0.11471896011840763, test error 0.22016533912747788\n",
            "Loss: 0.6500681840233336\n",
            "training error 0.11459825764253029, test error 0.21962926753146986\n",
            "Loss: 0.4049994420335601\n",
            "training error 0.11456509064038056, test error 0.21958964412920132\n",
            "Loss: 0.38688533671698\n",
            "training error 0.11472177298707187, test error 0.21956333209773332\n",
            "Loss: 0.3748566142495413\n",
            "training error 0.11463237706041958, test error 0.21937973109231088\n",
            "Loss: 0.2909221775772908\n",
            "training error 0.11451365741953586, test error 0.21926002982247858\n",
            "Loss: 0.23619993556551755\n",
            "training error 0.11453391625489001, test error 0.21911934083208465\n",
            "Loss: 0.17188301569062148\n",
            "training error 0.1145255982956786, test error 0.21919251641549273\n",
            "Loss: 0.2053357266787348\n",
            "training error 0.11449590045052241, test error 0.2193450322177685\n",
            "Loss: 0.2750593532905965\n",
            "training error 0.1146286713349081, test error 0.2190411035294579\n",
            "Loss: 0.13611630565750765\n",
            "training error 0.1145497546964705, test error 0.21942905638342255\n",
            "Loss: 0.313471566746637\n",
            "training error 0.11454412134475073, test error 0.21928177560251025\n",
            "Loss: 0.24614116542294173\n",
            "training error 0.11468443866549251, test error 0.21876970806811838\n",
            "Loss: 0.012046041932478602\n",
            "training error 0.1145703976049118, test error 0.21873089337108215\n",
            "Loss: 0.0\n",
            "training error 0.11447602816955578, test error 0.21886640064772725\n",
            "Loss: 0.061951594745801586\n",
            "training error 0.11447325977763484, test error 0.2193154193136537\n",
            "Loss: 0.2672352010101742\n",
            "training error 0.11436696865309982, test error 0.2190427964033593\n",
            "Loss: 0.14259669837675126\n",
            "training error 0.11445254392591123, test error 0.21890267838090952\n",
            "Loss: 0.07853715000192274\n",
            "training error 0.11443348812247338, test error 0.21918882511681373\n",
            "Loss: 0.20935851295349472\n",
            "training error 0.11439236557156107, test error 0.2189279900242273\n",
            "Loss: 0.09010919770293668\n",
            "training error 0.11432084080617645, test error 0.21918701589108172\n",
            "Loss: 0.2085313660863397\n",
            "training error 0.1144461900384778, test error 0.21875994162747095\n",
            "Loss: 0.013280362888434816\n",
            "training error 0.11445367279468115, test error 0.21872147106164763\n",
            "Loss: 0.0\n",
            "training error 0.11433496347300506, test error 0.21864794379630947\n",
            "Loss: 0.0\n",
            "training error 0.11445896873717964, test error 0.219112251080031\n",
            "Loss: 0.21235383039048816\n",
            "training error 0.11429385941604324, test error 0.21890188915737951\n",
            "Loss: 0.1161434938105943\n",
            "training error 0.11460205032878937, test error 0.2195895912835599\n",
            "Loss: 0.4306683478933815\n",
            "training error 0.11424915908932269, test error 0.21932535221252783\n",
            "Loss: 0.3098169616675861\n",
            "training error 0.11426184006211473, test error 0.2193373536086863\n",
            "Loss: 0.3153058750093196\n",
            "training error 0.11434396688550308, test error 0.21893953158559126\n",
            "Loss: 0.13335949299089211\n",
            "training error 0.11423029975754627, test error 0.21903826432636433\n",
            "Loss: 0.17851552741721122\n",
            "training error 0.11440393503536572, test error 0.21895847680502772\n",
            "Loss: 0.14202420719195974\n",
            "training error 0.11438350084604165, test error 0.21925638026352226\n",
            "Loss: 0.27827221086496046\n",
            "training error 0.11423984922479316, test error 0.21926164934610154\n",
            "Loss: 0.2806820586265246\n",
            "training error 0.11419101526410295, test error 0.2191309877724953\n",
            "Loss: 0.22092317348103574\n",
            "training error 0.11422437329271692, test error 0.2190621299002635\n",
            "Loss: 0.1894305964019738\n",
            "training error 0.11424006498754288, test error 0.21931415522491196\n",
            "Loss: 0.3046959495869306\n",
            "training error 0.11418248519638931, test error 0.21945723521451044\n",
            "Loss: 0.3701344746945834\n",
            "training error 0.11420175485694321, test error 0.21956974913692998\n",
            "Loss: 0.42159341844953957\n",
            "training error 0.11447530596524548, test error 0.21935055385250404\n",
            "Loss: 0.3213430888008295\n",
            "training error 0.11415977496197566, test error 0.21935264536298776\n",
            "Loss: 0.32229965415764283\n",
            "training error 0.11414326856009721, test error 0.21937264128201295\n",
            "Loss: 0.3314449123649643\n",
            "training error 0.11411626286386216, test error 0.21906942740706759\n",
            "Loss: 0.1927681566266104\n",
            "training error 0.11423862132299067, test error 0.2191715770793314\n",
            "Loss: 0.2394869459690696\n",
            "training error 0.1141234325853176, test error 0.21929406223315057\n",
            "Loss: 0.29550629455861177\n",
            "training error 0.11438377045314271, test error 0.21920107815605777\n",
            "Loss: 0.2529794472998059\n",
            "training error 0.11440431992999553, test error 0.21953433249631854\n",
            "Loss: 0.4053953971022928\n",
            "training error 0.11419029815979308, test error 0.21890338561433553\n",
            "Loss: 0.11682790772733487\n",
            "training error 0.11410493587773758, test error 0.21896940003680876\n",
            "Loss: 0.14702001533513087\n",
            "training error 0.11457201700119274, test error 0.21881514832491283\n",
            "Loss: 0.07647203339773423\n",
            "training error 0.11409125967112863, test error 0.218929892611101\n",
            "Loss: 0.12895104792487455\n",
            "training error 0.11408446226881194, test error 0.21916537078008952\n",
            "Loss: 0.23664845632487275\n",
            "training error 0.11405299419532909, test error 0.21952326377562012\n",
            "Loss: 0.4003330486958889\n",
            "training error 0.11409540252478549, test error 0.21937017607589165\n",
            "Loss: 0.33031743497895505\n",
            "training error 0.11441382970913201, test error 0.21948565020103403\n",
            "Loss: 0.383130245901131\n",
            "training error 0.11424847520473183, test error 0.2190100062189443\n",
            "Loss: 0.1655915058465407\n",
            "training error 0.11415470806460411, test error 0.21963239154821454\n",
            "Loss: 0.4502433157213437\n",
            "training error 0.11406149730498, test error 0.21973671846526235\n",
            "Loss: 0.49795788153725873\n",
            "training error 0.11404019980609006, test error 0.2196397146510062\n",
            "Loss: 0.45359258243042877\n",
            "training error 0.11396345134678863, test error 0.21955236423891505\n",
            "Loss: 0.4136423269766265\n",
            "training error 0.11401492130297988, test error 0.21952903157216608\n",
            "Loss: 0.40297098639876516\n",
            "training error 0.1139508030075971, test error 0.21953852757345516\n",
            "Loss: 0.40731404178002695\n",
            "training error 0.11399007582831931, test error 0.21968473423825324\n",
            "Loss: 0.474182571279802\n",
            "training error 0.11415616784949403, test error 0.21890373770181676\n",
            "Loss: 0.11698893713154579\n",
            "training error 0.11387570230632259, test error 0.21877044197101925\n",
            "Loss: 0.056025303775042445\n",
            "training error 0.11414570356564994, test error 0.21883349379472067\n",
            "Loss: 0.08486244836769519\n",
            "training error 0.11381780265356219, test error 0.21860893808214443\n",
            "Loss: 0.0\n",
            "training error 0.11396250121688371, test error 0.2184221605540063\n",
            "Loss: 0.0\n",
            "training error 0.1140488800590127, test error 0.21890103581010853\n",
            "Loss: 0.2192429810636609\n",
            "training error 0.11383277276496254, test error 0.2186695217373641\n",
            "Loss: 0.1132491239581146\n",
            "training error 0.1137868308752218, test error 0.21872362757341746\n",
            "Loss: 0.13802034493501925\n",
            "training error 0.11387283623121493, test error 0.21854038944947393\n",
            "Loss: 0.05412861733797847\n",
            "training error 0.11385235433751452, test error 0.21852073467572006\n",
            "Loss: 0.04513009186601913\n",
            "training error 0.11399602363742155, test error 0.21865527320161626\n",
            "Loss: 0.1067257310424452\n",
            "training error 0.11377514177502528, test error 0.21858815960040653\n",
            "Loss: 0.07599917791272226\n",
            "training error 0.11387545455800127, test error 0.21857523335082088\n",
            "Loss: 0.07008116595237368\n",
            "training error 0.11385849108209704, test error 0.21875964072352444\n",
            "Loss: 0.154508209543458\n",
            "training error 0.11380510510424365, test error 0.2187558880428396\n",
            "Loss: 0.15279012348694554\n",
            "training error 0.11376886600280563, test error 0.21835233625707057\n",
            "Loss: 0.0\n",
            "training error 0.11382337444944524, test error 0.21845961720445495\n",
            "Loss: 0.04913203550891421\n",
            "training error 0.11370959696004142, test error 0.21816418953775304\n",
            "Loss: 0.0\n",
            "training error 0.11379267586713286, test error 0.21805474410333386\n",
            "Loss: 0.0\n",
            "training error 0.11368606550707851, test error 0.21826761719798052\n",
            "Loss: 0.09762369331702825\n",
            "training error 0.11400309058114962, test error 0.21809809917638814\n",
            "Loss: 0.019882655262826177\n",
            "training error 0.1138013541743732, test error 0.21821207944533286\n",
            "Loss: 0.07215405592113644\n",
            "training error 0.11361029322697974, test error 0.21841008611937796\n",
            "Loss: 0.16296000231743601\n",
            "training error 0.11361909087518138, test error 0.2183266526405917\n",
            "Loss: 0.12469737284366289\n",
            "training error 0.11377144340139232, test error 0.21803653938112555\n",
            "Loss: 0.0\n",
            "training error 0.11377524515984688, test error 0.21844398251951677\n",
            "Loss: 0.18686920070722923\n",
            "training error 0.11355202686579562, test error 0.21833142257206514\n",
            "Loss: 0.13524485014144716\n",
            "training error 0.11356528677084114, test error 0.21843745641129103\n",
            "Loss: 0.18387607476408885\n",
            "training error 0.11368894098587295, test error 0.21834779009647684\n",
            "Loss: 0.14275163063710572\n",
            "training error 0.1135447360095294, test error 0.21864328104385714\n",
            "Loss: 0.27827522141645744\n",
            "training error 0.11368319088751512, test error 0.2180365089849643\n",
            "Loss: 0.0\n",
            "training error 0.113534697742589, test error 0.2182515652039008\n",
            "Loss: 0.0986331233872928\n",
            "training error 0.11360486624840602, test error 0.21778912202384532\n",
            "Loss: 0.0\n",
            "training error 0.11351724362536961, test error 0.2179983472775738\n",
            "Loss: 0.0960678163281159\n",
            "training error 0.11352773602906373, test error 0.21792122192967545\n",
            "Loss: 0.06065496045100094\n",
            "training error 0.11343465283175255, test error 0.21783640617755853\n",
            "Loss: 0.02171098045384845\n",
            "training error 0.11361907548789224, test error 0.21787464756427055\n",
            "Loss: 0.03926988622318106\n",
            "training error 0.11343779354996793, test error 0.21770937803293233\n",
            "Loss: 0.0\n",
            "training error 0.11342996643009966, test error 0.21789042650609003\n",
            "Loss: 0.08316062210711461\n",
            "training error 0.11342442659634636, test error 0.2177562821184153\n",
            "Loss: 0.021544356934355413\n",
            "training error 0.11347514173523768, test error 0.21778656593791385\n",
            "Loss: 0.0354545613417967\n",
            "training error 0.11341984161245175, test error 0.21753365198172983\n",
            "Loss: 0.0\n",
            "training error 0.11351266482583275, test error 0.2177291483637421\n",
            "Loss: 0.08986948926352767\n",
            "training error 0.11333127774467763, test error 0.2176977670667875\n",
            "Loss: 0.07544353876405285\n",
            "training error 0.11338954224143366, test error 0.21779596733230439\n",
            "Loss: 0.1205861015915799\n",
            "training error 0.11348862250456965, test error 0.21809353797508194\n",
            "Loss: 0.25737902538367496\n",
            "training error 0.11342171427920203, test error 0.2181644349313605\n",
            "Loss: 0.28997028454413876\n",
            "training error 0.1132922998946518, test error 0.2178711103506215\n",
            "Loss: 0.15512927118055408\n",
            "training error 0.11331984043018045, test error 0.21775881306857842\n",
            "Loss: 0.10350632410083271\n",
            "training error 0.11329482827306148, test error 0.21811016053768806\n",
            "Loss: 0.2650204006167556\n",
            "training error 0.11331092719603705, test error 0.21815751862880367\n",
            "Loss: 0.2867908672476327\n",
            "training error 0.11334544073378593, test error 0.21826942591586576\n",
            "Loss: 0.33823453402865855\n",
            "training error 0.11331195312852242, test error 0.2179405201830226\n",
            "Loss: 0.18703690099723946\n",
            "training error 0.11317890874470761, test error 0.2177332619503677\n",
            "Loss: 0.09176050087857934\n",
            "training error 0.11319052670875096, test error 0.2176455806555427\n",
            "Loss: 0.05145349824875467\n",
            "training error 0.11351316899777121, test error 0.21822038920745102\n",
            "Loss: 0.31569240872160176\n",
            "training error 0.1132192364037301, test error 0.21801172120622223\n",
            "Loss: 0.2197679394140506\n",
            "training error 0.11330404352989878, test error 0.21795662174514663\n",
            "Loss: 0.1944387728351593\n",
            "training error 0.11326114004935617, test error 0.2181605939536532\n",
            "Loss: 0.28820459097336215\n",
            "training error 0.11319821784981518, test error 0.2177430166727289\n",
            "Loss: 0.09624473689093804\n",
            "training error 0.11325626280612458, test error 0.21817607033999353\n",
            "Loss: 0.29531907013524705\n",
            "training error 0.1131281829412042, test error 0.21769637131153405\n",
            "Loss: 0.07480191148443449\n",
            "training error 0.11304688300339287, test error 0.2175099465690209\n",
            "Loss: 0.0\n",
            "training error 0.11317040343473173, test error 0.2173382569247229\n",
            "Loss: 0.0\n",
            "training error 0.11316229155272847, test error 0.21759096393713825\n",
            "Loss: 0.11627359857906416\n",
            "training error 0.1131585153216283, test error 0.21747465828255041\n",
            "Loss: 0.06275993916466938\n",
            "training error 0.11302702862527328, test error 0.21724071564665584\n",
            "Loss: 0.0\n",
            "training error 0.11303405804795638, test error 0.21727711434476596\n",
            "Loss: 0.01675500745879077\n",
            "training error 0.11299388068211297, test error 0.2173654750675335\n",
            "Loss: 0.057429115212714876\n",
            "training error 0.11305018652553, test error 0.2172224691872261\n",
            "Loss: 0.0\n",
            "training error 0.11295575260527259, test error 0.21713625919610344\n",
            "Loss: 0.0\n",
            "training error 0.11319187726057157, test error 0.21752746957767694\n",
            "Loss: 0.18016815018453425\n",
            "training error 0.11289015502807578, test error 0.21745528762035982\n",
            "Loss: 0.1469254492259875\n",
            "training error 0.11298798831940847, test error 0.21715099594236306\n",
            "Loss: 0.006786865682495424\n",
            "training error 0.11303002299069914, test error 0.2169600192132503\n",
            "Loss: 0.0\n",
            "training error 0.11293060692676075, test error 0.21727840306227386\n",
            "Loss: 0.14674770502791645\n",
            "training error 0.1129473908176328, test error 0.21755227513448305\n",
            "Loss: 0.27297929055334347\n",
            "training error 0.1128378316331805, test error 0.21768148190412537\n",
            "Loss: 0.33253255299812157\n",
            "training error 0.1128401880224576, test error 0.21749804656326124\n",
            "Loss: 0.2479845604558717\n",
            "training error 0.11276115399551642, test error 0.21744792847033725\n",
            "Loss: 0.22488440905206186\n",
            "training error 0.11291131142976445, test error 0.21712658606119045\n",
            "Loss: 0.07677306102025216\n",
            "training error 0.11285615992768208, test error 0.217564860213601\n",
            "Loss: 0.2787799349133424\n",
            "training error 0.112777007829043, test error 0.21759930792300855\n",
            "Loss: 0.2946573806899888\n",
            "training error 0.11273245447708859, test error 0.21749904803998832\n",
            "Loss: 0.24844615551411486\n",
            "training error 0.11287493458789699, test error 0.21768909063776318\n",
            "Loss: 0.33603952799998726\n",
            "training error 0.11272093572787699, test error 0.21765844251646876\n",
            "Loss: 0.32191336714990637\n",
            "training error 0.112639762337922, test error 0.2174004601673633\n",
            "Loss: 0.20300558402885915\n",
            "training error 0.1126454293549853, test error 0.21737083893318257\n",
            "Loss: 0.1893527302504916\n",
            "training error 0.11258592623988511, test error 0.21729103509721712\n",
            "Loss: 0.15256999200459198\n",
            "training error 0.11259259785772725, test error 0.21699216189218368\n",
            "Loss: 0.01481502400761947\n",
            "training error 0.11256174529415174, test error 0.217086302474807\n",
            "Loss: 0.058205775430253404\n",
            "training error 0.11259795468248668, test error 0.21704078020783715\n",
            "Loss: 0.03722390645046758\n",
            "training error 0.11250398145451922, test error 0.21688903813631202\n",
            "Loss: 0.0\n",
            "training error 0.11249884982909904, test error 0.21671895209500558\n",
            "Loss: 0.0\n",
            "training error 0.11246075469816334, test error 0.21686444688495118\n",
            "Loss: 0.06713524061421339\n",
            "training error 0.11245269080296852, test error 0.21689803135873886\n",
            "Loss: 0.08263202733407304\n",
            "training error 0.11244990320381071, test error 0.2167944513150215\n",
            "Loss: 0.03483738698719652\n",
            "training error 0.11255673783962161, test error 0.21693609352520987\n",
            "Loss: 0.10019494285349317\n",
            "training error 0.11244251029745478, test error 0.21641042078793218\n",
            "Loss: 0.0\n",
            "training error 0.11243130945525864, test error 0.21668994783389972\n",
            "Loss: 0.12916524303672183\n",
            "training error 0.11235547952920205, test error 0.2163679662385472\n",
            "Loss: 0.0\n",
            "training error 0.11235381319635168, test error 0.21628520643300034\n",
            "Loss: 0.0\n",
            "training error 0.1122987824877902, test error 0.2161452153446606\n",
            "Loss: 0.0\n",
            "training error 0.11244437746292953, test error 0.2161508266242159\n",
            "Loss: 0.0025960692890292236\n",
            "training error 0.11234868133698807, test error 0.2163924483888497\n",
            "Loss: 0.11438284386486863\n",
            "training error 0.11218124218511408, test error 0.2162935457962244\n",
            "Loss: 0.06862536898042393\n",
            "training error 0.11214756762773802, test error 0.21614580558595065\n",
            "Loss: 0.00027307626915273886\n",
            "training error 0.11222405462067533, test error 0.21609799645177039\n",
            "Loss: 0.0\n",
            "training error 0.11213585732717234, test error 0.21615530095485128\n",
            "Loss: 0.026517831734595987\n",
            "training error 0.11211363825577976, test error 0.21589860832721067\n",
            "Loss: 0.0\n",
            "training error 0.1121416686193828, test error 0.21576058788385846\n",
            "Loss: 0.0\n",
            "training error 0.11214557637304, test error 0.2158225664049506\n",
            "Loss: 0.028725598914980388\n",
            "training error 0.11207955880108532, test error 0.21603838667928366\n",
            "Loss: 0.12875326219203842\n",
            "training error 0.11197337911818585, test error 0.21587854652277838\n",
            "Loss: 0.05467107782604064\n",
            "training error 0.11190606983526771, test error 0.21601151603245553\n",
            "Loss: 0.11629934412866749\n",
            "training error 0.11191750402915462, test error 0.21593058416494093\n",
            "Loss: 0.07878931122211608\n",
            "training error 0.11184202172828549, test error 0.21581832546222218\n",
            "Loss: 0.026760020877780732\n",
            "training error 0.11183151687020018, test error 0.21580336521787727\n",
            "Loss: 0.019826296562475143\n",
            "training error 0.11182574596108108, test error 0.21585657049375948\n",
            "Loss: 0.04448570095325621\n",
            "training error 0.11189968751621115, test error 0.2160751821994369\n",
            "Loss: 0.1458071275499906\n",
            "training error 0.11177650830876702, test error 0.21612605725985182\n",
            "Loss: 0.1693865314225329\n",
            "training error 0.111700387698557, test error 0.21590349519106383\n",
            "Loss: 0.066234203663873\n",
            "training error 0.11176093868836164, test error 0.21537474596794506\n",
            "Loss: 0.0\n",
            "training error 0.11172247990462855, test error 0.21541733053168435\n",
            "Loss: 0.019772310605814525\n",
            "training error 0.11160640824623963, test error 0.21516390526110002\n",
            "Loss: 0.0\n",
            "training error 0.11153591303994027, test error 0.2152692168587549\n",
            "Loss: 0.048944825354002575\n",
            "training error 0.11156009075227843, test error 0.21535860837228946\n",
            "Loss: 0.09049060108532458\n",
            "training error 0.11155381978651172, test error 0.2151147423017808\n",
            "Loss: 0.0\n",
            "training error 0.11151966466401754, test error 0.21504020448078223\n",
            "Loss: 0.0\n",
            "training error 0.11142277472010552, test error 0.21495664941934925\n",
            "Loss: 0.0\n",
            "training error 0.11142999058870243, test error 0.21504742978145253\n",
            "Loss: 0.04223193948571513\n",
            "training error 0.11133066235482626, test error 0.21506421268439946\n",
            "Loss: 0.05003951510258453\n",
            "training error 0.11142431354049889, test error 0.21547072307379025\n",
            "Loss: 0.23915224573403115\n",
            "training error 0.11131628828306717, test error 0.21504275264520495\n",
            "Loss: 0.04005608855939258\n",
            "training error 0.111265559493908, test error 0.21476633968850078\n",
            "Loss: 0.0\n",
            "training error 0.11115932701522212, test error 0.2149121559938528\n",
            "Loss: 0.06789532547955002\n",
            "training error 0.1110941919881908, test error 0.21462881053214994\n",
            "Loss: 0.0\n",
            "training error 0.11110202308852936, test error 0.21471119269371883\n",
            "Loss: 0.03838355221958967\n",
            "training error 0.11102685220729631, test error 0.21447700736613667\n",
            "Loss: 0.0\n",
            "training error 0.11125056017882326, test error 0.21489745246344577\n",
            "Loss: 0.19603271346999573\n",
            "training error 0.11091366677470771, test error 0.21467148104322115\n",
            "Loss: 0.09067343836650643\n",
            "training error 0.11095157745966559, test error 0.21463711214298253\n",
            "Loss: 0.07464892335640183\n",
            "training error 0.11080614656256524, test error 0.21452897119834866\n",
            "Loss: 0.024228159862027532\n",
            "training error 0.11080910690698381, test error 0.21417285636181949\n",
            "Loss: 0.0\n",
            "training error 0.11081447573926717, test error 0.2140929757567901\n",
            "Loss: 0.0\n",
            "training error 0.11067740391887901, test error 0.21391125602999553\n",
            "Loss: 0.0\n",
            "training error 0.11063230409022685, test error 0.21374397017559377\n",
            "Loss: 0.0\n",
            "training error 0.11064008669822384, test error 0.21364178289924388\n",
            "Loss: 0.0\n",
            "training error 0.1105546984083107, test error 0.21358370663982604\n",
            "Loss: 0.0\n",
            "training error 0.11055578086933766, test error 0.21340748381612468\n",
            "Loss: 0.0\n",
            "training error 0.11044733736713026, test error 0.21335300556975262\n",
            "Loss: 0.0\n",
            "training error 0.11049446149376711, test error 0.21318761831679564\n",
            "Loss: 0.0\n",
            "training error 0.11045317291177598, test error 0.21303900627687533\n",
            "Loss: 0.0\n",
            "training error 0.11039990257736279, test error 0.21299179281517946\n",
            "Loss: 0.0\n",
            "training error 0.11040901551915107, test error 0.21290054547854406\n",
            "Loss: 0.0\n",
            "training error 0.11034216109130518, test error 0.21284133123925036\n",
            "Loss: 0.0\n",
            "training error 0.1102322676696764, test error 0.21285744050702562\n",
            "Loss: 0.007568674599744973\n",
            "training error 0.11016063323646552, test error 0.21294395246283762\n",
            "Loss: 0.048214894630538296\n",
            "training error 0.11009433747284128, test error 0.21288671347050414\n",
            "Loss: 0.021322095191544932\n",
            "training error 0.1100715313897871, test error 0.21285557208475384\n",
            "Loss: 0.006690827115463094\n",
            "training error 0.10999820734218983, test error 0.21310543628484263\n",
            "Loss: 0.12408541332387113\n",
            "training error 0.10990406328500057, test error 0.21280180319177508\n",
            "Loss: 0.0\n",
            "training error 0.10982820278609445, test error 0.2126260686617951\n",
            "Loss: 0.0\n",
            "training error 0.10980233844071019, test error 0.2125229791804358\n",
            "Loss: 0.0\n",
            "training error 0.10984097464785403, test error 0.21238098955369805\n",
            "Loss: 0.0\n",
            "training error 0.10973563854946093, test error 0.2125181821345972\n",
            "Loss: 0.06459739225599392\n",
            "training error 0.10962971299961413, test error 0.21214160438794508\n",
            "Loss: 0.0\n",
            "training error 0.10960725124289168, test error 0.21205564102748453\n",
            "Loss: 0.0\n",
            "training error 0.10958264138544095, test error 0.21181292073365823\n",
            "Loss: 0.0\n",
            "training error 0.10948868578981169, test error 0.21178907911354256\n",
            "Loss: 0.0\n",
            "training error 0.1093717638654766, test error 0.2118499495746384\n",
            "Loss: 0.028741076428784318\n",
            "training error 0.10930985911377791, test error 0.21194451190503397\n",
            "Loss: 0.0733903712797579\n",
            "training error 0.10928610866325116, test error 0.21201927122441677\n",
            "Loss: 0.10868932044925117\n",
            "training error 0.10911819162811634, test error 0.21198058032048225\n",
            "Loss: 0.09042071845311028\n",
            "training error 0.10906254248547285, test error 0.21179309396625173\n",
            "Loss: 0.0018956844828776909\n",
            "training error 0.1090264106762963, test error 0.21180701856962666\n",
            "Loss: 0.008470434905905044\n",
            "training error 0.10890619188967443, test error 0.21189642392105304\n",
            "Loss: 0.05068476994176674\n",
            "training error 0.10887308385714152, test error 0.21149185141963206\n",
            "Loss: 0.0\n",
            "training error 0.10876423384562305, test error 0.21132343397199255\n",
            "Loss: 0.0\n",
            "training error 0.10867600915662647, test error 0.210940888588692\n",
            "Loss: 0.0\n",
            "training error 0.10884263119210197, test error 0.21101227678148812\n",
            "Loss: 0.03384274773550189\n",
            "training error 0.10846132544157627, test error 0.21061905119041788\n",
            "Loss: 0.0\n",
            "training error 0.1084638622756763, test error 0.21077452518413256\n",
            "Loss: 0.0738176308534122\n",
            "training error 0.10827409001286467, test error 0.21047128169755774\n",
            "Loss: 0.0\n",
            "training error 0.10821556713970565, test error 0.2103487750604513\n",
            "Loss: 0.0\n",
            "training error 0.10815421159678736, test error 0.2101627645960991\n",
            "Loss: 0.0\n",
            "training error 0.10810231300528093, test error 0.20993905595173756\n",
            "Loss: 0.0\n",
            "training error 0.10803190478036556, test error 0.20978735388155462\n",
            "Loss: 0.0\n",
            "training error 0.10801252464455202, test error 0.2095660087126258\n",
            "Loss: 0.0\n",
            "training error 0.10790371670749892, test error 0.2094771609870374\n",
            "Loss: 0.0\n",
            "training error 0.10778018503269836, test error 0.20942210473500994\n",
            "Loss: 0.0\n",
            "training error 0.1076145750628371, test error 0.20941838192987883\n",
            "Loss: 0.0\n",
            "training error 0.1075648862216353, test error 0.20929476403679823\n",
            "Loss: 0.0\n",
            "training error 0.10763695752661087, test error 0.20931298258923017\n",
            "Loss: 0.008704733974496115\n",
            "training error 0.10745252471003859, test error 0.20893013672503047\n",
            "Loss: 0.0\n",
            "training error 0.1072304412143272, test error 0.20883757699890282\n",
            "Loss: 0.0\n",
            "training error 0.10722075495318491, test error 0.20864679172402278\n",
            "Loss: 0.0\n",
            "training error 0.10710449631753834, test error 0.20869511536266044\n",
            "Loss: 0.023160499252528055\n",
            "training error 0.10704630892364951, test error 0.20868402268993425\n",
            "Loss: 0.017844015526824464\n",
            "training error 0.10703912863561503, test error 0.2084469064094176\n",
            "Loss: 0.0\n",
            "training error 0.1068356994437834, test error 0.2081785206354166\n",
            "Loss: 0.0\n",
            "training error 0.10670615813157604, test error 0.20810648039948842\n",
            "Loss: 0.0\n",
            "training error 0.10676366012208624, test error 0.20769773210813092\n",
            "Loss: 0.0\n",
            "training error 0.10651553541934841, test error 0.2077556931220236\n",
            "Loss: 0.027906425989532302\n",
            "training error 0.10647178256190118, test error 0.20773552506029094\n",
            "Loss: 0.018196131357051115\n",
            "training error 0.10632998770137445, test error 0.20754782698992053\n",
            "Loss: 0.0\n",
            "training error 0.1063532605652102, test error 0.20749645769185673\n",
            "Loss: 0.0\n",
            "training error 0.10619027709054359, test error 0.20722571514706042\n",
            "Loss: 0.0\n",
            "training error 0.10611365755308476, test error 0.20677764603111815\n",
            "Loss: 0.0\n",
            "training error 0.10600494094957931, test error 0.2066331106264112\n",
            "Loss: 0.0\n",
            "training error 0.1059220542827674, test error 0.20633209768511807\n",
            "Loss: 0.0\n",
            "training error 0.10578703019194881, test error 0.2062660925938807\n",
            "Loss: 0.0\n",
            "training error 0.10586814804099426, test error 0.2061395877243193\n",
            "Loss: 0.0\n",
            "training error 0.10569261457696146, test error 0.20620459337852393\n",
            "Loss: 0.031534774529351495\n",
            "training error 0.10545296835816545, test error 0.20597929958524558\n",
            "Loss: 0.0\n",
            "training error 0.10534929714598057, test error 0.20573662412129295\n",
            "Loss: 0.0\n",
            "training error 0.10525484793054025, test error 0.20550631898487312\n",
            "Loss: 0.0\n",
            "training error 0.10539800077049241, test error 0.20563500470773205\n",
            "Loss: 0.06261886422500584\n",
            "training error 0.10501300911104075, test error 0.20539916204767922\n",
            "Loss: 0.0\n",
            "training error 0.10493851703699153, test error 0.2049739913335976\n",
            "Loss: 0.0\n",
            "training error 0.10479402090549825, test error 0.20487538132185037\n",
            "Loss: 0.0\n",
            "training error 0.10480965043287564, test error 0.20468615335075263\n",
            "Loss: 0.0\n",
            "training error 0.10460806096506652, test error 0.20451644215330805\n",
            "Loss: 0.0\n",
            "training error 0.10456081983458868, test error 0.20438665030499378\n",
            "Loss: 0.0\n",
            "training error 0.10449891965442026, test error 0.2042050230730419\n",
            "Loss: 0.0\n",
            "training error 0.10432996895746204, test error 0.20419819147777832\n",
            "Loss: 0.0\n",
            "training error 0.10414326756505247, test error 0.20410388688973788\n",
            "Loss: 0.0\n",
            "training error 0.10437434218232339, test error 0.20405693553535215\n",
            "Loss: 0.0\n",
            "training error 0.10384409221926953, test error 0.20405478467832747\n",
            "Loss: 0.0\n",
            "training error 0.10369788502119555, test error 0.20376530462947662\n",
            "Loss: 0.0\n",
            "training error 0.10368624647390329, test error 0.20342009024500382\n",
            "Loss: 0.0\n",
            "training error 0.10340665375592853, test error 0.20337428119943038\n",
            "Loss: 0.0\n",
            "training error 0.10336076426581832, test error 0.2030908103499751\n",
            "Loss: 0.0\n",
            "training error 0.10336521895768258, test error 0.20315227459248195\n",
            "Loss: 0.030264413441916105\n",
            "training error 0.10303217622184682, test error 0.2029030776042674\n",
            "Loss: 0.0\n",
            "training error 0.10289487389760353, test error 0.2026194107441164\n",
            "Loss: 0.0\n",
            "training error 0.10295870481244464, test error 0.2025888415764171\n",
            "Loss: 0.0\n",
            "training error 0.10284592596562975, test error 0.20202703426409246\n",
            "Loss: 0.0\n",
            "training error 0.10255587182885784, test error 0.20234355872344478\n",
            "Loss: 0.15667430871582066\n",
            "training error 0.10245638882459931, test error 0.2021230304899498\n",
            "Loss: 0.047516524809188\n",
            "training error 0.1024376421473098, test error 0.2016414780544519\n",
            "Loss: 0.0\n",
            "training error 0.10215837754418174, test error 0.20119637138678867\n",
            "Loss: 0.0\n",
            "training error 0.10205333470596854, test error 0.20094091996606556\n",
            "Loss: 0.0\n",
            "training error 0.10189782656189514, test error 0.2008963508957111\n",
            "Loss: 0.0\n",
            "training error 0.10184708291681248, test error 0.20089125410419148\n",
            "Loss: 0.0\n",
            "training error 0.1015400659025174, test error 0.20072307289816482\n",
            "Loss: 0.0\n",
            "training error 0.10148861839463119, test error 0.20065999060284623\n",
            "Loss: 0.0\n",
            "training error 0.1013137195815142, test error 0.20022314181328743\n",
            "Loss: 0.0\n",
            "training error 0.10141317747155057, test error 0.19960139437971255\n",
            "Loss: 0.0\n",
            "training error 0.10136336122538608, test error 0.1998437625479273\n",
            "Loss: 0.12142608971641433\n",
            "training error 0.10100744992405819, test error 0.1997823813617969\n",
            "Loss: 0.09067420728536835\n",
            "training error 0.10082847197626245, test error 0.199721212614696\n",
            "Loss: 0.06002875649029349\n",
            "training error 0.10072339454533015, test error 0.19970666205000012\n",
            "Loss: 0.05273894534389978\n",
            "training error 0.1005759634444875, test error 0.19953135483687645\n",
            "Loss: 0.0\n",
            "training error 0.10045502079701554, test error 0.19920811324954854\n",
            "Loss: 0.0\n",
            "training error 0.10032665276193149, test error 0.1990990709889719\n",
            "Loss: 0.0\n",
            "training error 0.10009357670998305, test error 0.19851280920231026\n",
            "Loss: 0.0\n",
            "training error 0.10003642279054098, test error 0.19822653127898449\n",
            "Loss: 0.0\n",
            "training error 0.09989818194747603, test error 0.19825827704076757\n",
            "Loss: 0.016014890427751283\n",
            "training error 0.09964686537827826, test error 0.19797712119533323\n",
            "Loss: 0.0\n",
            "training error 0.09951493224722001, test error 0.19788220148870653\n",
            "Loss: 0.0\n",
            "training error 0.09953499491757567, test error 0.1973973874858533\n",
            "Loss: 0.0\n",
            "training error 0.09926000532224873, test error 0.19729550215940977\n",
            "Loss: 0.0\n",
            "training error 0.09911409039633322, test error 0.1969996562655512\n",
            "Loss: 0.0\n",
            "training error 0.09923130074105499, test error 0.19663933179763665\n",
            "Loss: 0.0\n",
            "training error 0.09876943573714468, test error 0.19680036936008144\n",
            "Loss: 0.08189488896885866\n",
            "training error 0.09873222127997729, test error 0.1965645995586747\n",
            "Loss: 0.0\n",
            "training error 0.09854088878870666, test error 0.19593436982153908\n",
            "Loss: 0.0\n",
            "training error 0.0983243993592927, test error 0.19581929055258568\n",
            "Loss: 0.0\n",
            "training error 0.09815788533573655, test error 0.19554602654145561\n",
            "Loss: 0.0\n",
            "training error 0.09803830968582591, test error 0.19532951503035637\n",
            "Loss: 0.0\n",
            "training error 0.09795437984364662, test error 0.19508236057120792\n",
            "Loss: 0.0\n",
            "training error 0.09775086950771861, test error 0.19497342097591708\n",
            "Loss: 0.0\n",
            "training error 0.09762434109501655, test error 0.19452160606204952\n",
            "Loss: 0.0\n",
            "training error 0.0974953786000343, test error 0.19430416387296312\n",
            "Loss: 0.0\n",
            "training error 0.09735334076865394, test error 0.19414878000573937\n",
            "Loss: 0.0\n",
            "training error 0.09717363607745583, test error 0.1943130463108481\n",
            "Loss: 0.08460846630293783\n",
            "training error 0.09694973751803283, test error 0.19387590870024185\n",
            "Loss: 0.0\n",
            "training error 0.09676272640136818, test error 0.19369652632912188\n",
            "Loss: 0.0\n",
            "training error 0.09665703996804954, test error 0.19350200866611114\n",
            "Loss: 0.0\n",
            "training error 0.09651940042261348, test error 0.19341587707448685\n",
            "Loss: 0.0\n",
            "training error 0.09641375612117978, test error 0.19289168670125165\n",
            "Loss: 0.0\n",
            "training error 0.09637105851820611, test error 0.19243131442301642\n",
            "Loss: 0.0\n",
            "training error 0.09616333397123808, test error 0.1925192082717472\n",
            "Loss: 0.04567543956883746\n",
            "training error 0.0958497285382938, test error 0.1923120969189203\n",
            "Loss: 0.0\n",
            "training error 0.09574690908470475, test error 0.19216728917781298\n",
            "Loss: 0.0\n",
            "training error 0.09563217281493012, test error 0.19167317032241754\n",
            "Loss: 0.0\n",
            "training error 0.09536430706494471, test error 0.19167670554245236\n",
            "Loss: 0.0018444000424722162\n",
            "training error 0.0953129660392949, test error 0.19147456363483378\n",
            "Loss: 0.0\n",
            "training error 0.09501732621059343, test error 0.19104676317630853\n",
            "Loss: 0.0\n",
            "training error 0.09485904825191402, test error 0.19082110866729055\n",
            "Loss: 0.0\n",
            "training error 0.0946524398737671, test error 0.1904517776676255\n",
            "Loss: 0.0\n",
            "training error 0.09483751656468332, test error 0.1898210731266134\n",
            "Loss: 0.0\n",
            "training error 0.09433201167185998, test error 0.189829872559083\n",
            "Loss: 0.0046356457292562325\n",
            "training error 0.09412304669476536, test error 0.18977257153665494\n",
            "Loss: 0.0\n",
            "training error 0.09395990992018838, test error 0.18936544604155778\n",
            "Loss: 0.0\n",
            "training error 0.0937217954264097, test error 0.18936122549072182\n",
            "Loss: 0.0\n",
            "training error 0.0935318910481836, test error 0.18878340658379764\n",
            "Loss: 0.0\n",
            "training error 0.09345868586614205, test error 0.18879826023230437\n",
            "Loss: 0.007868090090923374\n",
            "training error 0.09320483660351295, test error 0.1883747929061896\n",
            "Loss: 0.0\n",
            "training error 0.09304724636648867, test error 0.1882162078679372\n",
            "Loss: 0.0\n",
            "training error 0.09289878591648289, test error 0.18788124519421903\n",
            "Loss: 0.0\n",
            "training error 0.09284528765684621, test error 0.18797730885889308\n",
            "Loss: 0.05112999148730868\n",
            "training error 0.09247352608115336, test error 0.18729779513363468\n",
            "Loss: 0.0\n",
            "training error 0.09228563406420087, test error 0.187537711658026\n",
            "Loss: 0.1280936191587978\n",
            "training error 0.09202100779906502, test error 0.1873641595177897\n",
            "Loss: 0.035432549597125274\n",
            "training error 0.0918008330199064, test error 0.186845394968976\n",
            "Loss: 0.0\n",
            "training error 0.09158930845638083, test error 0.1866650534046239\n",
            "Loss: 0.0\n",
            "training error 0.09145715147736641, test error 0.18604375414365726\n",
            "Loss: 0.0\n",
            "training error 0.09119072734408451, test error 0.1858499887497054\n",
            "Loss: 0.0\n",
            "training error 0.09115775189061333, test error 0.1858631043615917\n",
            "Loss: 0.007057095873141961\n",
            "training error 0.09085670186906754, test error 0.18562935689013238\n",
            "Loss: 0.0\n",
            "training error 0.09067926428289508, test error 0.1847660600784267\n",
            "Loss: 0.0\n",
            "training error 0.09044768009719015, test error 0.18474011860800615\n",
            "Loss: 0.0\n",
            "training error 0.09026620621272193, test error 0.18436339480408828\n",
            "Loss: 0.0\n",
            "training error 0.09015583974202383, test error 0.18394494402488143\n",
            "Loss: 0.0\n",
            "training error 0.08978096290051561, test error 0.18373675943511764\n",
            "Loss: 0.0\n",
            "training error 0.08956017612514068, test error 0.18344805001635978\n",
            "Loss: 0.0\n",
            "training error 0.08953327199164708, test error 0.18278934142089648\n",
            "Loss: 0.0\n",
            "training error 0.08913718721698546, test error 0.1826483983958203\n",
            "Loss: 0.0\n",
            "training error 0.08896461570658142, test error 0.18283789575397816\n",
            "Loss: 0.10374980554013202\n",
            "training error 0.08871838818860502, test error 0.18240964335662366\n",
            "Loss: 0.0\n",
            "training error 0.08853702245101515, test error 0.18206951271581487\n",
            "Loss: 0.0\n",
            "training error 0.0882577080587886, test error 0.18115990992242081\n",
            "Loss: 0.0\n",
            "training error 0.08808692345089757, test error 0.1810517378523772\n",
            "Loss: 0.0\n",
            "training error 0.08789254678821024, test error 0.1807442625309651\n",
            "Loss: 0.0\n",
            "training error 0.08784677879860163, test error 0.18016125152928225\n",
            "Loss: 0.0\n",
            "training error 0.08751406472002339, test error 0.17934973838284005\n",
            "Loss: 0.0\n",
            "training error 0.08745791293003236, test error 0.1788691551212639\n",
            "Loss: 0.0\n",
            "training error 0.08706694413680341, test error 0.1787009734041169\n",
            "Loss: 0.0\n",
            "training error 0.08686315695982953, test error 0.1787553201108701\n",
            "Loss: 0.03041209329637251\n",
            "training error 0.08652031967860455, test error 0.17870732321620203\n",
            "Loss: 0.0035533170100743305\n",
            "training error 0.08624776019827708, test error 0.17810869341183633\n",
            "Loss: 0.0\n",
            "training error 0.0860657427918786, test error 0.17837212618969134\n",
            "Loss: 0.14790562594599876\n",
            "training error 0.08595012397848975, test error 0.1782094911504661\n",
            "Loss: 0.056593385027370324\n",
            "training error 0.08552384863619837, test error 0.17746058109397847\n",
            "Loss: 0.0\n",
            "training error 0.08526888838963996, test error 0.17680408809853845\n",
            "Loss: 0.0\n",
            "training error 0.08511377265660394, test error 0.17638057204834315\n",
            "Loss: 0.0\n",
            "training error 0.08477743761818905, test error 0.1761338701632074\n",
            "Loss: 0.0\n",
            "training error 0.08456291312660139, test error 0.1757951245225967\n",
            "Loss: 0.0\n",
            "training error 0.08434379597758854, test error 0.17520415810294926\n",
            "Loss: 0.0\n",
            "training error 0.08403185041707022, test error 0.17518168929634959\n",
            "Loss: 0.0\n",
            "training error 0.08375868716471338, test error 0.17391542248120684\n",
            "Loss: 0.0\n",
            "training error 0.08365354733368086, test error 0.17368977719672946\n",
            "Loss: 0.0\n",
            "training error 0.08326660253522454, test error 0.17300080423215466\n",
            "Loss: 0.0\n",
            "training error 0.08290687729484073, test error 0.17301076925006684\n",
            "Loss: 0.005760099183582668\n",
            "training error 0.08288443165500482, test error 0.1722217129773192\n",
            "Loss: 0.0\n",
            "training error 0.08241357550535934, test error 0.172115588049454\n",
            "Loss: 0.0\n",
            "training error 0.0822409291672925, test error 0.1713304581683606\n",
            "Loss: 0.0\n",
            "training error 0.08195829002937066, test error 0.1712321975797312\n",
            "Loss: 0.0\n",
            "training error 0.08163851702466558, test error 0.17032791654938115\n",
            "Loss: 0.0\n",
            "training error 0.08134944072393409, test error 0.16977293229442092\n",
            "Loss: 0.0\n",
            "training error 0.08105010664099568, test error 0.16977508257766855\n",
            "Loss: 0.0012665642388220988\n",
            "training error 0.0809049456951683, test error 0.16949498085093664\n",
            "Loss: 0.0\n",
            "training error 0.08034287887713018, test error 0.16885723588975582\n",
            "Loss: 0.0\n",
            "training error 0.08020398466049428, test error 0.16882416180770807\n",
            "Loss: 0.0\n",
            "training error 0.079768677535332, test error 0.16803435922828472\n",
            "Loss: 0.0\n",
            "training error 0.07941344208673616, test error 0.1675125203693412\n",
            "Loss: 0.0\n",
            "training error 0.07910722779455161, test error 0.16732497238289454\n",
            "Loss: 0.0\n",
            "training error 0.07896938736058622, test error 0.1665852387430095\n",
            "Loss: 0.0\n",
            "training error 0.07846915550653695, test error 0.1658501680525427\n",
            "Loss: 0.0\n",
            "training error 0.07824328503875802, test error 0.16494013833695553\n",
            "Loss: 0.0\n",
            "training error 0.07784729163750816, test error 0.16496601773600525\n",
            "Loss: 0.01569017663660688\n",
            "training error 0.07758490944530722, test error 0.16412672011119714\n",
            "Loss: 0.0\n",
            "training error 0.07716446575751726, test error 0.16365138346346336\n",
            "Loss: 0.0\n",
            "training error 0.07677142504814212, test error 0.16266065313624037\n",
            "Loss: 0.0\n",
            "training error 0.07647128464717991, test error 0.1622436184552232\n",
            "Loss: 0.0\n",
            "training error 0.07610602226360126, test error 0.16190890950225842\n",
            "Loss: 0.0\n",
            "training error 0.075660923116287, test error 0.16147910915516253\n",
            "Loss: 0.0\n",
            "training error 0.07533770291475711, test error 0.16038488634441023\n",
            "Loss: 0.0\n",
            "training error 0.07509988070021724, test error 0.15994107099763022\n",
            "Loss: 0.0\n",
            "training error 0.07468828110700922, test error 0.15948897775479998\n",
            "Loss: 0.0\n",
            "training error 0.0744012485483192, test error 0.16026634898213604\n",
            "Loss: 0.48741376255556634\n",
            "training error 0.07385266498163139, test error 0.15843482779805126\n",
            "Loss: 0.0\n",
            "training error 0.07337564918652495, test error 0.15759377939755118\n",
            "Loss: 0.0\n",
            "training error 0.07358105842479011, test error 0.15690258759975256\n",
            "Loss: 0.0\n",
            "training error 0.07271158100342098, test error 0.1557514224068091\n",
            "Loss: 0.0\n",
            "training error 0.07228208482597381, test error 0.15495728358751265\n",
            "Loss: 0.0\n",
            "training error 0.0719489634167085, test error 0.15488121572990812\n",
            "Loss: 0.0\n",
            "training error 0.07142894206249177, test error 0.15400035405141443\n",
            "Loss: 0.0\n",
            "training error 0.0711031998554394, test error 0.15337565578654158\n",
            "Loss: 0.0\n",
            "training error 0.07062213294426081, test error 0.15218708658237295\n",
            "Loss: 0.0\n",
            "training error 0.07054072269330564, test error 0.15216832384344642\n",
            "Loss: 0.0\n",
            "training error 0.0698938863404329, test error 0.15088295652596703\n",
            "Loss: 0.0\n",
            "training error 0.0695810121301514, test error 0.14942061045736332\n",
            "Loss: 0.0\n",
            "training error 0.06898258519330504, test error 0.14901579613831914\n",
            "Loss: 0.0\n",
            "training error 0.06867453241958611, test error 0.148694568894711\n",
            "Loss: 0.0\n",
            "training error 0.06813783711780072, test error 0.14781985086400545\n",
            "Loss: 0.0\n",
            "training error 0.06814263065730594, test error 0.14728848740553133\n",
            "Loss: 0.0\n",
            "training error 0.0674770028399936, test error 0.1459952004130361\n",
            "Loss: 0.0\n",
            "training error 0.06686551789876304, test error 0.1455168820567177\n",
            "Loss: 0.0\n",
            "training error 0.06640114849677167, test error 0.14532327026214653\n",
            "Loss: 0.0\n",
            "training error 0.0659561837265205, test error 0.14420290775677808\n",
            "Loss: 0.0\n",
            "training error 0.06545305996764406, test error 0.1433191236213064\n",
            "Loss: 0.0\n",
            "training error 0.0651099599588129, test error 0.14205887947319268\n",
            "Loss: 0.0\n",
            "training error 0.06478993420096948, test error 0.14037394958357122\n",
            "Loss: 0.0\n",
            "training error 0.06431545711706067, test error 0.13993660348821607\n",
            "Loss: 0.0\n",
            "training error 0.06374422273556064, test error 0.139618993240974\n",
            "Loss: 0.0\n",
            "training error 0.06373863112976587, test error 0.13902573478941876\n",
            "Loss: 0.0\n",
            "training error 0.06279370671889323, test error 0.13787920395854786\n",
            "Loss: 0.0\n",
            "training error 0.06237387958716053, test error 0.13691616575095447\n",
            "Loss: 0.0\n",
            "training error 0.06193104271365809, test error 0.13652108701022447\n",
            "Loss: 0.0\n",
            "training error 0.061550750052603805, test error 0.13602489897603784\n",
            "Loss: 0.0\n",
            "training error 0.06112351530704683, test error 0.13447371400026542\n",
            "Loss: 0.0\n",
            "training error 0.06064835008084863, test error 0.13437071354502803\n",
            "Loss: 0.0\n",
            "training error 0.06023864401202272, test error 0.1332046699193939\n",
            "Loss: 0.0\n",
            "training error 0.05989516210210917, test error 0.13180168818236948\n",
            "Loss: 0.0\n",
            "training error 0.059508331976658065, test error 0.13072164743685616\n",
            "Loss: 0.0\n",
            "training error 0.05886543185561905, test error 0.13030384458726418\n",
            "Loss: 0.0\n",
            "training error 0.05848846762122331, test error 0.12937665637343748\n",
            "Loss: 0.0\n",
            "training error 0.05832197408201718, test error 0.12907922644157818\n",
            "Loss: 0.0\n",
            "training error 0.05783909389405667, test error 0.12838955727142878\n",
            "Loss: 0.0\n",
            "training error 0.05718956907387374, test error 0.1277512498117882\n",
            "Loss: 0.0\n",
            "training error 0.05668408656216384, test error 0.12654074010237001\n",
            "Loss: 0.0\n",
            "training error 0.056275730385691954, test error 0.12614827971115725\n",
            "Loss: 0.0\n",
            "training error 0.05584055743698711, test error 0.12562778444651068\n",
            "Loss: 0.0\n",
            "training error 0.05551923784355344, test error 0.12391572755723042\n",
            "Loss: 0.0\n",
            "training error 0.05500654171481848, test error 0.12347966800466202\n",
            "Loss: 0.0\n",
            "training error 0.05457962340903697, test error 0.12298204339741181\n",
            "Loss: 0.0\n",
            "training error 0.05419612911627714, test error 0.1220754514792335\n",
            "Loss: 0.0\n",
            "training error 0.053668867445809856, test error 0.12108157044115693\n",
            "Loss: 0.0\n",
            "training error 0.05338213477129417, test error 0.12018813042521055\n",
            "Loss: 0.0\n",
            "training error 0.052924254396233814, test error 0.11935490709051512\n",
            "Loss: 0.0\n",
            "training error 0.05247720793273566, test error 0.11783033446340808\n",
            "Loss: 0.0\n",
            "training error 0.051984880715257385, test error 0.11714404152421108\n",
            "Loss: 0.0\n",
            "training error 0.052267835964751604, test error 0.11574555897986276\n",
            "Loss: 0.0\n",
            "training error 0.051036925387544375, test error 0.1158953104691714\n",
            "Loss: 0.12937990073096373\n",
            "training error 0.05070816915626328, test error 0.11436673803115556\n",
            "Loss: 0.0\n",
            "training error 0.05056690493650183, test error 0.11396640459661261\n",
            "Loss: 0.0\n",
            "training error 0.05043620870633392, test error 0.11287487772427704\n",
            "Loss: 0.0\n",
            "training error 0.049811301670576, test error 0.11225427918429369\n",
            "Loss: 0.0\n",
            "training error 0.049346997182542915, test error 0.1114133750367454\n",
            "Loss: 0.0\n",
            "training error 0.04912262404073562, test error 0.10997952787844631\n",
            "Loss: 0.0\n",
            "training error 0.048693051733562344, test error 0.10938009637914131\n",
            "Loss: 0.0\n",
            "training error 0.04788512267958646, test error 0.1074376530897282\n",
            "Loss: 0.0\n",
            "training error 0.04791569584926612, test error 0.1080643001122599\n",
            "Loss: 0.5832657401854568\n",
            "training error 0.04714782857525757, test error 0.10652134109625368\n",
            "Loss: 0.0\n",
            "training error 0.04689682619290418, test error 0.10605777336313729\n",
            "Loss: 0.0\n",
            "training error 0.04671873111106528, test error 0.10592642719808305\n",
            "Loss: 0.0\n",
            "training error 0.04615523179501863, test error 0.10470553431381906\n",
            "Loss: 0.0\n",
            "training error 0.04569852983409629, test error 0.10381574021325359\n",
            "Loss: 0.0\n",
            "training error 0.04543026873131354, test error 0.10249520217314691\n",
            "Loss: 0.0\n",
            "training error 0.045056850221548914, test error 0.10237420306886004\n",
            "Loss: 0.0\n",
            "training error 0.0448235508650976, test error 0.10239661801594659\n",
            "Loss: 0.021895112650072157\n",
            "training error 0.04429787287311084, test error 0.10060028685538207\n",
            "Loss: 0.0\n",
            "training error 0.04398813893782797, test error 0.09998285179318409\n",
            "Loss: 0.0\n",
            "training error 0.04379385555140303, test error 0.10038831672684519\n",
            "Loss: 0.4055344755516721\n",
            "training error 0.04339960145511296, test error 0.09882729374882389\n",
            "Loss: 0.0\n",
            "training error 0.04295670758785847, test error 0.0972756633115047\n",
            "Loss: 0.0\n",
            "training error 0.04273080915656959, test error 0.0969707909831071\n",
            "Loss: 0.0\n",
            "training error 0.042425338035196325, test error 0.09587235098135999\n",
            "Loss: 0.0\n",
            "training error 0.041999565181682776, test error 0.09585386559655401\n",
            "Loss: 0.0\n",
            "training error 0.041659807168177666, test error 0.09429297306097673\n",
            "Loss: 0.0\n",
            "training error 0.0416262403625188, test error 0.09311451645902524\n",
            "Loss: 0.0\n",
            "training error 0.04113288541180038, test error 0.09309153877058562\n",
            "Loss: 0.0\n",
            "training error 0.04108021439017046, test error 0.09274176649654078\n",
            "Loss: 0.0\n",
            "training error 0.040473560045833606, test error 0.09299376803583273\n",
            "Loss: 0.27172389400340613\n",
            "training error 0.040474035898220476, test error 0.09130599939985834\n",
            "Loss: 0.0\n",
            "training error 0.03981330695136766, test error 0.09010445817016093\n",
            "Loss: 0.0\n",
            "training error 0.039716436050035116, test error 0.08984478402056413\n",
            "Loss: 0.0\n",
            "training error 0.03919493529199239, test error 0.08927517312709124\n",
            "Loss: 0.0\n",
            "training error 0.03896831978705143, test error 0.08910365205370994\n",
            "Loss: 0.0\n",
            "training error 0.03865230699707636, test error 0.08831558385154123\n",
            "Loss: 0.0\n",
            "training error 0.03836905754712196, test error 0.08829278536285265\n",
            "Loss: 0.0\n",
            "training error 0.03839092452698308, test error 0.08646723113300725\n",
            "Loss: 0.0\n",
            "training error 0.03780588024562836, test error 0.0862746759602482\n",
            "Loss: 0.0\n",
            "training error 0.0375792766249145, test error 0.08492697659648028\n",
            "Loss: 0.0\n",
            "training error 0.03756016064503994, test error 0.0853943540210503\n",
            "Loss: 0.5503285802704427\n",
            "training error 0.0370353135659711, test error 0.08440118207271533\n",
            "Loss: 0.0\n",
            "training error 0.03672353676985924, test error 0.08325630399615656\n",
            "Loss: 0.0\n",
            "training error 0.03655898569221755, test error 0.08304591774882662\n",
            "Loss: 0.0\n",
            "training error 0.03631107370807177, test error 0.08291859169289745\n",
            "Loss: 0.0\n",
            "training error 0.036279330719952554, test error 0.08169093553583405\n",
            "Loss: 0.0\n",
            "training error 0.036001001851224415, test error 0.08096454362850079\n",
            "Loss: 0.0\n",
            "training error 0.03549524184814236, test error 0.08085375390152287\n",
            "Loss: 0.0\n",
            "training error 0.03530236251799946, test error 0.08015891761986778\n",
            "Loss: 0.0\n",
            "training error 0.03516934852424708, test error 0.07991811075709658\n",
            "Loss: 0.0\n",
            "training error 0.034797294758148585, test error 0.07944851149157955\n",
            "Loss: 0.0\n",
            "training error 0.03448339772862879, test error 0.0788739671207532\n",
            "Loss: 0.0\n",
            "training error 0.03438444798298032, test error 0.07794925397051304\n",
            "Loss: 0.0\n",
            "training error 0.034105843696638265, test error 0.07766605403673761\n",
            "Loss: 0.0\n",
            "training error 0.033876708215923514, test error 0.0774257569078937\n",
            "Loss: 0.0\n",
            "training error 0.03387632395997327, test error 0.07636878996105737\n",
            "Loss: 0.0\n",
            "training error 0.033345363995702225, test error 0.07671769559454761\n",
            "Loss: 0.4568694013197705\n",
            "training error 0.033441524915186364, test error 0.07569621045984055\n",
            "Loss: 0.0\n",
            "training error 0.03299828160748531, test error 0.07540372599840596\n",
            "Loss: 0.0\n",
            "training error 0.03291611028584405, test error 0.0751745687916409\n",
            "Loss: 0.0\n",
            "training error 0.03281824485628659, test error 0.07633951014482299\n",
            "Loss: 1.5496482013896529\n",
            "training error 0.032639300282233545, test error 0.07468812451489162\n",
            "Loss: 0.0\n",
            "training error 0.032218763247469015, test error 0.07380650212242684\n",
            "Loss: 0.0\n",
            "training error 0.032075529810524674, test error 0.07367717969195264\n",
            "Loss: 0.0\n",
            "training error 0.03191550104378045, test error 0.07332012961010448\n",
            "Loss: 0.0\n",
            "training error 0.031814624961184985, test error 0.07256665621797956\n",
            "Loss: 0.0\n",
            "training error 0.03181982783212487, test error 0.0730217230794005\n",
            "Loss: 0.6271018745220625\n",
            "training error 0.03155822275117537, test error 0.07194471003221006\n",
            "Loss: 0.0\n",
            "training error 0.031447929846578376, test error 0.07075652688344254\n",
            "Loss: 0.0\n",
            "training error 0.030953562272241275, test error 0.07038627555740909\n",
            "Loss: 0.0\n",
            "training error 0.03089450242060161, test error 0.07001346263333318\n",
            "Loss: 0.0\n",
            "training error 0.030623988967454545, test error 0.06973433514767353\n",
            "Loss: 0.0\n",
            "training error 0.030499176568788686, test error 0.0697695165328926\n",
            "Loss: 0.050450592444239994\n",
            "training error 0.03048374187514571, test error 0.06934246482667733\n",
            "Loss: 0.0\n",
            "training error 0.030141290735606806, test error 0.06948731070304097\n",
            "Loss: 0.20888481066498876\n",
            "training error 0.0303700004569346, test error 0.06895326444481238\n",
            "Loss: 0.0\n",
            "training error 0.029982463444821403, test error 0.06908907673298964\n",
            "Loss: 0.1969628113632771\n",
            "training error 0.029724198941921385, test error 0.0682456107173756\n",
            "Loss: 0.0\n",
            "training error 0.02961317671171632, test error 0.06755043502066514\n",
            "Loss: 0.0\n",
            "training error 0.02952677725370874, test error 0.06827974595189905\n",
            "Loss: 1.079653937107583\n",
            "training error 0.029353936371386842, test error 0.06731963985743016\n",
            "Loss: 0.0\n",
            "training error 0.02924707762197011, test error 0.06684347434296284\n",
            "Loss: 0.0\n",
            "training error 0.029097383182303205, test error 0.0666188376277342\n",
            "Loss: 0.0\n",
            "training error 0.028931281129567034, test error 0.06579308734756066\n",
            "Loss: 0.0\n",
            "training error 0.02908283095791426, test error 0.06576283016828398\n",
            "Loss: 0.0\n",
            "training error 0.028709878445355438, test error 0.06596509627955333\n",
            "Loss: 0.30756904888635805\n",
            "training error 0.028635076224050662, test error 0.06613695060990808\n",
            "Loss: 0.5688934625635023\n",
            "training error 0.028540852453197332, test error 0.06555909475747454\n",
            "Loss: 0.0\n",
            "training error 0.028254611902380235, test error 0.06479515685911592\n",
            "Loss: 0.0\n",
            "training error 0.028383926931609505, test error 0.06511053162575246\n",
            "Loss: 0.4867258324912527\n",
            "training error 0.02811246880808958, test error 0.06416722645014399\n",
            "Loss: 0.0\n",
            "training error 0.02784746153349211, test error 0.0640611073138599\n",
            "Loss: 0.0\n",
            "training error 0.027679592454768503, test error 0.0634316124877404\n",
            "Loss: 0.0\n",
            "training error 0.027613718478278426, test error 0.06274687002778659\n",
            "Loss: 0.0\n",
            "training error 0.02751108126272479, test error 0.06333339564801266\n",
            "Loss: 0.9347488089307632\n",
            "training error 0.027454707119951523, test error 0.06283093794566998\n",
            "Loss: 0.13397946040361042\n",
            "training error 0.02731805580864333, test error 0.062337820909653535\n",
            "Loss: 0.0\n",
            "training error 0.027209049403197814, test error 0.06191373005843545\n",
            "Loss: 0.0\n",
            "training error 0.02710445263185812, test error 0.06240133109296239\n",
            "Loss: 0.7875491172422144\n",
            "training error 0.02697695045624775, test error 0.061721458750431946\n",
            "Loss: 0.0\n",
            "training error 0.026893472082927316, test error 0.061820828733735\n",
            "Loss: 0.16099746395310532\n",
            "training error 0.026980641754120654, test error 0.06189686773526302\n",
            "Loss: 0.28419448986183315\n",
            "training error 0.02678562496242196, test error 0.06111585697344581\n",
            "Loss: 0.0\n",
            "training error 0.026612996251093726, test error 0.06103817237050641\n",
            "Loss: 0.0\n",
            "training error 0.026662851531130453, test error 0.060527278694745\n",
            "Loss: 0.0\n",
            "training error 0.026409299369571856, test error 0.060699136692932476\n",
            "Loss: 0.28393478427173324\n",
            "training error 0.02638967619714776, test error 0.06022040447140303\n",
            "Loss: 0.0\n",
            "training error 0.026251603386665753, test error 0.05939204637841063\n",
            "Loss: 0.0\n",
            "training error 0.026227856430818212, test error 0.059548811177548046\n",
            "Loss: 0.26394914588159235\n",
            "training error 0.02603242860675903, test error 0.059268886440332326\n",
            "Loss: 0.0\n",
            "training error 0.02594501556549488, test error 0.059383070172005316\n",
            "Loss: 0.19265374892429854\n",
            "training error 0.025899194156769088, test error 0.058853553253766795\n",
            "Loss: 0.0\n",
            "training error 0.025769500315566896, test error 0.05900485744545727\n",
            "Loss: 0.2570859078602661\n",
            "training error 0.025655821609555745, test error 0.05902013786203403\n",
            "Loss: 0.28304936415468607\n",
            "training error 0.025592606244999275, test error 0.05892456333205848\n",
            "Loss: 0.12065554986204763\n",
            "training error 0.025588422770382382, test error 0.05787351383322335\n",
            "Loss: 0.0\n",
            "training error 0.025502945438386555, test error 0.05823959796344698\n",
            "Loss: 0.6325590170290774\n",
            "training error 0.02530144619454779, test error 0.05789952140301822\n",
            "Loss: 0.04493863958185962\n",
            "training error 0.025358949541558172, test error 0.05743599701887401\n",
            "Loss: 0.0\n",
            "training error 0.025191693831972534, test error 0.0577577188598505\n",
            "Loss: 0.5601397340952774\n",
            "training error 0.025118238184364424, test error 0.057572598542902316\n",
            "Loss: 0.2378325982282936\n",
            "training error 0.02509253676828578, test error 0.058072688531449805\n",
            "Loss: 1.1085234793897225\n",
            "training error 0.025042334291350995, test error 0.05731626562501405\n",
            "Loss: 0.0\n",
            "training error 0.024883947766628806, test error 0.057587562402638647\n",
            "Loss: 0.47333296171025996\n",
            "training error 0.02483572217824136, test error 0.05652330966278243\n",
            "Loss: 0.0\n",
            "training error 0.02472489488012787, test error 0.05667286675276934\n",
            "Loss: 0.2645936532718496\n",
            "training error 0.024741067937971636, test error 0.056462419145438\n",
            "Loss: 0.0\n",
            "training error 0.024617754759429802, test error 0.05657305579959872\n",
            "Loss: 0.19594742101951557\n",
            "training error 0.024634699384078543, test error 0.056365904908648054\n",
            "Loss: 0.0\n",
            "training error 0.024528911099392366, test error 0.056477422816144644\n",
            "Loss: 0.19784638901358953\n",
            "training error 0.024507270526652112, test error 0.05702310908252361\n",
            "Loss: 1.1659604772436216\n",
            "training error 0.024430447404689047, test error 0.056362316174352035\n",
            "Loss: 0.0\n",
            "training error 0.024327332262260744, test error 0.05565196129764696\n",
            "Loss: 0.0\n",
            "training error 0.02423265999145534, test error 0.05542706238398005\n",
            "Loss: 0.0\n",
            "training error 0.024149998139862596, test error 0.0556090611658828\n",
            "Loss: 0.32835725740238964\n",
            "training error 0.024098705137192047, test error 0.05537470249763346\n",
            "Loss: 0.0\n",
            "training error 0.024047779021047603, test error 0.055255794075843453\n",
            "Loss: 0.0\n",
            "training error 0.02405847653386154, test error 0.05473711532191519\n",
            "Loss: 0.0\n",
            "training error 0.023903356951450704, test error 0.05505778652590262\n",
            "Loss: 0.5858386984800346\n",
            "training error 0.023918014887465814, test error 0.055030155896128786\n",
            "Loss: 0.5353599152790434\n",
            "training error 0.023844865382105892, test error 0.054517557765390634\n",
            "Loss: 0.0\n",
            "training error 0.023882582776332095, test error 0.05473907471753094\n",
            "Loss: 0.4063222220877627\n",
            "training error 0.023819054800814254, test error 0.054081335112410464\n",
            "Loss: 0.0\n",
            "training error 0.023726590912873935, test error 0.053581438099390484\n",
            "Loss: 0.0\n",
            "training error 0.02365360007623747, test error 0.05391170473617811\n",
            "Loss: 0.6163825542998769\n",
            "training error 0.02361284009736787, test error 0.05393314115919333\n",
            "Loss: 0.656389735472307\n",
            "training error 0.023576629067515065, test error 0.053617103496411196\n",
            "Loss: 0.06656297084552953\n",
            "training error 0.023466104516897443, test error 0.05372745782519163\n",
            "Loss: 0.2725192361024087\n",
            "training error 0.023417693014493916, test error 0.0535218488107536\n",
            "Loss: 0.0\n",
            "training error 0.023425920978613964, test error 0.05327792979805639\n",
            "Loss: 0.0\n",
            "training error 0.02329651344654732, test error 0.053145420124038015\n",
            "Loss: 0.0\n",
            "training error 0.023349024921941217, test error 0.053222852104666506\n",
            "Loss: 0.14569831313360204\n",
            "training error 0.02329353833711172, test error 0.05310385343271828\n",
            "Loss: 0.0\n",
            "training error 0.023171884328212752, test error 0.052732718371312146\n",
            "Loss: 0.0\n",
            "training error 0.023168878778906755, test error 0.052853775978790145\n",
            "Loss: 0.22956830449283316\n",
            "training error 0.023107523443252932, test error 0.05253645294283625\n",
            "Loss: 0.0\n",
            "training error 0.023080626326898723, test error 0.052203410816005165\n",
            "Loss: 0.0\n",
            "training error 0.023030152283544773, test error 0.05273032076770173\n",
            "Loss: 1.009340086136712\n",
            "training error 0.022997103960588572, test error 0.0527523032696903\n",
            "Loss: 1.0514494074338243\n",
            "training error 0.022993035942628772, test error 0.05288876636691498\n",
            "Loss: 1.3128558846957405\n",
            "training error 0.022913616390120004, test error 0.05210031366904066\n",
            "Loss: 0.0\n",
            "training error 0.022806668483079526, test error 0.05248265457219742\n",
            "Loss: 0.7338552807676368\n",
            "training error 0.022802899774309916, test error 0.05212127480247863\n",
            "Loss: 0.04023225958122989\n",
            "training error 0.02273338622610839, test error 0.051480391665865405\n",
            "Loss: 0.0\n",
            "training error 0.022934648907508473, test error 0.0515154544207296\n",
            "Loss: 0.06810895125228811\n",
            "training error 0.022712259766705007, test error 0.051877171310670725\n",
            "Loss: 0.7707393669042606\n",
            "training error 0.022896565848134803, test error 0.05180341400333533\n",
            "Loss: 0.6274667441664272\n",
            "training error 0.0226361381975958, test error 0.05199649374803083\n",
            "Loss: 1.0025216698334338\n",
            "training error 0.022616089610216574, test error 0.051778031973599196\n",
            "Loss: 0.5781624772119631\n",
            "training error 0.02254318940663314, test error 0.05157767118243132\n",
            "Loss: 0.18896421223308923\n",
            "training error 0.022506224031604842, test error 0.051398908790497966\n",
            "Loss: 0.0\n",
            "training error 0.022523342413356368, test error 0.05097327837209369\n",
            "Loss: 0.0\n",
            "training error 0.02261147098580686, test error 0.05101602370181636\n",
            "Loss: 0.08385830985921938\n",
            "training error 0.02246765964101389, test error 0.050798206198235725\n",
            "Loss: 0.0\n",
            "training error 0.022386688505825356, test error 0.051128827246561745\n",
            "Loss: 0.6508518175539546\n",
            "training error 0.02233336877053857, test error 0.05084297419330669\n",
            "Loss: 0.08812908648045958\n",
            "training error 0.02236315632532083, test error 0.050821954711060414\n",
            "Loss: 0.04675069180988256\n",
            "training error 0.022254252135127682, test error 0.05068698400588688\n",
            "Loss: 0.0\n",
            "training error 0.022209903457386507, test error 0.050661576517933134\n",
            "Loss: 0.0\n",
            "training error 0.022247371687245533, test error 0.050346772415093465\n",
            "Loss: 0.0\n",
            "training error 0.02242680682204367, test error 0.050180992302851384\n",
            "Loss: 0.0\n",
            "training error 0.022161181886478046, test error 0.050529238206699606\n",
            "Loss: 0.693979707986836\n",
            "training error 0.022116215913996293, test error 0.050743883885901266\n",
            "Loss: 1.121722702597694\n",
            "training error 0.022200803810674755, test error 0.05015667873672201\n",
            "Loss: 0.0\n",
            "training error 0.02209404956443741, test error 0.05040230740298925\n",
            "Loss: 0.48972274969913965\n",
            "training error 0.022233370221583792, test error 0.05128993050014088\n",
            "Loss: 2.2594234545860292\n",
            "training error 0.022095523269451408, test error 0.05019188971461287\n",
            "Loss: 0.07020197265390493\n",
            "training error 0.02200397887065966, test error 0.04974316800243217\n",
            "Loss: 0.0\n",
            "training error 0.02192327699293272, test error 0.0498322357671382\n",
            "Loss: 0.17905527187507264\n",
            "training error 0.02193942483042005, test error 0.049651478260954084\n",
            "Loss: 0.0\n",
            "training error 0.021975551842920535, test error 0.04923349625813722\n",
            "Loss: 0.0\n",
            "training error 0.02189449514760826, test error 0.04974378481738047\n",
            "Loss: 1.0364662232552835\n",
            "training error 0.02195044451481538, test error 0.0494387800280998\n",
            "Loss: 0.4169595612025123\n",
            "training error 0.021845815566554516, test error 0.050081854949233395\n",
            "Loss: 1.7231331422170815\n",
            "training error 0.021822839266882634, test error 0.05007608496662774\n",
            "Loss: 1.7114135142316966\n",
            "training error 0.021768883055020893, test error 0.05009765434160222\n",
            "Loss: 1.7552238803722364\n",
            "training error 0.02181732850722625, test error 0.04995667157960395\n",
            "Loss: 1.4688685070729735\n",
            "training error 0.02167218960512112, test error 0.04929580098146111\n",
            "Loss: 0.12654945932990547\n",
            "training error 0.021670910796438986, test error 0.04969780968701479\n",
            "Loss: 0.9430844123746951\n",
            "training error 0.021749986198296992, test error 0.05006780347802625\n",
            "Loss: 1.694592672262507\n",
            "training error 0.021745125811812677, test error 0.04912020886965123\n",
            "Loss: 0.0\n",
            "training error 0.021646703970838378, test error 0.048917606982730684\n",
            "Loss: 0.0\n",
            "training error 0.021610128341110247, test error 0.04937407393605112\n",
            "Loss: 0.9331342669349763\n",
            "training error 0.021567675182936803, test error 0.049442283718396735\n",
            "Loss: 1.072572368168534\n",
            "training error 0.021522709172287893, test error 0.04931831172608616\n",
            "Loss: 0.8191421618333417\n",
            "training error 0.021564058763441, test error 0.049052774658902266\n",
            "Loss: 0.2763170247050306\n",
            "training error 0.021528724052840814, test error 0.04928836552119632\n",
            "Loss: 0.7579245211167596\n",
            "training error 0.021524509897392526, test error 0.04936096477228953\n",
            "Loss: 0.9063358101621066\n",
            "training error 0.021461294357214746, test error 0.04886537453363307\n",
            "Loss: 0.0\n",
            "training error 0.021524357560039297, test error 0.04911844517416223\n",
            "Loss: 0.517893586091267\n",
            "training error 0.021495861430112926, test error 0.048789209826864605\n",
            "Loss: 0.0\n",
            "training error 0.021555450656238647, test error 0.0484714635520656\n",
            "Loss: 0.0\n",
            "training error 0.021448503382128607, test error 0.04873097649380516\n",
            "Loss: 0.53539324526648\n",
            "training error 0.02145658029128489, test error 0.048840657231486596\n",
            "Loss: 0.7616722342712601\n",
            "training error 0.021479337908649965, test error 0.048861468384402446\n",
            "Loss: 0.8046070899384361\n",
            "training error 0.0215249516128319, test error 0.04891003065888304\n",
            "Loss: 0.9047944391989526\n",
            "training error 0.021326594866244383, test error 0.048612377804036364\n",
            "Loss: 0.29071590095355315\n",
            "training error 0.021330542829904982, test error 0.0483010181141002\n",
            "Loss: 0.0\n",
            "training error 0.02139658955528809, test error 0.04819786546421397\n",
            "Loss: 0.0\n",
            "training error 0.021229503950867926, test error 0.04813146352077412\n",
            "Loss: 0.0\n",
            "training error 0.021257696536471853, test error 0.04832673869618504\n",
            "Loss: 0.40571210831068516\n",
            "training error 0.02129285897320419, test error 0.04856388659890653\n",
            "Loss: 0.898420796919619\n",
            "training error 0.021259244225961652, test error 0.04799705391637191\n",
            "Loss: 0.0\n",
            "training error 0.02131675907480299, test error 0.04835805011759136\n",
            "Loss: 0.7521215819796812\n",
            "training error 0.0211896354958863, test error 0.04837272498201673\n",
            "Loss: 0.7826960927630688\n",
            "training error 0.021163469257411936, test error 0.0484606877119593\n",
            "Loss: 0.9659630284708953\n",
            "training error 0.021214003698971497, test error 0.048501929050274804\n",
            "Loss: 1.0518877570747875\n",
            "training error 0.02122377396514191, test error 0.04849191604204905\n",
            "Loss: 1.0310260428470608\n",
            "training error 0.021363810682364273, test error 0.04862497868460347\n",
            "Loss: 1.3082568970288033\n",
            "training error 0.02112836699464687, test error 0.04797400707988744\n",
            "Loss: 0.0\n",
            "training error 0.02110769923043782, test error 0.04763900118176047\n",
            "Loss: 0.0\n",
            "training error 0.02110794425403242, test error 0.04795913120828853\n",
            "Loss: 0.6719914746042832\n",
            "training error 0.021034179792681185, test error 0.04761511139925853\n",
            "Loss: 0.0\n",
            "training error 0.021048527187335603, test error 0.04741100304093518\n",
            "Loss: 0.0\n",
            "training error 0.02110583789774868, test error 0.047985515859731376\n",
            "Loss: 1.2117710698931194\n",
            "training error 0.021008485311062235, test error 0.04803180644243319\n",
            "Loss: 1.3094078624786842\n",
            "training error 0.020994838964094376, test error 0.0481472178074794\n",
            "Loss: 1.552835247776918\n",
            "training error 0.021069791895649906, test error 0.04788662564749099\n",
            "Loss: 1.0031903483356919\n",
            "training error 0.021059651137418176, test error 0.04775591806991834\n",
            "Loss: 0.7274999617395972\n",
            "training error 0.021016503743302384, test error 0.04782645429438496\n",
            "Loss: 0.8762760262445379\n",
            "training error 0.0210733625994453, test error 0.04756908672834175\n",
            "Loss: 0.33343248880450815\n",
            "training error 0.020957114391802277, test error 0.04763573274043388\n",
            "Loss: 0.47400325891580053\n",
            "training error 0.02099135583573759, test error 0.047977446176308426\n",
            "Loss: 1.1947503723643615\n",
            "training error 0.020940328124965546, test error 0.04801675301064678\n",
            "Loss: 1.277656937965621\n",
            "training error 0.021067665590351902, test error 0.04836675216937263\n",
            "Loss: 2.015880422551386\n",
            "training error 0.020930210631025944, test error 0.04797170926773553\n",
            "Loss: 1.1826499986010264\n",
            "training error 0.020913178602434798, test error 0.047712381635736704\n",
            "Loss: 0.6356722605959542\n",
            "training error 0.02098585897388128, test error 0.047075694537041204\n",
            "Loss: 0.0\n",
            "training error 0.020965365244811334, test error 0.047043644131009525\n",
            "Loss: 0.0\n",
            "training error 0.020900084504979717, test error 0.04755167909636768\n",
            "Loss: 1.0799226436271514\n",
            "training error 0.020852528902755907, test error 0.04750828594015186\n",
            "Loss: 0.9876824334619672\n",
            "training error 0.020817640374863937, test error 0.04711155257033886\n",
            "Loss: 0.1443519960745876\n",
            "training error 0.02079869085828809, test error 0.04739184972803507\n",
            "Loss: 0.7401756463760512\n",
            "training error 0.020798260442298266, test error 0.047239147746421656\n",
            "Loss: 0.41557923290909127\n",
            "training error 0.02080637883994434, test error 0.04728420444554648\n",
            "Loss: 0.5113556123905516\n",
            "training error 0.020777483999305547, test error 0.04738738659520789\n",
            "Loss: 0.7306884289003834\n",
            "training error 0.02082243974323955, test error 0.04707586976485267\n",
            "Loss: 0.06850156793423157\n",
            "training error 0.020843154474648944, test error 0.04736666498059542\n",
            "Loss: 0.6866407897447857\n",
            "training error 0.020791139384752664, test error 0.04683291498013338\n",
            "Loss: 0.0\n",
            "training error 0.02077154929571063, test error 0.04720903782315323\n",
            "Loss: 0.8031164474374464\n",
            "training error 0.02081815401008207, test error 0.047239984589195316\n",
            "Loss: 0.8691955417138075\n",
            "training error 0.02074712902795532, test error 0.047138711254584215\n",
            "Loss: 0.6529516144373027\n",
            "training error 0.02078825694240225, test error 0.047420811311794965\n",
            "Loss: 1.2553058717591492\n",
            "training error 0.0206957463379091, test error 0.04714100021974632\n",
            "Loss: 0.6578391281935492\n",
            "training error 0.02069867876972518, test error 0.0473313882004569\n",
            "Loss: 1.0643651383540398\n",
            "training error 0.020849873597579734, test error 0.04674502347839176\n",
            "Loss: 0.0\n",
            "training error 0.02072767521980216, test error 0.04654060735530292\n",
            "Loss: 0.0\n",
            "training error 0.020651418629760845, test error 0.04677388955228562\n",
            "Loss: 0.501244419097846\n",
            "training error 0.02099777603621194, test error 0.046742574638836555\n",
            "Loss: 0.433959277737328\n",
            "training error 0.020720020537447568, test error 0.04689344633147182\n",
            "Loss: 0.7581314387997473\n",
            "training error 0.020741271103627473, test error 0.046793918505550765\n",
            "Loss: 0.5442798550392869\n",
            "training error 0.020655557517782877, test error 0.046990637731237\n",
            "Loss: 0.9669628341943293\n",
            "training error 0.020622059541284148, test error 0.047071918262684684\n",
            "Loss: 1.1416071632361913\n",
            "training error 0.020609620101025745, test error 0.047046274247707597\n",
            "Loss: 1.086506861726777\n",
            "training error 0.020670747521609762, test error 0.04681296983406877\n",
            "Loss: 0.5852147065605884\n",
            "training error 0.02070411517894144, test error 0.04654825740694021\n",
            "Loss: 0.016437369583277572\n",
            "training error 0.02055162385824289, test error 0.04679030145894882\n",
            "Loss: 0.5365080471332773\n",
            "training error 0.020580098018541246, test error 0.046753589255689544\n",
            "Loss: 0.4576259582533382\n",
            "training error 0.02068611859640135, test error 0.04687480757673165\n",
            "Loss: 0.7180830685714179\n",
            "training error 0.020667288266698707, test error 0.04657241867401139\n",
            "Loss: 0.06835174811024025\n",
            "training error 0.02070074618406261, test error 0.046346282200837724\n",
            "Loss: 0.0\n",
            "training error 0.020494715688566947, test error 0.04646068943195239\n",
            "Loss: 0.24685309302456826\n",
            "training error 0.02048521166422048, test error 0.04660820383379923\n",
            "Loss: 0.5651405474693671\n",
            "training error 0.0205923702101521, test error 0.04634059978637111\n",
            "Loss: 0.0\n",
            "training error 0.020533631927567273, test error 0.04680945444978259\n",
            "Loss: 1.0117578658301651\n",
            "training error 0.020510964418586124, test error 0.04643430959259346\n",
            "Loss: 0.2022196662415876\n",
            "training error 0.02051513776643884, test error 0.04646153966001688\n",
            "Loss: 0.26098038049420236\n",
            "training error 0.020790372240826673, test error 0.04658377460004188\n",
            "Loss: 0.5247554299939949\n",
            "training error 0.02045228374413088, test error 0.04641516987576552\n",
            "Loss: 0.16091740231714002\n",
            "training error 0.020528168471791768, test error 0.04664137993992492\n",
            "Loss: 0.6490640063797182\n",
            "training error 0.020490334733656863, test error 0.04650303433323038\n",
            "Loss: 0.35052318616524136\n",
            "training error 0.020511479355120123, test error 0.04721664741800793\n",
            "Loss: 1.8904538043861496\n",
            "training error 0.020478286013397393, test error 0.04658953095641444\n",
            "Loss: 0.5371772726095347\n",
            "training error 0.020471348522548838, test error 0.04630955632668063\n",
            "Loss: 0.0\n",
            "training error 0.020429285717709307, test error 0.04632794593894901\n",
            "Loss: 0.03971018884019184\n",
            "training error 0.020483402630093395, test error 0.046984949896477786\n",
            "Loss: 1.4584323914328623\n",
            "training error 0.020515930951227633, test error 0.04717045234031116\n",
            "Loss: 1.8590029400358032\n",
            "training error 0.020491387895093926, test error 0.046453557354220576\n",
            "Loss: 0.310953157322702\n",
            "training error 0.02041672600544636, test error 0.04631685589469043\n",
            "Loss: 0.01576255224366996\n",
            "training error 0.02040610407677947, test error 0.046618194167215216\n",
            "Loss: 0.666466848348457\n",
            "training error 0.02041966490263249, test error 0.04642886176319586\n",
            "Loss: 0.2576259545084447\n",
            "training error 0.02051720561121347, test error 0.04607309923751144\n",
            "Loss: 0.0\n",
            "training error 0.020428461940666855, test error 0.04635789889118921\n",
            "Loss: 0.6181473753471556\n",
            "training error 0.02044686196194013, test error 0.04680548203120524\n",
            "Loss: 1.589610436055744\n",
            "training error 0.020499368820123775, test error 0.046656246858071196\n",
            "Loss: 1.2657008758051536\n",
            "training error 0.020506470564928936, test error 0.04622348948340909\n",
            "Loss: 0.32641660401957484\n",
            "training error 0.020402260416372428, test error 0.04607557066110847\n",
            "Loss: 0.005364135771057654\n",
            "training error 0.020442401202887206, test error 0.046369832266076313\n",
            "Loss: 0.6440483350928616\n",
            "training error 0.02044344792837659, test error 0.046648517001086555\n",
            "Loss: 1.2489235000423538\n",
            "training error 0.020488593065233637, test error 0.046178049171117015\n",
            "Loss: 0.22779004525947943\n",
            "training error 0.020614331584030667, test error 0.04604974942061277\n",
            "Loss: 0.0\n",
            "training error 0.020363393404359584, test error 0.046096564377283156\n",
            "Loss: 0.10166169688088367\n",
            "training error 0.020512954903983915, test error 0.046711212938875674\n",
            "Loss: 1.4364106788533837\n",
            "training error 0.02038336809725721, test error 0.046429604333877356\n",
            "Loss: 0.824879435922754\n",
            "training error 0.02036978554060505, test error 0.04663603133093202\n",
            "Loss: 1.2731489697462184\n",
            "training error 0.020381140294791454, test error 0.046171193442194884\n",
            "Loss: 0.2637235231680801\n",
            "training error 0.020362337215903033, test error 0.046274997651855505\n",
            "Loss: 0.489141057392839\n",
            "training error 0.0203896903504478, test error 0.04604904925867224\n",
            "Loss: 0.0\n",
            "training error 0.020457338047226475, test error 0.04685961415942417\n",
            "Loss: 1.760220707703919\n",
            "training error 0.020294362761849837, test error 0.04619387179372223\n",
            "Loss: 0.31449625427981687\n",
            "training error 0.02044415620863783, test error 0.04593588878857747\n",
            "Loss: 0.0\n",
            "training error 0.020292530055106638, test error 0.04642374182343843\n",
            "Loss: 1.062030250696444\n",
            "training error 0.020318660043791046, test error 0.046365018512107725\n",
            "Loss: 0.9341927082446411\n",
            "training error 0.02040406873845171, test error 0.04570128909809877\n",
            "Loss: 0.0\n",
            "training error 0.020334771324163257, test error 0.0459904780581331\n",
            "Loss: 0.6327807502619409\n",
            "training error 0.02023640644180967, test error 0.04603290938666677\n",
            "Loss: 0.7256256773330305\n",
            "training error 0.020280869290873953, test error 0.04601716573605657\n",
            "Loss: 0.6911766477303516\n",
            "training error 0.020261766114572474, test error 0.04624246214101042\n",
            "Loss: 1.184152687137563\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04624246214101042\n",
            "training error 0.12301991006736625, test error 0.23925845773885654\n",
            "training error 0.12047120690132576, test error 0.23374149547409973\n",
            "training error 0.11926054580393311, test error 0.22983979258883575\n",
            "training error 0.11835396063505596, test error 0.22724729573772173\n",
            "training error 0.11802263841883749, test error 0.22475929015185284\n",
            "training error 0.11789258042663558, test error 0.22427127118226883\n",
            "training error 0.1181457311616514, test error 0.22326458663286997\n",
            "training error 0.11779793595631693, test error 0.22406592878549547\n",
            "training error 0.11770594401445905, test error 0.22344599151023425\n",
            "training error 0.11780392647963688, test error 0.22263964025875493\n",
            "training error 0.11759184720773383, test error 0.2235545041205151\n",
            "training error 0.11760106099047321, test error 0.22268944583055322\n",
            "training error 0.11750276417178082, test error 0.2232048956080779\n",
            "training error 0.11740179803149399, test error 0.22325304789513425\n",
            "training error 0.11756025291356255, test error 0.22377106880515352\n",
            "training error 0.11763406480211992, test error 0.22455614680701008\n",
            "training error 0.11782842966046593, test error 0.2232648210682573\n",
            "training error 0.11751399541415843, test error 0.22306325029278035\n",
            "training error 0.11782977037356286, test error 0.22449540486950836\n",
            "training error 0.11795337448639268, test error 0.22470650282985433\n",
            "training error 0.11730947736140226, test error 0.22351291008716886\n",
            "training error 0.11743359154529495, test error 0.2238122363391363\n",
            "training error 0.11728910084858421, test error 0.2238826604955261\n",
            "training error 0.11740110739324688, test error 0.22231018067501399\n",
            "training error 0.11721570694201414, test error 0.2229300116950355\n",
            "training error 0.11755639983978725, test error 0.22222384463753808\n",
            "training error 0.11740829356183635, test error 0.22168333381371996\n",
            "training error 0.11717048759928071, test error 0.2224613893018966\n",
            "training error 0.11728930887109389, test error 0.22246505992006102\n",
            "training error 0.11708190256694691, test error 0.22212885601029045\n",
            "training error 0.11729834232677507, test error 0.2229944640888341\n",
            "training error 0.11722048183185331, test error 0.22295528275153947\n",
            "training error 0.11712193232513844, test error 0.22276869476242397\n",
            "training error 0.1171161483870788, test error 0.22273014182003942\n",
            "training error 0.11693958488862011, test error 0.22223792292772618\n",
            "training error 0.11692514832699301, test error 0.2222049055867033\n",
            "training error 0.11701388040471335, test error 0.22181100334890647\n",
            "training error 0.11736224497781549, test error 0.22153446292855886\n",
            "training error 0.1175833117906064, test error 0.2230539551484715\n",
            "training error 0.11695168726186846, test error 0.22185786335014468\n",
            "training error 0.11712664445366358, test error 0.22243427001271893\n",
            "training error 0.11694805765489598, test error 0.2221586017112266\n",
            "training error 0.11686385555559932, test error 0.22187654920313604\n",
            "training error 0.11682985529844978, test error 0.2217763343540963\n",
            "training error 0.11681143259174144, test error 0.22142275657133592\n",
            "training error 0.11680164969654697, test error 0.222047323072932\n",
            "training error 0.11682451606808002, test error 0.22229824343880247\n",
            "training error 0.11667842880276479, test error 0.22209054038987242\n",
            "training error 0.11668111460436055, test error 0.2220935457158679\n",
            "training error 0.116858514571883, test error 0.22137621207993494\n",
            "Loss: 0.0\n",
            "training error 0.11721172913979312, test error 0.2215667549025066\n",
            "Loss: 0.08607194999925571\n",
            "training error 0.11657058476878102, test error 0.2217352905642765\n",
            "Loss: 0.16220283153633996\n",
            "training error 0.11676605714010223, test error 0.221518222403151\n",
            "Loss: 0.06414886309680234\n",
            "training error 0.1165963787695103, test error 0.221369266793307\n",
            "Loss: 0.0\n",
            "training error 0.11680082234299292, test error 0.22129656276795556\n",
            "Loss: 0.0\n",
            "training error 0.11656589802025728, test error 0.22110324881197932\n",
            "Loss: 0.0\n",
            "training error 0.11668051111279942, test error 0.2215248957961786\n",
            "Loss: 0.1907013969558724\n",
            "training error 0.11670323447220854, test error 0.22159245082933782\n",
            "Loss: 0.22125501094492073\n",
            "training error 0.1170517037483064, test error 0.22201136867371005\n",
            "Loss: 0.4107220796664812\n",
            "training error 0.1163849231986143, test error 0.2212560383531128\n",
            "Loss: 0.06910325468054701\n",
            "training error 0.11653843529137732, test error 0.22209163877823723\n",
            "Loss: 0.4470264329306195\n",
            "training error 0.11644952598845082, test error 0.22195911667031396\n",
            "Loss: 0.3870896800175272\n",
            "training error 0.11645017465345797, test error 0.2219817200718582\n",
            "Loss: 0.39731268744309656\n",
            "training error 0.11650973059994961, test error 0.22193110780746264\n",
            "Loss: 0.3744219046674102\n",
            "training error 0.11636013706057134, test error 0.22197181420111722\n",
            "Loss: 0.39283248609183197\n",
            "training error 0.11643763231376375, test error 0.22108935370287425\n",
            "Loss: 0.0\n",
            "training error 0.11643741595746879, test error 0.22144640557081471\n",
            "Loss: 0.16149663561833005\n",
            "training error 0.11644394511114685, test error 0.22162404335147642\n",
            "Loss: 0.24184323652272077\n",
            "training error 0.11645186570493518, test error 0.22154236253166898\n",
            "Loss: 0.20489852686598198\n",
            "training error 0.11658241692446907, test error 0.22236924718383863\n",
            "Loss: 0.5789032622006918\n",
            "training error 0.11634158477340033, test error 0.22210955565730184\n",
            "Loss: 0.4614432750111863\n",
            "training error 0.11630614992474941, test error 0.2212931290504323\n",
            "Loss: 0.0921687743643762\n",
            "training error 0.11627905992389158, test error 0.2207780213580847\n",
            "Loss: 0.0\n",
            "training error 0.11628194050143033, test error 0.22040468381528988\n",
            "Loss: 0.0\n",
            "training error 0.1161713492942902, test error 0.2206330576894558\n",
            "Loss: 0.10361570825658806\n",
            "training error 0.11646186401785728, test error 0.22122544490185048\n",
            "Loss: 0.37238822349547895\n",
            "training error 0.1162671625585146, test error 0.22138849687234063\n",
            "Loss: 0.4463666742559935\n",
            "training error 0.11627610538105539, test error 0.2214221550474213\n",
            "Loss: 0.4616377540252792\n",
            "training error 0.1161404749646719, test error 0.22111493077846128\n",
            "Loss: 0.32224676484944315\n",
            "training error 0.11609223445282292, test error 0.22111393111615718\n",
            "Loss: 0.32179320719958326\n",
            "training error 0.11625237581449097, test error 0.2209478030456138\n",
            "Loss: 0.24641909641951454\n",
            "training error 0.11604075101552219, test error 0.22097223626513668\n",
            "Loss: 0.2575047136123665\n",
            "training error 0.11610823552518894, test error 0.2213866835510331\n",
            "Loss: 0.44554395067493147\n",
            "training error 0.11625602930438499, test error 0.22090846400279956\n",
            "Loss: 0.22857054523028886\n",
            "training error 0.11600000857426375, test error 0.22102538326216223\n",
            "Loss: 0.2816180836667348\n",
            "training error 0.11607458828666312, test error 0.22068947830565866\n",
            "Loss: 0.12921435490338418\n",
            "training error 0.11591841020014679, test error 0.22059492220492172\n",
            "Loss: 0.08631322453713786\n",
            "training error 0.1159581225252284, test error 0.22067283234115964\n",
            "Loss: 0.12166189993243481\n",
            "training error 0.11611053507630607, test error 0.22100124286981693\n",
            "Loss: 0.2706653253462532\n",
            "training error 0.11599842034737894, test error 0.22045378504479715\n",
            "Loss: 0.022277761369360327\n",
            "training error 0.11600374804977183, test error 0.2206489695439624\n",
            "Loss: 0.11083508954703447\n",
            "training error 0.11594331074388772, test error 0.22050040340761687\n",
            "Loss: 0.043429019143359504\n",
            "training error 0.11594381543028034, test error 0.2207847389992068\n",
            "Loss: 0.1724351666843038\n",
            "training error 0.11580614772805464, test error 0.22071305963990437\n",
            "Loss: 0.13991346248927172\n",
            "training error 0.11589302435681605, test error 0.22072947868706927\n",
            "Loss: 0.14736296260000614\n",
            "training error 0.11580076244355243, test error 0.22056588912481714\n",
            "Loss: 0.07314060061553995\n",
            "training error 0.11614364911211818, test error 0.22132583863628807\n",
            "Loss: 0.41793795170439463\n",
            "training error 0.11578682096777045, test error 0.2208277185328985\n",
            "Loss: 0.19193544814282149\n",
            "training error 0.11585627709423585, test error 0.2210906575983886\n",
            "Loss: 0.31123375929416053\n",
            "training error 0.1158582642484394, test error 0.2205735428336547\n",
            "Loss: 0.07661317148157654\n",
            "training error 0.11573377232313763, test error 0.2205306818285075\n",
            "Loss: 0.05716666771165002\n",
            "training error 0.11586455416589464, test error 0.2204534097361424\n",
            "Loss: 0.02210747975455174\n",
            "training error 0.115849065922728, test error 0.2205733259926514\n",
            "Loss: 0.07651478836214753\n",
            "training error 0.11578214609327098, test error 0.22133918014568504\n",
            "Loss: 0.42399113948881073\n",
            "training error 0.11590922332259945, test error 0.22191411770083902\n",
            "Loss: 0.6848465556267946\n",
            "training error 0.115835453927282, test error 0.2211443735664991\n",
            "Loss: 0.3356052777123031\n",
            "training error 0.11568288399473535, test error 0.22051898689570815\n",
            "Loss: 0.051860549621562946\n",
            "training error 0.1157057044311929, test error 0.22020913775092987\n",
            "Loss: 0.0\n",
            "training error 0.11566513673895176, test error 0.22051784247458134\n",
            "Loss: 0.1401870634454072\n",
            "training error 0.11569538642692744, test error 0.22120547775988542\n",
            "Loss: 0.4524517098297931\n",
            "training error 0.11564268392915797, test error 0.22072265923781068\n",
            "Loss: 0.23319717434324705\n",
            "training error 0.11578217406044777, test error 0.22107381573482668\n",
            "Loss: 0.39266217230040645\n",
            "training error 0.11625395867162698, test error 0.22030589423837377\n",
            "Loss: 0.04393845252386175\n",
            "training error 0.11565223254024207, test error 0.21972771078583275\n",
            "Loss: 0.0\n",
            "training error 0.11567532498760334, test error 0.22050005707737078\n",
            "Loss: 0.35150154196565975\n",
            "training error 0.11568777638385887, test error 0.21988609467463532\n",
            "Loss: 0.0720818909167642\n",
            "training error 0.11567458101448994, test error 0.2200399148321027\n",
            "Loss: 0.142086787849105\n",
            "training error 0.11555844592532097, test error 0.2199792314451116\n",
            "Loss: 0.11446924849820572\n",
            "training error 0.11551176629480775, test error 0.22066990382716464\n",
            "Loss: 0.42880028102156853\n",
            "training error 0.11570992515008287, test error 0.22055132451018655\n",
            "Loss: 0.37483379834442054\n",
            "training error 0.11554512138029256, test error 0.22117655254401553\n",
            "Loss: 0.6593805364836003\n",
            "training error 0.11579255056748501, test error 0.22022374023992677\n",
            "Loss: 0.22574733624631804\n",
            "training error 0.11547724883659607, test error 0.22072832376507215\n",
            "Loss: 0.45538770492843383\n",
            "training error 0.11551204680560118, test error 0.22104734999454373\n",
            "Loss: 0.6005793279288296\n",
            "training error 0.11550519226105933, test error 0.22085751807823367\n",
            "Loss: 0.5141851650664719\n",
            "training error 0.11543980833078124, test error 0.22054421580067793\n",
            "Loss: 0.37159856256865353\n",
            "training error 0.1155910950643493, test error 0.21995059415075927\n",
            "Loss: 0.10143616575688519\n",
            "training error 0.11539569319473347, test error 0.22053190924014388\n",
            "Loss: 0.36599773939982594\n",
            "training error 0.11536846814485575, test error 0.22071985944617056\n",
            "Loss: 0.4515355194797621\n",
            "training error 0.1154852404137864, test error 0.22017072451527703\n",
            "Loss: 0.20161941698655372\n",
            "training error 0.11545188011709054, test error 0.22024078186450996\n",
            "Loss: 0.2335031284139255\n",
            "training error 0.11529174214277456, test error 0.22054422295051265\n",
            "Loss: 0.3716018165208723\n",
            "training error 0.11534764930403821, test error 0.22025874631394352\n",
            "Loss: 0.24167890622970312\n",
            "training error 0.1154049751530479, test error 0.2201837540605961\n",
            "Loss: 0.20754927684467628\n",
            "training error 0.11532142640138593, test error 0.22042563276748794\n",
            "Loss: 0.3176303886110343\n",
            "training error 0.11530824451642138, test error 0.22045364251282815\n",
            "Loss: 0.33037786831673355\n",
            "training error 0.11534045159779269, test error 0.22094020348599586\n",
            "Loss: 0.5518160162078622\n",
            "training error 0.11536715020579923, test error 0.22035372014533627\n",
            "Loss: 0.28490232627675915\n",
            "training error 0.11549569941901724, test error 0.21958616845225237\n",
            "Loss: 0.0\n",
            "training error 0.11527446093262084, test error 0.21975356087461895\n",
            "Loss: 0.0762308589591143\n",
            "training error 0.11518543603825665, test error 0.2200555294864805\n",
            "Loss: 0.213747995848923\n",
            "training error 0.11524995211155609, test error 0.22032411080888747\n",
            "Loss: 0.3360604913489995\n",
            "training error 0.11518735592047215, test error 0.2195537011865141\n",
            "Loss: 0.0\n",
            "training error 0.11518612697708287, test error 0.2197889342566573\n",
            "Loss: 0.10714147330332935\n",
            "training error 0.11519961649057371, test error 0.2195365053127712\n",
            "Loss: 0.0\n",
            "training error 0.11508288160032555, test error 0.2196074888049941\n",
            "Loss: 0.0323333434326889\n",
            "training error 0.11517407778548744, test error 0.22025646832961152\n",
            "Loss: 0.3279468331768287\n",
            "training error 0.11507748076975269, test error 0.22044644303283048\n",
            "Loss: 0.41448128126249095\n",
            "training error 0.11504745735337804, test error 0.22050900830590853\n",
            "Loss: 0.442980082857658\n",
            "training error 0.11505912414343532, test error 0.22056729263735897\n",
            "Loss: 0.46952889366587147\n",
            "training error 0.11519441557701585, test error 0.22031200026255215\n",
            "Loss: 0.35324191239909375\n",
            "training error 0.11505878679319782, test error 0.22045726122167275\n",
            "Loss: 0.41940902156103466\n",
            "training error 0.1150806705947529, test error 0.22045526789690237\n",
            "Loss: 0.41850105194223275\n",
            "training error 0.11516160842415528, test error 0.21970267787644934\n",
            "Loss: 0.07569245189604779\n",
            "training error 0.11501859010142552, test error 0.2195555979159589\n",
            "Loss: 0.008696778315075981\n",
            "training error 0.11499689170412099, test error 0.21941113563987025\n",
            "Loss: 0.0\n",
            "training error 0.11507765519138162, test error 0.21937301294832004\n",
            "Loss: 0.0\n",
            "training error 0.11499064826767015, test error 0.2194591279255615\n",
            "Loss: 0.03925504604422869\n",
            "training error 0.11523731745058395, test error 0.2195551391090261\n",
            "Loss: 0.08302122410515089\n",
            "training error 0.11491373087289075, test error 0.21940452601366336\n",
            "Loss: 0.014365060186660727\n",
            "training error 0.1150074502480291, test error 0.21930019606724083\n",
            "Loss: 0.0\n",
            "training error 0.11499056255131977, test error 0.2194676675152339\n",
            "Loss: 0.07636630107785702\n",
            "training error 0.11488181949254482, test error 0.2197704690269742\n",
            "Loss: 0.2144425623719748\n",
            "training error 0.11493151172605275, test error 0.2196426665281663\n",
            "Loss: 0.15616514123883984\n",
            "training error 0.1149421238384575, test error 0.21984277852027534\n",
            "Loss: 0.2474153980547067\n",
            "training error 0.11493282645965286, test error 0.21986584266542752\n",
            "Loss: 0.25793255470381027\n",
            "training error 0.11489706555122112, test error 0.2198429888316181\n",
            "Loss: 0.24751129917404135\n",
            "training error 0.11480460797073595, test error 0.21995572637549324\n",
            "Loss: 0.2989191619561682\n",
            "training error 0.11492984643024264, test error 0.21970903749766607\n",
            "Loss: 0.1864300341527736\n",
            "training error 0.11503241860537242, test error 0.22046713867247686\n",
            "Loss: 0.5321210952671684\n",
            "training error 0.11495500943940512, test error 0.21962037384474997\n",
            "Loss: 0.1459997680125058\n",
            "training error 0.11493635452739748, test error 0.21960860985482442\n",
            "Loss: 0.14063543631717135\n",
            "training error 0.11481421579219325, test error 0.220095639390466\n",
            "Loss: 0.36271892934436334\n",
            "training error 0.11476554321202109, test error 0.21982634648357283\n",
            "Loss: 0.23992245596109463\n",
            "training error 0.1147353256364006, test error 0.2198804349049159\n",
            "Loss: 0.2645865567293848\n",
            "training error 0.11477638825817649, test error 0.21942562367797114\n",
            "Loss: 0.057194481801481345\n",
            "training error 0.11491761710165309, test error 0.21972190746073855\n",
            "Loss: 0.19229868511765336\n",
            "training error 0.11500163651009783, test error 0.219444897508151\n",
            "Loss: 0.06598327019542438\n",
            "training error 0.11475275225105201, test error 0.21959538477439783\n",
            "Loss: 0.13460485327905225\n",
            "training error 0.11494522897833255, test error 0.22007476294370865\n",
            "Loss: 0.3531993542907452\n",
            "training error 0.11469747937578656, test error 0.21953251953545866\n",
            "Loss: 0.10593855928273666\n",
            "training error 0.11474426381695196, test error 0.21949187041688384\n",
            "Loss: 0.08740272607155042\n",
            "training error 0.11468276362193457, test error 0.2196819146441711\n",
            "Loss: 0.1740621229600947\n",
            "training error 0.11466887289260677, test error 0.21949525065682712\n",
            "Loss: 0.08894410177657797\n",
            "training error 0.11459645246977046, test error 0.21988793726154446\n",
            "Loss: 0.2680076009250021\n",
            "training error 0.11467771047721281, test error 0.21981061516204373\n",
            "Loss: 0.232749037144675\n",
            "training error 0.11468922342035372, test error 0.21982840813001484\n",
            "Loss: 0.2408625583772972\n",
            "training error 0.11460725598004275, test error 0.21959310372758895\n",
            "Loss: 0.13356470518535168\n",
            "training error 0.11476639104693145, test error 0.2191610427047187\n",
            "Loss: 0.0\n",
            "training error 0.1146154088261268, test error 0.21950616030200878\n",
            "Loss: 0.1574721460670725\n",
            "training error 0.11470213806775138, test error 0.21963965037728247\n",
            "Loss: 0.21838172818360313\n",
            "training error 0.11461693556518496, test error 0.21936064408808612\n",
            "Loss: 0.09107521159057441\n",
            "training error 0.11459966387999222, test error 0.21964370996500368\n",
            "Loss: 0.2202340590865326\n",
            "training error 0.11461350886278558, test error 0.2198376466679886\n",
            "Loss: 0.30872455931025833\n",
            "training error 0.11468389663688819, test error 0.2198522224407798\n",
            "Loss: 0.315375272690388\n",
            "training error 0.11460537445832164, test error 0.21984645705366307\n",
            "Loss: 0.3127446103036835\n",
            "training error 0.11485350236559794, test error 0.22050845636867913\n",
            "Loss: 0.6148052807796844\n",
            "training error 0.11472388218870255, test error 0.22068813121519987\n",
            "Loss: 0.6967883030829736\n",
            "training error 0.11475369026085266, test error 0.2202306059438602\n",
            "Loss: 0.48802616831065126\n",
            "training error 0.11454091470147348, test error 0.21968794886432222\n",
            "Loss: 0.24041962618028823\n",
            "training error 0.11456468238826287, test error 0.2193715067091633\n",
            "Loss: 0.09603166778511252\n",
            "training error 0.11445158345464305, test error 0.21914935982756695\n",
            "Loss: 0.0\n",
            "training error 0.1145978518056279, test error 0.21877857991768437\n",
            "Loss: 0.0\n",
            "training error 0.11451514629980092, test error 0.21919574333713102\n",
            "Loss: 0.19067836513226855\n",
            "training error 0.11460201373994072, test error 0.21887789650483858\n",
            "Loss: 0.045395937386372154\n",
            "training error 0.11446175434830863, test error 0.21905439302198443\n",
            "Loss: 0.1260695194218009\n",
            "training error 0.11443493056235751, test error 0.21890980579322017\n",
            "Loss: 0.05998113507508229\n",
            "training error 0.11450895037579256, test error 0.21896512263034504\n",
            "Loss: 0.08526552861383152\n",
            "training error 0.11445980319278361, test error 0.21900667465480114\n",
            "Loss: 0.10425825837363512\n",
            "training error 0.11450720809289894, test error 0.2190705157751792\n",
            "Loss: 0.1334389580573525\n",
            "training error 0.11443319254437005, test error 0.2192727646526988\n",
            "Loss: 0.22588350980263794\n",
            "training error 0.11473975382586175, test error 0.21973350176981055\n",
            "Loss: 0.4364786774305962\n",
            "training error 0.11443202355473935, test error 0.21946983199389597\n",
            "Loss: 0.31595966866211356\n",
            "training error 0.11444733772060309, test error 0.21962097719387033\n",
            "Loss: 0.3850455910733741\n",
            "training error 0.11432746604670452, test error 0.21936963940791973\n",
            "Loss: 0.2701633269846404\n",
            "training error 0.11431654193038912, test error 0.2189811427412249\n",
            "Loss: 0.09258805117793312\n",
            "training error 0.11437654086537201, test error 0.2192996288394107\n",
            "Loss: 0.23816267658487433\n",
            "training error 0.114474490940094, test error 0.21913452272143458\n",
            "Loss: 0.16269545395355411\n",
            "training error 0.11458518941890937, test error 0.21922984764562606\n",
            "Loss: 0.20626686950406814\n",
            "training error 0.1143115833995254, test error 0.2196492021181742\n",
            "Loss: 0.3979467280651461\n",
            "training error 0.11434549481287451, test error 0.2191283365072361\n",
            "Loss: 0.15986783975072694\n",
            "training error 0.11421179274556208, test error 0.21898839145097101\n",
            "Loss: 0.09590131418055758\n",
            "training error 0.11421732666992541, test error 0.2188329265552584\n",
            "Loss: 0.024840931682845735\n",
            "training error 0.1142858459501182, test error 0.21881034233623972\n",
            "Loss: 0.014518065967572547\n",
            "training error 0.11419346526740803, test error 0.2190262286771034\n",
            "Loss: 0.11319607226274453\n",
            "training error 0.11423905623107873, test error 0.2187882854079648\n",
            "Loss: 0.004436215960490486\n",
            "training error 0.11422086739111373, test error 0.21875281265406588\n",
            "Loss: 0.0\n",
            "training error 0.11416381143677647, test error 0.21876616112528624\n",
            "Loss: 0.006102079812553285\n",
            "training error 0.11422878365663976, test error 0.21846313768613812\n",
            "Loss: 0.0\n",
            "training error 0.11435798951763229, test error 0.21842786165640055\n",
            "Loss: 0.0\n",
            "training error 0.11435198141087972, test error 0.2189877129832858\n",
            "Loss: 0.25630948480643845\n",
            "training error 0.11412150108493814, test error 0.21866330017009417\n",
            "Loss: 0.10778776659177147\n",
            "training error 0.11417636590559904, test error 0.21853624797829546\n",
            "Loss: 0.04962110651680618\n",
            "training error 0.11418975879956043, test error 0.21854139509656503\n",
            "Loss: 0.05197754503638574\n",
            "training error 0.11423911907545255, test error 0.21843489738865124\n",
            "Loss: 0.003221078207404915\n",
            "training error 0.11417769994969895, test error 0.21848168108799706\n",
            "Loss: 0.024639453588193305\n",
            "training error 0.11419085982366044, test error 0.21896541448627155\n",
            "Loss: 0.24610085260854397\n",
            "training error 0.11414328624836152, test error 0.21869054312830608\n",
            "Loss: 0.12026005744576462\n",
            "training error 0.11412023176807737, test error 0.21909783914793696\n",
            "Loss: 0.3067271210072553\n",
            "training error 0.11406887612645482, test error 0.2191097720731578\n",
            "Loss: 0.31219021767008304\n",
            "training error 0.11420591914400019, test error 0.21928235306781332\n",
            "Loss: 0.39120074011296246\n",
            "training error 0.11402626039950597, test error 0.21928008439263624\n",
            "Loss: 0.39016210192832634\n",
            "training error 0.11409788446563743, test error 0.21900260474537328\n",
            "Loss: 0.2631271874449892\n",
            "training error 0.11400570401252903, test error 0.21883992750425912\n",
            "Loss: 0.18865077226584148\n",
            "training error 0.11402198737554438, test error 0.2190337564625548\n",
            "Loss: 0.27738897481282\n",
            "training error 0.1141790678405503, test error 0.21869094395248653\n",
            "Loss: 0.12044356159097713\n",
            "training error 0.11413495460455404, test error 0.21902863858719204\n",
            "Loss: 0.27504592419467233\n",
            "training error 0.1140367808393296, test error 0.21875526499765924\n",
            "Loss: 0.14989083296237382\n",
            "training error 0.11402205847269908, test error 0.21903209882441957\n",
            "Loss: 0.2766300798061838\n",
            "training error 0.11427971077339084, test error 0.21877311135353314\n",
            "Loss: 0.15806119902217475\n",
            "training error 0.11455619827713144, test error 0.2182589250110738\n",
            "Loss: 0.0\n",
            "training error 0.11390962961786939, test error 0.21857817485462483\n",
            "Loss: 0.14627115181422568\n",
            "training error 0.11402829201041653, test error 0.21875841180502495\n",
            "Loss: 0.22885056999424336\n",
            "training error 0.11396687128461841, test error 0.21873803526095878\n",
            "Loss: 0.21951462001412736\n",
            "training error 0.11424640837122864, test error 0.2190440062666386\n",
            "Loss: 0.35970178792228413\n",
            "training error 0.11385068484108307, test error 0.21883079725693452\n",
            "Loss: 0.2620155147523562\n",
            "training error 0.11398136452406697, test error 0.21882240800257313\n",
            "Loss: 0.2581717982303555\n",
            "training error 0.11389714579198962, test error 0.21873469648720595\n",
            "Loss: 0.21798488932720517\n",
            "training error 0.11405516737833425, test error 0.21829373596659288\n",
            "Loss: 0.01594938466653595\n",
            "training error 0.11386881417922538, test error 0.2182055820518715\n",
            "Loss: 0.0\n",
            "training error 0.11395789172851145, test error 0.2183308285842862\n",
            "Loss: 0.05739840898522086\n",
            "training error 0.11386552376012629, test error 0.21839635069303825\n",
            "Loss: 0.08742610494787417\n",
            "training error 0.11389337534121213, test error 0.21826370301414064\n",
            "Loss: 0.026635873254310383\n",
            "training error 0.11377774587537051, test error 0.21800469857899205\n",
            "Loss: 0.0\n",
            "training error 0.11382544219360609, test error 0.21823087079218761\n",
            "Loss: 0.10374648558943989\n",
            "training error 0.11381417752972518, test error 0.21802740348254837\n",
            "Loss: 0.010414868901587049\n",
            "training error 0.11389163242180657, test error 0.21796802911317095\n",
            "Loss: 0.0\n",
            "training error 0.11394567012966203, test error 0.21804041092712254\n",
            "Loss: 0.03320753701636647\n",
            "training error 0.113936303472463, test error 0.21812417931093664\n",
            "Loss: 0.07163903734002108\n",
            "training error 0.1138062419114849, test error 0.21802499160709657\n",
            "Loss: 0.026133416977414115\n",
            "training error 0.11371399100944136, test error 0.21813505574083383\n",
            "Loss: 0.07662895716515905\n",
            "training error 0.11366880699847112, test error 0.2180668460622355\n",
            "Loss: 0.04533552441914335\n",
            "training error 0.11372353440344705, test error 0.21814011977004674\n",
            "Loss: 0.0789522470685089\n",
            "training error 0.11367284826147411, test error 0.21810374756704273\n",
            "Loss: 0.06226530304649369\n",
            "training error 0.11368556256312574, test error 0.2181934393242988\n",
            "Loss: 0.10341434569325347\n",
            "training error 0.11362973955837805, test error 0.218057769578312\n",
            "Loss: 0.04117138899046857\n",
            "training error 0.11359362165332826, test error 0.21824038057643735\n",
            "Loss: 0.12495018850906536\n",
            "training error 0.11355918097308236, test error 0.21810495487025974\n",
            "Loss: 0.06281919309263362\n",
            "training error 0.1136171476931113, test error 0.21778546020637726\n",
            "Loss: 0.0\n",
            "training error 0.11357420737786424, test error 0.21757954035052138\n",
            "Loss: 0.0\n",
            "training error 0.11359904435774844, test error 0.2177677074028287\n",
            "Loss: 0.08648196057596813\n",
            "training error 0.11354086271474273, test error 0.21761769252434973\n",
            "Loss: 0.017534816815456544\n",
            "training error 0.11367935826930972, test error 0.21783083477502713\n",
            "Loss: 0.11549542944200297\n",
            "training error 0.11347334892367085, test error 0.21787139378067538\n",
            "Loss: 0.13413643106507944\n",
            "training error 0.11349415914164498, test error 0.2179867981960541\n",
            "Loss: 0.18717653547599689\n",
            "training error 0.11347843987530608, test error 0.21796774883711223\n",
            "Loss: 0.1784214112988014\n",
            "training error 0.11351449543568672, test error 0.21802072972355277\n",
            "Loss: 0.20277153463998943\n",
            "training error 0.11344633218249035, test error 0.21833071448832964\n",
            "Loss: 0.34524116403504834\n",
            "training error 0.11344782661649211, test error 0.2181139671096045\n",
            "Loss: 0.24562362721336495\n",
            "training error 0.11349763847597194, test error 0.21800234431494087\n",
            "Loss: 0.19432156338705653\n",
            "training error 0.11340062300514418, test error 0.21828142235211295\n",
            "Loss: 0.32258639781150844\n",
            "training error 0.11361321893105464, test error 0.21822448894650598\n",
            "Loss: 0.29641968860931733\n",
            "training error 0.11338292393226425, test error 0.2178162180589018\n",
            "Loss: 0.10877755693350366\n",
            "training error 0.1133482988319575, test error 0.21802824260969195\n",
            "Loss: 0.20622447241487318\n",
            "training error 0.11355166746850046, test error 0.2179108071371082\n",
            "Loss: 0.1522508899748365\n",
            "training error 0.11332220565075968, test error 0.21783282618806876\n",
            "Loss: 0.11641068693284407\n",
            "training error 0.11325454155412146, test error 0.21788230170934697\n",
            "Loss: 0.13914973730426716\n",
            "training error 0.11338334406508874, test error 0.21770950566029254\n",
            "Loss: 0.05973232113727356\n",
            "training error 0.11326768005138456, test error 0.21756245805150068\n",
            "Loss: 0.0\n",
            "training error 0.11329039344646848, test error 0.21745010563317757\n",
            "Loss: 0.0\n",
            "training error 0.11321869792391034, test error 0.21752011708672653\n",
            "Loss: 0.03219655991661963\n",
            "training error 0.11334750622701771, test error 0.21739259679173378\n",
            "Loss: 0.0\n",
            "training error 0.11336035585068306, test error 0.21775583339300478\n",
            "Loss: 0.16708784320700332\n",
            "training error 0.11324720500356675, test error 0.21763066507126108\n",
            "Loss: 0.10951075751459705\n",
            "training error 0.11313895364338643, test error 0.21751971250569418\n",
            "Loss: 0.058472880786353265\n",
            "training error 0.11321821411469223, test error 0.217460506094056\n",
            "Loss: 0.03123809335019434\n",
            "training error 0.11331428228629448, test error 0.21745659274685503\n",
            "Loss: 0.02943796433994006\n",
            "training error 0.11323863618829333, test error 0.21762971589018623\n",
            "Loss: 0.10907413681597866\n",
            "training error 0.11310841360404608, test error 0.2175771103989649\n",
            "Loss: 0.08487575471942677\n",
            "training error 0.11323849294782573, test error 0.21771264915043023\n",
            "Loss: 0.1472232097227577\n",
            "training error 0.11313950335639533, test error 0.21783685005916778\n",
            "Loss: 0.2043552880780064\n",
            "training error 0.11312263845753569, test error 0.21769264130898192\n",
            "Loss: 0.1380196573738779\n",
            "training error 0.11311821984857433, test error 0.2178899558006164\n",
            "Loss: 0.22878378391104626\n",
            "training error 0.11309580172558448, test error 0.21816934616832429\n",
            "Loss: 0.35730258898127865\n",
            "training error 0.11315747612842875, test error 0.21829185053230307\n",
            "Loss: 0.4136542613871974\n",
            "training error 0.113026727915884, test error 0.21814835462799553\n",
            "Loss: 0.34764653783760924\n",
            "training error 0.11304449108119732, test error 0.21822372314599223\n",
            "Loss: 0.3823158499986379\n",
            "training error 0.11308039044452269, test error 0.21807770495027679\n",
            "Loss: 0.31514787929938226\n",
            "training error 0.11297724654681991, test error 0.21789268518427332\n",
            "Loss: 0.23003929292892966\n",
            "training error 0.11295422312156723, test error 0.21782059671207146\n",
            "Loss: 0.19687879286327536\n",
            "training error 0.11303012720079073, test error 0.21803007814668843\n",
            "Loss: 0.2932396798982717\n",
            "training error 0.11306972321971283, test error 0.21801095585848168\n",
            "Loss: 0.2844434796187123\n",
            "training error 0.11305762227015297, test error 0.21746567725359972\n",
            "Loss: 0.03361681259823612\n",
            "training error 0.11285332795630425, test error 0.21746270622589514\n",
            "Loss: 0.03225014797929582\n",
            "training error 0.11288965865384658, test error 0.21760839337528873\n",
            "Loss: 0.09926583827584157\n",
            "training error 0.11284169223810604, test error 0.21754635781661538\n",
            "Loss: 0.07072965094063743\n",
            "training error 0.11286152281820615, test error 0.21767112653893025\n",
            "Loss: 0.12812292198860487\n",
            "training error 0.11283857108228894, test error 0.21721903418903524\n",
            "Loss: 0.0\n",
            "training error 0.11272703422152756, test error 0.21720681579843146\n",
            "Loss: 0.0\n",
            "training error 0.11279867688452898, test error 0.21734269040033344\n",
            "Loss: 0.06255540435162743\n",
            "training error 0.11275353235342037, test error 0.21736123589692422\n",
            "Loss: 0.07109357868220201\n",
            "training error 0.11272238260072026, test error 0.2172583869666288\n",
            "Loss: 0.023742886708122413\n",
            "training error 0.1126730790509093, test error 0.21708466748739028\n",
            "Loss: 0.0\n",
            "training error 0.11265595554178993, test error 0.21728025608725443\n",
            "Loss: 0.09009784160620704\n",
            "training error 0.11263467131644878, test error 0.21745798237694444\n",
            "Loss: 0.1719674143158212\n",
            "training error 0.11272908458536983, test error 0.21767746629273416\n",
            "Loss: 0.27307262747071626\n",
            "training error 0.11261685756334151, test error 0.21756212743341444\n",
            "Loss: 0.21994180959459264\n",
            "training error 0.11255436203161891, test error 0.2173872722330378\n",
            "Loss: 0.13939480348841293\n",
            "training error 0.11258432479696875, test error 0.21736911460260724\n",
            "Loss: 0.13103049538654155\n",
            "training error 0.11256160196482405, test error 0.21702623527186463\n",
            "Loss: 0.0\n",
            "training error 0.11256400950645615, test error 0.2168180812864601\n",
            "Loss: 0.0\n",
            "training error 0.11245612072890132, test error 0.21667136989876068\n",
            "Loss: 0.0\n",
            "training error 0.11258412288736175, test error 0.2168123384013681\n",
            "Loss: 0.06506097352561024\n",
            "training error 0.11242695611977968, test error 0.21674389491539825\n",
            "Loss: 0.03347235800994497\n",
            "training error 0.11255870694779095, test error 0.2170281218784091\n",
            "Loss: 0.16465118571740156\n",
            "training error 0.11239059017366577, test error 0.21695697515213994\n",
            "Loss: 0.13181494791523196\n",
            "training error 0.11234797507084178, test error 0.2167246935495029\n",
            "Loss: 0.024610381504097667\n",
            "training error 0.11239439327980975, test error 0.21652756402312218\n",
            "Loss: 0.0\n",
            "training error 0.11229206244761783, test error 0.21675693728933765\n",
            "Loss: 0.10593259442523983\n",
            "training error 0.11224808106034047, test error 0.2167513861256936\n",
            "Loss: 0.10336887295676611\n",
            "training error 0.11243374655237583, test error 0.21694165000222057\n",
            "Loss: 0.19123938375540384\n",
            "training error 0.11230010836426714, test error 0.21679807013131414\n",
            "Loss: 0.1249291790689\n",
            "training error 0.11251065028877666, test error 0.21661543216457504\n",
            "Loss: 0.04058058005191878\n",
            "training error 0.11217359543480918, test error 0.21679347441560545\n",
            "Loss: 0.1228067168643987\n",
            "training error 0.11228426514652266, test error 0.21671718606118007\n",
            "Loss: 0.0875740873516051\n",
            "training error 0.11218069809596366, test error 0.2166418391109995\n",
            "Loss: 0.05277623123545183\n",
            "training error 0.11209317536963713, test error 0.2167711440062758\n",
            "Loss: 0.11249375304829279\n",
            "training error 0.11204606979990892, test error 0.21658992542079228\n",
            "Loss: 0.028800673924100906\n",
            "training error 0.11199750384232603, test error 0.21647156896483777\n",
            "Loss: 0.0\n",
            "training error 0.1119649679434002, test error 0.21660035258934215\n",
            "Loss: 0.05949216570111382\n",
            "training error 0.1119296916704174, test error 0.2164237242598061\n",
            "Loss: 0.0\n",
            "training error 0.11189575895197801, test error 0.2163628421693691\n",
            "Loss: 0.0\n",
            "training error 0.11188427255557913, test error 0.21613471118194955\n",
            "Loss: 0.0\n",
            "training error 0.11196305981310857, test error 0.21588905699631236\n",
            "Loss: 0.0\n",
            "training error 0.11184687740302707, test error 0.21602274421105366\n",
            "Loss: 0.06192403478031405\n",
            "training error 0.11187132199704306, test error 0.21590786389112346\n",
            "Loss: 0.008711370123504203\n",
            "training error 0.11189350337555865, test error 0.21623185688196184\n",
            "Loss: 0.15878520681820163\n",
            "training error 0.11180344350876908, test error 0.2162742992473043\n",
            "Loss: 0.17844454756152928\n",
            "training error 0.11180485069662531, test error 0.2163843529752809\n",
            "Loss: 0.2294215306045011\n",
            "training error 0.11171103492311163, test error 0.2164650718561673\n",
            "Loss: 0.2668105868213644\n",
            "training error 0.11169626831059482, test error 0.21639580764108376\n",
            "Loss: 0.23472734182170552\n",
            "training error 0.11170709834566137, test error 0.21659569456372624\n",
            "Loss: 0.32731513919481703\n",
            "training error 0.11159913655454959, test error 0.2161640771666061\n",
            "Loss: 0.1273895833907135\n",
            "training error 0.11155141459190485, test error 0.21606292915275374\n",
            "Loss: 0.08053773491834004\n",
            "training error 0.11155411612717037, test error 0.21615921587204162\n",
            "Loss: 0.12513782749714597\n",
            "training error 0.11174259919961502, test error 0.2157747567105505\n",
            "Loss: 0.0\n",
            "training error 0.11149586339318426, test error 0.21576956824498275\n",
            "Loss: 0.0\n",
            "training error 0.1113515503301169, test error 0.21560049119302366\n",
            "Loss: 0.0\n",
            "training error 0.11139762048732707, test error 0.2156021309785148\n",
            "Loss: 0.0007605666768606412\n",
            "training error 0.1114530593906893, test error 0.2156608319025904\n",
            "Loss: 0.02798727833728254\n",
            "training error 0.11132788868310144, test error 0.21554582023710442\n",
            "Loss: 0.0\n",
            "training error 0.11128561953893676, test error 0.2158960764912463\n",
            "Loss: 0.1624973538139729\n",
            "training error 0.11133148258959664, test error 0.21594029889596875\n",
            "Loss: 0.18301382899950092\n",
            "training error 0.11145811414734753, test error 0.21621853482732906\n",
            "Loss: 0.31209818380362186\n",
            "training error 0.11127624143332472, test error 0.2160763915337206\n",
            "Loss: 0.246152440363967\n",
            "training error 0.11132357909883007, test error 0.21600712888944118\n",
            "Loss: 0.21401883452405457\n",
            "training error 0.11111555251546325, test error 0.2156515332466821\n",
            "Loss: 0.049044332876135854\n",
            "training error 0.11096739779425255, test error 0.21528146394875705\n",
            "Loss: 0.0\n",
            "training error 0.11101073762849707, test error 0.2149548152133963\n",
            "Loss: 0.0\n",
            "training error 0.11093844691828776, test error 0.2150415380652113\n",
            "Loss: 0.0403446890589132\n",
            "training error 0.11085792819110185, test error 0.21492519015220068\n",
            "Loss: 0.0\n",
            "training error 0.11098441261931608, test error 0.21469620525474686\n",
            "Loss: 0.0\n",
            "training error 0.11084728614314532, test error 0.21482246157653268\n",
            "Loss: 0.05880696476958658\n",
            "training error 0.11090648134053763, test error 0.21465715036307426\n",
            "Loss: 0.0\n",
            "training error 0.11072299050650902, test error 0.21461674095529729\n",
            "Loss: 0.0\n",
            "training error 0.11079945404280295, test error 0.21473126749284518\n",
            "Loss: 0.053363282397311806\n",
            "training error 0.11059376564776101, test error 0.21462919977586656\n",
            "Loss: 0.005805148523752024\n",
            "training error 0.11064574071927097, test error 0.21452633356831677\n",
            "Loss: 0.0\n",
            "training error 0.1106295446767183, test error 0.2146880327024645\n",
            "Loss: 0.0753749581499541\n",
            "training error 0.11064604023317312, test error 0.21478144567546825\n",
            "Loss: 0.11891878395910993\n",
            "training error 0.11058229012687192, test error 0.2147185086330198\n",
            "Loss: 0.08958110713332967\n",
            "training error 0.1104522121298843, test error 0.21436203068081391\n",
            "Loss: 0.0\n",
            "training error 0.11041198416327536, test error 0.21408900802174333\n",
            "Loss: 0.0\n",
            "training error 0.11043900042686203, test error 0.21438947254199045\n",
            "Loss: 0.14034560812978825\n",
            "training error 0.11027954701232778, test error 0.2144732418027173\n",
            "Loss: 0.17947384806180633\n",
            "training error 0.110283989474839, test error 0.2140306074816725\n",
            "Loss: 0.0\n",
            "training error 0.1102057012071139, test error 0.21398516906117654\n",
            "Loss: 0.0\n",
            "training error 0.11012786496929085, test error 0.21393833955102498\n",
            "Loss: 0.0\n",
            "training error 0.11009821099699928, test error 0.21372217260749696\n",
            "Loss: 0.0\n",
            "training error 0.11008892725762946, test error 0.2136937357491715\n",
            "Loss: 0.0\n",
            "training error 0.10999053758608714, test error 0.21355591582844474\n",
            "Loss: 0.0\n",
            "training error 0.1099281824081249, test error 0.21351930729446364\n",
            "Loss: 0.0\n",
            "training error 0.1100151239405911, test error 0.21345660863958404\n",
            "Loss: 0.0\n",
            "training error 0.10991851674375111, test error 0.21361709573200627\n",
            "Loss: 0.07518487876532198\n",
            "training error 0.10978594424687528, test error 0.21371621670536778\n",
            "Loss: 0.12162100177561808\n",
            "training error 0.1097147604219078, test error 0.21368347514685965\n",
            "Loss: 0.10628225976299088\n",
            "training error 0.10965662625503024, test error 0.21359136742095397\n",
            "Loss: 0.06313169792624418\n",
            "training error 0.10962381982872751, test error 0.21332712332522716\n",
            "Loss: 0.0\n",
            "training error 0.1095620287125329, test error 0.21330916435808867\n",
            "Loss: 0.0\n",
            "training error 0.10954621037151478, test error 0.21306376525938475\n",
            "Loss: 0.0\n",
            "training error 0.10947121656588812, test error 0.21303839532592225\n",
            "Loss: 0.0\n",
            "training error 0.10938326470325947, test error 0.21304760777572113\n",
            "Loss: 0.004324314302484034\n",
            "training error 0.10931228144574769, test error 0.21290174136890488\n",
            "Loss: 0.0\n",
            "training error 0.10922661184247437, test error 0.2129591559311791\n",
            "Loss: 0.026967633944674496\n",
            "training error 0.10913051269967045, test error 0.21303163473751693\n",
            "Loss: 0.06101094701098653\n",
            "training error 0.10908483311549048, test error 0.2130566929225117\n",
            "Loss: 0.0727807826326421\n",
            "training error 0.10916083598065954, test error 0.21308202945270208\n",
            "Loss: 0.0846813570607674\n",
            "training error 0.10908557903845294, test error 0.21268661362935248\n",
            "Loss: 0.0\n",
            "training error 0.10898475807518551, test error 0.2129106627326448\n",
            "Loss: 0.1053423623937011\n",
            "training error 0.10887049750717895, test error 0.21266314963834637\n",
            "Loss: 0.0\n",
            "training error 0.10877282187315301, test error 0.2127803217578367\n",
            "Loss: 0.05509751909984484\n",
            "training error 0.10870638657788699, test error 0.21262538331630126\n",
            "Loss: 0.0\n",
            "training error 0.10871831423544473, test error 0.2124781546362254\n",
            "Loss: 0.0\n",
            "training error 0.10860833223461092, test error 0.2124097367230799\n",
            "Loss: 0.0\n",
            "training error 0.10844952339984969, test error 0.21212760806116965\n",
            "Loss: 0.0\n",
            "training error 0.10856492543189711, test error 0.21253371861258483\n",
            "Loss: 0.19144634455032783\n",
            "training error 0.10854021199326198, test error 0.21172857258804362\n",
            "Loss: 0.0\n",
            "training error 0.10842087549991115, test error 0.21168794243351569\n",
            "Loss: 0.0\n",
            "training error 0.10821825724697337, test error 0.2114266812877278\n",
            "Loss: 0.0\n",
            "training error 0.10809359884333024, test error 0.21139272558610772\n",
            "Loss: 0.0\n",
            "training error 0.10810857972081142, test error 0.21138871720536437\n",
            "Loss: 0.0\n",
            "training error 0.10796609753502213, test error 0.21147447017600243\n",
            "Loss: 0.04056648423422793\n",
            "training error 0.10786187662814252, test error 0.2114183293083108\n",
            "Loss: 0.014008364939210871\n",
            "training error 0.10776600736852258, test error 0.2111869926111874\n",
            "Loss: 0.0\n",
            "training error 0.10782181524587688, test error 0.2109557044310632\n",
            "Loss: 0.0\n",
            "training error 0.1076693689567245, test error 0.21089169805510743\n",
            "Loss: 0.0\n",
            "training error 0.10758984816738461, test error 0.21082888832994848\n",
            "Loss: 0.0\n",
            "training error 0.10779793347524926, test error 0.2109568212666736\n",
            "Loss: 0.06068093311999423\n",
            "training error 0.1075235688918767, test error 0.21053575403188465\n",
            "Loss: 0.0\n",
            "training error 0.10736698279256544, test error 0.21078434026151735\n",
            "Loss: 0.11807316566052606\n",
            "training error 0.10719817449885788, test error 0.21066384908891042\n",
            "Loss: 0.06084242442088161\n",
            "training error 0.1072663993524819, test error 0.2110049220855655\n",
            "Loss: 0.22284483499643848\n",
            "training error 0.10720943436768743, test error 0.21091416299127627\n",
            "Loss: 0.17973619784044104\n",
            "training error 0.10694377868785337, test error 0.21056959833514352\n",
            "Loss: 0.016075323364672656\n",
            "training error 0.10688261811196528, test error 0.21078862804664425\n",
            "Loss: 0.12010977229135467\n",
            "training error 0.10680342124083395, test error 0.21061608820717614\n",
            "Loss: 0.038157022621110315\n",
            "training error 0.1066837940568023, test error 0.210638078755463\n",
            "Loss: 0.04860206478889406\n",
            "training error 0.10680440747410029, test error 0.21041501673254767\n",
            "Loss: 0.0\n",
            "training error 0.10645895304430811, test error 0.2105859712625079\n",
            "Loss: 0.08124635428350402\n",
            "training error 0.10638658246474147, test error 0.20992486786446515\n",
            "Loss: 0.0\n",
            "training error 0.10625491436612415, test error 0.20977837623732803\n",
            "Loss: 0.0\n",
            "training error 0.106172378168292, test error 0.20991012131493375\n",
            "Loss: 0.06280202944113356\n",
            "training error 0.10618325468202812, test error 0.20959235784812158\n",
            "Loss: 0.0\n",
            "training error 0.10589168112306112, test error 0.20937604464918252\n",
            "Loss: 0.0\n",
            "training error 0.1058235270799128, test error 0.20892489039789247\n",
            "Loss: 0.0\n",
            "training error 0.10573772134404971, test error 0.20897077533520786\n",
            "Loss: 0.02196240822622819\n",
            "training error 0.10559923093669624, test error 0.2085357412804764\n",
            "Loss: 0.0\n",
            "training error 0.10561114447858472, test error 0.20823990325908814\n",
            "Loss: 0.0\n",
            "training error 0.10554061013097665, test error 0.20841197266177228\n",
            "Loss: 0.08263037006410734\n",
            "training error 0.10534017516642004, test error 0.20818380357327923\n",
            "Loss: 0.0\n",
            "training error 0.10515929238347928, test error 0.20833602531332318\n",
            "Loss: 0.07311891579997454\n",
            "training error 0.10507459313683243, test error 0.20791575332277223\n",
            "Loss: 0.0\n",
            "training error 0.10495652980596679, test error 0.2081438375988595\n",
            "Loss: 0.10970033412194269\n",
            "training error 0.10481832965547123, test error 0.20752644177637541\n",
            "Loss: 0.0\n",
            "training error 0.1046847277828692, test error 0.20753685037484898\n",
            "Loss: 0.005015552902309928\n",
            "training error 0.10459439119360986, test error 0.20705034050590987\n",
            "Loss: 0.0\n",
            "training error 0.1044539511965162, test error 0.20697531893215088\n",
            "Loss: 0.0\n",
            "training error 0.10429289323665451, test error 0.20682833972102446\n",
            "Loss: 0.0\n",
            "training error 0.10414782935803185, test error 0.20661195132385715\n",
            "Loss: 0.0\n",
            "training error 0.10413724745225542, test error 0.20659873330278108\n",
            "Loss: 0.0\n",
            "training error 0.1039864100610352, test error 0.20647795149139553\n",
            "Loss: 0.0\n",
            "training error 0.10384640266714457, test error 0.20628512589159628\n",
            "Loss: 0.0\n",
            "training error 0.10370057250341967, test error 0.2059143991214756\n",
            "Loss: 0.0\n",
            "training error 0.10351584296676683, test error 0.20547946658261096\n",
            "Loss: 0.0\n",
            "training error 0.10360511934691936, test error 0.20514901107590788\n",
            "Loss: 0.0\n",
            "training error 0.10334673827527571, test error 0.2050924080081352\n",
            "Loss: 0.0\n",
            "training error 0.10317920320085286, test error 0.20519093079563697\n",
            "Loss: 0.04803824210688479\n",
            "training error 0.10298857895129337, test error 0.20505302129119735\n",
            "Loss: 0.0\n",
            "training error 0.103257268652436, test error 0.20456902616608885\n",
            "Loss: 0.0\n",
            "training error 0.10285439897516926, test error 0.20409380587362597\n",
            "Loss: 0.0\n",
            "training error 0.10276104193417991, test error 0.20417734911780253\n",
            "Loss: 0.0409337479983618\n",
            "training error 0.10244623961197964, test error 0.2039595678518941\n",
            "Loss: 0.0\n",
            "training error 0.1023326442192804, test error 0.20383318859356805\n",
            "Loss: 0.0\n",
            "training error 0.10223396261359691, test error 0.20389147281174838\n",
            "Loss: 0.028594076647903144\n",
            "training error 0.10204680217875939, test error 0.20385556279019135\n",
            "Loss: 0.01097671913865561\n",
            "training error 0.10195193170486186, test error 0.20377272847071898\n",
            "Loss: 0.0\n",
            "training error 0.10195429846307194, test error 0.20322099004598843\n",
            "Loss: 0.0\n",
            "training error 0.10156636902172751, test error 0.20276655695629525\n",
            "Loss: 0.0\n",
            "training error 0.1013723104692746, test error 0.20251174910615666\n",
            "Loss: 0.0\n",
            "training error 0.10129613190651512, test error 0.20242674200428754\n",
            "Loss: 0.0\n",
            "training error 0.10119351314447644, test error 0.202641768362701\n",
            "Loss: 0.10622428454087895\n",
            "training error 0.10096866637106881, test error 0.2017531979225078\n",
            "Loss: 0.0\n",
            "training error 0.1007525227563388, test error 0.20189154682403962\n",
            "Loss: 0.06857333760081907\n",
            "training error 0.10054897187099945, test error 0.20134538607181895\n",
            "Loss: 0.0\n",
            "training error 0.10036115717203196, test error 0.20124399347205513\n",
            "Loss: 0.0\n",
            "training error 0.10030389992262025, test error 0.20075037587410802\n",
            "Loss: 0.0\n",
            "training error 0.10003871690631336, test error 0.20060657521933575\n",
            "Loss: 0.0\n",
            "training error 0.09984869516568937, test error 0.20047110538165078\n",
            "Loss: 0.0\n",
            "training error 0.10014284389816695, test error 0.199673478852293\n",
            "Loss: 0.0\n",
            "training error 0.09969236816119535, test error 0.19963894537405666\n",
            "Loss: 0.0\n",
            "training error 0.09944793097439035, test error 0.19939859015771672\n",
            "Loss: 0.0\n",
            "training error 0.09931651532940021, test error 0.19898932027311125\n",
            "Loss: 0.0\n",
            "training error 0.09919009665751605, test error 0.19883130770918978\n",
            "Loss: 0.0\n",
            "training error 0.0990267235955771, test error 0.19843339786914307\n",
            "Loss: 0.0\n",
            "training error 0.09878821739909542, test error 0.1981166723715523\n",
            "Loss: 0.0\n",
            "training error 0.09861461114862345, test error 0.19796269922007942\n",
            "Loss: 0.0\n",
            "training error 0.09854513664673992, test error 0.1979362067880795\n",
            "Loss: 0.0\n",
            "training error 0.09838784624608092, test error 0.19752518352731413\n",
            "Loss: 0.0\n",
            "training error 0.0982388257975913, test error 0.19811655045478144\n",
            "Loss: 0.29938811695144896\n",
            "training error 0.09789547093778422, test error 0.1982148006241154\n",
            "Loss: 0.3491286956358586\n",
            "training error 0.09761085271687668, test error 0.197117460115284\n",
            "Loss: 0.0\n",
            "training error 0.09757458736674801, test error 0.19705201222717933\n",
            "Loss: 0.0\n",
            "training error 0.09717949319302968, test error 0.1967981898192758\n",
            "Loss: 0.0\n",
            "training error 0.09700203473222717, test error 0.19682485078534195\n",
            "Loss: 0.013547363464394557\n",
            "training error 0.09693769871707063, test error 0.19613928295042746\n",
            "Loss: 0.0\n",
            "training error 0.09671605826333148, test error 0.19585554461011337\n",
            "Loss: 0.0\n",
            "training error 0.09629316522375449, test error 0.1954406486181742\n",
            "Loss: 0.0\n",
            "training error 0.09607736551604316, test error 0.19528102681085593\n",
            "Loss: 0.0\n",
            "training error 0.0959629250335456, test error 0.1947873226697108\n",
            "Loss: 0.0\n",
            "training error 0.09574575655998031, test error 0.19432496708562266\n",
            "Loss: 0.0\n",
            "training error 0.09559020172948414, test error 0.1948038993326921\n",
            "Loss: 0.24645945101764433\n",
            "training error 0.09525325644683953, test error 0.19445588887128049\n",
            "Loss: 0.06737260148363955\n",
            "training error 0.09503918715827857, test error 0.19370709605631195\n",
            "Loss: 0.0\n",
            "training error 0.09489370023765724, test error 0.1929627128291027\n",
            "Loss: 0.0\n",
            "training error 0.09482739534008157, test error 0.19237589839467248\n",
            "Loss: 0.0\n",
            "training error 0.09457275449297671, test error 0.19217953386406303\n",
            "Loss: 0.0\n",
            "training error 0.09434521997804518, test error 0.19158082519471048\n",
            "Loss: 0.0\n",
            "training error 0.09400619556120611, test error 0.19128052411756263\n",
            "Loss: 0.0\n",
            "training error 0.09400865051361854, test error 0.1908146591732175\n",
            "Loss: 0.0\n",
            "training error 0.09378911140473561, test error 0.1915353805267097\n",
            "Loss: 0.37770753914558863\n",
            "training error 0.09338303682195591, test error 0.19091949211236914\n",
            "Loss: 0.05493966742695644\n",
            "training error 0.09320835539640106, test error 0.19052910670685988\n",
            "Loss: 0.0\n",
            "training error 0.09285371665729565, test error 0.19037899783299583\n",
            "Loss: 0.0\n",
            "training error 0.0927683561864008, test error 0.18992963072302402\n",
            "Loss: 0.0\n",
            "training error 0.09244126368829442, test error 0.18941335310188806\n",
            "Loss: 0.0\n",
            "training error 0.09212550699216682, test error 0.18896103092574357\n",
            "Loss: 0.0\n",
            "training error 0.09192780795179134, test error 0.18911339183955972\n",
            "Loss: 0.08063086503589112\n",
            "training error 0.09172525201304954, test error 0.18817903415355744\n",
            "Loss: 0.0\n",
            "training error 0.09148034392768867, test error 0.18826347850218225\n",
            "Loss: 0.04487447233676445\n",
            "training error 0.09132684823168127, test error 0.18777297211587693\n",
            "Loss: 0.0\n",
            "training error 0.09107872532564674, test error 0.18723161939888538\n",
            "Loss: 0.0\n",
            "training error 0.0906163871793827, test error 0.18741672593037012\n",
            "Loss: 0.09886499517497427\n",
            "training error 0.09030882155376556, test error 0.1869134876542491\n",
            "Loss: 0.0\n",
            "training error 0.09017172528447913, test error 0.18613949374307115\n",
            "Loss: 0.0\n",
            "training error 0.08986071454222938, test error 0.1858147432284702\n",
            "Loss: 0.0\n",
            "training error 0.08956529146313232, test error 0.18545259931995947\n",
            "Loss: 0.0\n",
            "training error 0.0893061938340854, test error 0.18466734008897717\n",
            "Loss: 0.0\n",
            "training error 0.08917165971215696, test error 0.18406493923134806\n",
            "Loss: 0.0\n",
            "training error 0.08882923302079819, test error 0.18393399969271124\n",
            "Loss: 0.0\n",
            "training error 0.08870823884687096, test error 0.18343339301549083\n",
            "Loss: 0.0\n",
            "training error 0.08832939542687045, test error 0.18239593114440664\n",
            "Loss: 0.0\n",
            "training error 0.08797009069770936, test error 0.18262930240966213\n",
            "Loss: 0.12794762678709493\n",
            "training error 0.08768199178662067, test error 0.18229870342314203\n",
            "Loss: 0.0\n",
            "training error 0.08736957103499864, test error 0.18146450866154284\n",
            "Loss: 0.0\n",
            "training error 0.08724133518694477, test error 0.18150039754929392\n",
            "Loss: 0.019777359228978497\n",
            "training error 0.0867999623192445, test error 0.18067122459841486\n",
            "Loss: 0.0\n",
            "training error 0.0867657025866003, test error 0.18070641002441162\n",
            "Loss: 0.019474836723420985\n",
            "training error 0.08619409596627824, test error 0.1797827443249887\n",
            "Loss: 0.0\n",
            "training error 0.08588600200673323, test error 0.17949854975673432\n",
            "Loss: 0.0\n",
            "training error 0.08562306591910906, test error 0.17850170772785073\n",
            "Loss: 0.0\n",
            "training error 0.08532787315184387, test error 0.1783097390974105\n",
            "Loss: 0.0\n",
            "training error 0.08495708893813311, test error 0.1779231769826055\n",
            "Loss: 0.0\n",
            "training error 0.08465056015993551, test error 0.1772479497799582\n",
            "Loss: 0.0\n",
            "training error 0.08458930274278623, test error 0.17596947778094504\n",
            "Loss: 0.0\n",
            "training error 0.08433963837007498, test error 0.17586571851825836\n",
            "Loss: 0.0\n",
            "training error 0.0838065840887594, test error 0.1754438620807202\n",
            "Loss: 0.0\n",
            "training error 0.08343157324401149, test error 0.17495609120415076\n",
            "Loss: 0.0\n",
            "training error 0.08327624860225101, test error 0.1742340459217515\n",
            "Loss: 0.0\n",
            "training error 0.08291031183444221, test error 0.1735397311215214\n",
            "Loss: 0.0\n",
            "training error 0.082615414815617, test error 0.1732945714058171\n",
            "Loss: 0.0\n",
            "training error 0.082229427632228, test error 0.17271325280310246\n",
            "Loss: 0.0\n",
            "training error 0.08193200660705009, test error 0.1722082443300672\n",
            "Loss: 0.0\n",
            "training error 0.08175388619990892, test error 0.17246713955361234\n",
            "Loss: 0.15033846059595568\n",
            "training error 0.08132591272494698, test error 0.1710515691643996\n",
            "Loss: 0.0\n",
            "training error 0.08090404350746265, test error 0.1705655678863593\n",
            "Loss: 0.0\n",
            "training error 0.08089433205210564, test error 0.1699131141763177\n",
            "Loss: 0.0\n",
            "training error 0.08041159470109759, test error 0.16871943453161317\n",
            "Loss: 0.0\n",
            "training error 0.08005017595595712, test error 0.16889398352441687\n",
            "Loss: 0.10345517888219469\n",
            "training error 0.07954882036432931, test error 0.16841459062528033\n",
            "Loss: 0.0\n",
            "training error 0.07943833367934301, test error 0.16721325422856406\n",
            "Loss: 0.0\n",
            "training error 0.07881059338766107, test error 0.16699945922620918\n",
            "Loss: 0.0\n",
            "training error 0.07844157342588703, test error 0.1664345459167757\n",
            "Loss: 0.0\n",
            "training error 0.07800718581936031, test error 0.166239048636124\n",
            "Loss: 0.0\n",
            "training error 0.07783357757940723, test error 0.16463146140004006\n",
            "Loss: 0.0\n",
            "training error 0.0773550791668422, test error 0.16494454468744474\n",
            "Loss: 0.19017220933483792\n",
            "training error 0.07702203790751189, test error 0.16348166905880798\n",
            "Loss: 0.0\n",
            "training error 0.07678712290549107, test error 0.16278419540550493\n",
            "Loss: 0.0\n",
            "training error 0.07634548053988767, test error 0.1619844515344945\n",
            "Loss: 0.0\n",
            "training error 0.07598591063814975, test error 0.16204954003766245\n",
            "Loss: 0.0401819449653118\n",
            "training error 0.07573435936447648, test error 0.16152822440520462\n",
            "Loss: 0.0\n",
            "training error 0.07501836089740524, test error 0.16031718198973507\n",
            "Loss: 0.0\n",
            "training error 0.07477585573692251, test error 0.15956737950660255\n",
            "Loss: 0.0\n",
            "training error 0.07427712603618447, test error 0.15913538060313245\n",
            "Loss: 0.0\n",
            "training error 0.07430418642883131, test error 0.15884230176986702\n",
            "Loss: 0.0\n",
            "training error 0.07381012131597761, test error 0.1579507259457262\n",
            "Loss: 0.0\n",
            "training error 0.07321960679037992, test error 0.15729119581842052\n",
            "Loss: 0.0\n",
            "training error 0.07284630970008336, test error 0.1570039437219014\n",
            "Loss: 0.0\n",
            "training error 0.07231080946096677, test error 0.15641181043454264\n",
            "Loss: 0.0\n",
            "training error 0.07191187481366246, test error 0.15491455130542764\n",
            "Loss: 0.0\n",
            "training error 0.07156926112168999, test error 0.154756260838174\n",
            "Loss: 0.0\n",
            "training error 0.07115342882841381, test error 0.1536823669104886\n",
            "Loss: 0.0\n",
            "training error 0.07062271550315688, test error 0.15236572109850324\n",
            "Loss: 0.0\n",
            "training error 0.07030946238093319, test error 0.1520863019234212\n",
            "Loss: 0.0\n",
            "training error 0.06979869273163776, test error 0.1507597789494411\n",
            "Loss: 0.0\n",
            "training error 0.06946204655993121, test error 0.15023713658065393\n",
            "Loss: 0.0\n",
            "training error 0.06890635825208134, test error 0.14942225591080324\n",
            "Loss: 0.0\n",
            "training error 0.06880223536863916, test error 0.14920317079843148\n",
            "Loss: 0.0\n",
            "training error 0.06812603902714794, test error 0.14724375052132646\n",
            "Loss: 0.0\n",
            "training error 0.06767412467377704, test error 0.14701417810435663\n",
            "Loss: 0.0\n",
            "training error 0.06723359731987051, test error 0.14660384058881573\n",
            "Loss: 0.0\n",
            "training error 0.06703435827776939, test error 0.14631267985528057\n",
            "Loss: 0.0\n",
            "training error 0.06637838713793726, test error 0.14436327374446709\n",
            "Loss: 0.0\n",
            "training error 0.06619670579027609, test error 0.14368517147161605\n",
            "Loss: 0.0\n",
            "training error 0.0657094886427765, test error 0.14247855911843502\n",
            "Loss: 0.0\n",
            "training error 0.06514424735327887, test error 0.14152964072440433\n",
            "Loss: 0.0\n",
            "training error 0.06476768408410265, test error 0.14097946290513794\n",
            "Loss: 0.0\n",
            "training error 0.06422392394048006, test error 0.14115282204450047\n",
            "Loss: 0.12296765485564354\n",
            "training error 0.06375217130614308, test error 0.1398628103472282\n",
            "Loss: 0.0\n",
            "training error 0.0635200407914537, test error 0.13908416055369147\n",
            "Loss: 0.0\n",
            "training error 0.06298016501395043, test error 0.1380063248660706\n",
            "Loss: 0.0\n",
            "training error 0.06258680438236988, test error 0.13843253690709068\n",
            "Loss: 0.30883515044235477\n",
            "training error 0.06210549132954048, test error 0.13607677081555397\n",
            "Loss: 0.0\n",
            "training error 0.06185803181482829, test error 0.13506646792785462\n",
            "Loss: 0.0\n",
            "training error 0.06114146818794963, test error 0.13466743853456287\n",
            "Loss: 0.0\n",
            "training error 0.06113968466422858, test error 0.1343806898702286\n",
            "Loss: 0.0\n",
            "training error 0.060285508016765445, test error 0.13441131782775986\n",
            "Loss: 0.022791933544041854\n",
            "training error 0.059785259782012275, test error 0.13285979660857708\n",
            "Loss: 0.0\n",
            "training error 0.05946492309235535, test error 0.13198558237072205\n",
            "Loss: 0.0\n",
            "training error 0.059038860205381086, test error 0.13157860637222685\n",
            "Loss: 0.0\n",
            "training error 0.058857541969148594, test error 0.1313906748299156\n",
            "Loss: 0.0\n",
            "training error 0.058054045715354864, test error 0.12990991173767272\n",
            "Loss: 0.0\n",
            "training error 0.05765312820259454, test error 0.1278397431740043\n",
            "Loss: 0.0\n",
            "training error 0.057536281353385385, test error 0.12787578091453633\n",
            "Loss: 0.028189778575349322\n",
            "training error 0.056781272684778325, test error 0.12679806884175937\n",
            "Loss: 0.0\n",
            "training error 0.056391607630697796, test error 0.12560590754379056\n",
            "Loss: 0.0\n",
            "training error 0.05605752351999032, test error 0.12543618101716866\n",
            "Loss: 0.0\n",
            "training error 0.05559248981583119, test error 0.12398565256703785\n",
            "Loss: 0.0\n",
            "training error 0.05515194557343637, test error 0.1229773095751341\n",
            "Loss: 0.0\n",
            "training error 0.05479253343719296, test error 0.12184615658600616\n",
            "Loss: 0.0\n",
            "training error 0.05419640609478383, test error 0.12057759333191259\n",
            "Loss: 0.0\n",
            "training error 0.05405966235705506, test error 0.11923450335231071\n",
            "Loss: 0.0\n",
            "training error 0.05390660284262165, test error 0.1200086988105835\n",
            "Loss: 0.6493048878521535\n",
            "training error 0.05296830389705978, test error 0.11814346339507857\n",
            "Loss: 0.0\n",
            "training error 0.05260645723761383, test error 0.11782660672506216\n",
            "Loss: 0.0\n",
            "training error 0.052324099843295016, test error 0.11744622905135123\n",
            "Loss: 0.0\n",
            "training error 0.05176350237031596, test error 0.11714144254718115\n",
            "Loss: 0.0\n",
            "training error 0.051448149842718026, test error 0.11656638602349577\n",
            "Loss: 0.0\n",
            "training error 0.050952264114952045, test error 0.1145998799796474\n",
            "Loss: 0.0\n",
            "training error 0.050654593853220846, test error 0.11306796460369606\n",
            "Loss: 0.0\n",
            "training error 0.050097815290859445, test error 0.11255007639922765\n",
            "Loss: 0.0\n",
            "training error 0.04974079139434823, test error 0.11238457302929332\n",
            "Loss: 0.0\n",
            "training error 0.04937361663005525, test error 0.11129151971302463\n",
            "Loss: 0.0\n",
            "training error 0.049042572304966496, test error 0.10973163606582591\n",
            "Loss: 0.0\n",
            "training error 0.049306436353695686, test error 0.10972119291351959\n",
            "Loss: 0.0\n",
            "training error 0.048171110203992465, test error 0.10895952001092021\n",
            "Loss: 0.0\n",
            "training error 0.04785492879456296, test error 0.10790211032988557\n",
            "Loss: 0.0\n",
            "training error 0.047440823500052604, test error 0.10748005522752835\n",
            "Loss: 0.0\n",
            "training error 0.04730991941632225, test error 0.10602271427014351\n",
            "Loss: 0.0\n",
            "training error 0.0469741894840066, test error 0.10547721504604606\n",
            "Loss: 0.0\n",
            "training error 0.046691856439671164, test error 0.10584351186425672\n",
            "Loss: 0.34727577709627866\n",
            "training error 0.04636558937919258, test error 0.10401907141177974\n",
            "Loss: 0.0\n",
            "training error 0.04563608575258706, test error 0.10340648074753725\n",
            "Loss: 0.0\n",
            "training error 0.04553918867642086, test error 0.1030776264025627\n",
            "Loss: 0.0\n",
            "training error 0.04506592692202192, test error 0.1028573135628125\n",
            "Loss: 0.0\n",
            "training error 0.04462055115913356, test error 0.10084092218794993\n",
            "Loss: 0.0\n",
            "training error 0.04440400112392101, test error 0.10020716285252332\n",
            "Loss: 0.0\n",
            "training error 0.04413047253249018, test error 0.10062971538066569\n",
            "Loss: 0.4216789659679865\n",
            "training error 0.043707213699395356, test error 0.09992907773084155\n",
            "Loss: 0.0\n",
            "training error 0.043228141431750855, test error 0.09889343695384645\n",
            "Loss: 0.0\n",
            "training error 0.04290300116380298, test error 0.09799534928519656\n",
            "Loss: 0.0\n",
            "training error 0.04265451820955925, test error 0.09647926547039068\n",
            "Loss: 0.0\n",
            "training error 0.04220216782727358, test error 0.09581443797335683\n",
            "Loss: 0.0\n",
            "training error 0.041862465738255646, test error 0.09484025688254072\n",
            "Loss: 0.0\n",
            "training error 0.04174925464362052, test error 0.09506341187205335\n",
            "Loss: 0.23529564010882353\n",
            "training error 0.04140350660705235, test error 0.09461063250990222\n",
            "Loss: 0.0\n",
            "training error 0.04096598541377044, test error 0.09313705821081221\n",
            "Loss: 0.0\n",
            "training error 0.04080763412187305, test error 0.09262886131588657\n",
            "Loss: 0.0\n",
            "training error 0.04029490019657466, test error 0.09121197019076191\n",
            "Loss: 0.0\n",
            "training error 0.04003307724422056, test error 0.09101830891364478\n",
            "Loss: 0.0\n",
            "training error 0.039797667797266394, test error 0.09083002971105097\n",
            "Loss: 0.0\n",
            "training error 0.03928049941651825, test error 0.08975269186293182\n",
            "Loss: 0.0\n",
            "training error 0.0391390461715362, test error 0.08888043421434029\n",
            "Loss: 0.0\n",
            "training error 0.03888860406048887, test error 0.08833126514349977\n",
            "Loss: 0.0\n",
            "training error 0.038590938840959925, test error 0.08777584311059534\n",
            "Loss: 0.0\n",
            "training error 0.03859001208683686, test error 0.08700740770107254\n",
            "Loss: 0.0\n",
            "training error 0.03813295465331587, test error 0.08679625492572703\n",
            "Loss: 0.0\n",
            "training error 0.037815647828653993, test error 0.08562543075529398\n",
            "Loss: 0.0\n",
            "training error 0.03758527633967177, test error 0.08567375478901651\n",
            "Loss: 0.056436543788751514\n",
            "training error 0.037347803995494776, test error 0.08505308838234044\n",
            "Loss: 0.0\n",
            "training error 0.037408994615763545, test error 0.08540044017381364\n",
            "Loss: 0.408394096063569\n",
            "training error 0.036710103071209095, test error 0.08397768110739008\n",
            "Loss: 0.0\n",
            "training error 0.036475593317756405, test error 0.08355081002536956\n",
            "Loss: 0.0\n",
            "training error 0.03638407094874301, test error 0.08301693641852421\n",
            "Loss: 0.0\n",
            "training error 0.03625712232655616, test error 0.08231774419721045\n",
            "Loss: 0.0\n",
            "training error 0.036093016114130794, test error 0.08292806122699027\n",
            "Loss: 0.7414161256869001\n",
            "training error 0.035649253059521796, test error 0.0821274790962357\n",
            "Loss: 0.0\n",
            "training error 0.03557442352140627, test error 0.08083775563553548\n",
            "Loss: 0.0\n",
            "training error 0.034990959152983454, test error 0.08060820943304445\n",
            "Loss: 0.0\n",
            "training error 0.034860862680302106, test error 0.08024177484163521\n",
            "Loss: 0.0\n",
            "training error 0.03459174083804437, test error 0.0791589742847718\n",
            "Loss: 0.0\n",
            "training error 0.0344457235270173, test error 0.07852934406663967\n",
            "Loss: 0.0\n",
            "training error 0.03405570939269968, test error 0.07838540861750622\n",
            "Loss: 0.0\n",
            "training error 0.03396911173551176, test error 0.07795730372682466\n",
            "Loss: 0.0\n",
            "training error 0.033783694211105, test error 0.07762344300495035\n",
            "Loss: 0.0\n",
            "training error 0.033494545559193435, test error 0.07680885046715012\n",
            "Loss: 0.0\n",
            "training error 0.03328119134452866, test error 0.07599599399638793\n",
            "Loss: 0.0\n",
            "training error 0.0332063043963436, test error 0.07616322815048446\n",
            "Loss: 0.22005653890713184\n",
            "training error 0.03293069815401117, test error 0.07565253615108519\n",
            "Loss: 0.0\n",
            "training error 0.03267371350409983, test error 0.0748394452692256\n",
            "Loss: 0.0\n",
            "training error 0.03264967426406941, test error 0.07433722419925674\n",
            "Loss: 0.0\n",
            "training error 0.032283247109389755, test error 0.07388154079631705\n",
            "Loss: 0.0\n",
            "training error 0.03214820515653802, test error 0.07362723328526939\n",
            "Loss: 0.0\n",
            "training error 0.03217022675028131, test error 0.07335644006125867\n",
            "Loss: 0.0\n",
            "training error 0.03195681042655975, test error 0.07217221772291486\n",
            "Loss: 0.0\n",
            "training error 0.031675312336610424, test error 0.07289802800206213\n",
            "Loss: 1.0056643706499502\n",
            "training error 0.03174242238400774, test error 0.07222333663481452\n",
            "Loss: 0.07082907178481701\n",
            "training error 0.03130623941738973, test error 0.07183374829795583\n",
            "Loss: 0.0\n",
            "training error 0.031208922969108925, test error 0.07115459752937314\n",
            "Loss: 0.0\n",
            "training error 0.031007844997830703, test error 0.0716810439684632\n",
            "Loss: 0.7398628582963029\n",
            "training error 0.0310726002843328, test error 0.0711780233240526\n",
            "Loss: 0.03292239081218451\n",
            "training error 0.03069623105701939, test error 0.07072662332058881\n",
            "Loss: 0.0\n",
            "training error 0.030405181600005046, test error 0.06970666591646323\n",
            "Loss: 0.0\n",
            "training error 0.030501515564372406, test error 0.06896547287025966\n",
            "Loss: 0.0\n",
            "training error 0.03025067383338133, test error 0.06860837326290334\n",
            "Loss: 0.0\n",
            "training error 0.030021845957389003, test error 0.06846294599146596\n",
            "Loss: 0.0\n",
            "training error 0.029956582984808237, test error 0.06762734808285187\n",
            "Loss: 0.0\n",
            "training error 0.02991750151381263, test error 0.06879925449887513\n",
            "Loss: 1.7328883199553058\n",
            "training error 0.02963461884472391, test error 0.06755441784473222\n",
            "Loss: 0.0\n",
            "training error 0.029446901503314787, test error 0.06758563542021877\n",
            "Loss: 0.04621100511634779\n",
            "training error 0.029288353080776416, test error 0.06738719704657348\n",
            "Loss: 0.0\n",
            "training error 0.02919178275629312, test error 0.06718848309965698\n",
            "Loss: 0.0\n",
            "training error 0.029042889017172797, test error 0.06668004369749396\n",
            "Loss: 0.0\n",
            "training error 0.029034729638073322, test error 0.06663614298811411\n",
            "Loss: 0.0\n",
            "training error 0.028922972286355427, test error 0.06579063799236075\n",
            "Loss: 0.0\n",
            "training error 0.028639615736752836, test error 0.06558400425997217\n",
            "Loss: 0.0\n",
            "training error 0.028460223089838334, test error 0.06587253969426764\n",
            "Loss: 0.43994787685077696\n",
            "training error 0.028332515260766328, test error 0.0652545870166971\n",
            "Loss: 0.0\n",
            "training error 0.02823608116748613, test error 0.06504073190698671\n",
            "Loss: 0.0\n",
            "training error 0.02826622776965226, test error 0.06503669163956943\n",
            "Loss: 0.0\n",
            "training error 0.02805722440529151, test error 0.06425658479705289\n",
            "Loss: 0.0\n",
            "training error 0.028303348588231553, test error 0.06542452583260258\n",
            "Loss: 1.817620776514195\n",
            "training error 0.027773366409624183, test error 0.0640306220814261\n",
            "Loss: 0.0\n",
            "training error 0.027696828715977177, test error 0.0635290541773013\n",
            "Loss: 0.0\n",
            "training error 0.027721594898779536, test error 0.06326439263378171\n",
            "Loss: 0.0\n",
            "training error 0.027413591226931724, test error 0.063505771834646\n",
            "Loss: 0.38154037494921855\n",
            "training error 0.027414639016898133, test error 0.06267667158582486\n",
            "Loss: 0.0\n",
            "training error 0.027216300260953882, test error 0.062160842848536534\n",
            "Loss: 0.0\n",
            "training error 0.027141720963269816, test error 0.06201112059278219\n",
            "Loss: 0.0\n",
            "training error 0.027118518416735793, test error 0.06210475873410248\n",
            "Loss: 0.15100217577941333\n",
            "training error 0.027210742389927604, test error 0.06207150185685061\n",
            "Loss: 0.09737167058299079\n",
            "training error 0.026785451297974116, test error 0.06168795979822235\n",
            "Loss: 0.0\n",
            "training error 0.02675322714260602, test error 0.06172223197592287\n",
            "Loss: 0.055557320768317986\n",
            "training error 0.02654266954561095, test error 0.06091989862367223\n",
            "Loss: 0.0\n",
            "training error 0.026415214360662072, test error 0.06070893540980195\n",
            "Loss: 0.0\n",
            "training error 0.0263861935379847, test error 0.060415693752042386\n",
            "Loss: 0.0\n",
            "training error 0.02635201156020196, test error 0.059979064490040215\n",
            "Loss: 0.0\n",
            "training error 0.026175885503322772, test error 0.05972191921800672\n",
            "Loss: 0.0\n",
            "training error 0.026100437812009845, test error 0.0597225148318054\n",
            "Loss: 0.0009973118856088092\n",
            "training error 0.026010796548365078, test error 0.059145477222941126\n",
            "Loss: 0.0\n",
            "training error 0.02599934360810251, test error 0.059222295370387756\n",
            "Loss: 0.12988000275502287\n",
            "training error 0.025916376410292888, test error 0.059114174014397475\n",
            "Loss: 0.0\n",
            "training error 0.02582219289489487, test error 0.058775337674266404\n",
            "Loss: 0.0\n",
            "training error 0.025735731790310752, test error 0.05902254435160364\n",
            "Loss: 0.42059592869929663\n",
            "training error 0.02559259675481998, test error 0.05864804697703761\n",
            "Loss: 0.0\n",
            "training error 0.025809504527190278, test error 0.05812226261403126\n",
            "Loss: 0.0\n",
            "training error 0.025522871902771742, test error 0.057963259772838116\n",
            "Loss: 0.0\n",
            "training error 0.02538590965858371, test error 0.058663780885595235\n",
            "Loss: 1.2085605873487948\n",
            "training error 0.025441037012281627, test error 0.05801335921075592\n",
            "Loss: 0.0864330924695178\n",
            "training error 0.025310549477408822, test error 0.057354597098886656\n",
            "Loss: 0.0\n",
            "training error 0.02531931798787499, test error 0.05709279725882554\n",
            "Loss: 0.0\n",
            "training error 0.025253332661920647, test error 0.057171127623637914\n",
            "Loss: 0.13719833074086196\n",
            "training error 0.02497486946525368, test error 0.05742882692532151\n",
            "Loss: 0.5885675297579329\n",
            "training error 0.025021974264970312, test error 0.056925325535533595\n",
            "Loss: 0.0\n",
            "training error 0.024803290841788797, test error 0.056633467078080556\n",
            "Loss: 0.0\n",
            "training error 0.024866561942822597, test error 0.05682187864600357\n",
            "Loss: 0.3326859146081329\n",
            "training error 0.024836130517930672, test error 0.05725086806956098\n",
            "Loss: 1.0901698648066338\n",
            "training error 0.024727024984215154, test error 0.056479321134367745\n",
            "Loss: 0.0\n",
            "training error 0.024681567818714674, test error 0.05678962513633798\n",
            "Loss: 0.5494117063340687\n",
            "training error 0.024550056288299475, test error 0.05646095672555374\n",
            "Loss: 0.0\n",
            "training error 0.024514849834653324, test error 0.056040376102007884\n",
            "Loss: 0.0\n",
            "training error 0.02438926455118193, test error 0.05579903071037777\n",
            "Loss: 0.0\n",
            "training error 0.024353391184698075, test error 0.05577314491688532\n",
            "Loss: 0.0\n",
            "training error 0.02432334918864733, test error 0.05562240489691195\n",
            "Loss: 0.0\n",
            "training error 0.024266215362116258, test error 0.05567670944035613\n",
            "Loss: 0.09763070033528276\n",
            "training error 0.024137911438747352, test error 0.05489312981837402\n",
            "Loss: 0.0\n",
            "training error 0.02409867886201408, test error 0.055096406873405994\n",
            "Loss: 0.3703142008928184\n",
            "training error 0.02403063770556923, test error 0.054543105509609606\n",
            "Loss: 0.0\n",
            "training error 0.02393699531434083, test error 0.0550631909004714\n",
            "Loss: 0.9535309476834897\n",
            "training error 0.02394964743970048, test error 0.05491038251466309\n",
            "Loss: 0.6733701750604837\n",
            "training error 0.02395146961136363, test error 0.054284958451038576\n",
            "Loss: 0.0\n",
            "training error 0.023839808416739473, test error 0.05408620443063627\n",
            "Loss: 0.0\n",
            "training error 0.02378303933196335, test error 0.05419604295807085\n",
            "Loss: 0.20308048714241522\n",
            "training error 0.02368174935220601, test error 0.05403174040926158\n",
            "Loss: 0.0\n",
            "training error 0.02378748494745261, test error 0.05344233295594762\n",
            "Loss: 0.0\n",
            "training error 0.023711901922329498, test error 0.05383128643385698\n",
            "Loss: 0.7278003342967354\n",
            "training error 0.02359256203356301, test error 0.05406073570169546\n",
            "Loss: 1.1571402510769602\n",
            "training error 0.023499119542603357, test error 0.053619001440881976\n",
            "Loss: 0.3305777932261611\n",
            "training error 0.023482389635070405, test error 0.05358560397994821\n",
            "Loss: 0.26808527262214277\n",
            "training error 0.023489962327350587, test error 0.053628543455431894\n",
            "Loss: 0.3484325799133048\n",
            "training error 0.023412295038294915, test error 0.05363615392600053\n",
            "Loss: 0.3626731082504886\n",
            "training error 0.02333111562905573, test error 0.05305803783725193\n",
            "Loss: 0.0\n",
            "training error 0.023370122052280395, test error 0.05318711412290345\n",
            "Loss: 0.24327376381207966\n",
            "training error 0.023345770006942226, test error 0.053570694392053926\n",
            "Loss: 0.9662184575586874\n",
            "training error 0.02328532689930824, test error 0.052814052559111355\n",
            "Loss: 0.0\n",
            "training error 0.023139825659360975, test error 0.05296275891820393\n",
            "Loss: 0.28156589371008955\n",
            "training error 0.02307193177710564, test error 0.053191040952047026\n",
            "Loss: 0.7138031918943133\n",
            "training error 0.02305831183133254, test error 0.05300876616061914\n",
            "Loss: 0.36867763800148\n",
            "training error 0.023345144763266473, test error 0.0542854859845414\n",
            "Loss: 2.7860642274765146\n",
            "training error 0.02301386877411495, test error 0.05289431872616813\n",
            "Loss: 0.1519788070929451\n",
            "training error 0.022976729703654393, test error 0.05236064228648326\n",
            "Loss: 0.0\n",
            "training error 0.02299612648877458, test error 0.05207697429773167\n",
            "Loss: 0.0\n",
            "training error 0.02293253212320477, test error 0.05230019237931745\n",
            "Loss: 0.42863104970269905\n",
            "training error 0.022910715559110104, test error 0.05245867922749761\n",
            "Loss: 0.7329629551511063\n",
            "training error 0.022847268015564356, test error 0.052145361302073714\n",
            "Loss: 0.13131908154084826\n",
            "training error 0.022791783295728157, test error 0.05206678348075988\n",
            "Loss: 0.0\n",
            "training error 0.022752882452399273, test error 0.05214594444955089\n",
            "Loss: 0.15203737104341197\n",
            "training error 0.022714334610471388, test error 0.05188920128121534\n",
            "Loss: 0.0\n",
            "training error 0.02272668897337721, test error 0.05150138963487945\n",
            "Loss: 0.0\n",
            "training error 0.02260404746334951, test error 0.051454787877297244\n",
            "Loss: 0.0\n",
            "training error 0.022546708921904978, test error 0.05161458276381101\n",
            "Loss: 0.3105539700111404\n",
            "training error 0.022587889339851723, test error 0.051495428710704325\n",
            "Loss: 0.07898357972828673\n",
            "training error 0.022476400203494805, test error 0.05145087809402139\n",
            "Loss: 0.0\n",
            "training error 0.022504768733434183, test error 0.05113272985591479\n",
            "Loss: 0.0\n",
            "training error 0.02247728636946115, test error 0.051462865407232855\n",
            "Loss: 0.6456442913342242\n",
            "training error 0.022397974451241927, test error 0.050873497016285865\n",
            "Loss: 0.0\n",
            "training error 0.022543992601453188, test error 0.050800187467062406\n",
            "Loss: 0.0\n",
            "training error 0.022403125796435858, test error 0.050652008131440066\n",
            "Loss: 0.0\n",
            "training error 0.022367172455128884, test error 0.050706619529584274\n",
            "Loss: 0.10781684706850925\n",
            "training error 0.022326090469238096, test error 0.05119727692034412\n",
            "Loss: 1.076499844762524\n",
            "training error 0.022228649132595764, test error 0.05109419830587781\n",
            "Loss: 0.8729963346966851\n",
            "training error 0.022383815267092006, test error 0.05093730709574394\n",
            "Loss: 0.56325301765634\n",
            "training error 0.022263060357581885, test error 0.05097926595095243\n",
            "Loss: 0.6460905136537631\n",
            "training error 0.022134671346150193, test error 0.0507172777098953\n",
            "Loss: 0.1288588169808813\n",
            "training error 0.02210125545743119, test error 0.050341278384434036\n",
            "Loss: 0.0\n",
            "training error 0.02218517865520945, test error 0.05005521374756223\n",
            "Loss: 0.0\n",
            "training error 0.022243399345112443, test error 0.049686992672847985\n",
            "Loss: 0.0\n",
            "training error 0.022040508120924764, test error 0.050425218261926454\n",
            "Loss: 1.4857522046849203\n",
            "training error 0.022154278697320062, test error 0.049907882457141874\n",
            "Loss: 0.44456259558367517\n",
            "training error 0.02204078391509841, test error 0.04990564747811936\n",
            "Loss: 0.4400644786676011\n",
            "training error 0.022051750642848787, test error 0.05041668475766054\n",
            "Loss: 1.4685776811187656\n",
            "training error 0.021939881232052073, test error 0.050050497016154154\n",
            "Loss: 0.7315885380698717\n",
            "training error 0.021946470989879993, test error 0.04989089983237012\n",
            "Loss: 0.410383379136503\n",
            "training error 0.021966425797185392, test error 0.04990384476822895\n",
            "Loss: 0.43643634624612737\n",
            "training error 0.02199425290615377, test error 0.049976851175314245\n",
            "Loss: 0.5833689802374753\n",
            "training error 0.021890472204781734, test error 0.04951135734256828\n",
            "Loss: 0.0\n",
            "training error 0.021966195809828806, test error 0.04956349643029475\n",
            "Loss: 0.1053073285099515\n",
            "training error 0.02181647430256766, test error 0.04977426827440462\n",
            "Loss: 0.5310113597114086\n",
            "training error 0.021731991598556245, test error 0.049173426025216835\n",
            "Loss: 0.0\n",
            "training error 0.02187086879342595, test error 0.05019413251666769\n",
            "Loss: 2.075727835045349\n",
            "training error 0.021791877847668062, test error 0.050475130364426433\n",
            "Loss: 2.647170320290604\n",
            "training error 0.02193915260235319, test error 0.049838523682970495\n",
            "Loss: 1.3525550516097606\n",
            "training error 0.021804718529185346, test error 0.050068491669271076\n",
            "Loss: 1.8202222549944747\n",
            "training error 0.021657602424626655, test error 0.049557293558897514\n",
            "Loss: 0.7806402049021832\n",
            "training error 0.0217245447761865, test error 0.04947144973956538\n",
            "Loss: 0.6060666063733677\n",
            "training error 0.021615256759303203, test error 0.04963125127981951\n",
            "Loss: 0.9310420111218187\n",
            "training error 0.02157447709907567, test error 0.04905181175889599\n",
            "Loss: 0.0\n",
            "training error 0.02167571165072031, test error 0.04950563540911551\n",
            "Loss: 0.9251924321372673\n",
            "training error 0.021560212272743327, test error 0.04939094385624953\n",
            "Loss: 0.6913752727839562\n",
            "training error 0.021520626243459545, test error 0.04908872035433367\n",
            "Loss: 0.07524410233632484\n",
            "training error 0.021591223043664586, test error 0.048983792369809105\n",
            "Loss: 0.0\n",
            "training error 0.02149830407205089, test error 0.04905894335073903\n",
            "Loss: 0.15342009528900302\n",
            "training error 0.021431130806937378, test error 0.04892505877601264\n",
            "Loss: 0.0\n",
            "training error 0.021444808663939427, test error 0.04901467285674654\n",
            "Loss: 0.1831660154853587\n",
            "training error 0.021506316743757966, test error 0.048996735557573085\n",
            "Loss: 0.14650320991660415\n",
            "training error 0.02154967260273484, test error 0.04864504623048244\n",
            "Loss: 0.0\n",
            "training error 0.02133968911011181, test error 0.04874443284025504\n",
            "Loss: 0.20430982694867872\n",
            "training error 0.021388274772266284, test error 0.04854311100958782\n",
            "Loss: 0.0\n",
            "training error 0.02138222556423683, test error 0.04872217812974144\n",
            "Loss: 0.3688826620903196\n",
            "training error 0.02137598789900058, test error 0.04839278695490009\n",
            "Loss: 0.0\n",
            "training error 0.021322373350884438, test error 0.048472355545277415\n",
            "Loss: 0.1644224178522391\n",
            "training error 0.02157204607625626, test error 0.04842714596961227\n",
            "Loss: 0.07100028098030453\n",
            "training error 0.021286053498226164, test error 0.04824521422900274\n",
            "Loss: 0.0\n",
            "training error 0.021485349769937136, test error 0.04864266871283044\n",
            "Loss: 0.8238215752159883\n",
            "training error 0.021298462306665045, test error 0.04849976212027779\n",
            "Loss: 0.5276127287295207\n",
            "training error 0.021290799251159134, test error 0.0487445868778834\n",
            "Loss: 1.0350718861156016\n",
            "training error 0.0214968295495988, test error 0.048126317428170216\n",
            "Loss: 0.0\n",
            "training error 0.021248929263467827, test error 0.04786899448872001\n",
            "Loss: 0.0\n",
            "training error 0.021236975465571004, test error 0.04781993511390214\n",
            "Loss: 0.0\n",
            "training error 0.021277851568099207, test error 0.047880818124520955\n",
            "Loss: 0.12731721712671007\n",
            "training error 0.021200763846642913, test error 0.04846211045837673\n",
            "Loss: 1.3429030025762234\n",
            "training error 0.021371070612244476, test error 0.04830907324492596\n",
            "Loss: 1.0228749366947953\n",
            "training error 0.02112135920682675, test error 0.04785087544028557\n",
            "Loss: 0.06470173225818776\n",
            "training error 0.02113293886630978, test error 0.04842590053787878\n",
            "Loss: 1.2671816106259781\n",
            "training error 0.021258963320259998, test error 0.04762676188273161\n",
            "Loss: 0.0\n",
            "training error 0.021141254621051743, test error 0.04769990281684629\n",
            "Loss: 0.15357108319640211\n",
            "training error 0.021118658239608325, test error 0.048153021517257324\n",
            "Loss: 1.1049662284861927\n",
            "training error 0.021096023108108087, test error 0.047954761999987876\n",
            "Loss: 0.6886886789907898\n",
            "training error 0.020997826817153696, test error 0.047712045965880495\n",
            "Loss: 0.1790675657498575\n",
            "training error 0.021054560824449592, test error 0.04780079527678399\n",
            "Loss: 0.3654109311082232\n",
            "training error 0.02103505755743708, test error 0.04757511627504848\n",
            "Loss: 0.0\n",
            "training error 0.02100775118867951, test error 0.04787669271919305\n",
            "Loss: 0.6338953380608858\n",
            "training error 0.02099795554921432, test error 0.04766736522695129\n",
            "Loss: 0.19390168458965906\n",
            "training error 0.020977051440364734, test error 0.04755990578291262\n",
            "Loss: 0.0\n",
            "training error 0.020981704451258854, test error 0.047580032659584576\n",
            "Loss: 0.04231900030211566\n",
            "training error 0.020956144287369985, test error 0.04781625589205596\n",
            "Loss: 0.5390046614336175\n",
            "training error 0.02101670522474403, test error 0.047311951653898496\n",
            "Loss: 0.0\n",
            "training error 0.02093301146256524, test error 0.04721163239188633\n",
            "Loss: 0.0\n",
            "training error 0.020891609797984673, test error 0.0476004821699088\n",
            "Loss: 0.8236312923789013\n",
            "training error 0.020903391945509327, test error 0.04757207490749004\n",
            "Loss: 0.7634612432203314\n",
            "training error 0.02096652774453819, test error 0.048338781881276494\n",
            "Loss: 2.387440197013535\n",
            "training error 0.020938511818970575, test error 0.04828371991000798\n",
            "Loss: 2.2708122210701065\n",
            "training error 0.02100184855245076, test error 0.04776505546932502\n",
            "Loss: 1.172217628157668\n",
            "training error 0.02099333401347164, test error 0.04741720644573662\n",
            "Loss: 0.43543093817195455\n",
            "training error 0.020910582689699683, test error 0.047409043696931136\n",
            "Loss: 0.4181412398668316\n",
            "training error 0.020906367796834677, test error 0.04731688050455527\n",
            "Loss: 0.22292834908845816\n",
            "training error 0.02090416918134951, test error 0.04710403066527371\n",
            "Loss: 0.0\n",
            "training error 0.02078254646770518, test error 0.04718492693138322\n",
            "Loss: 0.17173958357061814\n",
            "training error 0.020889034679535495, test error 0.04772290054657044\n",
            "Loss: 1.3138363587067214\n",
            "training error 0.020830237792046662, test error 0.04740898168733532\n",
            "Loss: 0.6473989969746574\n",
            "training error 0.02080696228160298, test error 0.046874740720618334\n",
            "Loss: 0.0\n",
            "training error 0.020820199023976076, test error 0.04738337309981935\n",
            "Loss: 1.0850884109046\n",
            "training error 0.02081452712046985, test error 0.04720613582208053\n",
            "Loss: 0.7069801269672604\n",
            "training error 0.020807662598850654, test error 0.04751268136979946\n",
            "Loss: 1.360947579386873\n",
            "training error 0.020852374634338085, test error 0.046848236121590635\n",
            "Loss: 0.0\n",
            "training error 0.020755011266426468, test error 0.046985670014693726\n",
            "Loss: 0.29335980280322804\n",
            "training error 0.020747274159674103, test error 0.04744399279723391\n",
            "Loss: 1.271673652978178\n",
            "training error 0.020763961274050304, test error 0.04711684614575907\n",
            "Loss: 0.5733620866136269\n",
            "training error 0.020702393902572818, test error 0.04723868591795576\n",
            "Loss: 0.8334354261529731\n",
            "training error 0.020683672150448206, test error 0.04723631749296457\n",
            "Loss: 0.8283798996544967\n",
            "training error 0.020730260909242272, test error 0.0468621421361908\n",
            "Loss: 0.029683112431544423\n",
            "training error 0.020605689375225843, test error 0.0468784833185437\n",
            "Loss: 0.06456421726221961\n",
            "training error 0.02065000407450673, test error 0.04667961326318912\n",
            "Loss: 0.0\n",
            "training error 0.020692261882863747, test error 0.04688082731852728\n",
            "Loss: 0.43105338984639197\n",
            "training error 0.02068699735499527, test error 0.047055357249565194\n",
            "Loss: 0.8049423722890747\n",
            "training error 0.02078379973537454, test error 0.047035823442792925\n",
            "Loss: 0.7630958242850427\n",
            "training error 0.020694328053980648, test error 0.047059753018451854\n",
            "Loss: 0.8143592645453834\n",
            "training error 0.020624458478657032, test error 0.04689753706414383\n",
            "Loss: 0.466850056631829\n",
            "training error 0.020602177581259744, test error 0.046483426758779596\n",
            "Loss: 0.0\n",
            "training error 0.020577483412034206, test error 0.04674569501833236\n",
            "Loss: 0.564218857860399\n",
            "training error 0.020699183116248, test error 0.04680972285467784\n",
            "Loss: 0.7019622232059541\n",
            "training error 0.0206658206054584, test error 0.04679892428641261\n",
            "Loss: 0.678731215902495\n",
            "training error 0.020619287216031464, test error 0.046688080817361984\n",
            "Loss: 0.4402731744464816\n",
            "training error 0.020553726321146132, test error 0.046718055782040246\n",
            "Loss: 0.5047584475177169\n",
            "training error 0.020623333393965233, test error 0.04682114693222675\n",
            "Loss: 0.7265388913767268\n",
            "training error 0.020567815748699866, test error 0.047158364573862084\n",
            "Loss: 1.451996683861112\n",
            "training error 0.02069532040074393, test error 0.046492225443307854\n",
            "Loss: 0.01892864864270205\n",
            "training error 0.020581024883661612, test error 0.046291844074957095\n",
            "Loss: 0.0\n",
            "training error 0.020545451052834878, test error 0.04661406987627828\n",
            "Loss: 0.6960746709494314\n",
            "training error 0.0204986031662252, test error 0.04676634132530056\n",
            "Loss: 1.0250126341373456\n",
            "training error 0.020555027107479713, test error 0.04686161279944481\n",
            "Loss: 1.2308188102533313\n",
            "training error 0.020632161658513417, test error 0.04649751048285835\n",
            "Loss: 0.4442821667856478\n",
            "training error 0.02048223149778809, test error 0.04676615946450465\n",
            "Loss: 1.024619777037894\n",
            "training error 0.020556159388257177, test error 0.04622006722336108\n",
            "Loss: 0.0\n",
            "training error 0.020453558533598863, test error 0.046525313476282484\n",
            "Loss: 0.6604193184018614\n",
            "training error 0.02062021324004333, test error 0.04646417498725075\n",
            "Loss: 0.5281423817711017\n",
            "training error 0.02050341283911155, test error 0.046440349853755954\n",
            "Loss: 0.4765952185451061\n",
            "training error 0.020502681483252523, test error 0.04648331634460273\n",
            "Loss: 0.5695559030009179\n",
            "training error 0.020462426273141692, test error 0.04643817772554198\n",
            "Loss: 0.4718956835931598\n",
            "training error 0.020466163992158448, test error 0.04636379410025881\n",
            "Loss: 0.3109620680626701\n",
            "training error 0.020502528689656456, test error 0.04677036195603604\n",
            "Loss: 1.1905969976539144\n",
            "training error 0.020521085045575378, test error 0.04668009654378106\n",
            "Loss: 0.9953021448386501\n",
            "training error 0.020487488762586943, test error 0.04651925189789603\n",
            "Loss: 0.6473047152638856\n",
            "training error 0.020560071522057792, test error 0.04699087010213784\n",
            "Loss: 1.6676801335052227\n",
            "training error 0.020504519488099907, test error 0.0464513694196947\n",
            "Loss: 0.5004367371770346\n",
            "training error 0.020485037606220866, test error 0.046284185772969486\n",
            "Loss: 0.1387244836718704\n",
            "training error 0.02037422766557302, test error 0.04623727778546131\n",
            "Loss: 0.03723612520305508\n",
            "training error 0.020445121236686226, test error 0.046930491668947895\n",
            "Loss: 1.537047625122745\n",
            "training error 0.02064313916453502, test error 0.046422497929132986\n",
            "Loss: 0.4379714654971112\n",
            "training error 0.02047359026623391, test error 0.046674837838022024\n",
            "Loss: 0.9839246067367968\n",
            "training error 0.020437801670921883, test error 0.046264491665034393\n",
            "Loss: 0.09611505205873172\n",
            "training error 0.020374776645752393, test error 0.04665825092805249\n",
            "Loss: 0.9480377918401839\n",
            "training error 0.020519646251514097, test error 0.04628631545480891\n",
            "Loss: 0.14333218324342756\n",
            "training error 0.020373275920737406, test error 0.04641201195056574\n",
            "Loss: 0.41528439644424875\n",
            "training error 0.020490665685790006, test error 0.0461240972754527\n",
            "Loss: 0.0\n",
            "training error 0.020488629611576194, test error 0.04681426270278484\n",
            "Loss: 1.4963228943224216\n",
            "training error 0.020426308417902973, test error 0.04660614620707711\n",
            "Loss: 1.045112988869179\n",
            "training error 0.02044125256450859, test error 0.04651353361180759\n",
            "Loss: 0.8443229447487877\n",
            "training error 0.020380462907763852, test error 0.04646370714145068\n",
            "Loss: 0.736295962541722\n",
            "training error 0.020388342784964004, test error 0.04613208124113421\n",
            "Loss: 0.017309749465299618\n",
            "training error 0.020448025326478988, test error 0.04687430767355085\n",
            "Loss: 1.6265042405446017\n",
            "training error 0.020395082462792837, test error 0.04671318661287579\n",
            "Loss: 1.2771834512121716\n",
            "training error 0.0204199102903159, test error 0.04706045530875332\n",
            "Loss: 2.030084247955477\n",
            "training error 0.020438558947761965, test error 0.04673277443316451\n",
            "Loss: 1.3196511014119006\n",
            "training error 0.020317868362974632, test error 0.04614279601902752\n",
            "Loss: 0.04054007488354383\n",
            "training error 0.020461633051917477, test error 0.04690764973355434\n",
            "Loss: 1.6987919642573734\n",
            "training error 0.020393953083097292, test error 0.04637790364256507\n",
            "Loss: 0.5502684759262522\n",
            "training error 0.020371887318693372, test error 0.046813822887979584\n",
            "Loss: 1.49536934762724\n",
            "training error 0.02037062536737004, test error 0.04627988197854492\n",
            "Loss: 0.33775122396841883\n",
            "training error 0.020483974606560523, test error 0.04636393605964305\n",
            "Loss: 0.51998586066202\n",
            "training error 0.020328786431316637, test error 0.04629518491160149\n",
            "Loss: 0.37092896393626784\n",
            "training error 0.020325533526978107, test error 0.04608568872800698\n",
            "Loss: 0.0\n",
            "training error 0.020302937700042392, test error 0.04626955995719608\n",
            "Loss: 0.3989768500028079\n",
            "training error 0.020370737090729334, test error 0.0461780526725374\n",
            "Loss: 0.2004178457124528\n",
            "training error 0.020304106411271613, test error 0.04613228037560352\n",
            "Loss: 0.10109786548166966\n",
            "training error 0.0202900153315397, test error 0.04616703790124757\n",
            "Loss: 0.17651721279614563\n",
            "training error 0.020402227144037, test error 0.04605094263443184\n",
            "Loss: 0.0\n",
            "training error 0.020421585476257786, test error 0.04587372859872289\n",
            "Loss: 0.0\n",
            "training error 0.02034330254489571, test error 0.045832851106403054\n",
            "Loss: 0.0\n",
            "training error 0.020320681064703507, test error 0.046149155977946846\n",
            "Loss: 0.690126980775152\n",
            "training error 0.020463688634237358, test error 0.045686264468202675\n",
            "Loss: 0.0\n",
            "training error 0.02028747900323322, test error 0.04622540765376571\n",
            "Loss: 1.1800990775647113\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.04622540765376571\n",
            "training error 0.12328474523989054, test error 0.2355173230807778\n",
            "training error 0.12022062493540824, test error 0.23137557872032155\n",
            "training error 0.11910008815443603, test error 0.22752517478118198\n",
            "training error 0.11805082806208249, test error 0.22613980163826364\n",
            "training error 0.11845551800960188, test error 0.22541774439813453\n",
            "training error 0.11788862118759706, test error 0.2256631031183606\n",
            "training error 0.11789524394454327, test error 0.22481765509891455\n",
            "training error 0.117957456024873, test error 0.22382814115978228\n",
            "training error 0.11859424957101079, test error 0.22248908914138257\n",
            "training error 0.11789617028192045, test error 0.22349794144640833\n",
            "training error 0.11744506581866644, test error 0.22308523932828248\n",
            "training error 0.11767933563336484, test error 0.22332676142697472\n",
            "training error 0.11742147641087058, test error 0.22298224562174024\n",
            "training error 0.11741895082937553, test error 0.22310192632902137\n",
            "training error 0.11753916086939914, test error 0.2225322820376214\n",
            "training error 0.11765775453063368, test error 0.2229219137468547\n",
            "training error 0.11741011660281223, test error 0.22350752913071034\n",
            "training error 0.11770439737265466, test error 0.22294242147126547\n",
            "training error 0.11751615175489243, test error 0.22310571243602073\n",
            "training error 0.11737317661962107, test error 0.2225190379248552\n",
            "training error 0.11743600490474196, test error 0.22295519803624325\n",
            "training error 0.11749921681581987, test error 0.22275495692806127\n",
            "training error 0.118259179344778, test error 0.22298504427900476\n",
            "training error 0.11722640929104355, test error 0.2226444399937556\n",
            "training error 0.11735804412884099, test error 0.22250400218613806\n",
            "training error 0.11717175981186083, test error 0.22256964633837523\n",
            "training error 0.1171422288689998, test error 0.22296689327037383\n",
            "training error 0.11743189056828696, test error 0.22378287542393252\n",
            "training error 0.11715556718606293, test error 0.22357730244768906\n",
            "training error 0.11716668646194565, test error 0.22340378917663783\n",
            "training error 0.1170892695340642, test error 0.22330560427641744\n",
            "training error 0.11700315940451239, test error 0.22273804041354647\n",
            "training error 0.11720472354853544, test error 0.22280794056640482\n",
            "training error 0.11707439044971364, test error 0.22348537910616686\n",
            "training error 0.11695998876414618, test error 0.22279844969077375\n",
            "training error 0.11731388745027525, test error 0.22273990613585443\n",
            "training error 0.11687387378586053, test error 0.22234934071398083\n",
            "training error 0.11723028357269764, test error 0.22340995165438318\n",
            "training error 0.11690273400805198, test error 0.2224410928696933\n",
            "training error 0.11691796135623707, test error 0.22256402712057569\n",
            "training error 0.11729273667718247, test error 0.22201780844668867\n",
            "training error 0.11701879668295087, test error 0.2210136714302565\n",
            "training error 0.11711831616878332, test error 0.22163549421482218\n",
            "training error 0.11684021393432541, test error 0.2208859613695218\n",
            "training error 0.11680362581660601, test error 0.22121250705385648\n",
            "training error 0.11706420039256382, test error 0.22113076930318923\n",
            "training error 0.11681760914106994, test error 0.2215856370496993\n",
            "training error 0.11699310695660158, test error 0.22114698018653275\n",
            "training error 0.11671701459544596, test error 0.22113496467939875\n",
            "training error 0.11695824566248852, test error 0.22136349980220668\n",
            "Loss: 0.21619229656972827\n",
            "training error 0.11680997860048686, test error 0.2213373889036092\n",
            "Loss: 0.20437131055703883\n",
            "training error 0.11671061926399337, test error 0.22143544389904954\n",
            "Loss: 0.2487629934111224\n",
            "training error 0.11656110112040813, test error 0.2217316411512726\n",
            "Loss: 0.38285809406242155\n",
            "training error 0.11678465952793046, test error 0.22122198231614085\n",
            "Loss: 0.15212417508820852\n",
            "training error 0.11662260227425757, test error 0.2218010739734581\n",
            "Loss: 0.4142918808703433\n",
            "training error 0.11673329207199434, test error 0.22113499728679775\n",
            "Loss: 0.11274411272310658\n",
            "training error 0.11657169072885568, test error 0.22104867372000106\n",
            "Loss: 0.07366350920194886\n",
            "training error 0.11660646603090137, test error 0.22202690165096345\n",
            "Loss: 0.5165291059548105\n",
            "training error 0.11643622304504403, test error 0.22161111676869308\n",
            "Loss: 0.32829401863079255\n",
            "training error 0.11639464217312853, test error 0.2210370469468294\n",
            "Loss: 0.0683998097347871\n",
            "training error 0.11703940292478365, test error 0.22023283815242434\n",
            "Loss: 0.0\n",
            "training error 0.1164938232108827, test error 0.2211257627770875\n",
            "Loss: 0.4054457237867348\n",
            "training error 0.11637255156079222, test error 0.22150829972876537\n",
            "Loss: 0.5791423236612303\n",
            "training error 0.11639456456981662, test error 0.2214493214795352\n",
            "Loss: 0.5523623712595072\n",
            "training error 0.11638676587010795, test error 0.22100317033505643\n",
            "Loss: 0.34978079976382137\n",
            "training error 0.11640151199841897, test error 0.22113857422913125\n",
            "Loss: 0.41126295438287386\n",
            "training error 0.11645861830557469, test error 0.22050580085302543\n",
            "Loss: 0.12394277932892273\n",
            "training error 0.11623836621721684, test error 0.2210263490029465\n",
            "Loss: 0.36030541910963\n",
            "training error 0.11645494005700817, test error 0.22118055033146355\n",
            "Loss: 0.430322828779639\n",
            "training error 0.11635440522983882, test error 0.22166050352398856\n",
            "Loss: 0.6482527235907032\n",
            "training error 0.11678412190969119, test error 0.22132019219032853\n",
            "Loss: 0.4937292944259486\n",
            "training error 0.11647783247868489, test error 0.2222478917552325\n",
            "Loss: 0.914965097717868\n",
            "training error 0.11643479027369875, test error 0.2223094300707289\n",
            "Loss: 0.9429074863337661\n",
            "training error 0.11623927745323656, test error 0.22203304642607183\n",
            "Loss: 0.8174113764095159\n",
            "training error 0.11627603691359813, test error 0.2222182420939908\n",
            "Loss: 0.9015022274708961\n",
            "training error 0.11623216004728829, test error 0.22251985117276407\n",
            "Loss: 1.0384523214276076\n",
            "training error 0.11638384515203498, test error 0.22231423442227358\n",
            "Loss: 0.9450889737018686\n",
            "training error 0.1160575160913539, test error 0.2213104186789367\n",
            "Loss: 0.48929148602561146\n",
            "training error 0.11634541742315757, test error 0.22053903940031006\n",
            "Loss: 0.13903523673148843\n",
            "training error 0.11616873798573896, test error 0.2210938564491048\n",
            "Loss: 0.3909581803983819\n",
            "training error 0.11608027436301877, test error 0.22116174700165703\n",
            "Loss: 0.42178489685076315\n",
            "training error 0.11603818845159676, test error 0.22137013775902004\n",
            "Loss: 0.5164078237090974\n",
            "training error 0.11615395605414541, test error 0.22073906412811028\n",
            "Loss: 0.22985944327502672\n",
            "training error 0.11611468297903256, test error 0.2203677519007362\n",
            "Loss: 0.06125959663585423\n",
            "training error 0.11642056847315707, test error 0.22052889159782005\n",
            "Loss: 0.13442747588385817\n",
            "training error 0.11599026911075927, test error 0.22036573257164918\n",
            "Loss: 0.060342690190862136\n",
            "training error 0.11616938676887914, test error 0.22065210503594007\n",
            "Loss: 0.19037437242921396\n",
            "training error 0.11605779667926981, test error 0.22012254625315691\n",
            "Loss: 0.0\n",
            "training error 0.11593228436620234, test error 0.22042932627290227\n",
            "Loss: 0.1393678316770508\n",
            "training error 0.11591665106007386, test error 0.2206775173747313\n",
            "Loss: 0.25211916317564587\n",
            "training error 0.11589346168857893, test error 0.22076683256381183\n",
            "Loss: 0.2926943748478905\n",
            "training error 0.11584482969972781, test error 0.22070065502794822\n",
            "Loss: 0.26263042320364693\n",
            "training error 0.11605004781770052, test error 0.22021485492703766\n",
            "Loss: 0.04193512906878194\n",
            "training error 0.11597897123573939, test error 0.21990372815677356\n",
            "Loss: 0.0\n",
            "training error 0.11581519815659709, test error 0.21993006992557007\n",
            "Loss: 0.011978773173737522\n",
            "training error 0.11624505813319698, test error 0.2198806863671508\n",
            "Loss: 0.0\n",
            "training error 0.11578002420021515, test error 0.22033756904406138\n",
            "Loss: 0.2077866339509571\n",
            "training error 0.11571381295647849, test error 0.22017012069193773\n",
            "Loss: 0.13163244556351206\n",
            "training error 0.11566387318527183, test error 0.22013730125768904\n",
            "Loss: 0.11670642600676295\n",
            "training error 0.11582295033184782, test error 0.22030306535951738\n",
            "Loss: 0.19209463065861243\n",
            "training error 0.11571874133658457, test error 0.22017106215771176\n",
            "Loss: 0.1320606167638072\n",
            "training error 0.11634951804398216, test error 0.22015835482834492\n",
            "Loss: 0.12628142370378903\n",
            "training error 0.11568405262357583, test error 0.22050735402248048\n",
            "Loss: 0.28500350152778076\n",
            "training error 0.11571714631602015, test error 0.2208163596696113\n",
            "Loss: 0.4255368299597384\n",
            "training error 0.1158187752383983, test error 0.22013511415148415\n",
            "Loss: 0.11571174737399215\n",
            "training error 0.11563853996162342, test error 0.22053278987430788\n",
            "Loss: 0.2965715260994761\n",
            "training error 0.1155677812387585, test error 0.22048283507761338\n",
            "Loss: 0.27385247900177934\n",
            "training error 0.1159747190483063, test error 0.22005971038092018\n",
            "Loss: 0.08141870790345784\n",
            "training error 0.11552331136092625, test error 0.22008525781727506\n",
            "Loss: 0.09303748023719027\n",
            "training error 0.11561312995375354, test error 0.22055888433762194\n",
            "Loss: 0.30843908197497605\n",
            "training error 0.11591711982322955, test error 0.22038903013700817\n",
            "Loss: 0.23119073269062262\n",
            "training error 0.1159689129159567, test error 0.22001927356905038\n",
            "Loss: 0.0630283651507968\n",
            "training error 0.11574131632512709, test error 0.2205412353201629\n",
            "Loss: 0.30041244818979074\n",
            "training error 0.11540063763069165, test error 0.22085336579423734\n",
            "Loss: 0.4423669232423544\n",
            "training error 0.11552344826325064, test error 0.22045582885226941\n",
            "Loss: 0.26157026095428026\n",
            "training error 0.11552726979512293, test error 0.22005721382969606\n",
            "Loss: 0.08028329611928786\n",
            "training error 0.11557208322216918, test error 0.22012027986880578\n",
            "Loss: 0.10896523274213088\n",
            "training error 0.11539817164239732, test error 0.22009731058827048\n",
            "Loss: 0.09851898531823\n",
            "training error 0.1157092485536506, test error 0.2200853338516905\n",
            "Loss: 0.09307206008897229\n",
            "training error 0.11536866766295518, test error 0.2200799480175629\n",
            "Loss: 0.09062262525385556\n",
            "training error 0.1154292441702668, test error 0.21986136761302516\n",
            "Loss: 0.0\n",
            "training error 0.11529555654720702, test error 0.22003504219133843\n",
            "Loss: 0.0789927672145474\n",
            "training error 0.11558686087179548, test error 0.21953595540175883\n",
            "Loss: 0.0\n",
            "training error 0.1153696323080146, test error 0.21941394687408342\n",
            "Loss: 0.0\n",
            "training error 0.11535090814476553, test error 0.21955378464660552\n",
            "Loss: 0.0637323991999228\n",
            "training error 0.11531466157168482, test error 0.2196710359067532\n",
            "Loss: 0.11717077985808899\n",
            "training error 0.11559557961828312, test error 0.2198651957537033\n",
            "Loss: 0.20566098283572032\n",
            "training error 0.11529587749056837, test error 0.22046079712643454\n",
            "Loss: 0.4771119918607125\n",
            "training error 0.1152914651630563, test error 0.22070245404027325\n",
            "Loss: 0.5872494363037273\n",
            "training error 0.1154008848990158, test error 0.2205435213933155\n",
            "Loss: 0.5148143658708859\n",
            "training error 0.11533649555725187, test error 0.22054594743043884\n",
            "Loss: 0.5159200554398113\n",
            "training error 0.11583928177819115, test error 0.22133458328035893\n",
            "Loss: 0.875348369435125\n",
            "training error 0.11551156701383307, test error 0.2205016098288359\n",
            "Loss: 0.49571277042688155\n",
            "training error 0.11528604691863654, test error 0.2211829644302662\n",
            "Loss: 0.8062466317138695\n",
            "training error 0.11530428551023195, test error 0.22048852841374156\n",
            "Loss: 0.48975079067095084\n",
            "training error 0.11518189267529182, test error 0.22040298554312174\n",
            "Loss: 0.4507638111108436\n",
            "training error 0.11520704396872603, test error 0.22009844749820948\n",
            "Loss: 0.31196769115087175\n",
            "training error 0.11509907905465466, test error 0.21987957868761618\n",
            "Loss: 0.21221614221267338\n",
            "training error 0.11515462218778438, test error 0.219974560722769\n",
            "Loss: 0.25550511107996776\n",
            "training error 0.11518171473259883, test error 0.22032630241774184\n",
            "Loss: 0.4158147449861094\n",
            "training error 0.11530090704478883, test error 0.22033741413749555\n",
            "Loss: 0.4208790172951504\n",
            "training error 0.1151547850640092, test error 0.2206968767127258\n",
            "Loss: 0.5847075160535065\n",
            "training error 0.11514783935072266, test error 0.2205468014710021\n",
            "Loss: 0.5163092925760226\n",
            "training error 0.11518590029670676, test error 0.22032370068739168\n",
            "Loss: 0.4146289815525561\n",
            "training error 0.11506130276165506, test error 0.22043371080391094\n",
            "Loss: 0.4647671419049537\n",
            "training error 0.11507546710751916, test error 0.22057946088276983\n",
            "Loss: 0.5311941311348267\n",
            "training error 0.11537296969106507, test error 0.2200153559623106\n",
            "Loss: 0.27409793078116973\n",
            "training error 0.11509579898322869, test error 0.21992899088492993\n",
            "Loss: 0.2347362226440719\n",
            "training error 0.1150973570535039, test error 0.21975502445042192\n",
            "Loss: 0.15544936007838572\n",
            "training error 0.11501442354926714, test error 0.21999726226714716\n",
            "Loss: 0.26585155655511894\n",
            "training error 0.11529830570776027, test error 0.22036819030926424\n",
            "Loss: 0.43490555125396124\n",
            "training error 0.11512847881198195, test error 0.21994040112912616\n",
            "Loss: 0.2399365503163997\n",
            "training error 0.11506067750025727, test error 0.220205991209886\n",
            "Loss: 0.36098176396102133\n",
            "training error 0.11492766300841158, test error 0.21998027353868888\n",
            "Loss: 0.2581087814488292\n",
            "training error 0.11493283409035261, test error 0.2200922134344993\n",
            "Loss: 0.30912645712768416\n",
            "training error 0.11510143331373505, test error 0.22003618509143957\n",
            "Loss: 0.28359100513937197\n",
            "training error 0.1149317490730396, test error 0.21981494397860316\n",
            "Loss: 0.18275825681668412\n",
            "training error 0.1152880880870888, test error 0.22077365457457807\n",
            "Loss: 0.6196997592295084\n",
            "training error 0.11497701861371604, test error 0.2200434091311448\n",
            "Loss: 0.28688343016891604\n",
            "training error 0.11511964780637846, test error 0.2203476339078863\n",
            "Loss: 0.42553677517076505\n",
            "training error 0.11491868082515753, test error 0.21979921518612813\n",
            "Loss: 0.17558970955744435\n",
            "training error 0.11496240696823329, test error 0.21953240178652053\n",
            "Loss: 0.05398695667468978\n",
            "training error 0.1148897563267154, test error 0.21994450436442126\n",
            "Loss: 0.24180663895640997\n",
            "training error 0.11492605461721073, test error 0.21981172714664915\n",
            "Loss: 0.18129215495767959\n",
            "training error 0.1149522068290054, test error 0.220326384255016\n",
            "Loss: 0.41585204310472523\n",
            "training error 0.11487395671808913, test error 0.22072109769894163\n",
            "Loss: 0.595746461645108\n",
            "training error 0.11499089246668467, test error 0.22090870942080473\n",
            "Loss: 0.6812522941302079\n",
            "training error 0.11500499335170433, test error 0.22051899544335887\n",
            "Loss: 0.5036364301443497\n",
            "training error 0.11482983335612472, test error 0.2202946011627466\n",
            "Loss: 0.40136659551937015\n",
            "training error 0.11487974547742687, test error 0.22007306997455178\n",
            "Loss: 0.30040164258411384\n",
            "training error 0.11500078358543254, test error 0.2196911204661473\n",
            "Loss: 0.12632450945471163\n",
            "training error 0.11483603462881298, test error 0.21961827386452928\n",
            "Loss: 0.09312397564369412\n",
            "training error 0.11477151536673028, test error 0.21946043592890851\n",
            "Loss: 0.021187830348723402\n",
            "training error 0.11483837026453908, test error 0.21953754658944372\n",
            "Loss: 0.05633174970014476\n",
            "training error 0.11480001692825592, test error 0.21981622522984567\n",
            "Loss: 0.18334219929652118\n",
            "training error 0.11484545477624154, test error 0.2193727215170396\n",
            "Loss: 0.0\n",
            "training error 0.11474323866421708, test error 0.21939814172827632\n",
            "Loss: 0.011587681030222896\n",
            "training error 0.11472306759684787, test error 0.21965339096441353\n",
            "Loss: 0.1279418176667546\n",
            "training error 0.11478601056404923, test error 0.21993134876232592\n",
            "Loss: 0.25464754296853354\n",
            "training error 0.11501374938360644, test error 0.220317954573921\n",
            "Loss: 0.43087994274984\n",
            "training error 0.11470516721828734, test error 0.22003497420559165\n",
            "Loss: 0.3018847028802618\n",
            "training error 0.11463162638571686, test error 0.21972435861235004\n",
            "Loss: 0.16029207864987072\n",
            "training error 0.11464423211001375, test error 0.21964546153626716\n",
            "Loss: 0.12432722598392232\n",
            "training error 0.11460152206047487, test error 0.21967288285927436\n",
            "Loss: 0.13682710419009592\n",
            "training error 0.11473886828751981, test error 0.21995003624374565\n",
            "Loss: 0.2631661414936648\n",
            "training error 0.11461908742677501, test error 0.21993606323733714\n",
            "Loss: 0.2567966137274613\n",
            "training error 0.11470057947927348, test error 0.22003126379033222\n",
            "Loss: 0.3001933279300095\n",
            "training error 0.11489011987812583, test error 0.21915700165889831\n",
            "Loss: 0.0\n",
            "training error 0.11465346787728756, test error 0.21919552844342624\n",
            "Loss: 0.01757953623944264\n",
            "training error 0.11477924864426281, test error 0.2190833967531945\n",
            "Loss: 0.0\n",
            "training error 0.11491849104657519, test error 0.2187365095860568\n",
            "Loss: 0.0\n",
            "training error 0.11477118015675988, test error 0.21875861026485702\n",
            "Loss: 0.010103790556970083\n",
            "training error 0.11450389320829717, test error 0.21903094669121848\n",
            "Loss: 0.13460812084771234\n",
            "training error 0.11456134772344316, test error 0.2188616541600828\n",
            "Loss: 0.05721247644612237\n",
            "training error 0.11452512634751685, test error 0.21908952932092704\n",
            "Loss: 0.16139040324740783\n",
            "training error 0.11448440765568962, test error 0.21887350899770705\n",
            "Loss: 0.06263216502333524\n",
            "training error 0.11452261066103203, test error 0.218901179048138\n",
            "Loss: 0.07528211106266891\n",
            "training error 0.11444370614324655, test error 0.21889930661279794\n",
            "Loss: 0.07442608783014837\n",
            "training error 0.11519519092405708, test error 0.21901913190961653\n",
            "Loss: 0.12920674472429727\n",
            "training error 0.11476896486072746, test error 0.21893904291248198\n",
            "Loss: 0.092592373723277\n",
            "training error 0.11473255184941443, test error 0.21927331717636736\n",
            "Loss: 0.24541289029729185\n",
            "training error 0.11440914345742824, test error 0.21910738376004166\n",
            "Loss: 0.16955293594411724\n",
            "training error 0.11439692348741219, test error 0.21954114630211863\n",
            "Loss: 0.36785661323046615\n",
            "training error 0.11441825305945658, test error 0.21964067142353424\n",
            "Loss: 0.4133566175982706\n",
            "training error 0.11454254444752407, test error 0.2192659509359172\n",
            "Loss: 0.24204525840807456\n",
            "training error 0.1143673060132315, test error 0.2192619182912989\n",
            "Loss: 0.2402016500292481\n",
            "training error 0.11445874069807987, test error 0.21958422849184958\n",
            "Loss: 0.38755254319318144\n",
            "training error 0.1143364723674683, test error 0.21906026172231935\n",
            "Loss: 0.1480101044289306\n",
            "training error 0.11447097077263059, test error 0.21892187017970546\n",
            "Loss: 0.08474149742969672\n",
            "training error 0.1143188221010514, test error 0.21902797966908613\n",
            "Loss: 0.13325168422084754\n",
            "training error 0.11432234227993175, test error 0.21893424501137457\n",
            "Loss: 0.09039891223094898\n",
            "training error 0.11433144887949118, test error 0.21906808875097436\n",
            "Loss: 0.1515883953460806\n",
            "training error 0.11439394648429628, test error 0.21878707427595015\n",
            "Loss: 0.02311671242676283\n",
            "training error 0.11432990693292691, test error 0.21877764555208165\n",
            "Loss: 0.018806172825325262\n",
            "training error 0.11431796112019699, test error 0.21864199161081765\n",
            "Loss: 0.0\n",
            "training error 0.11427461190538954, test error 0.218678038396984\n",
            "Loss: 0.016486671156235033\n",
            "training error 0.11421353767702984, test error 0.2190447722468144\n",
            "Loss: 0.1842192494814432\n",
            "training error 0.1146200158080168, test error 0.21951479656531944\n",
            "Loss: 0.39919365354821323\n",
            "training error 0.11422570134460383, test error 0.21914299221381467\n",
            "Loss: 0.22914198654429008\n",
            "training error 0.11438246543057452, test error 0.21872336404975307\n",
            "Loss: 0.03721720532086081\n",
            "training error 0.11418963368295959, test error 0.21904315648962222\n",
            "Loss: 0.18348025274057544\n",
            "training error 0.11420455495355267, test error 0.21921330596551528\n",
            "Loss: 0.2613012946362847\n",
            "training error 0.1142041724118787, test error 0.21933040578249022\n",
            "Loss: 0.3148590838387255\n",
            "training error 0.11414379700542529, test error 0.21891050066559015\n",
            "Loss: 0.12280763306000697\n",
            "training error 0.11424156202628531, test error 0.21933470001580682\n",
            "Loss: 0.31682313168011067\n",
            "training error 0.11411259594867766, test error 0.2189971150873351\n",
            "Loss: 0.16242235716072972\n",
            "training error 0.11415494483608939, test error 0.2186781297760817\n",
            "Loss: 0.016528465093923472\n",
            "training error 0.11417379018754795, test error 0.21898290757039654\n",
            "Loss: 0.15592428383368606\n",
            "training error 0.11429816608768226, test error 0.21890630620390764\n",
            "Loss: 0.12088921763961924\n",
            "training error 0.11406614344214913, test error 0.21890937400240645\n",
            "Loss: 0.12229233260221406\n",
            "training error 0.11411325286077711, test error 0.2189989139654623\n",
            "Loss: 0.16324510768268574\n",
            "training error 0.11404820099480517, test error 0.21886504762495113\n",
            "Loss: 0.10201883567293457\n",
            "training error 0.1140660470647864, test error 0.21889021377186044\n",
            "Loss: 0.11352904316963564\n",
            "training error 0.11421991049484943, test error 0.21956101603996547\n",
            "Loss: 0.42033299384853784\n",
            "training error 0.11415527539441889, test error 0.21972747981387464\n",
            "Loss: 0.4964683110777468\n",
            "training error 0.11406189275894375, test error 0.21946601456720455\n",
            "Loss: 0.3768822952608497\n",
            "training error 0.11409867794864419, test error 0.21911489282190097\n",
            "Loss: 0.21629020463969084\n",
            "training error 0.11398247565654165, test error 0.21888316183583542\n",
            "Loss: 0.11030370846925042\n",
            "training error 0.11395523140904264, test error 0.21872878135695445\n",
            "Loss: 0.039694911987120385\n",
            "training error 0.11400072958496801, test error 0.21871930071307574\n",
            "Loss: 0.03535876237155122\n",
            "training error 0.11406505428862158, test error 0.21882321968944243\n",
            "Loss: 0.08288804784917225\n",
            "training error 0.114109758711292, test error 0.2186352865756122\n",
            "Loss: 0.0\n",
            "training error 0.1139979260311333, test error 0.21884488209050704\n",
            "Loss: 0.09586536472572238\n",
            "training error 0.11393238352460307, test error 0.21872457739151366\n",
            "Loss: 0.04084007540592349\n",
            "training error 0.11425319075584864, test error 0.21930549191119025\n",
            "Loss: 0.30654033302455197\n",
            "training error 0.11393635431213123, test error 0.2188981704060486\n",
            "Loss: 0.12023851892977167\n",
            "training error 0.11399176296174399, test error 0.21900779166384787\n",
            "Loss: 0.1703773869579983\n",
            "training error 0.1139809304401244, test error 0.21899824678649454\n",
            "Loss: 0.1660117250820825\n",
            "training error 0.11389096122427725, test error 0.21857279901014387\n",
            "Loss: 0.0\n",
            "training error 0.11397177297069166, test error 0.21876437686543526\n",
            "Loss: 0.08764944959254173\n",
            "training error 0.11398033201396973, test error 0.2185823807442363\n",
            "Loss: 0.004383772425398114\n",
            "training error 0.11402230252004303, test error 0.21910190699105794\n",
            "Loss: 0.24207402902385322\n",
            "training error 0.1139227174243799, test error 0.2189938346578091\n",
            "Loss: 0.19262948069109775\n",
            "training error 0.11388426106882854, test error 0.2190257872789986\n",
            "Loss: 0.20724823532762837\n",
            "training error 0.11387764174803955, test error 0.21879293347309114\n",
            "Loss: 0.10071448228883284\n",
            "training error 0.11402130318622068, test error 0.2187324076694206\n",
            "Loss: 0.07302311175019227\n",
            "training error 0.11419576178113072, test error 0.21874325546378798\n",
            "Loss: 0.07798612380682801\n",
            "training error 0.11396008043085548, test error 0.21904085730287703\n",
            "Loss: 0.21414297426434192\n",
            "training error 0.11385494817054294, test error 0.2193104745606292\n",
            "Loss: 0.3374965017724385\n",
            "training error 0.11392809542413515, test error 0.21899727173497355\n",
            "Loss: 0.1942019897956282\n",
            "training error 0.11377891418792375, test error 0.2187998087204472\n",
            "Loss: 0.10386000057251987\n",
            "training error 0.11389683206507814, test error 0.2183479450634946\n",
            "Loss: 0.0\n",
            "training error 0.11377119315397329, test error 0.21841070552486438\n",
            "Loss: 0.028743325865310254\n",
            "training error 0.11402054325020816, test error 0.21837431906102336\n",
            "Loss: 0.012078885157862373\n",
            "training error 0.11377231106261712, test error 0.21857622238674176\n",
            "Loss: 0.10454750246484679\n",
            "training error 0.1138369652528533, test error 0.21857674801757296\n",
            "Loss: 0.1047882332997574\n",
            "training error 0.11370978886795331, test error 0.21851640641622\n",
            "Loss: 0.0771527081129264\n",
            "training error 0.11369135665909454, test error 0.21852629428504386\n",
            "Loss: 0.0816811999295064\n",
            "training error 0.1137329065080874, test error 0.21797971455616033\n",
            "Loss: 0.0\n",
            "training error 0.11363698670993483, test error 0.2179682094207579\n",
            "Loss: 0.0\n",
            "training error 0.11371916768428314, test error 0.21824401012017647\n",
            "Loss: 0.12653253433219103\n",
            "training error 0.11373432495380228, test error 0.2185588038625619\n",
            "Loss: 0.27095439439241975\n",
            "training error 0.11367767199275257, test error 0.21866414974685486\n",
            "Loss: 0.31928524253439505\n",
            "training error 0.11364468727599625, test error 0.21840141731901888\n",
            "Loss: 0.19874820250724845\n",
            "training error 0.11359210489862491, test error 0.218477762945853\n",
            "Loss: 0.23377424003676595\n",
            "training error 0.11369709534056908, test error 0.21838533665315513\n",
            "Loss: 0.19137067442345224\n",
            "training error 0.11360518858329854, test error 0.21850934506109917\n",
            "Loss: 0.24826356181908427\n",
            "training error 0.11382038999008785, test error 0.21867941879572847\n",
            "Loss: 0.32629041494656175\n",
            "training error 0.11360188340427602, test error 0.2186266288867997\n",
            "Loss: 0.30207132856279184\n",
            "training error 0.11359597452163725, test error 0.21851133705373774\n",
            "Loss: 0.24917745318144835\n",
            "training error 0.11356315494507056, test error 0.21874485182265474\n",
            "Loss: 0.3563099426107774\n",
            "training error 0.11359866576512788, test error 0.21868298405759012\n",
            "Loss: 0.3279260946959628\n",
            "training error 0.11353224589635591, test error 0.2184861785741819\n",
            "Loss: 0.2376351830390755\n",
            "training error 0.11352241706997249, test error 0.21835470214569158\n",
            "Loss: 0.1773160985084843\n",
            "training error 0.11347281412686828, test error 0.21842129066097957\n",
            "Loss: 0.2078657440118148\n",
            "training error 0.11369769773434704, test error 0.21804938468293655\n",
            "Loss: 0.037241789706121686\n",
            "training error 0.11349284608902983, test error 0.21787464805853865\n",
            "Loss: 0.0\n",
            "training error 0.11358918559461045, test error 0.21822726571723933\n",
            "Loss: 0.161844281490664\n",
            "training error 0.1134605211719078, test error 0.21792277336460744\n",
            "Loss: 0.022088529573149884\n",
            "training error 0.11362714699936738, test error 0.2179768415271945\n",
            "Loss: 0.04690470854065154\n",
            "training error 0.11354470888823846, test error 0.2183117013305485\n",
            "Loss: 0.20059849822107179\n",
            "training error 0.11340479071669932, test error 0.21838038270967072\n",
            "Loss: 0.23212184420657866\n",
            "training error 0.11335392473266015, test error 0.21814724520942197\n",
            "Loss: 0.125116507731593\n",
            "training error 0.1133766674814927, test error 0.21820613794069443\n",
            "Loss: 0.15214706488784202\n",
            "training error 0.11348714137514557, test error 0.21784908732378275\n",
            "Loss: 0.0\n",
            "training error 0.11340413349394833, test error 0.21754696029591528\n",
            "Loss: 0.0\n",
            "training error 0.11375589066432067, test error 0.21815553752916575\n",
            "Loss: 0.2797452248574972\n",
            "training error 0.11327639615686663, test error 0.21800588961827333\n",
            "Loss: 0.21095643981134948\n",
            "training error 0.11335579524603717, test error 0.21794384683065834\n",
            "Loss: 0.18243717779518054\n",
            "training error 0.11338007212300645, test error 0.21779094130281576\n",
            "Loss: 0.11215096113896816\n",
            "training error 0.11332455419777905, test error 0.2176121740742825\n",
            "Loss: 0.02997687408663463\n",
            "training error 0.11338222501041688, test error 0.2174584887218228\n",
            "Loss: 0.0\n",
            "training error 0.11321692899579991, test error 0.21747363384792132\n",
            "Loss: 0.006964605607051588\n",
            "training error 0.11322801958047667, test error 0.217565879998682\n",
            "Loss: 0.04938472509876668\n",
            "training error 0.11332563395597561, test error 0.2178447786938625\n",
            "Loss: 0.17763848829734918\n",
            "training error 0.11322883369816553, test error 0.21805260982262578\n",
            "Loss: 0.2732112709396217\n",
            "training error 0.11317516246971727, test error 0.21791012323833292\n",
            "Loss: 0.20768769210377513\n",
            "training error 0.11324769365971389, test error 0.2175898991328484\n",
            "Loss: 0.060430113258869156\n",
            "training error 0.11318959686413661, test error 0.21774218184227426\n",
            "Loss: 0.13045851744806214\n",
            "training error 0.11311164148266424, test error 0.217541305060525\n",
            "Loss: 0.038083746092865134\n",
            "training error 0.11313302951608575, test error 0.217521283270262\n",
            "Loss: 0.028876568032942806\n",
            "training error 0.11314412398571613, test error 0.21749665911709776\n",
            "Loss: 0.017552957118072143\n",
            "training error 0.11307914994590909, test error 0.2176138818313779\n",
            "Loss: 0.07145874620413384\n",
            "training error 0.11312813701777462, test error 0.21729105381754152\n",
            "Loss: 0.0\n",
            "training error 0.11312904750301907, test error 0.2171886414704798\n",
            "Loss: 0.0\n",
            "training error 0.11302895510980329, test error 0.2173737981371507\n",
            "Loss: 0.08525154235381471\n",
            "training error 0.1130330196269473, test error 0.21739735950838757\n",
            "Loss: 0.09609988648329182\n",
            "training error 0.11317361869922214, test error 0.21777013584271654\n",
            "Loss: 0.267737008850788\n",
            "training error 0.11300823313175139, test error 0.21745727243504273\n",
            "Loss: 0.123685549457897\n",
            "training error 0.1129587404691726, test error 0.21731271503165867\n",
            "Loss: 0.057127094832765124\n",
            "training error 0.11299753710746396, test error 0.21753123797549262\n",
            "Loss: 0.1577414466489735\n",
            "training error 0.11294804195440557, test error 0.21752572030556264\n",
            "Loss: 0.1552009501052387\n",
            "training error 0.1128919460791952, test error 0.2175142906220577\n",
            "Loss: 0.1499383896750306\n",
            "training error 0.11291990453079581, test error 0.2176333845777781\n",
            "Loss: 0.20477272857692963\n",
            "training error 0.1130401591909755, test error 0.21777264701415477\n",
            "Loss: 0.26889322559455753\n",
            "training error 0.11290903410070607, test error 0.2173933121921513\n",
            "Loss: 0.09423638376564458\n",
            "training error 0.11295581362986086, test error 0.21726440784634027\n",
            "Loss: 0.03488505446116452\n",
            "training error 0.11290458561661551, test error 0.21734871845653547\n",
            "Loss: 0.07370412419906991\n",
            "training error 0.11304511881680424, test error 0.21725204559850034\n",
            "Loss: 0.02919311414779635\n",
            "training error 0.11280048788041505, test error 0.21751799520190485\n",
            "Loss: 0.15164408653931538\n",
            "training error 0.1127861519674542, test error 0.217305656328542\n",
            "Loss: 0.05387706155808303\n",
            "training error 0.11277638188728824, test error 0.2172303511430627\n",
            "Loss: 0.019204352631185806\n",
            "training error 0.1130244776102772, test error 0.21753534710335706\n",
            "Loss: 0.15963340924731728\n",
            "training error 0.1127783903000365, test error 0.21723381282542512\n",
            "Loss: 0.020798212392447724\n",
            "training error 0.1128468918540204, test error 0.21711507922749762\n",
            "Loss: 0.0\n",
            "training error 0.11270951623127261, test error 0.21729437666338117\n",
            "Loss: 0.08258175181636851\n",
            "training error 0.11265540238089897, test error 0.2172647077273876\n",
            "Loss: 0.0689166779306083\n",
            "training error 0.11285224506044063, test error 0.21720323078881415\n",
            "Loss: 0.04060130767065129\n",
            "training error 0.11286534528176757, test error 0.21720534256810736\n",
            "Loss: 0.041573962034746614\n",
            "training error 0.11267750655376492, test error 0.21701828030401366\n",
            "Loss: 0.0\n",
            "training error 0.11262170943775081, test error 0.2168215488844164\n",
            "Loss: 0.0\n",
            "training error 0.11263819349239726, test error 0.2166907339402372\n",
            "Loss: 0.0\n",
            "training error 0.11269676679496696, test error 0.2167917040690903\n",
            "Loss: 0.04659642201449987\n",
            "training error 0.11255475965325125, test error 0.21694744268811555\n",
            "Loss: 0.11846780118855982\n",
            "training error 0.1125664090657587, test error 0.2168001265990205\n",
            "Loss: 0.05048331176611409\n",
            "training error 0.11265331507206962, test error 0.2169000789484405\n",
            "Loss: 0.09661004160013142\n",
            "training error 0.11269843041241207, test error 0.21643387772702158\n",
            "Loss: 0.0\n",
            "training error 0.1124410503196534, test error 0.21673209068781216\n",
            "Loss: 0.1377847885563943\n",
            "training error 0.11252311287190406, test error 0.21697517572163408\n",
            "Loss: 0.2500985521754595\n",
            "training error 0.11247113207733678, test error 0.216988162291426\n",
            "Loss: 0.2560988003474707\n",
            "training error 0.11248927776618443, test error 0.2169724897186317\n",
            "Loss: 0.24885752510956927\n",
            "training error 0.1123952642771793, test error 0.2167271971890656\n",
            "Loss: 0.1355238214665988\n",
            "training error 0.11235229076632555, test error 0.21676303448867432\n",
            "Loss: 0.1520819037710286\n",
            "training error 0.11241433041239154, test error 0.21663047894025753\n",
            "Loss: 0.09083661730808767\n",
            "training error 0.11243950072822358, test error 0.21672776607929484\n",
            "Loss: 0.1357866685935072\n",
            "training error 0.11231464312120075, test error 0.21644585815026102\n",
            "Loss: 0.005535373373732888\n",
            "training error 0.11250918737004713, test error 0.216445518394765\n",
            "Loss: 0.005378394485044957\n",
            "training error 0.1122957688664196, test error 0.2167252961496023\n",
            "Loss: 0.13464547493264867\n",
            "training error 0.11230579054289143, test error 0.21637439310975384\n",
            "Loss: 0.0\n",
            "training error 0.11230851871038089, test error 0.21634885507285567\n",
            "Loss: 0.0\n",
            "training error 0.11215047461581626, test error 0.21647327523032456\n",
            "Loss: 0.05750904363555076\n",
            "training error 0.11228050887280439, test error 0.21635458990587053\n",
            "Loss: 0.0026507341640114035\n",
            "training error 0.11210001045121937, test error 0.21656831449182012\n",
            "Loss: 0.10143775380302422\n",
            "training error 0.11212644661375279, test error 0.21656227601169636\n",
            "Loss: 0.09864666894994212\n",
            "training error 0.11205300340168363, test error 0.21663647882766165\n",
            "Loss: 0.13294443121001365\n",
            "training error 0.11204333938110454, test error 0.21641776868325271\n",
            "Loss: 0.031853004432980114\n",
            "training error 0.11213369009102621, test error 0.2160459344409244\n",
            "Loss: 0.0\n",
            "training error 0.11201352018467846, test error 0.21620426377238577\n",
            "Loss: 0.07328503166286193\n",
            "training error 0.11190674343660972, test error 0.21616345694841935\n",
            "Loss: 0.054397000248607164\n",
            "training error 0.11187703130105937, test error 0.2161299199608752\n",
            "Loss: 0.03887391825636577\n",
            "training error 0.11190933704901139, test error 0.2162515729734883\n",
            "Loss: 0.09518278281701598\n",
            "training error 0.11190539369446859, test error 0.21587265650908807\n",
            "Loss: 0.0\n",
            "training error 0.1118325669846487, test error 0.21569947411654888\n",
            "Loss: 0.0\n",
            "training error 0.11181128309850583, test error 0.21557716151070813\n",
            "Loss: 0.0\n",
            "training error 0.11180959932029698, test error 0.215368831544019\n",
            "Loss: 0.0\n",
            "training error 0.1117482445180869, test error 0.21541255507469004\n",
            "Loss: 0.020301698420133185\n",
            "training error 0.11177531622582434, test error 0.21565666500899539\n",
            "Loss: 0.13364675979938845\n",
            "training error 0.11162518817412255, test error 0.21561611982728457\n",
            "Loss: 0.1148208315440602\n",
            "training error 0.11169010734563502, test error 0.21551133431593678\n",
            "Loss: 0.06616685009439571\n",
            "training error 0.11161664731188499, test error 0.21539146005452708\n",
            "Loss: 0.010506864129711246\n",
            "training error 0.11156408941881495, test error 0.21544803700777204\n",
            "Loss: 0.03677666038544025\n",
            "training error 0.11158191093212849, test error 0.21539617558399488\n",
            "Loss: 0.012696377549081816\n",
            "training error 0.11162661016251058, test error 0.21540087954793707\n",
            "Loss: 0.0148805208666003\n",
            "training error 0.11162474894334609, test error 0.21541616278645834\n",
            "Loss: 0.021976830212611098\n",
            "training error 0.11155495682178677, test error 0.21523177627007245\n",
            "Loss: 0.0\n",
            "training error 0.11150890066621269, test error 0.2152083955028922\n",
            "Loss: 0.0\n",
            "training error 0.11136657816763215, test error 0.21519778493039396\n",
            "Loss: 0.0\n",
            "training error 0.11147905363369848, test error 0.21547361932305695\n",
            "Loss: 0.12817715235879934\n",
            "training error 0.11133059811003124, test error 0.2152850074868902\n",
            "Loss: 0.04053134493202659\n",
            "training error 0.11129962011071587, test error 0.21533499360564382\n",
            "Loss: 0.06375933436966186\n",
            "training error 0.11137631929816338, test error 0.2149325124980838\n",
            "Loss: 0.0\n",
            "training error 0.11123157471385778, test error 0.2148541180953031\n",
            "Loss: 0.0\n",
            "training error 0.11116655703332928, test error 0.21482112500710993\n",
            "Loss: 0.0\n",
            "training error 0.11124875557718569, test error 0.2150202980603421\n",
            "Loss: 0.09271576676901372\n",
            "training error 0.11111533235098217, test error 0.21501609579989633\n",
            "Loss: 0.09075959954123469\n",
            "training error 0.11110360181533001, test error 0.2150071385145341\n",
            "Loss: 0.08658995125270241\n",
            "training error 0.11113497075158729, test error 0.2151744690499062\n",
            "Loss: 0.16448291236934587\n",
            "training error 0.1109806426257762, test error 0.21512074300411937\n",
            "Loss: 0.13947324640419811\n",
            "training error 0.11095339696264417, test error 0.21494909765697284\n",
            "Loss: 0.05957172501478425\n",
            "training error 0.11088340990274055, test error 0.21508813648932065\n",
            "Loss: 0.12429479745155181\n",
            "training error 0.11095494278410906, test error 0.21523497848711376\n",
            "Loss: 0.19265027123851475\n",
            "training error 0.11088184163835124, test error 0.21514028666037605\n",
            "Loss: 0.14857088810775743\n",
            "training error 0.11082673418233661, test error 0.21471693018829455\n",
            "Loss: 0.0\n",
            "training error 0.11080826954305278, test error 0.21479023044713597\n",
            "Loss: 0.03413808998533607\n",
            "training error 0.11106833275371011, test error 0.21465284019454947\n",
            "Loss: 0.0\n",
            "training error 0.11070888639598077, test error 0.21437744231415737\n",
            "Loss: 0.0\n",
            "training error 0.11070522973447022, test error 0.21456374362828487\n",
            "Loss: 0.0869034130253743\n",
            "training error 0.11063635978748278, test error 0.21439658093908573\n",
            "Loss: 0.008927536741620834\n",
            "training error 0.11056838371937865, test error 0.21432168933433743\n",
            "Loss: 0.0\n",
            "training error 0.11051619296677165, test error 0.21420110958328412\n",
            "Loss: 0.0\n",
            "training error 0.11047844284625898, test error 0.21405651874217513\n",
            "Loss: 0.0\n",
            "training error 0.11049973401761994, test error 0.2141631181826401\n",
            "Loss: 0.04979967024194565\n",
            "training error 0.11042172490491883, test error 0.21405470517590566\n",
            "Loss: 0.0\n",
            "training error 0.11050605212604878, test error 0.21395125316230185\n",
            "Loss: 0.0\n",
            "training error 0.11034164388398932, test error 0.21389105123544444\n",
            "Loss: 0.0\n",
            "training error 0.11048959815687812, test error 0.2139078158128741\n",
            "Loss: 0.00783790501417414\n",
            "training error 0.11024107995095812, test error 0.21379906671604562\n",
            "Loss: 0.0\n",
            "training error 0.11022056698041462, test error 0.21385602883791574\n",
            "Loss: 0.026642829992229444\n",
            "training error 0.11026266111118285, test error 0.21397129354804068\n",
            "Loss: 0.08055546482987896\n",
            "training error 0.11017865982750756, test error 0.2140286743445567\n",
            "Loss: 0.10739412104918689\n",
            "training error 0.10998483482338998, test error 0.21386498794259703\n",
            "Loss: 0.030833262073581835\n",
            "training error 0.11001758173639191, test error 0.21371792115414026\n",
            "Loss: 0.0\n",
            "training error 0.11005725142395859, test error 0.21395868411006358\n",
            "Loss: 0.11265454699500577\n",
            "training error 0.1098387739918233, test error 0.21372402809310587\n",
            "Loss: 0.0028574763092592548\n",
            "training error 0.10985224740549795, test error 0.21353515122055575\n",
            "Loss: 0.0\n",
            "training error 0.10979849102407992, test error 0.21368236692303663\n",
            "Loss: 0.06894213980199737\n",
            "training error 0.11001425074820567, test error 0.2137839872585414\n",
            "Loss: 0.11653165137603949\n",
            "training error 0.10968691786466132, test error 0.2135383494579048\n",
            "Loss: 0.0014977568474350278\n",
            "training error 0.10957327335272335, test error 0.21322215469412983\n",
            "Loss: 0.0\n",
            "training error 0.10968368311305492, test error 0.21321659827569633\n",
            "Loss: 0.0\n",
            "training error 0.10939483495088187, test error 0.2131852939659978\n",
            "Loss: 0.0\n",
            "training error 0.10947576566598195, test error 0.21289294206233364\n",
            "Loss: 0.0\n",
            "training error 0.10926217137001366, test error 0.21288408265945583\n",
            "Loss: 0.0\n",
            "training error 0.10928303755538663, test error 0.21252493421812907\n",
            "Loss: 0.0\n",
            "training error 0.10927607427058843, test error 0.2124856732922655\n",
            "Loss: 0.0\n",
            "training error 0.10919590897573633, test error 0.21237924045950443\n",
            "Loss: 0.0\n",
            "training error 0.10915114062576592, test error 0.21245505772693657\n",
            "Loss: 0.03569900112088131\n",
            "training error 0.10905936157359966, test error 0.21231798051471637\n",
            "Loss: 0.0\n",
            "training error 0.10905394740350727, test error 0.21244018759820857\n",
            "Loss: 0.05755851821684921\n",
            "training error 0.10893737340970434, test error 0.21230094742140568\n",
            "Loss: 0.0\n",
            "training error 0.10890875439990569, test error 0.2120403679205589\n",
            "Loss: 0.0\n",
            "training error 0.10881131341449003, test error 0.21210342986928724\n",
            "Loss: 0.029740539193912063\n",
            "training error 0.10884349888122187, test error 0.21235350661691507\n",
            "Loss: 0.1476788120238881\n",
            "training error 0.1087479678159272, test error 0.212335031875732\n",
            "Loss: 0.13896597051912263\n",
            "training error 0.10877866675584077, test error 0.21198425854168176\n",
            "Loss: 0.0\n",
            "training error 0.10874695901218757, test error 0.2120869615826764\n",
            "Loss: 0.04844842805837857\n",
            "training error 0.1084883448321922, test error 0.21179873416800968\n",
            "Loss: 0.0\n",
            "training error 0.10846811552472606, test error 0.21174415656165388\n",
            "Loss: 0.0\n",
            "training error 0.10841836959336702, test error 0.21184312427626192\n",
            "Loss: 0.04673928962910523\n",
            "training error 0.10834856002501217, test error 0.21169441912554748\n",
            "Loss: 0.0\n",
            "training error 0.10826247492706072, test error 0.21185613294160283\n",
            "Loss: 0.07639021223295739\n",
            "training error 0.10825556619640521, test error 0.21174657415774065\n",
            "Loss: 0.024636942442124443\n",
            "training error 0.1080601855773278, test error 0.21146762972701807\n",
            "Loss: 0.0\n",
            "training error 0.10801247571254265, test error 0.21128719433877813\n",
            "Loss: 0.0\n",
            "training error 0.10799358113846153, test error 0.2111705207598063\n",
            "Loss: 0.0\n",
            "training error 0.10792251230751673, test error 0.2109589313462963\n",
            "Loss: 0.0\n",
            "training error 0.10778143539032797, test error 0.21103047333430033\n",
            "Loss: 0.033912756168907876\n",
            "training error 0.10778573094449678, test error 0.2108097888729198\n",
            "Loss: 0.0\n",
            "training error 0.10767257146114077, test error 0.2107901268422083\n",
            "Loss: 0.0\n",
            "training error 0.10766515640270194, test error 0.21054721116624375\n",
            "Loss: 0.0\n",
            "training error 0.1075946238411376, test error 0.21076126708193935\n",
            "Loss: 0.10166646924929523\n",
            "training error 0.10760468692402948, test error 0.2107485762558656\n",
            "Loss: 0.09563892511634808\n",
            "training error 0.10751564255330075, test error 0.2108942073029292\n",
            "Loss: 0.164806807349005\n",
            "training error 0.10764366267356817, test error 0.2106375018578907\n",
            "Loss: 0.04288382218260445\n",
            "training error 0.10722187206869949, test error 0.2106536971852871\n",
            "Loss: 0.05057583923981923\n",
            "training error 0.10728277921107526, test error 0.21032412765915218\n",
            "Loss: 0.0\n",
            "training error 0.1071183335374269, test error 0.21051591188463076\n",
            "Loss: 0.09118508067196274\n",
            "training error 0.10717664664990387, test error 0.21033873373544332\n",
            "Loss: 0.006944555745325154\n",
            "training error 0.10693716802177605, test error 0.2098881982380859\n",
            "Loss: 0.0\n",
            "training error 0.10698598413814416, test error 0.20990389798143022\n",
            "Loss: 0.007480050558394957\n",
            "training error 0.10681048295514817, test error 0.2100798541106226\n",
            "Loss: 0.09131331544391941\n",
            "training error 0.10680067695027229, test error 0.2099230067140616\n",
            "Loss: 0.016584294051735782\n",
            "training error 0.1066917152255529, test error 0.20992133482079434\n",
            "Loss: 0.01578773031860603\n",
            "training error 0.10655200554630632, test error 0.20966670485254424\n",
            "Loss: 0.0\n",
            "training error 0.10647417193938441, test error 0.20956330082029156\n",
            "Loss: 0.0\n",
            "training error 0.10664805069609536, test error 0.2097157215002626\n",
            "Loss: 0.0727325249098465\n",
            "training error 0.10644805001677575, test error 0.20911177073585013\n",
            "Loss: 0.0\n",
            "training error 0.10652426773634861, test error 0.20920365900580995\n",
            "Loss: 0.0439421796470274\n",
            "training error 0.10637664036784165, test error 0.2086105229408955\n",
            "Loss: 0.0\n",
            "training error 0.10618211639984625, test error 0.20859604598966314\n",
            "Loss: 0.0\n",
            "training error 0.10599687801945244, test error 0.20844734549324082\n",
            "Loss: 0.0\n",
            "training error 0.10597461829435532, test error 0.20855230965265426\n",
            "Loss: 0.05035523919245666\n",
            "training error 0.10591733053317444, test error 0.20824610240225444\n",
            "Loss: 0.0\n",
            "training error 0.10581078271134674, test error 0.20794285749410213\n",
            "Loss: 0.0\n",
            "training error 0.10573990445831793, test error 0.20785999717880724\n",
            "Loss: 0.0\n",
            "training error 0.10567135665693579, test error 0.20764372075370296\n",
            "Loss: 0.0\n",
            "training error 0.10572367861916582, test error 0.20748815151103883\n",
            "Loss: 0.0\n",
            "training error 0.10547880702739768, test error 0.20745639164889382\n",
            "Loss: 0.0\n",
            "training error 0.10544061641675911, test error 0.20742472388369887\n",
            "Loss: 0.0\n",
            "training error 0.10560842369218001, test error 0.20730079514070401\n",
            "Loss: 0.0\n",
            "training error 0.10519649569447602, test error 0.20725396703700277\n",
            "Loss: 0.0\n",
            "training error 0.10523777997672765, test error 0.20744625364458827\n",
            "Loss: 0.09277825188802602\n",
            "training error 0.10499042712098375, test error 0.2073041025113442\n",
            "Loss: 0.024190356912434652\n",
            "training error 0.10497820134791883, test error 0.2073104082839154\n",
            "Loss: 0.02723289098853776\n",
            "training error 0.10498878830719459, test error 0.20744651005696196\n",
            "Loss: 0.09290197080995544\n",
            "training error 0.104654439511612, test error 0.20733581655416278\n",
            "Loss: 0.03949237659002236\n",
            "training error 0.10468707754512652, test error 0.20713392553741505\n",
            "Loss: 0.0\n",
            "training error 0.10452239319597707, test error 0.20687724554172454\n",
            "Loss: 0.0\n",
            "training error 0.10455898519340172, test error 0.20656120756641969\n",
            "Loss: 0.0\n",
            "training error 0.10442461178668119, test error 0.2065869346999138\n",
            "Loss: 0.012454968576736114\n",
            "training error 0.10434359027664439, test error 0.20666675801370224\n",
            "Loss: 0.05109887210967834\n",
            "training error 0.10410824096411928, test error 0.20645500956961452\n",
            "Loss: 0.0\n",
            "training error 0.10398172019335203, test error 0.2064668453064033\n",
            "Loss: 0.005732840686922813\n",
            "training error 0.10401073940508056, test error 0.20629230322095785\n",
            "Loss: 0.0\n",
            "training error 0.1037250231241145, test error 0.2060069374518378\n",
            "Loss: 0.0\n",
            "training error 0.10364041734343553, test error 0.20581337421018264\n",
            "Loss: 0.0\n",
            "training error 0.10353109368421254, test error 0.20575519094962094\n",
            "Loss: 0.0\n",
            "training error 0.10339331552501639, test error 0.205851296819409\n",
            "Loss: 0.046708843331977334\n",
            "training error 0.1033833988422088, test error 0.2055239067566013\n",
            "Loss: 0.0\n",
            "training error 0.10338101127059932, test error 0.20561037865265105\n",
            "Loss: 0.04207388688468594\n",
            "training error 0.10301366674579694, test error 0.20535804421865084\n",
            "Loss: 0.0\n",
            "training error 0.10300006203363596, test error 0.20568703264360605\n",
            "Loss: 0.16020235594225163\n",
            "training error 0.10302475847951102, test error 0.20510808929096927\n",
            "Loss: 0.0\n",
            "training error 0.10283164634501629, test error 0.20498119474396545\n",
            "Loss: 0.0\n",
            "training error 0.10269807247044742, test error 0.20481666688655908\n",
            "Loss: 0.0\n",
            "training error 0.10246078177839642, test error 0.20427649718972915\n",
            "Loss: 0.0\n",
            "training error 0.10248126049964555, test error 0.20390909871170765\n",
            "Loss: 0.0\n",
            "training error 0.10225603959902128, test error 0.20395224332122525\n",
            "Loss: 0.021158746613170187\n",
            "training error 0.10231102936768736, test error 0.20410063085750615\n",
            "Loss: 0.09393016153207423\n",
            "training error 0.10188820754139381, test error 0.20379504997848655\n",
            "Loss: 0.0\n",
            "training error 0.1018033669167514, test error 0.20370113880480623\n",
            "Loss: 0.0\n",
            "training error 0.10176200103452157, test error 0.203674792351406\n",
            "Loss: 0.0\n",
            "training error 0.10162255253238221, test error 0.2031692670867082\n",
            "Loss: 0.0\n",
            "training error 0.10148200811603947, test error 0.2031674641581491\n",
            "Loss: 0.0\n",
            "training error 0.1013092855335714, test error 0.20283265671989553\n",
            "Loss: 0.0\n",
            "training error 0.10127074140091659, test error 0.20274787024318805\n",
            "Loss: 0.0\n",
            "training error 0.10110288967445744, test error 0.20262582679219432\n",
            "Loss: 0.0\n",
            "training error 0.10094200112273032, test error 0.20251176551783062\n",
            "Loss: 0.0\n",
            "training error 0.1007088925460103, test error 0.20220013371441628\n",
            "Loss: 0.0\n",
            "training error 0.10063565548056319, test error 0.20184575950653008\n",
            "Loss: 0.0\n",
            "training error 0.10065816446854478, test error 0.20185269571278297\n",
            "Loss: 0.00343638938458124\n",
            "training error 0.10037116237474555, test error 0.2015996372843404\n",
            "Loss: 0.0\n",
            "training error 0.10050035555069073, test error 0.20128784199434294\n",
            "Loss: 0.0\n",
            "training error 0.10015189061054489, test error 0.20111285293536177\n",
            "Loss: 0.0\n",
            "training error 0.1000931884519742, test error 0.20134105515904768\n",
            "Loss: 0.11346973619794642\n",
            "training error 0.0999657742913277, test error 0.2008712750992814\n",
            "Loss: 0.0\n",
            "training error 0.0998465103644173, test error 0.20088086266233418\n",
            "Loss: 0.004772988595824756\n",
            "training error 0.09980296177838531, test error 0.20045925686755553\n",
            "Loss: 0.0\n",
            "training error 0.09947066576937774, test error 0.20044582885343942\n",
            "Loss: 0.0\n",
            "training error 0.09933150051874859, test error 0.2002541803956665\n",
            "Loss: 0.0\n",
            "training error 0.09923764696786815, test error 0.2001102145140652\n",
            "Loss: 0.0\n",
            "training error 0.0991931185431243, test error 0.19965492340749233\n",
            "Loss: 0.0\n",
            "training error 0.09892086710296825, test error 0.19971033625987125\n",
            "Loss: 0.027754313008254705\n",
            "training error 0.09875397414080825, test error 0.19960595392013358\n",
            "Loss: 0.0\n",
            "training error 0.0985812036509089, test error 0.19939702212528404\n",
            "Loss: 0.0\n",
            "training error 0.09859576353377734, test error 0.19932421401808362\n",
            "Loss: 0.0\n",
            "training error 0.09832714511300993, test error 0.19890420665094946\n",
            "Loss: 0.0\n",
            "training error 0.09824887486829008, test error 0.19835851673606691\n",
            "Loss: 0.0\n",
            "training error 0.0980494695662852, test error 0.1986071298851144\n",
            "Loss: 0.12533525312568017\n",
            "training error 0.09792486983076924, test error 0.19802562788045974\n",
            "Loss: 0.0\n",
            "training error 0.09774918470364163, test error 0.19821069349825018\n",
            "Loss: 0.09345538745224591\n",
            "training error 0.09770016477403325, test error 0.19795198644760542\n",
            "Loss: 0.0\n",
            "training error 0.09782524883625816, test error 0.197727698374585\n",
            "Loss: 0.0\n",
            "training error 0.09741815298301858, test error 0.1967591844562711\n",
            "Loss: 0.0\n",
            "training error 0.09712640925762188, test error 0.19655124989052739\n",
            "Loss: 0.0\n",
            "training error 0.09713242709982725, test error 0.19623566175674126\n",
            "Loss: 0.0\n",
            "training error 0.09679146453010677, test error 0.19645991120822676\n",
            "Loss: 0.1142755855271016\n",
            "training error 0.09678755922447466, test error 0.1957285618151302\n",
            "Loss: 0.0\n",
            "training error 0.09647791198342744, test error 0.19540972272765925\n",
            "Loss: 0.0\n",
            "training error 0.09648660531586609, test error 0.19538531688538452\n",
            "Loss: 0.0\n",
            "training error 0.09618953866155959, test error 0.19550540153447532\n",
            "Loss: 0.061460426507498056\n",
            "training error 0.09594460591636882, test error 0.19518076132105228\n",
            "Loss: 0.0\n",
            "training error 0.09588107866355766, test error 0.1955421503332024\n",
            "Loss: 0.18515606236195747\n",
            "training error 0.09559306538393626, test error 0.1953725782053284\n",
            "Loss: 0.0982765324706536\n",
            "training error 0.0954961126039021, test error 0.19477725861230882\n",
            "Loss: 0.0\n",
            "training error 0.09506985303236724, test error 0.19434605734711177\n",
            "Loss: 0.0\n",
            "training error 0.09498778015453672, test error 0.19376215951070758\n",
            "Loss: 0.0\n",
            "training error 0.09487410883899859, test error 0.19311152128149459\n",
            "Loss: 0.0\n",
            "training error 0.0946479775660429, test error 0.1933082926303343\n",
            "Loss: 0.10189518861118962\n",
            "training error 0.09437749547121269, test error 0.19306705236683191\n",
            "Loss: 0.0\n",
            "training error 0.0943915779970692, test error 0.1928311059936868\n",
            "Loss: 0.0\n",
            "training error 0.09397567560129767, test error 0.19294589598517276\n",
            "Loss: 0.05952877306512061\n",
            "training error 0.0936819824361153, test error 0.19241342805521977\n",
            "Loss: 0.0\n",
            "training error 0.0935488645097795, test error 0.191896700738029\n",
            "Loss: 0.0\n",
            "training error 0.0934687409421376, test error 0.19137529388334446\n",
            "Loss: 0.0\n",
            "training error 0.09310575429987186, test error 0.19132141737913638\n",
            "Loss: 0.0\n",
            "training error 0.09301158496451196, test error 0.19073736378528033\n",
            "Loss: 0.0\n",
            "training error 0.09273663798482099, test error 0.1905204297438711\n",
            "Loss: 0.0\n",
            "training error 0.09253093768307012, test error 0.19015492309374427\n",
            "Loss: 0.0\n",
            "training error 0.09232669922942212, test error 0.18992349130764896\n",
            "Loss: 0.0\n",
            "training error 0.09211419550306506, test error 0.18988186734852966\n",
            "Loss: 0.0\n",
            "training error 0.09192046755841614, test error 0.1893045150684142\n",
            "Loss: 0.0\n",
            "training error 0.09162522789761474, test error 0.18868060806592668\n",
            "Loss: 0.0\n",
            "training error 0.0916093205324719, test error 0.1883099997480535\n",
            "Loss: 0.0\n",
            "training error 0.0914090054353705, test error 0.18835855631729176\n",
            "Loss: 0.025785443844306144\n",
            "training error 0.09101328944011172, test error 0.18777339840323565\n",
            "Loss: 0.0\n",
            "training error 0.09065193620870415, test error 0.18761881875485564\n",
            "Loss: 0.0\n",
            "training error 0.09037271325070215, test error 0.18722781630289598\n",
            "Loss: 0.0\n",
            "training error 0.09026675362094293, test error 0.1865140367472572\n",
            "Loss: 0.0\n",
            "training error 0.09006357909668848, test error 0.18656181414453413\n",
            "Loss: 0.02561597942447591\n",
            "training error 0.08993192029405568, test error 0.18640721229580615\n",
            "Loss: 0.0\n",
            "training error 0.08937082724266825, test error 0.1861919345311553\n",
            "Loss: 0.0\n",
            "training error 0.08910848075873519, test error 0.18538102763643166\n",
            "Loss: 0.0\n",
            "training error 0.08893850935559063, test error 0.184357809941923\n",
            "Loss: 0.0\n",
            "training error 0.08871886196384318, test error 0.18412662145136516\n",
            "Loss: 0.0\n",
            "training error 0.08829152183120634, test error 0.18346949189509082\n",
            "Loss: 0.0\n",
            "training error 0.08802421307143755, test error 0.18286925341495097\n",
            "Loss: 0.0\n",
            "training error 0.08796615915874709, test error 0.18236108410344493\n",
            "Loss: 0.0\n",
            "training error 0.08770751476326825, test error 0.1817700089740253\n",
            "Loss: 0.0\n",
            "training error 0.087317436813818, test error 0.1814392123047809\n",
            "Loss: 0.0\n",
            "training error 0.08715301674587445, test error 0.18108236150034587\n",
            "Loss: 0.0\n",
            "training error 0.08697972264498408, test error 0.18098192760006565\n",
            "Loss: 0.0\n",
            "training error 0.08670252381552225, test error 0.18116161916532858\n",
            "Loss: 0.09928702144228474\n",
            "training error 0.08648360587152969, test error 0.1809756164370526\n",
            "Loss: 0.0\n",
            "training error 0.08583754680325797, test error 0.17941542634997115\n",
            "Loss: 0.0\n",
            "training error 0.08556693946395401, test error 0.17897389092707786\n",
            "Loss: 0.0\n",
            "training error 0.08529003974545668, test error 0.17903375445849445\n",
            "Loss: 0.03344819241875019\n",
            "training error 0.08518713863036866, test error 0.17949171969959796\n",
            "Loss: 0.2893320192335125\n",
            "training error 0.08447125314841762, test error 0.17825070807512244\n",
            "Loss: 0.0\n",
            "training error 0.08414340241334935, test error 0.17768825197712923\n",
            "Loss: 0.0\n",
            "training error 0.0838794177790651, test error 0.17770917770369\n",
            "Loss: 0.011776651707662289\n",
            "training error 0.08366099347023574, test error 0.17703339825165534\n",
            "Loss: 0.0\n",
            "training error 0.08335328574384997, test error 0.1765252913356467\n",
            "Loss: 0.0\n",
            "training error 0.08326731293953549, test error 0.17500059416357197\n",
            "Loss: 0.0\n",
            "training error 0.08264040963613319, test error 0.17423208703734497\n",
            "Loss: 0.0\n",
            "training error 0.08222654106386895, test error 0.17376729050131312\n",
            "Loss: 0.0\n",
            "training error 0.08203547833265158, test error 0.17349968691639212\n",
            "Loss: 0.0\n",
            "training error 0.08171346683335463, test error 0.17238387336038466\n",
            "Loss: 0.0\n",
            "training error 0.08169396013504436, test error 0.17158541106411668\n",
            "Loss: 0.0\n",
            "training error 0.08102036779816985, test error 0.17150547501217128\n",
            "Loss: 0.0\n",
            "training error 0.08060601953545049, test error 0.17169379004692822\n",
            "Loss: 0.10980117966705727\n",
            "training error 0.08039550577075477, test error 0.17052925293028945\n",
            "Loss: 0.0\n",
            "training error 0.07998514861969921, test error 0.17049336881940788\n",
            "Loss: 0.0\n",
            "training error 0.07953890740161536, test error 0.17024919721309886\n",
            "Loss: 0.0\n",
            "training error 0.07918097877041007, test error 0.1693522690089495\n",
            "Loss: 0.0\n",
            "training error 0.078918856491102, test error 0.16793976957880652\n",
            "Loss: 0.0\n",
            "training error 0.07871450077159378, test error 0.16743932799109476\n",
            "Loss: 0.0\n",
            "training error 0.07815019750455526, test error 0.1679189479391132\n",
            "Loss: 0.2864440234996213\n",
            "training error 0.07779133914467676, test error 0.16688958280808608\n",
            "Loss: 0.0\n",
            "training error 0.07772307855715073, test error 0.1665567737328552\n",
            "Loss: 0.0\n",
            "training error 0.07697322626047878, test error 0.1652724273505374\n",
            "Loss: 0.0\n",
            "training error 0.076888375953066, test error 0.165184771392703\n",
            "Loss: 0.0\n",
            "training error 0.07617646220855104, test error 0.16483707603954292\n",
            "Loss: 0.0\n",
            "training error 0.07587874124490285, test error 0.1648034208418955\n",
            "Loss: 0.0\n",
            "training error 0.07541772575553223, test error 0.16356553678779484\n",
            "Loss: 0.0\n",
            "training error 0.07559968279684098, test error 0.1618167679513598\n",
            "Loss: 0.0\n",
            "training error 0.0750324544797427, test error 0.16142496989412566\n",
            "Loss: 0.0\n",
            "training error 0.07427376702595097, test error 0.16074073271676229\n",
            "Loss: 0.0\n",
            "training error 0.0740584528393621, test error 0.16085033619372155\n",
            "Loss: 0.06818649828628232\n",
            "training error 0.07352204438721216, test error 0.1591163299895478\n",
            "Loss: 0.0\n",
            "training error 0.07328598794497315, test error 0.15840160287255795\n",
            "Loss: 0.0\n",
            "training error 0.07328879988113311, test error 0.15842337487740601\n",
            "Loss: 0.013744813469829253\n",
            "training error 0.07224069617221153, test error 0.15775258596514088\n",
            "Loss: 0.0\n",
            "training error 0.07173956902802958, test error 0.15695067751648795\n",
            "Loss: 0.0\n",
            "training error 0.07180913951569447, test error 0.1572719400639848\n",
            "Loss: 0.20469013105286482\n",
            "training error 0.07109632476345361, test error 0.155152208822424\n",
            "Loss: 0.0\n",
            "training error 0.07066526465831724, test error 0.15393487416513385\n",
            "Loss: 0.0\n",
            "training error 0.07056494413488898, test error 0.15363559464374488\n",
            "Loss: 0.0\n",
            "training error 0.06991196069420647, test error 0.15345741099196278\n",
            "Loss: 0.0\n",
            "training error 0.06958334618620474, test error 0.15138927777350614\n",
            "Loss: 0.0\n",
            "training error 0.06907500630527066, test error 0.15172971906542207\n",
            "Loss: 0.22487807387869818\n",
            "training error 0.06874100197739987, test error 0.1505485583887385\n",
            "Loss: 0.0\n",
            "training error 0.06816511928883415, test error 0.14911113506419657\n",
            "Loss: 0.0\n",
            "training error 0.06768507806304523, test error 0.1488924520581986\n",
            "Loss: 0.0\n",
            "training error 0.06726265460830648, test error 0.1478745052025945\n",
            "Loss: 0.0\n",
            "training error 0.06723244849854339, test error 0.14670890188701768\n",
            "Loss: 0.0\n",
            "training error 0.0664721745040018, test error 0.14598840474196714\n",
            "Loss: 0.0\n",
            "training error 0.06597571171027922, test error 0.14540904227462073\n",
            "Loss: 0.0\n",
            "training error 0.06554645603533742, test error 0.14491767321979354\n",
            "Loss: 0.0\n",
            "training error 0.0652761072853655, test error 0.144825018396704\n",
            "Loss: 0.0\n",
            "training error 0.06478722416966555, test error 0.14319909175389345\n",
            "Loss: 0.0\n",
            "training error 0.06469370005211637, test error 0.14262443451032772\n",
            "Loss: 0.0\n",
            "training error 0.06421804989982102, test error 0.1424045489929913\n",
            "Loss: 0.0\n",
            "training error 0.06361549069765697, test error 0.1414946188934463\n",
            "Loss: 0.0\n",
            "training error 0.06308874340441668, test error 0.1397492116966542\n",
            "Loss: 0.0\n",
            "training error 0.06274383083071318, test error 0.138882413000911\n",
            "Loss: 0.0\n",
            "training error 0.06237674741023935, test error 0.13789695821868297\n",
            "Loss: 0.0\n",
            "training error 0.06221697825343077, test error 0.1379516939269178\n",
            "Loss: 0.03969319478971389\n",
            "training error 0.06160217287565346, test error 0.13740704708291207\n",
            "Loss: 0.0\n",
            "training error 0.06119390374881782, test error 0.13567778298251484\n",
            "Loss: 0.0\n",
            "training error 0.06076842017858222, test error 0.13448372771460107\n",
            "Loss: 0.0\n",
            "training error 0.060275438060799436, test error 0.13454516470662084\n",
            "Loss: 0.045683587943190496\n",
            "training error 0.05997489184418133, test error 0.13415773079250043\n",
            "Loss: 0.0\n",
            "training error 0.059549968790986056, test error 0.13367938161106777\n",
            "Loss: 0.0\n",
            "training error 0.05903721905474117, test error 0.1322192423893819\n",
            "Loss: 0.0\n",
            "training error 0.058476749845055, test error 0.1305787479305161\n",
            "Loss: 0.0\n",
            "training error 0.05834582125088196, test error 0.12951920586400448\n",
            "Loss: 0.0\n",
            "training error 0.05778170973829174, test error 0.129225063044984\n",
            "Loss: 0.0\n",
            "training error 0.057572810599586195, test error 0.1296064227481115\n",
            "Loss: 0.29511280098561965\n",
            "training error 0.05704713370921461, test error 0.1288582487740103\n",
            "Loss: 0.0\n",
            "training error 0.0566241059443653, test error 0.12774672929604014\n",
            "Loss: 0.0\n",
            "training error 0.05625555954484894, test error 0.12816427587979315\n",
            "Loss: 0.32685500916849186\n",
            "training error 0.05568735810809831, test error 0.12577282192824774\n",
            "Loss: 0.0\n",
            "training error 0.05540612966575055, test error 0.12416432533085003\n",
            "Loss: 0.0\n",
            "training error 0.054993390845042414, test error 0.12372205217941751\n",
            "Loss: 0.0\n",
            "training error 0.05460117189871826, test error 0.12216019190758656\n",
            "Loss: 0.0\n",
            "training error 0.054179593256546005, test error 0.12153085963799715\n",
            "Loss: 0.0\n",
            "training error 0.053733940686527676, test error 0.12097467151201206\n",
            "Loss: 0.0\n",
            "training error 0.05330878994111094, test error 0.12022088335637508\n",
            "Loss: 0.0\n",
            "training error 0.05304287761245174, test error 0.12028530533300984\n",
            "Loss: 0.053586344432177135\n",
            "training error 0.052450299424091844, test error 0.11799430187934525\n",
            "Loss: 0.0\n",
            "training error 0.05230486962130513, test error 0.11701161779247457\n",
            "Loss: 0.0\n",
            "training error 0.05193489175805429, test error 0.11707769819899289\n",
            "Loss: 0.05647337227274729\n",
            "training error 0.051422546214019114, test error 0.1159207097993747\n",
            "Loss: 0.0\n",
            "training error 0.050838818000415335, test error 0.1155029502353001\n",
            "Loss: 0.0\n",
            "training error 0.05056738977784256, test error 0.11429097683122308\n",
            "Loss: 0.0\n",
            "training error 0.050294735358940586, test error 0.11453959532715795\n",
            "Loss: 0.21753116722591503\n",
            "training error 0.04981480301168964, test error 0.11316403364039891\n",
            "Loss: 0.0\n",
            "training error 0.04948401882224945, test error 0.11292370328601925\n",
            "Loss: 0.0\n",
            "training error 0.04945140437203518, test error 0.11145269636296701\n",
            "Loss: 0.0\n",
            "training error 0.04877845316786311, test error 0.11068177225103028\n",
            "Loss: 0.0\n",
            "training error 0.04821767529947166, test error 0.11007475212750086\n",
            "Loss: 0.0\n",
            "training error 0.04798706206749945, test error 0.11048230399497289\n",
            "Loss: 0.37025008877600296\n",
            "training error 0.04767331349370574, test error 0.10877944638141636\n",
            "Loss: 0.0\n",
            "training error 0.04759416835096428, test error 0.10895531269237846\n",
            "Loss: 0.16167237176907268\n",
            "training error 0.04707352233385444, test error 0.10840516687936967\n",
            "Loss: 0.0\n",
            "training error 0.04655565641492394, test error 0.10636937856751345\n",
            "Loss: 0.0\n",
            "training error 0.04633993827940487, test error 0.10637382256420574\n",
            "Loss: 0.004177890998469103\n",
            "training error 0.046150613740723136, test error 0.10493075182121966\n",
            "Loss: 0.0\n",
            "training error 0.04559429600082559, test error 0.1044844831592523\n",
            "Loss: 0.0\n",
            "training error 0.045766514439772706, test error 0.10350403969541264\n",
            "Loss: 0.0\n",
            "training error 0.044775509892955145, test error 0.10294376628805682\n",
            "Loss: 0.0\n",
            "training error 0.04447900936225286, test error 0.10216549750572873\n",
            "Loss: 0.0\n",
            "training error 0.044232911762624436, test error 0.10109194120079837\n",
            "Loss: 0.0\n",
            "training error 0.0443480617698472, test error 0.09991097842468549\n",
            "Loss: 0.0\n",
            "training error 0.043648871988720264, test error 0.0997695518264312\n",
            "Loss: 0.0\n",
            "training error 0.043150800397913074, test error 0.09912075120294336\n",
            "Loss: 0.0\n",
            "training error 0.04287518184652679, test error 0.09834109460798754\n",
            "Loss: 0.0\n",
            "training error 0.04258774898143469, test error 0.09788442106208102\n",
            "Loss: 0.0\n",
            "training error 0.04245872498521336, test error 0.09681095018762848\n",
            "Loss: 0.0\n",
            "training error 0.042120823412373366, test error 0.09684979408348661\n",
            "Loss: 0.040123452752860445\n",
            "training error 0.04207074680826918, test error 0.09675602058210937\n",
            "Loss: 0.0\n",
            "training error 0.041386959896395355, test error 0.09504182021107654\n",
            "Loss: 0.0\n",
            "training error 0.04110882590538722, test error 0.09452970511926213\n",
            "Loss: 0.0\n",
            "training error 0.040646949824839684, test error 0.09414247394088199\n",
            "Loss: 0.0\n",
            "training error 0.040423774668296664, test error 0.09363494179311194\n",
            "Loss: 0.0\n",
            "training error 0.04047881892853172, test error 0.09367223656140908\n",
            "Loss: 0.03982996900830926\n",
            "training error 0.03980441286871358, test error 0.09279275321782769\n",
            "Loss: 0.0\n",
            "training error 0.03964381550041471, test error 0.0925861312018544\n",
            "Loss: 0.0\n",
            "training error 0.039426559535719614, test error 0.09095409998980603\n",
            "Loss: 0.0\n",
            "training error 0.039030355129894216, test error 0.09102396439239889\n",
            "Loss: 0.07681281283713481\n",
            "training error 0.03872279597300883, test error 0.08939039512807188\n",
            "Loss: 0.0\n",
            "training error 0.0389015452338379, test error 0.08929031738245796\n",
            "Loss: 0.0\n",
            "training error 0.03845734954196228, test error 0.08800446403044952\n",
            "Loss: 0.0\n",
            "training error 0.038275821882982196, test error 0.08838794307345517\n",
            "Loss: 0.43574953524285753\n",
            "training error 0.037958170862212454, test error 0.08747560901320527\n",
            "Loss: 0.0\n",
            "training error 0.03759397940684741, test error 0.08663791128874015\n",
            "Loss: 0.0\n",
            "training error 0.037207141563043326, test error 0.08683843558643556\n",
            "Loss: 0.2314509834235423\n",
            "training error 0.036994209001789014, test error 0.08641696227074054\n",
            "Loss: 0.0\n",
            "training error 0.03678025781411226, test error 0.08500575756876827\n",
            "Loss: 0.0\n",
            "training error 0.03654816826705578, test error 0.08412987153886053\n",
            "Loss: 0.0\n",
            "training error 0.036238881655647925, test error 0.0838101059846582\n",
            "Loss: 0.0\n",
            "training error 0.03611812928163873, test error 0.08397902243417042\n",
            "Loss: 0.20154663632467873\n",
            "training error 0.035881233304828, test error 0.08370469609095141\n",
            "Loss: 0.0\n",
            "training error 0.03564155733095296, test error 0.08257715109380626\n",
            "Loss: 0.0\n",
            "training error 0.035568487494199996, test error 0.08169985978632151\n",
            "Loss: 0.0\n",
            "training error 0.035235881651623654, test error 0.08166359532587676\n",
            "Loss: 0.0\n",
            "training error 0.03495441579556906, test error 0.0808988596621795\n",
            "Loss: 0.0\n",
            "training error 0.03483728712354886, test error 0.08083305156050641\n",
            "Loss: 0.0\n",
            "training error 0.034511386296940526, test error 0.08044537733557734\n",
            "Loss: 0.0\n",
            "training error 0.03437275254937681, test error 0.08068777597933349\n",
            "Loss: 0.3013207865816714\n",
            "training error 0.03416809321619505, test error 0.07974371143132801\n",
            "Loss: 0.0\n",
            "training error 0.03413217830416598, test error 0.07946074071454191\n",
            "Loss: 0.0\n",
            "training error 0.03379836543111352, test error 0.07808139680945363\n",
            "Loss: 0.0\n",
            "training error 0.033545960810381005, test error 0.07787820204414\n",
            "Loss: 0.0\n",
            "training error 0.03348883850985172, test error 0.07712234121685065\n",
            "Loss: 0.0\n",
            "training error 0.03326392272477883, test error 0.07635675673422065\n",
            "Loss: 0.0\n",
            "training error 0.03314828171808158, test error 0.07673368706772171\n",
            "Loss: 0.4936437188041598\n",
            "training error 0.0328362138491553, test error 0.07654732906740802\n",
            "Loss: 0.24958149263816232\n",
            "training error 0.032564037125119114, test error 0.07554144282010146\n",
            "Loss: 0.0\n",
            "training error 0.03248927174603474, test error 0.07581545995735976\n",
            "Loss: 0.36273749484883044\n",
            "training error 0.03229649840073882, test error 0.07511093264796666\n",
            "Loss: 0.0\n",
            "training error 0.03218169562243351, test error 0.07476937915736243\n",
            "Loss: 0.0\n",
            "training error 0.03198601367882004, test error 0.07433533997950008\n",
            "Loss: 0.0\n",
            "training error 0.03171227156507557, test error 0.07452193610026724\n",
            "Loss: 0.2510193951068551\n",
            "training error 0.031592039663544534, test error 0.07421016921638793\n",
            "Loss: 0.0\n",
            "training error 0.03163972918782753, test error 0.07464530163793662\n",
            "Loss: 0.5863514746609733\n",
            "training error 0.03129127751327496, test error 0.07297394813782308\n",
            "Loss: 0.0\n",
            "training error 0.03110942531302898, test error 0.07257230601967136\n",
            "Loss: 0.0\n",
            "training error 0.031096205219045655, test error 0.07217994649056458\n",
            "Loss: 0.0\n",
            "training error 0.03081592276014764, test error 0.07216174336119499\n",
            "Loss: 0.0\n",
            "training error 0.030686645920844573, test error 0.07127744060246413\n",
            "Loss: 0.0\n",
            "training error 0.030522879125205505, test error 0.07130818845626963\n",
            "Loss: 0.04313826863815429\n",
            "training error 0.03033101757070812, test error 0.07073309039692234\n",
            "Loss: 0.0\n",
            "training error 0.030403665792773704, test error 0.07092146481953153\n",
            "Loss: 0.2663172520133372\n",
            "training error 0.030077523543379534, test error 0.07085136403249304\n",
            "Loss: 0.1672111806609866\n",
            "training error 0.03002079513002628, test error 0.07009198868187749\n",
            "Loss: 0.0\n",
            "training error 0.02986434063116364, test error 0.07056212342582346\n",
            "Loss: 0.6707396277194411\n",
            "training error 0.029666527605799704, test error 0.06912391942639759\n",
            "Loss: 0.0\n",
            "training error 0.02977261194961719, test error 0.06857056772181758\n",
            "Loss: 0.0\n",
            "training error 0.02956298896339457, test error 0.06821496215533508\n",
            "Loss: 0.0\n",
            "training error 0.029379942057736523, test error 0.06894719229326589\n",
            "Loss: 1.0734157357786378\n",
            "training error 0.029155961641341134, test error 0.06832425291239652\n",
            "Loss: 0.16021522787414977\n",
            "training error 0.029081575248689907, test error 0.06781023528709625\n",
            "Loss: 0.0\n",
            "training error 0.029035146230349404, test error 0.06692144308609539\n",
            "Loss: 0.0\n",
            "training error 0.028809134056773354, test error 0.06714818769422229\n",
            "Loss: 0.3388220541436615\n",
            "training error 0.028702574097641695, test error 0.06640119327098362\n",
            "Loss: 0.0\n",
            "training error 0.02864245340270511, test error 0.06585277232330519\n",
            "Loss: 0.0\n",
            "training error 0.028362206738486658, test error 0.06572741064726971\n",
            "Loss: 0.0\n",
            "training error 0.028278092889312746, test error 0.06550546545797876\n",
            "Loss: 0.0\n",
            "training error 0.028304324370371035, test error 0.06526820913385334\n",
            "Loss: 0.0\n",
            "training error 0.028024140750499995, test error 0.06575391193415454\n",
            "Loss: 0.7441644358666455\n",
            "training error 0.02798213071866041, test error 0.06473715466613822\n",
            "Loss: 0.0\n",
            "training error 0.027822062181762457, test error 0.06472319155177776\n",
            "Loss: 0.0\n",
            "training error 0.027781630067557093, test error 0.06458903119596218\n",
            "Loss: 0.0\n",
            "training error 0.027687946989526768, test error 0.06469950714203383\n",
            "Loss: 0.17104443901081456\n",
            "training error 0.027551770962863105, test error 0.06430602057040453\n",
            "Loss: 0.0\n",
            "training error 0.027580833255015876, test error 0.06436209008703166\n",
            "Loss: 0.08719170635933526\n",
            "training error 0.027433918533570394, test error 0.06471026504413124\n",
            "Loss: 0.6286261692777684\n",
            "training error 0.02739577404868252, test error 0.06304368593693147\n",
            "Loss: 0.0\n",
            "training error 0.02718455453120448, test error 0.06310505046480601\n",
            "Loss: 0.0973365166750062\n",
            "training error 0.02710569638790759, test error 0.06299497791396742\n",
            "Loss: 0.0\n",
            "training error 0.027247279866164757, test error 0.06242345910509065\n",
            "Loss: 0.0\n",
            "training error 0.02700578152056797, test error 0.062252952691183444\n",
            "Loss: 0.0\n",
            "training error 0.02682945987364976, test error 0.06209993964995928\n",
            "Loss: 0.0\n",
            "training error 0.026763115288235245, test error 0.06181291711408225\n",
            "Loss: 0.0\n",
            "training error 0.02666099141725461, test error 0.06201255100997335\n",
            "Loss: 0.322964689601446\n",
            "training error 0.02658108112505105, test error 0.06192025103568068\n",
            "Loss: 0.1736431907918723\n",
            "training error 0.026528157899856495, test error 0.06142493298597158\n",
            "Loss: 0.0\n",
            "training error 0.02649513929593489, test error 0.06186876496172069\n",
            "Loss: 0.7225599673840621\n",
            "training error 0.026440653619403905, test error 0.06193080460756328\n",
            "Loss: 0.8235607220071994\n",
            "training error 0.026408056525865916, test error 0.06120845730845293\n",
            "Loss: 0.0\n",
            "training error 0.026412279947024768, test error 0.060465039923597065\n",
            "Loss: 0.0\n",
            "training error 0.026167062635006486, test error 0.061110316559705814\n",
            "Loss: 1.0671896304444983\n",
            "training error 0.02620479536329669, test error 0.06180294963140942\n",
            "Loss: 2.2126996186605075\n",
            "training error 0.026171513651158988, test error 0.060845823246224354\n",
            "Loss: 0.6297578288353867\n",
            "training error 0.02586963534298728, test error 0.060488387107918075\n",
            "Loss: 0.038612699752627044\n",
            "training error 0.02596920688119522, test error 0.061149662966402264\n",
            "Loss: 1.1322626160013893\n",
            "training error 0.02582504297659768, test error 0.06063815869257419\n",
            "Loss: 0.2863121717870065\n",
            "training error 0.025639081095644885, test error 0.06004458389750564\n",
            "Loss: 0.0\n",
            "training error 0.025726983397645876, test error 0.059681526329312395\n",
            "Loss: 0.0\n",
            "training error 0.025776169993452013, test error 0.06028160065215932\n",
            "Loss: 1.0054607510133318\n",
            "training error 0.02572652459687937, test error 0.05959733377310268\n",
            "Loss: 0.0\n",
            "training error 0.025443065984545175, test error 0.05996833442916243\n",
            "Loss: 0.6225121705481174\n",
            "training error 0.025438188124546898, test error 0.05952496969589077\n",
            "Loss: 0.0\n",
            "training error 0.025405850121120257, test error 0.0596027265535934\n",
            "Loss: 0.13062897486531\n",
            "training error 0.025257253749878923, test error 0.059084081919741155\n",
            "Loss: 0.0\n",
            "training error 0.025154420889515042, test error 0.05915141411036729\n",
            "Loss: 0.11395995069805043\n",
            "training error 0.025121343455058023, test error 0.05933216776658506\n",
            "Loss: 0.4198860992388642\n",
            "training error 0.025065722683917102, test error 0.05888958679977421\n",
            "Loss: 0.0\n",
            "training error 0.02508675753273128, test error 0.05845729366953633\n",
            "Loss: 0.0\n",
            "training error 0.02509150299198313, test error 0.059035466606235015\n",
            "Loss: 0.9890518366572731\n",
            "training error 0.025137728005906336, test error 0.05824818515972424\n",
            "Loss: 0.0\n",
            "training error 0.02488121114622923, test error 0.05821941716501404\n",
            "Loss: 0.0\n",
            "training error 0.024826316602917137, test error 0.05781536914998609\n",
            "Loss: 0.0\n",
            "training error 0.02490100042255726, test error 0.05849777826730549\n",
            "Loss: 1.1803247602710565\n",
            "training error 0.024854188201985282, test error 0.05764379441774675\n",
            "Loss: 0.0\n",
            "training error 0.024644454555891617, test error 0.05794870603824698\n",
            "Loss: 0.5289582748327026\n",
            "training error 0.02455622589877058, test error 0.058159706805771066\n",
            "Loss: 0.8950007424658457\n",
            "training error 0.02449536447742979, test error 0.05799816695217318\n",
            "Loss: 0.6147626782828874\n",
            "training error 0.024583065117633647, test error 0.05731571867708329\n",
            "Loss: 0.0\n",
            "training error 0.02449184029059647, test error 0.056835285481038174\n",
            "Loss: 0.0\n",
            "training error 0.024440631993958156, test error 0.05673875089999736\n",
            "Loss: 0.0\n",
            "training error 0.02440325038434697, test error 0.05657441255697158\n",
            "Loss: 0.0\n",
            "training error 0.024349755388266437, test error 0.056361963504260155\n",
            "Loss: 0.0\n",
            "training error 0.02437715608845154, test error 0.05684872033646005\n",
            "Loss: 0.8636264635512703\n",
            "training error 0.02422606867491284, test error 0.056487592808354574\n",
            "Loss: 0.22289731635223298\n",
            "training error 0.024295229758473737, test error 0.05719513069776576\n",
            "Loss: 1.4782437333692666\n",
            "training error 0.02443630769346054, test error 0.05648716081287832\n",
            "Loss: 0.22213085001678845\n",
            "training error 0.02417040409141463, test error 0.05682431769477957\n",
            "Loss: 0.8203301690943965\n",
            "training error 0.024021472992263804, test error 0.05648572660218312\n",
            "Loss: 0.21958620712994037\n",
            "training error 0.02405732913739372, test error 0.05653396599894591\n",
            "Loss: 0.3051747738929578\n",
            "training error 0.024082612659288297, test error 0.05696929486889423\n",
            "Loss: 1.0775553704550633\n",
            "training error 0.02398114599110778, test error 0.05617834472056728\n",
            "Loss: 0.0\n",
            "training error 0.0239093772071187, test error 0.056316696848227155\n",
            "Loss: 0.2462730583253192\n",
            "training error 0.023837821500723503, test error 0.05589119810284311\n",
            "Loss: 0.0\n",
            "training error 0.02376059062676769, test error 0.05564272438348948\n",
            "Loss: 0.0\n",
            "training error 0.02379164097642489, test error 0.05559140846167279\n",
            "Loss: 0.0\n",
            "training error 0.023769451493050223, test error 0.055166768360339055\n",
            "Loss: 0.0\n",
            "training error 0.02375440695613319, test error 0.05540804030616458\n",
            "Loss: 0.43735015299350977\n",
            "training error 0.023654822965899772, test error 0.0554972873590282\n",
            "Loss: 0.5991269898759644\n",
            "training error 0.023606659571099437, test error 0.05540476701646792\n",
            "Loss: 0.43141670828767964\n",
            "training error 0.023638277006250437, test error 0.05511830359239162\n",
            "Loss: 0.0\n",
            "training error 0.02352360256164155, test error 0.054878036533634225\n",
            "Loss: 0.0\n",
            "training error 0.02359725152813473, test error 0.055129438536195376\n",
            "Loss: 0.4581104180122475\n",
            "training error 0.023617849233529394, test error 0.05438120916239261\n",
            "Loss: 0.0\n",
            "training error 0.02342599746922205, test error 0.05454757777345181\n",
            "Loss: 0.305930327077486\n",
            "training error 0.02346225492681595, test error 0.054444157682302506\n",
            "Loss: 0.115754174795768\n",
            "training error 0.023474464510884613, test error 0.054568291096670204\n",
            "Loss: 0.3440194456120427\n",
            "training error 0.023355544523194945, test error 0.054013016077047615\n",
            "Loss: 0.0\n",
            "training error 0.023415418342146225, test error 0.05440556889669972\n",
            "Loss: 0.7267744854168923\n",
            "training error 0.023315608005412995, test error 0.054110118254966845\n",
            "Loss: 0.1797755151845548\n",
            "training error 0.02348719099642007, test error 0.05460141066575742\n",
            "Loss: 1.089357031776328\n",
            "training error 0.023231683605961895, test error 0.05465090352928028\n",
            "Loss: 1.180988396061311\n",
            "training error 0.023290522862175717, test error 0.05426290070106124\n",
            "Loss: 0.46263779022666096\n",
            "training error 0.023305986772217062, test error 0.05480375696806867\n",
            "Loss: 1.4639821073740622\n",
            "training error 0.023175309903456162, test error 0.05430222409711852\n",
            "Loss: 0.5354413455793017\n",
            "training error 0.023175342528884427, test error 0.05436074051087099\n",
            "Loss: 0.6437789612180778\n",
            "training error 0.023259849292194924, test error 0.05466196999432687\n",
            "Loss: 1.2014769113310564\n",
            "training error 0.023241724783599815, test error 0.0539198243013297\n",
            "Loss: 0.0\n",
            "training error 0.023156418641950477, test error 0.05373987166407486\n",
            "Loss: 0.0\n",
            "training error 0.023273169316229046, test error 0.053848532784250315\n",
            "Loss: 0.20219832465304677\n",
            "training error 0.02313336613309075, test error 0.05325179537545314\n",
            "Loss: 0.0\n",
            "training error 0.023004442985256494, test error 0.0534860440649506\n",
            "Loss: 0.439888810970368\n",
            "training error 0.02304391404077104, test error 0.053861482028593394\n",
            "Loss: 1.1449128594475333\n",
            "training error 0.023066615634844398, test error 0.05396398625746872\n",
            "Loss: 1.337402573930624\n",
            "training error 0.022977357808573348, test error 0.05312083131666869\n",
            "Loss: 0.0\n",
            "training error 0.022826991670471954, test error 0.053017113755354534\n",
            "Loss: 0.0\n",
            "training error 0.022882329092694786, test error 0.053655103730773174\n",
            "Loss: 1.2033661024299036\n",
            "training error 0.02281451238946144, test error 0.05359485902665703\n",
            "Loss: 1.0897335414532083\n",
            "training error 0.02291363692363294, test error 0.05318440859891704\n",
            "Loss: 0.315548757207873\n",
            "training error 0.022950389549584886, test error 0.05292966481708208\n",
            "Loss: 0.0\n",
            "training error 0.02288198309322963, test error 0.0528295995025816\n",
            "Loss: 0.0\n",
            "training error 0.022721134225415437, test error 0.05262902256177085\n",
            "Loss: 0.0\n",
            "training error 0.02269121838566409, test error 0.05271675142616486\n",
            "Loss: 0.1666929388457472\n",
            "training error 0.0226613309062424, test error 0.053061709466667766\n",
            "Loss: 0.8221450519797724\n",
            "training error 0.02268820467067565, test error 0.05265823188223091\n",
            "Loss: 0.05550040460238215\n",
            "training error 0.022713703070726905, test error 0.05255794286560819\n",
            "Loss: 0.0\n",
            "training error 0.022595504454712832, test error 0.0526816626507824\n",
            "Loss: 0.23539693227827563\n",
            "training error 0.022721274576178303, test error 0.05250223459012469\n",
            "Loss: 0.0\n",
            "training error 0.022631643181723768, test error 0.05219843733058333\n",
            "Loss: 0.0\n",
            "training error 0.022554651592466606, test error 0.052188117497338184\n",
            "Loss: 0.0\n",
            "training error 0.022558254012542953, test error 0.052240850022844475\n",
            "Loss: 0.10104316468011465\n",
            "training error 0.022510385249395998, test error 0.052563934490000644\n",
            "Loss: 0.7201198485107918\n",
            "training error 0.022512468021979065, test error 0.051992287632769675\n",
            "Loss: 0.0\n",
            "training error 0.022520567512974456, test error 0.05228670976776408\n",
            "Loss: 0.5662804011894229\n",
            "training error 0.0225661667355053, test error 0.05231003272952567\n",
            "Loss: 0.6111389039087589\n",
            "training error 0.02248664753054408, test error 0.05238692665033136\n",
            "Loss: 0.7590337635248634\n",
            "training error 0.022434542022886774, test error 0.051976487320779335\n",
            "Loss: 0.0\n",
            "training error 0.022478705022943832, test error 0.05215478363898369\n",
            "Loss: 0.34303264301793757\n",
            "training error 0.02253698849097149, test error 0.05188437476565575\n",
            "Loss: 0.0\n",
            "training error 0.0226139599696167, test error 0.05214707281912458\n",
            "Loss: 0.5063143858923924\n",
            "training error 0.022515226579531582, test error 0.0518076844306554\n",
            "Loss: 0.0\n",
            "training error 0.0223685332429344, test error 0.05218921773757008\n",
            "Loss: 0.7364415358600995\n",
            "training error 0.02234711717268535, test error 0.052037956246949006\n",
            "Loss: 0.4444742489925879\n",
            "training error 0.022423158979156033, test error 0.05204404740659831\n",
            "Loss: 0.45623150028888393\n",
            "training error 0.022330620778681982, test error 0.05183875308165044\n",
            "Loss: 0.05996919440902637\n",
            "training error 0.02234047199233158, test error 0.051850251244325914\n",
            "Loss: 0.08216312722388874\n",
            "training error 0.022356954670453594, test error 0.05214254548924523\n",
            "Loss: 0.6463540346761665\n",
            "training error 0.022378942159535443, test error 0.051781860273094144\n",
            "Loss: 0.0\n",
            "training error 0.022296218047069646, test error 0.05240698656239297\n",
            "Loss: 1.2072302655832479\n",
            "training error 0.022337804110619745, test error 0.05173609861968267\n",
            "Loss: 0.0\n",
            "training error 0.02234340902259503, test error 0.05169212634096701\n",
            "Loss: 0.0\n",
            "training error 0.022290915525568573, test error 0.05215100054892632\n",
            "Loss: 0.8877061951998666\n",
            "training error 0.02227102923445826, test error 0.05194509510409336\n",
            "Loss: 0.48937581220347415\n",
            "training error 0.02225214629732422, test error 0.05151018673798153\n",
            "Loss: 0.0\n",
            "training error 0.022186744742474864, test error 0.05157874121266226\n",
            "Loss: 0.1330891596830197\n",
            "training error 0.022161042879805203, test error 0.05151174924680027\n",
            "Loss: 0.0030333976979823873\n",
            "training error 0.0222012146908989, test error 0.05110919604476298\n",
            "Loss: 0.0\n",
            "training error 0.02229792136214006, test error 0.0512316273889511\n",
            "Loss: 0.2395485620256821\n",
            "training error 0.02214460051790426, test error 0.051209190703514595\n",
            "Loss: 0.19564905435811575\n",
            "training error 0.022254456288407592, test error 0.05179170308463504\n",
            "Loss: 1.3353898959285182\n",
            "training error 0.022212708727343638, test error 0.05150548373445643\n",
            "Loss: 0.7753745321025463\n",
            "training error 0.022181726568042247, test error 0.051979085684447326\n",
            "Loss: 1.702021763211592\n",
            "training error 0.022143506852456748, test error 0.05153504453999298\n",
            "Loss: 0.8332130578947661\n",
            "training error 0.022056349225553013, test error 0.05165381097786973\n",
            "Loss: 1.065590882372236\n",
            "training error 0.022182224906732904, test error 0.05140900397333601\n",
            "Loss: 0.5866027090515091\n",
            "training error 0.02210753927113858, test error 0.05142199980480914\n",
            "Loss: 0.6120302885848528\n",
            "training error 0.02221681695975668, test error 0.052340671171972664\n",
            "Loss: 2.409498138321564\n",
            "training error 0.022215165595109426, test error 0.05115861004371495\n",
            "Loss: 0.09668318575914991\n",
            "training error 0.02211953973152416, test error 0.0512065830208087\n",
            "Loss: 0.19054687528332614\n",
            "training error 0.022036418200107148, test error 0.051105240184796674\n",
            "Loss: 0.0\n",
            "training error 0.022050328247117005, test error 0.051172129735196074\n",
            "Loss: 0.1308858938095625\n",
            "training error 0.02204947342756017, test error 0.051603946530904186\n",
            "Loss: 0.9758418986080208\n",
            "training error 0.022188659168874497, test error 0.05107039444103203\n",
            "Loss: 0.0\n",
            "training error 0.02205793901791793, test error 0.05202336832562608\n",
            "Loss: 1.866000635053644\n",
            "training error 0.022026530794165868, test error 0.05147527294507108\n",
            "Loss: 0.7927851516920326\n",
            "training error 0.02201642645773888, test error 0.0512184846813633\n",
            "Loss: 0.28997277571893854\n",
            "training error 0.022057247813316385, test error 0.05149439155205747\n",
            "Loss: 0.8302209443770803\n",
            "training error 0.022063700466014528, test error 0.05212991554812271\n",
            "Loss: 2.0746287916652895\n",
            "training error 0.022039047194351742, test error 0.05165241876660021\n",
            "Loss: 1.1396511265253872\n",
            "training error 0.021958779440505328, test error 0.05113303497174704\n",
            "Loss: 0.12265527102466312\n",
            "training error 0.022101263720837355, test error 0.050435645666686776\n",
            "Loss: 0.0\n",
            "training error 0.021986217830051946, test error 0.050758813597313615\n",
            "Loss: 0.6407530355862834\n",
            "training error 0.021938770193995795, test error 0.05048721531940498\n",
            "Loss: 0.10224842378148136\n",
            "training error 0.021967978589387465, test error 0.05106132314658184\n",
            "Loss: 1.240546188364422\n",
            "training error 0.02206592254278388, test error 0.05094531878736803\n",
            "Loss: 1.0105414810182456\n",
            "training error 0.022045355637455074, test error 0.050862559661839855\n",
            "Loss: 0.8464529193785264\n",
            "training error 0.02193970525382188, test error 0.05060903241358655\n",
            "Loss: 0.34377818427393514\n",
            "training error 0.021900377737418982, test error 0.050565369903103834\n",
            "Loss: 0.25720744664272654\n",
            "training error 0.022006851987318218, test error 0.05085579951272465\n",
            "Loss: 0.8330494048089276\n",
            "training error 0.0219266747902975, test error 0.050841481758138955\n",
            "Loss: 0.8046612392636376\n",
            "training error 0.021938998835240038, test error 0.050744016196396756\n",
            "Loss: 0.6114138634169652\n",
            "training error 0.021931080964401033, test error 0.050451523601032\n",
            "Loss: 0.031481572477831676\n",
            "training error 0.02194945948051147, test error 0.051033428874268975\n",
            "Loss: 1.185239525895554\n",
            "training error 0.02194967084806646, test error 0.05098704714360249\n",
            "Loss: 1.0932773232640969\n",
            "training error 0.0218618880842349, test error 0.050649090595974465\n",
            "Loss: 0.42320253159497945\n",
            "training error 0.021876521276981434, test error 0.05064690720694476\n",
            "Loss: 0.41887347225439964\n",
            "training error 0.021872718160057668, test error 0.05034484326812313\n",
            "Loss: 0.0\n",
            "training error 0.021802405424918795, test error 0.05046139599758594\n",
            "Loss: 0.2315087740805577\n",
            "training error 0.0219190115409719, test error 0.050329140137165516\n",
            "Loss: 0.0\n",
            "training error 0.02184967605127639, test error 0.050158902446248245\n",
            "Loss: 0.0\n",
            "training error 0.021869098371600955, test error 0.05069207194363827\n",
            "Loss: 1.0629608531833146\n",
            "training error 0.021818710058308544, test error 0.05047114973083867\n",
            "Loss: 0.6225161822969172\n",
            "training error 0.021815307877815257, test error 0.05047778233851943\n",
            "Loss: 0.6357393737091988\n",
            "training error 0.021775958535405062, test error 0.050639657471903333\n",
            "Loss: 0.9584640058069027\n",
            "training error 0.021740963609511714, test error 0.0503161105408786\n",
            "Loss: 0.31342012477013625\n",
            "training error 0.0218763677577394, test error 0.05030730499781885\n",
            "Loss: 0.2958648302355593\n",
            "training error 0.021782641676629407, test error 0.05043686875098305\n",
            "Loss: 0.5541714255663521\n",
            "training error 0.02174311951038014, test error 0.05054070827249632\n",
            "Loss: 0.7611925453457236\n",
            "training error 0.02177257004822413, test error 0.05068622542233255\n",
            "Loss: 1.0513048539078529\n",
            "training error 0.021869688130491408, test error 0.05005572061797556\n",
            "Loss: 0.0\n",
            "training error 0.021899889742505164, test error 0.051418755456073696\n",
            "Loss: 2.723035092234105\n",
            "training error 0.021708896780482285, test error 0.05043518409022591\n",
            "Loss: 0.7580821284072892\n",
            "training error 0.021807784896277112, test error 0.05049555327771139\n",
            "Loss: 0.8786861008207802\n",
            "training error 0.02176480070146195, test error 0.05103873660344779\n",
            "Loss: 1.9638434395433002\n",
            "training error 0.021753481375196098, test error 0.049965831640440606\n",
            "Loss: 0.0\n",
            "training error 0.02171911880648053, test error 0.04988622383211475\n",
            "Loss: 0.0\n",
            "training error 0.021665844908747987, test error 0.049923948542049894\n",
            "Loss: 0.07562149835613763\n",
            "training error 0.02169964113821869, test error 0.05010485463717653\n",
            "Loss: 0.43825887843815803\n",
            "training error 0.021720264167507743, test error 0.05001808055784741\n",
            "Loss: 0.264314906208174\n",
            "training error 0.021718495076612894, test error 0.049893726140583065\n",
            "Loss: 0.015038838164138646\n",
            "training error 0.02179125905497285, test error 0.0503613574775537\n",
            "Loss: 0.9524345780068444\n",
            "training error 0.021693141261907183, test error 0.05042103545300265\n",
            "Loss: 1.0720627455943266\n",
            "training error 0.021691694877742678, test error 0.05028106503305269\n",
            "Loss: 0.7914834409329607\n",
            "training error 0.021665352602106815, test error 0.04983071497704877\n",
            "Loss: 0.0\n",
            "training error 0.02173387286041231, test error 0.05016627116327016\n",
            "Loss: 0.6733922769840639\n",
            "training error 0.021752905855575558, test error 0.05062624436373707\n",
            "Loss: 1.5964639220101606\n",
            "training error 0.02166195446155283, test error 0.0501109476075172\n",
            "Loss: 0.5623692748488507\n",
            "training error 0.021673750877046857, test error 0.05049713836079777\n",
            "Loss: 1.3373747176935735\n",
            "training error 0.021613078040008504, test error 0.050101880098577634\n",
            "Loss: 0.5441726486440146\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fn48c8zk4VVkEW2AMGCIBTCJjCgEIi2qAgo9StUC66grVLsVxHtr611qUprVVzQaFGjFLRaXMEFZMAv3IpsouACYihBwYAQQYRs5/fHvZnMTGaSSchkkpnn/XrNK/eec+fOuZlknjnLPUeMMSillEpcrlgXQCmlVGxpIFBKqQSngUAppRKcBgKllEpwGgiUUirBaSBQSqkEp4FA1VsicpaIfB7rcigV7zQQqJBEJFdEzo5lGYwx7xtjesayDPWR2HaKyLZYl0XFBw0EKmZExB3rMpyoGF3DSOAU4FQROaMuX1hEkury9VTd0ECgqkVEXCIyR0S+FJEDIvKiiLTyy/+XiOwVkQIRWS0iffzynhGR+SKyVER+AEY7NY+bRGSL85wXRKSRc3ymiOT5PT/ssU7+bBH5RkS+FpGrRcSISPcw19FKRJ52jj0oIq846ZeLyP8FHes7T4hruMm5Xrff8ReKyJZIfl81NA14FVjqbPuXtY+IvCsi34nIPhG5zUl3i8htTjkOi8gGEeksIunO9SX5ncMrIlf7/T7WiMgDInIAuF1EfiIi7znXs19EFopIS7/ndxaRf4tIvnPMIyKS4pSpr99xp4jIURFpe4K/D3WCNBCo6roBmAiMAjoCB4FH/fKXAT2wv7FuBBYGPf+XwN1Ac6DsA/d/gLFAN6AfcHklrx/yWBEZC/wOOBvoDmRWcR3PAU2APk5ZH6ji+HDX8BDwAzAmKP+fznZVv69qEZEmwC+wf68LgckikuLkNQeWA285r9UdWOE89XfAFOA84CTgSuBohC87FNgJtMO+bgHucV7jdKAzcLtTBjfwBrALSAc6AYuNMYXAYuAyv/NOAVYYY/Ij/w2oqDDG6EMfFR5ALnB2iPRPgSy//Q5AEZAU4tiWgAFaOPvPADkhXucyv/25wOPOdiaQF+GxC4B7/PK6O6/dPUS5OgClwMkh8i4H/i8ozXeeMNdwF7DA2W6OHRi6Vvf3FeH7chmQDyQBjYAC4EInbwqwKczzPgcmhEhPd64vyS/NC1zt9/v4bxVlmlj2uoCnrHwhjhsK/BcQZ3898D+x/lvXh9Eagaq2rsASETkkIoewP+hKgHZO88O9TvPD99gf3ABt/J6/O8Q59/ptHwWaVfL64Y7tGHTuUK9TpjPwnTHmYCXHVCb43P8ELhKRVOAiYKMxZpeTF/b3FXxSEVkmIkecx6VhXnsa8KIxptgYcwx4mfLmoc7Al2GeV1leVQKuV0TaichiEdnjvM/PU/4edwZ2GWOKg09ijPkA+z3LFJFe2MH6tRqWSdUi7fhR1bUbuNIYsyY4Q0R+BUzAbp7JBVpgN4WI32HRmu72GyDNb79zJcfuBlqJSEtjzKGgvB+wm4wAEJH2IZ4fcA3GmG0isgs4l8BmobLXCvn7qnBSY86tLF9E0rCboIaIyCQnuQnQSETaOK81OczTdwM/AT4JSv/B7zzfO9vB1xz8nv3FSetrjPlORCYCj/i9ThcRSQoVDIBnsWs1e4GXnGCmYkxrBKoyySLSyO+RBDwO3C0iXQFEpK2ITHCObw4cBw5gf7D8pQ7L+iJwhYic7rSj/yHcgcaYb7D7Mh4TkZNFJFlERjrZHwF9RKS/0xF9e4Sv/0/gt9gjev7ll17Z76u6fgV8AfQE+juP04A87GahN4AOIjJLRFJFpLmIDHWe+xRwp4j0EFs/EWlt7Pb5PcBlTo3uSuyAUZnmwBGgQEQ6ATf75a3DDsr3ikhT5+9mhF/+88CF2MEgp4a/B1XLNBCoyiwFfvR73I7dOfoa8I6IHAb+g932C/Y/9i7sD5ZtTl6dMMYsA+YBK4Edfq99PMxTfoXdVv8Z8C0wyznPF8Ad2J2u2ynv0K7KIuwO4feMMfv90iv7fVXXNOAxY8xe/wd2sJlmjDkMnANcgP2Nezsw2nnu37GD5TvY3/z/ATR28q7B/jA/gN15vraKcvwZGIjdP/Em8O+yDGNMifP63bH7A/KAS/zyd2MPIjDA+9X/FahoKOu0USquiMjp2M0gqWGaKFSMiMgC4GtjzP+LdVmUTQOBihsiciF2LaYJdlt0qTFmYmxLpfyJSDqwGRhgjPkqtqVRZbRpSMWTGdjNPF9ij8y5LrbFUf5E5E7sWtpfNQjUL1ojUEqpBKc1AqWUSnAN7j6CNm3amPT09FgXQymlGpQNGzbsN8aEnNepwQWC9PR01q9fH+tiKKVUg+Lc9BiSNg0ppVSC00CglFIJTgOBUkoluAbXRxBKUVEReXl5HDum81clgkaNGpGWlkZycnKsi6JUXIiLQJCXl0fz5s1JT09HRKp+gmqwjDEcOHCAvLw8unXrFuviKBUXotY0JCILRORbEQme9rYsX0RknojsEHvpwYE1fa1jx47RunVrDQIJQERo3bq11v6UqkXRrBE8gz1HebipZs/FXtKwB/ZsjPOp+ayMGgQSiL7XDZ9lgdcLW7fC229DaSm0bw/jxsF//gMffgiFhSACLpedb4y9D+XbleXR2aKkTw6m6V5o/B20/QRSjkCp87HnLgQMGHFWzHC2cYGU1r+80hRO+uEM/vrze5l+rqdW34+oBQJjzGpngqlwJmAv+WeA/4hISxHp4MwVr5SKU5YFY8ZAcKXuu+9g27YITpBmQdYc6LARXIX2B6UAJSkgJeByJpt1l4Q5QeEJlD6G3D/yfcvVzLBGAqtrNRjEctRQJwKXwMtz0ioQkekisl5E1ufn1791rg8cOED//v3p378/7du3p1OnTr79wsLK/+jWr1/PzJkzq3yN4cOH11ZxAZg1axadOnWitLS0Vs+rVFW83opBIGJpFlx+JqSvhtQjkFwIScXgLoaUo5B83A4A7hI7OMTjw1XMyxu8NfwFhtYgOouNMdlANsDgwYPr3Sx5rVu3ZvPmzQDcfvvtNGvWjJtuusmXX1xcTFJS6F/14MGDGTx4cJWvsXZtVWuFRK60tJQlS5bQuXNnVq1axejRo6t+Ug1Udt0qcaxdC3/6E2zeDAUFUFyT1SGyboFBT0DqYXCVBi5+Wh0G+7n17lOkGkqTmDQos1ZPGcsawR4C15VNc9LqhGXBPffYP6Ph8ssv59prr2Xo0KHMnj2bdevW4fF4GDBgAMOHD+fzzz8HwOv1Mm7cOMAOIldeeSWZmZmceuqpzJs3z3e+Zs2a+Y7PzMzkF7/4Bb169eLSSy+lbAbZpUuX0qtXLwYNGsTMmTN95w3m9Xrp06cP1113HYsWLfKl79u3jwsvvJCMjAwyMjJ8wScnJ4d+/fqRkZHBr371K9/1vfTSSyHLd9ZZZzF+/Hh69+4NwMSJExk0aBB9+vQhOzvb95y33nqLgQMHkpGRQVZWFqWlpfTo0YOyWl9paSndu3enPtYCVWQsC0aOhOXLYf9+KCqy2/AjMigbrh4K/3sKnDkXGhcEBgET9AiVVtkxJW77UZwEJUnl28Upgfv1Ja+oMScdGskTntptFoLY1gheA64XkcXYncQFtdE/MGuW/c2jMgUFsGWL3cnkckG/ftCiRfjj+/eHBx+sflny8vJYu3Ytbreb77//nvfff5+kpCSWL1/Obbfdxssvv1zhOZ999hkrV67k8OHD9OzZk+uuu67CePlNmzaxdetWOnbsyIgRI1izZg2DBw9mxowZrF69mm7dujFlypSw5Vq0aBFTpkxhwoQJ3HbbbRQVFZGcnMzMmTMZNWoUS5YsoaSkhCNHjrB161buuusu1q5dS5s2bfjuu++qvO6NGzfyySef+IZ3LliwgFatWvHjjz9yxhlnMGnSJEpLS7nmmmt85f3uu+9wuVxcdtllLFy4kFmzZrF8+XIyMjJo2zbkPFmqHrIs+PWv4Ysv4OST7Xb/knBN9ZUZmA3jZlT+zV9AEFziosSU+NJcuHC5XCS7kkly2R9xTVOaMixtGOd2P5cDRw+QmZ6Jp3Ptfpg2ZFELBCKyCMgE2ohIHvAnIBnAGPM49kpS52GvL3sUuCJaZQlWUGAHAbB/FhRUHghq6uKLL8btdjuvWcC0adPYvn07IkJRUVHI55x//vmkpqaSmprKKaecwr59+0hLSws4ZsiQIb60/v37k5ubS7NmzTj11FN9H75TpkwJ+PZdprCwkKVLl/L3v/+d5s2bM3ToUN5++23GjRvHe++9R06OPcjL7XbTokULcnJyuPjii2nTpg0ArVq1qvK6hwwZEjDGf968eSxZsgSA3bt3s337dvLz8xk5cqTvuLLzXnnllUyYMIFZs2axYMECrriizv4s1AmyLPDvyjp69ARONvShiJp/Zgyawfxx87F2W3hzvfoBX0PRHDUU/iupnW+A39T260byzd2yICvLHp6WkgILF4InCn87TZs29W3/4Q9/YPTo0SxZsoTc3FwyMzNDPic1NdW37Xa7KQ7RoBrJMeG8/fbbHDp0iL59+wJw9OhRGjduHLYZKZykpCRfR3NpaWlAp7j/dXu9XpYvX45lWTRp0oTMzMxK7wHo3Lkz7dq147333mPdunUsXLiwWuVSseP1RnacCCQnQ1KSvT1iBJx6KqxYAf/9LzDhKo63q3r4UKo7lakZUwHwdPZoADgBCTnXkMdj/9Hdeaf9MxpBIFhBQQGdOtmDop555plaP3/Pnj3ZuXMnubm5ALzwwgshj1u0aBFPPfUUubm55Obm8tVXX/Huu+9y9OhRsrKymD9/PgAlJSUUFBQwZswY/vWvf3HgwAEAX9NQeno6GzZsAOC1114LW8MpKCjg5JNPpkmTJnz22Wf85z//AWDYsGGsXr2ar776KuC8AFdffTWXXXZZQI1K1X9hvtsESE6GNWvg+HH44Qf4y4p5bDmnAws6pZL7qxSKb0vieO8FYZ//xLgnWHvlWv4y5i+snLZSP/xrSUIGArA//G+9tW6CAMDs2bO59dZbGTBgQLW+wUeqcePGPPbYY4wdO5ZBgwbRvHlzWgS1dx09epS33nqL888/35fWtGlTzjzzTF5//XUeeughVq5cSd++fRk0aBDbtm2jT58+/P73v2fUqFFkZGTwu9/9DoBrrrmGVatWkZGRgWVZAbUAf2PHjqW4uJjTTz+dOXPmMGzYMADatm1LdnY2F110ERkZGVxyySW+54wfP54jR45os1ADc8YZ4fOaNIGJE2HVqvL/uVuW38Jv3/ote3/YS2FJIUWlReVt/SHMHjGb6YOm4+ns4dazbtUgUIsa3JrFgwcPNsEL03z66aecfvrpMSpR/XHkyBGaNWuGMYbf/OY39OjRgxtvvDHWxaq29evXc+ONN/L++++HPUbf8/pj1Sq7Zr1+PSxbVjE/NRVWrgz80nXL8luYu2ZuxK8xsedElkxeUgulTVwissEYE3Ksug7yjiNPPvkkzz77LIWFhQwYMIAZM2bEukjVdu+99zJ//nztG2ggyu4SDndf4rXXwtSpgUHgsn9fxsKPI39/k13JzB4x+wRLqiqjNQLVIOl7Xj/ccw/cdlv4/LVraxYEmqc0p3WT1vRv35/Zw2drM1At0BqBUioqWreuPD8rq3xAxqy3ZoUNAhN7TmT2iNk6BDRGNBAopWps06aKaY0alc8lVFjoDCtNs3jog4fCn0h0CGgsJeyoIaXUibEsePLJiukzZ0LjxuB22/fptO5v8cuXf1npudo3bR+lUqpIaI1AKVUjXm/o6SNatrSbg7xeOPSTbGasCz9oQRCS3cm+G8NUbGggqAUHDhwgKysLgL179+J2u33z46xbt46UlJRKn+/1eklJSal0qumJEyeyd+9e3w1ZSsXS2rX2ojLB3G77xjKPB0izGL4gdBBo26Qtd425S+f9qSc0ENSCqqahrorX66VZs2ZhA8GhQ4fYsGEDzZo1Y+fOnZx66qm1Uu5gOm20ioRlwejRdvt/sJLzrmH0u/+k6J1jlBJ+rYu7xtzF9EHTo1hKVR0J20dg7ba45/17sHZHZx7qDRs2MGrUKAYNGsTPf/5zvvnGnlh13rx59O7dm379+jF58mRyc3N5/PHHeeCBB+jfv3/Im6j+/e9/c8EFFzB58mQWL17sS9+xYwdnn302GRkZDBw4kC+//BKA++67j759+5KRkcGcOXMAyMzMpGzY7f79+0lPTwfs6S7Gjx/PmDFjyMrK4siRI2RlZTFw4ED69u3Lq6++6nu94OmoDx8+TLdu3XzTS3z//fcB+yo+eb2hgwD/cyEMeorj5mjYINCqUSueGPeEBoF6Ju6+/s16axab91Y+D3XB8QK27NtCqSnFJS76tetHi9Tw04/2b9+fB8dGPg+1MYYbbriBV199lbZt2/LCCy/w+9//ngULFnDvvffy1VdfkZqayqFDh2jZsiXXXnttpbWIRYsW8cc//pF27doxadIkbnMGbl966aXMmTOHCy+8kGPHjlFaWsqyZct49dVX+eCDD2jSpEnE00Zv2bKFVq1aUVxczJIlSzjppJPYv38/w4YNY/z48Wzbtq3CdNTNmzcnMzOTN998k4kTJ7J48WIuuuiiCtNmq/jiCvX1cWA29Hql0ud1bdGV3Fm5USmTOjFxFwgiUXCsgFLjzJxpSik4VlBpIKiu48eP88knn3DOOecA9gRuHTp0AKBfv35ceumlTJw4kYkTJ1Z5rn379rF9+3bOPPNMRITk5GQ++eQTunbtyp49e7jwwgsBaNSoEQDLly/niiuuoEmTJkBk00afc845vuOMMdx2222sXr0al8vFnj172LdvH++9917I6aivvvpq5s6dy8SJE3n66ad5MtQwEhU3LAsWBM8Jl2bBuGurnDb6trMqufNMxVTcBYJIvrlbuy2ycrIoLCkkxZ3CwosW1mpnlTGGPn36YIVY/uzNN99k9erVvP7669x99918/PHHlZ7rxRdf5ODBg755+7///nsWLVrka/KJlP+00cHTQPtPGLdw4ULy8/PZsGEDycnJpKenVzpt9IgRI8jNzcXr9VJSUsJPf/rTapVLNRxlfQPHjwdlZM0BMRUCQZIriWRXMu2atePWM2/V5qB6LCH7CDydPayYuoI7R9/Jiqkran3EQmpqKvn5+b5AUFRUxNatWyktLWX37t2MHj2a++67j4KCAo4cOULz5s05fPhwyHMtWrSIt956yzdt9IYNG1i8eDHNmzcnLS2NV16xq+PHjx/n6NGjnHPOOTz99NMcdVYFCTVttP8Sk8EKCgo45ZRTSE5OZuXKlezatQsg7HTUAFOnTuWXv/ylzhYaxyzLXv2vQhBIs6Dr6gpB4IlxT1D0hyKO/v4oX/32Kw0C9VxCBgIgqlPZulwuXnrpJW655RYyMjLo378/a9eupaSkhMsuu4y+ffsyYMAAZs6cScuWLbngggtYsmRJhc7i3Nxcdu3a5Zu6GaBbt260aNGCDz74gOeee4558+bRr18/hg8fzt69exk7dizjx49n8ODB9O/fn7/97W8A3HTTTcyfP58BAwawf//+sGW/9NJLWb9+PX379iUnJ4devXoBhJ2Ouuw5Bw8erHR5TNVwWZY9JHTduhCZGTkVPkUu7XupfvA3MDrpnDphL730Eq+++irPPfdcnb2mvud15/rr4dFHw2RePgrSV/t2+7frz6ZrQ8w7oWJOJ51TUXPDDTewbNkyli5dGuuiqCj5yU/CZHS2oMvqgKT0lulRL4+qfRoI1Al5+OGHY10EFWV5eWEyht9ToVmofTOdM6ghips+gobWxKVqTt/ruhVyUfqx18PprwckuXDpnEENVFwEgkaNGnHgwAH9gEgAxhgOHDjgu29CRV+XLn47aZZ9B/HQip0GN424SecMaqDiomkoLS2NvLw88vPzY10UVQcaNWpEWlparIuRMHxzJqZZMG0MuEPfV9IytWXdFUrVqrgIBMnJyb4brpRStcvXWZyRA8l+QcDgu38g2ZVMZnpmHZdM1Za4aBpSSkVPp07YtYEBTwVmOEEgvUU6qy5fpc1CDZgGAqVUWJYF998PDJ8L7uKQx4ztPlaDQAMXF01DSqnaZ1lw5plQ2tGCnq+FnFROEB0pFAe0RqCUCmnuXCgtxZlGwllfIGhg3s0jbtbaQBzQGoFSqoLsbHilbHmBpnvLM5xawSlNTuHOMXfqnEJxQgOBUqqCl1/222n7aUCzkEtcvDL5Fa0JxJGoNg2JyFgR+VxEdohIhQn0RaSriKwQkS0i4hURHRyuVD3Qr5+zMTAb2nwekDf+tPEaBOJM1AKBiLiBR4Fzgd7AFBHpHXTY34AcY0w/4A7gnmiVRykVOd9NZEMfCkgXhNkjZtd9gVRURbNpaAiwwxizE0BEFgMTgG1+x/QGyia2XwlUvuipUipqLMvuIP76a0hOxq4NtN0W0Cx0VpeztDYQh6IZCDoBu/3284ChQcd8BFwEPARcCDQXkdbGmANRLJdSKohlwciRUFx2q0CaBVf8OrBvABf3nn1vTMqnoivWw0dvAkaJyCZgFLAHKAk+SESmi8h6EVmv8wkpVbvKlqEs9r9fLCMHXCUBgWBK3ylaG4hT0awR7AE6++2nOWk+xpivsWsEiEgzYJIx5lDwiYwx2UA22CuURavASiWasmUoCwuDMlrsqnADWf4P+iUsXkWzRvAh0ENEuolICjAZeM3/ABFpIyJlZbgVWBDF8iilguTkhAgCACnfl287X70m9Z5UJ2VSdS9qgcAYUwxcD7wNfAq8aIzZKiJ3iMh457BM4HMR+QJoB9wdrfIopQJZFjz5ZJjM4ibl2wIju4zUm8fiWFRvKDPGLAWWBqX90W/7JeClaJZBKRWa1wslQT1ySUnQvj18W9wOu6IgpLpTtJM4zsW6s1gpFSOtW1dMmzEDXlxrUdjreQDc4mLeufO0kzjO6RQTSiUgy4Lrr6+YvmABfHR6+bf/ElPCpm821WHJVCxojUCpBJSTA0VFFdOP9c7m//YHjOlg7w97Kx6o4ooGAqUSTNhO4jQLc961FZLbN20f/UKpmNJAoFSCCdVJDMDw+8AdeJuOLjyTGDQQKJVgQnUSA9Bid4WkCT0naEdxAtBAoFSCORBuJq+vBwbsJrmSdKbRBKGBQKkEk5kZuC+CPcncgOd8aSO7jmT15au1NpAgdPioUgnGBM3WNWMG7O3h5ZXDZbeQCWN/MlaDQALRQKBUgrAsu6N4586Keaf1OwRr7AhhMBw6XmHuRxXHNBAolQDKZhktLrankfD39NPQr/fGgLTN32yuu8KpmNNAoFQC8HrLZxkNvpGssN1adnwXWE3o36F/3RRM1QsaCJRKAP4dxP59BNLFwlx+FgcpDTi+ZWrLuimYqhd01JBSCcATpt+38dlzwRUYBNziJjM9M/qFUvWGBgKlElWaxdEur1VIHtF5hI4YSjAaCJRKAJYVIrF/DgQ1CQH0bts76uVR9YsGAqUSgNcbIjHE6t/JrmSdWygBaSBQKgEE300M4P5kKv4r1AvCVQOu0mahBKSBQKkEMGxYxbRB7Tyc1qoHguASF42SGmltIEHp8FGlEkBxcVBCmkWjs70UlhTSsXlHLjjtAqZmTNXaQILSQKBUAii7mQywJ5i7fBSrk4qgwE569qNntTaQwLRpSKk4Z1lw3XX2tssF0s0L7sDbi48VH8Ob663zsqn6QWsESsUxy4JRo8qnlSgtBTna2r+PGLAnmmvdJNyKNSreaY1AqTgWapF60+mDCscJwoGj4VasUfFOA4FScSrcIvXSclfFNBGdViKBaSBQKk6FXKQ+zYJuqysce9Pwm3TEUALTPgKl4lTIReozcjBS3laU1jyNP4z6A9MHTa+7gql6RwOBUnGqwiL1aRYMWODbTXYl8+LFL2pNQGnTkFLxqsK0Ehk54C6/oaCkNLjdSCUqDQRKxamAaSXSLBiUHTBstJRScj7KqfNyqfpHA4FScSpgWol0b4UFaJQqE9VAICJjReRzEdkhInNC5HcRkZUisklEtojIedEsj1KJ5Ngxv53czAr5qe5UnVZCAVEMBCLiBh4FzgV6A1NEJHjFi/8HvGiMGQBMBh6LVnmUSjQ//hg+zy1u5p07TzuKFRDdGsEQYIcxZqcxphBYDEwIOsYAJznbLYCvo1gepRLKmjV+O93eC8grNaV6J7HyqTIQiMgFIlKTgNEJ2O23n+ek+bsduExE8oClwA1hyjBdRNaLyPr8/PwaFEWpxLPa/76x480C8nRuIeUvkg/4S4DtIjJXRHrV8utPAZ4xxqQB5wHPhQo6xphsY8xgY8zgtm3b1nIRlIpPKSl+O2kV5xfSGoEqU2UgMMZcBgwAvgSeERHL+YbevIqn7gE6++2nOWn+rgJedF7HAhoBbSIsu1IqDMuCuXPtbeliwU9frHCM1ghUmYiafIwx3wMvYbfzdwAuBDaKSMimHMeHQA8R6SYiKdidwa8FHfNfIAtARE7HDgTa9qPUCbAsuP328n3T71lwBd485sKlNQLlU+UUEyIyHrgC6A7kAEOMMd+KSBNgG/BwqOcZY4pF5HrgbcANLDDGbBWRO4D1xpjXgP8FnhSRG7E7ji83xpjauDClEtHy5TB2rL3ugI/7eMAxgpCalKqzjSqfSOYamgQ8YIwJmLLQGHNURK6q7InGmKXYncD+aX/0294GjIi8uEqpytx9d4gZR4NWoZnQawKzh8/WoaPKJ5JAcDvwTdmOiDQG2hljco0xK6JVMKVU9VhW0EghsKeW6Fc+jYQLF0M6DtEgoAJE0kfwL8C/olnipCml6hGvN6hJCJypJcqrCG6XW5uEVAWRBIIk54YwAJztlEqOV0rFQGYmuN1BiUHrE9/ouVFrA6qCSAJBvtNhDICITAD2R69ISqma8Hhg0KDAtLSe5SODXLhomdqyjkulGoJI+giuBRaKyCPY3y12AzpTlVL1THY2bNoUmFawtzXSUzAYHSmkwqoyEBhjvgSGiUgzZ/9I1EullKqW7GyYMSMoMc3i8IiZYAyI8ODYB7VZSIUU0VKVInI+0AdoJGI3OGbsy9AAABuiSURBVBpj7ohiuZRS1ZCdHSIx3QtJZfcQGDZ9synEQUpFNunc49jzDd2A3TR0MdA1yuVSSkXIsmDjxhAZRwOnkHhy45NYu626KZRqUCLpLB5ujJkKHDTG/BnwAKdFt1hKqUh5vXbrj7/0dOh1xt6AtBJToktTqpAiCQRl6xwdFZGOQBH2fENKqXogeJH61FT45z8hc9w3IY9XKlgkfQSvi0hL4K/ARuw5gZ6MaqmUUhHbsiVw/7e/BdIsHn/n8YB0t7h1aUoVUqWBwFkbYIUx5hDwsoi8ATQyxhTUSemUUlX6V9B9/ps3w/dBTUCC8Nj5j+moIRVSpU1DxphS7HWHy/aPaxBQqn45//zA/UmT4J0v3wlIO6vrWUwfNL0OS6Uakkj6CFaIyCQpGzeqlKpXLrnE/tm7NzzxBHx56i3sPLQz4JjebXrHoGSqoYikj2AG8DugWESOYQ8hNcaYkyp/mlKqLhxzhnPMng3TpsEpf326wjHaN6AqE8mdxVUtSamUiqEff7R/Nm4Mtyy/hfyjgYv8Xdr3Uu0bUJWKZIWykaHSgxeqUUrVrbVrYdkyKC4G0iz+d2UOee0DRwq1atSK5y96PjYFVA1GJE1DN/ttNwKGABuAMVEpkVKqSpZl3z9QVIS9+MzlmeS5C+3B3X69ee2atYtRCVVDEknT0AX++yLSGXgwaiVSSlXJ63WCAEBGDrgLg1ekBGDWsFl1WSzVQEUyaihYHnB6bRdEKRW5Q4eqPmZkl5E6ZFRFJJI+goexK5xgB47+2HcYK6ViJGDdgY+mwqDHA2oEbnFz79n31nm5VMMUSR/Ber/tYmCRMWZNlMqjlIrA+efDu+86O3keKGwOqYd9weCagdfoSCEVsUgCwUvAMWNMCYCIuEWkiTHmaHSLppQKZ9IkmDULWrWC74feQnGjw768VHeq3jegqiWiO4uBxn77jYHl0SmOUioSf/+7/XPEZIuSoX8NyDu3+7laG1DVEkkgaOS/PKWz3SR6RVJKVeYPf4AHHrC3X9/ixRC4GEH7Zu1jUCrVkEUSCH4QkYFlOyIyCPgxekVSSlVm8WK/ndxMMOX/xsmuZG0WUtUWSR/BLOBfIvI1dldUe+ylK5VSdcyyYMcOv4Q8D2klZ/JDs4+5pM8lTM2Yqs1CqtoiuaHsQxHpBfR0kj43xhRV9hylVHR4vRXTSpIOc1LqSRoEVI1Fsnj9b4CmxphPjDGfAM1E5NfRL5pSKljrwPXocadb7GUzuwp2kZWTpYvTqxqJpI/gGmeFMgCMMQeBa6JXJKVUOPv3B+4PuLC8s7iwpBBvrrfuC6UavEgCgdt/URoRcQMpkZxcRMaKyOciskNE5oTIf0BENjuPL0QkghvnlUpM998PixYFpo3qNsK3neRKIjM9s24LpeJCJJ3FbwEviMgTzv4MYFlVT3ICxqPAOdjzE30oIq8ZY7aVHWOMudHv+BuAAdUou1IJIzsbbrqpYvr96+6G7vZ28DBSpSIVSY3gFuA94Frn8TGBN5iFMwTYYYzZaYwpBBYDEyo5fgqwqJJ8pRLWyy+HSLxoMnQvX5u4qKRIm4ZUjVQZCJwF7D8AcrE/3McAn0Zw7k7Abr/9PCetAhHpCnTDDjih8qeLyHoRWZ+fnx/qEKXi2qRJQQlpFvz0hQrHadOQqomwgUBEThORP4nIZ8DDwH8BjDGjjTGP1HI5JgMvlc1nFMwYk22MGWyMGdy2bdtafmml6r9p04ISht9X4b/3l31/qcNHVY1U1kfwGfA+MM4YswNARG6s5Phge4DOfvtpTlook4HfVOPcSiWU1cELw7bdFrDbvml7XZJS1VhlTUMXAd8AK0XkSRHJIuQaSGF9CPQQkW4ikoL9Yf9a8EHOzWonAzoAWqkwnvf/jE+zoNXOgPw/j/5z3RZIxZWwgcAY84oxZjLQC1iJPdXEKSIyX0R+VtWJjTHFwPXA29h9Ci8aY7aKyB0iMt7v0MnAYmOMDnlQKgTLChw26u7uRdzl/y4Te07UlcjUCYlkiokfgH8C/xSRk4GLsUcSvVPpE+3nLgWWBqX9MWj/9mqUV6mE478+sQiMGNCaNSKUGGiU1IjZI2bHtHyq4avWmsXGmINOx21WtAqklAqUmem309libYuZlDjjKv4y5i/aQaxOWE0Wr1dKxYjp4qWY4779VbmrYlgaFS80EChVzwXMOHo0cNa5V794lewN2XVaHhV/IpliIi5Yuy3mLJ/Dh3s+pLC0kLLpk4wxiAgucVFqSn37mpc4eW5x065ZO24989Z62eka0DTUcUOF/H9s/Ee9LLdqOBIiEFi7Lc56+ixfuypAwLQsweOVNC/h8nIP5TLjjRl8efBL7jv7PuqTEufPtusIi12DnqqQ37F5xzoukYo3CdE05M31BgYBpcKYu2ZuvZrT37LgZ85g7d1JXpDSgHwXLh01pE5YQgSCzPRM3OKOdTFUA/HrN+vPukteL/zorBBeeqQ1/vd0usXN/HHzddSQOmEJ0TTk6ezh/Sve1z4CzauQZ4ypUFvcvG8z2Ruy60W7u69/IM2C866nrD1rZNeR3Jt1rwYBVSsSIhCAHQxWXaFD7VRFl/37MhZ+vDAg7ZZ3b6HvKX1j/kHr8UCHDvDN8LngKl8q/P/++38xLJWKNwnRNKRUZZ6/6Hl+dmrgrCmHjh9ixIIR9WJoZpcuwElfB8z0VWpKde0BVWs0EChF6Hn8DYZfv/nrmHcet2oFbL24QnrrJq0rHqxUDWggUAo7EEiIyXVLTEnMvnlbFtxzD3z5JbibBy7I5MLFgaMHYlIuFX80ECiF3Yf0+LjHQ+bF4pu3ZUFWFtx2G3xx1KJk2F8D7ntwu9y6GpmqNRoIlHJMHzSdJ8Y9UaFmEItv3v7DRsnIATF2H4EBQXjkvEdi3pGt4ocGAqX8TB80nZtH3ByQduj4oTovR8C0Es2+Lt8WOKvLWfViaKuKHxoIlArSMrVlwP4D1gN13mH88cd+OylHAkYM9W7bu07LouKfBgKlgmSmZ5LkKr/FJhYdxi+/7GykWZBefv9LsiuZqRlT67QsKv5pIFAqiKezh/t/dr9v3yWuOu8wnjTJ2cjIAVf5nc/n9zhf+wZUrdNAoFQINwy5wddpXFxazLVvXMsty2+pk9e2LDhQ1j990i5CjGpVqlYlzBQTSlXHkxufxPiN1zQY5q6Zy09O/klUO2rLho0eL1uErKhZQH77Zu2j9toqcWmNQKkQXt72crXSa4vXC8eOQWkpdv9A2YghA67SVO0fUFGhgUCpECb1nlSt9NoSMNvolSOg6xp737iY0nKe9g+oqNBAoFQI0wdNZ2TXkQFpI7uMjPr4fY8HevUC0r3gMuX9A65SmvfYFNXXVokrYfoILAvmzIEPP4TCQnCmpccYe9vlsqvjZfual1h5AG3awJ//DNOdz/rebXqzetdq399Q77a9WbZ9GRu+2UBWt6yofTt3uYAfT66QvvfI3qi8nlIJEQgsC848s/wfXqlQ9u6FGTPs7enTYWrGVJ7e/DTHS+ye2635W3l8gz0f0Z2r7+TK/lcyNWNqrQaEtWth61ZgwgcV8rSjWEVLQjQNeb0aBFTk/vEP+6ens4d5587zDSN9/7/v+44pLCnk8Q2PM/rZ0bV61/FddzkbzfeUJxoA0Y5iFTUJEQgyM8GtSxarCG3caNcioeoJ546XHCfno5xaed3sbFi2zNlJOh6QN7LNBO0oVlGTEE1DHg+8/772EWhe6Lzi4sAaY0mJXYv0eOzpJpLdyRSWFIb9+6qttvuAaSU6l40WAiGZe8fPrpXXUCqUhAgEYP9Tr9Ili1UIlgWjRkFR+ZLArFtnp3s8Hh4+92FmvDEj7PPf3P4m1m7rhL+x9+8P77yDM2LIiUxGmND5Kq0NqKhKiKYhpSrj8cAf/1i+bwy88gqMHm0Hg03fVD5ss7i0+IQnpbMs+PvfnZ3cTCh12X0DJY04t5P2DajoimogEJGxIvK5iOwQkTlhjvkfEdkmIltF5J/RLI9S4YTqQzp+3G5OrEqKO+WEVwvzeu0mKgDyPLA3AwqbwlsPcmCz1gZUdEUtEIiIG3gUOBfoDUwRkd5Bx/QAbgVGGGP6ALOiVR6lKtM6zOSiq1fD4TVTA6al9jc8bTgrp6084aabgDuKz78OOmyClB9g7CwONa/btRBU4olmjWAIsMMYs9MYUwgsBiYEHXMN8Kgx5iCAMebbKJZHqbAOVDI4aMk8Dw8NXB4y7+sjX/Pxtx+HzKsOjwc7CFw+Gs54vHxpSlchmw95T/j8SlUmmoGgE7Dbbz/PSfN3GnCaiKwRkf+IyNhQJxKR6SKyXkTW5+fnR6m4KpFVNsT46FGYeX1KyLzcQ7nMeGMG2RuyT7wQ6V5wO8NGnfWJKU1h0qDMEz+3UpWIdWdxEtADyASmAE+KSMvgg4wx2caYwcaYwW3btq3jIqpEUDbEeORIaNnSmebBT0mfyu8V+MfGf5x4IY5WbJ/qUXQR08/VPgIVXdEMBHuAzn77aU6avzzgNWNMkTHmK+AL7MCgVJ0rG2J88CA8/HCIA0yINEfHkzqeeAGaVGyf+rLJojpfL1klnmgGgg+BHiLSTURSgMnAa0HHvIJdG0BE2mA3Fe2MYpmUisiAAUEJH02FkhQEwS1uTm9zOi6x/32SXEnMHl4LN3zlZgbui70gTl2vl6wST9QCgTGmGLgeeBv4FHjRGLNVRO4QkfHOYW8DB0RkG7ASuNkYU/k9/UrVAa83KCHPA894+cmuu3n/ivf5x8BtjHM9AsD9P7s/ajd8JbmSTnhoqlJVieqdxcaYpcDSoLQ/+m0b4HfOQ6l6o6zzuKTELzHPw83DPJBn32x2vNVQmAFLP/qQMzqe2J3Fjz2G3VlcxoCIi0fOe0TvKlZRF+vOYqXqJY8HrrkmMK2lM4zB63XWFG71BQBvf/M8WTlZNW7Ltyy44w7KO4sNUJrEBPf8qC+EoxRoIFAqrKlTIcVv1OihQ/Z6BVu3OgntN/vyCksKa9SWb1l27WNfsgXn3eAMG3XheutRZmdpEFB1QwOBUmF4PHDllRXTfZMX5o72pdW0Ld/rtWfDJd0LSc4Mp2KY/tsD9k1mStUBDQRKVWLqVEgK6klr0cLZKGrsSzOVjS2thG9qiaJG5YliGNArzJwXSkWBBgKlKuHx2PMNdewIycl2B7KvaajLGt+9BUUlJzgDadfAOdKXbV8W5kClap8GAqWq4PHAGWfY2wGjiPzuBDamlNZNqv8tPqfshuXm+8oTDbz+xet6I5mqMxoIlKqCZcGbbwYuXAM4dwLbS56JuKpc1jLUebOzsSeb6/ihnWjQG8lUndNAoFQVvN6gmkCZ3EwosTsQUpOqtyaBZcGsWc4SmRk54Ap8gVR3qt5IpuqMBgKlqpCZWXESOsC+23jVnwCY0mU23lxvRM05ZUNG161zEtpsK88U6N2mNyumrtAbyVSdSZg1i5WqKY/HvpN4eaglCb4eDMDTO+9CdhqS3cl4p3kr/RD3DRkFu1mo6+qyFiYARnYdqUFA1SmtESgVgaysimnJyUBhc2evFIOhsKSQnI8qn7LaN2QUYPjcgP9CQZiaoWsUq7qlgUCpCOzbVzFt/HigZcXJcvf+sLfScwXcKHZS4Mzsvdr00tqAqnMaCJSKwLZtFdP27gX6PVchvX3T9pWey/LvRtjjjEs19mPWMF22W9U9DQRKRWDSpIppH3wAND5UIb2yph3LgrPOcnbSLBjymL1t4GdNZ+skcyomNBAoFYHpIT6fi4uBjVcFpJ3e5vSw57AsuP12v6GoZ99c3knsgiadv6iNoipVbRoIlIqAFW5U6MbpuNeWr0726f5PGf3s6ArDSC3L7nB+5x0nIc2yp6jw88V3GghUbGggUCoCXi+IhM4r/bEl/uM/j5ccr3BXsNcLP/7ol5CREzBkFOC0VqfVQkmVqj4NBEpFIDMTGjUqv7HMPyjIrkwk6F/p0PHyvgPLgq++Cjphh40BgUAQZo+ohXWPlaoBvaFMqQh4PLBihf3NvnVrOHAA8vPhgQfA7PbA14Og4zrf8a9//jr3nX0fluUsa3nc72RZt0CndQHnv3nEzTpsVMWMBgKlIuTxBN4DcM899k9jQDZcFRAIPt3/KRfelU37PdMDg0CaBSPmVmgWapnaMnoFV6oK2jSkVA2V3SEsAo22TSe9qd+IIQOvfP4yTz0V9KThFYOAS1w6wZyKKQ0EStWQxwPt20PbtvDgg3Dr6KCbwbZNCpy1NM2Cnq+WBwJnUZv558/XZiEVUxoIlKohy4Jvv7Ufs2YB3/bFJc6/VGkyfNs3cKRRuhfcgUtaTuw5UW8iUzGnfQRK1ZDX66wngD2b6MsbvBjjfNC7imH4XJoeGczhLWPsKatzM8ufbCDZnawjhVS9oIFAqRrKzLTXMC5r/tm1KhM5042hGDBw+isclldgUBK8+ShIafmTBW703KhNQqpe0KYhpU5AWdNPSQl8vtxD6a6hTobfQa5iOP9aGHddwHPvX3u/rkus6gUNBErVkH/TkE9R4/Jt8fvpMgQrNaW6LrGqFzQQKFVDmZkhpp042N03GiiAUGHYaIq7euscKxUtGgiUqiGPB3r2DEr8aCqUuKt8bu82vVk5baX2Eah6QQOBUidg6NCghDwPbL+g0ue4cPHU+Kc0CKh6Q0cNKXUCOncOkXikvd08JFRoJhIR5o/TG8hU/RLVGoGIjBWRz0Vkh4jMCZF/uYjki8hm53F1NMujVG0bOxYaNy6flRRwmof8vmOVAkdPpnvKSNZcuUZvIFP1TtQCgYi4gUeBc4HewBQR6R3i0BeMMf2dR/DMLErVa2Wzkk6f7hcM8jyw6aryWoG4mdj+ZrbftkprAqpeimaNYAiwwxiz0xhTCCwGJkTx9ZSKCY8HunSxZyH1+WgaFDdGcNM4JYXZF2fGqnhKVSmagaATsNtvP89JCzZJRLaIyEsiEqrFFRGZLiLrRWR9fn5+NMqq1AnJzITkZL+EPA88u4IJze9kxdQVWhNQ9VqsRw29DqQbY/oB7wLPhjrIGJNtjBlsjBnctm3bOi2gUpHweOwbzM44ozzN9bWHIcdv1SCg6r1oBoI9gP83/DQnzccYc8AYU7Zsx1PAoCiWR6mo8njgoYfszmO3G1JTy9csUKo+i+bw0Q+BHiLSDTsATAZ+6X+AiHQwxnzj7I4HPo1ieZSKOv8lLTMzA1c0U6q+ilogMMYUi8j1wNuAG1hgjNkqIncA640xrwEzRWQ8UAx8B1werfIoVVeCl7RUqr4TY0JNjFJ/DR482Kxfvz7WxVBKqQZFRDYYYwaHyot1Z7FSSqkY00CglFIJTgOBUkolOA0ESimV4DQQKKVUgmtwo4ZEJB/YVcOntwH212JxGgK95sSg15wYTuSauxpjQk7N0OACwYkQkfXhhk/FK73mxKDXnBiidc3aNKSUUglOA4FSSiW4RAsE2bEuQAzoNScGvebEEJVrTqg+AqWUUhUlWo1AKaVUEA0ESimV4BImEIjIWBH5XER2iMicWJenNohIZxFZKSLbRGSriPzWSW8lIu+KyHbn58lOuojIPOd3sEVEBsb2CmpORNwisklE3nD2u4nIB861vSAiKU56qrO/w8lPj2W5a0pEWjrLuX4mIp+KiCfe32cRudH5u/5ERBaJSKN4e59FZIGIfCsin/ilVft9FZFpzvHbRWRadcuREIFARNzAo8C5QG9gioj0jm2pakUx8L/GmN7AMOA3znXNAVYYY3oAK5x9sK+/h/OYDsyv+yLXmt8SuJDRfcADxpjuwEHgKif9KuCgk/6Ac1xD9BDwljGmF5CBfe1x+z6LSCdgJjDYGPNT7DVNJhN/7/MzwNigtGq9ryLSCvgTMBQYAvypLHhEzBgT9w/AA7ztt38rcGusyxWF63wVOAf4HOjgpHUAPne2nwCm+B3vO64hPbCXPV0BjAHeAAT7bsuk4Pcbe2Ekj7Od5Bwnsb6Gal5vC+Cr4HLH8/sMdAJ2A62c9+0N4Ofx+D4D6cAnNX1fgSnAE37pAcdF8kiIGgHlf1Rl8py0uOFUhQcAHwDtTPkSoHuBds52vPweHgRmA6XOfmvgkDGm2Nn3vy7fNTv5Bc7xDUk3IB942mkOe0pEmhLH77MxZg/wN+C/wDfY79sG4vt9LlPd9/WE3+9ECQRxTUSaAS8Ds4wx3/vnGfsrQtyMERaRccC3xpgNsS5LHUoCBgLzjTEDgB8oby4A4vJ9PhmYgB0EOwJNqdiEEvfq6n1NlECwB+jst5/mpDV4IpKMHQQWGmP+7STvE5EOTn4H4FsnPR5+DyOA8SKSCyzGbh56CGgpImVrcPtfl++anfwWwIG6LHAtyAPyjDEfOPsvYQeGeH6fzwa+MsbkG2OKgH9jv/fx/D6Xqe77esLvd6IEgg+BHs6IgxTsTqfXYlymEyYiAvwD+NQY83e/rNeAspED07D7DsrSpzqjD4YBBX5V0AbBGHOrMSbNGJOO/T6+Z4y5FFgJ/MI5LPiay34Xv3COb1DfnI0xe4HdItLTScoCthHH7zN2k9AwEWni/J2XXXPcvs9+qvu+vg38TEROdmpSP3PSIhfrjpI67JA5D/gC+BL4fazLU0vXdCZ2tXELsNl5nIfdNroC2A4sB1o5xwv26KkvgY+xR2TE/DpO4PozgTec7VOBdcAO4F9AqpPeyNnf4eSfGuty1/Ba+wPrnff6FeDkeH+fgT8DnwGfAM8BqfH2PgOLsPtAirBrflfV5H0FrnSufQdwRXXLoVNMKKVUgkuUpiGllFJhaCBQSqkEp4FAKaUSnAYCpZRKcBoIlFIqwWkgUMohIiUistnvUWuz1IpIuv8Mk0rVJ0lVH6JUwvjRGNM/1oVQqq5pjUCpKohIrojMFZGPRWSdiHR30tNF5D1nbvgVItLFSW8nIktE5CPnMdw5lVtEnnTm2H9HRBo7x88Ue02JLSKyOEaXqRKYBgKlyjUOahq6xC+vwBjTF3gEe/ZTgIeBZ40x/YCFwDwnfR6wyhiTgT0n0FYnvQfwqDGmD3AImOSkzwEGOOe5NloXp1Q4emexUg4ROWKMaRYiPRcYY4zZ6Uzyt9cY01pE9mPPG1/kpH9jjGkjIvlAmjHmuN850oF3jb3YCCJyC5BsjLlLRN4CjmBPHfGKMeZIlC9VqQBaI1AqMibMdnUc99suobyP7nzsOWQGAh/6za6pVJ3QQKBUZC7x+2k522uxZ0AFuBR439leAVwHvrWVW4Q7qYi4gM7GmJXALdjTJ1eolSgVTfrNQ6lyjUVks9/+W8aYsiGkJ4vIFuxv9VOctBuwVw27GXsFsSuc9N8C2SJyFfY3/+uwZ5gMxQ087wQLAeYZYw7V2hUpFQHtI1CqCk4fwWBjzP5Yl0WpaNCmIaWUSnBaI1BKqQSnNQKllEpwGgiUUirBaSBQSqkEp4FAKaUSnAYCpZRKcP8ffTCcyI7d6EsAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0 0.050101880098577634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test error, mean test error and std test error')\n",
        "print(error_vals)\n",
        "print(np.mean(error_vals), np.std(error_vals)) \n",
        "\n",
        "print('Test accuracy, mean test accuracy and std test accuracy')\n",
        "print(acc_vals)\n",
        "print(np.mean(acc_vals), np.std(acc_vals)) \n",
        "\n",
        "print('Train error, mean train error and std train error')\n",
        "\n",
        "print(error_trains)\n",
        "print(np.mean(error_trains), np.std(error_trains)) \n",
        "\n",
        "print('Train accuracy, mean train accuracy and std train accuracy')\n",
        "\n",
        "print(acc_trains)\n",
        "print(np.mean(acc_trains), np.std(acc_trains)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wizk1stRfglK",
        "outputId": "08f6c776-6cc9-4790-82b5-587bd9f4e292"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test error, mean test error and std test error\n",
            "[0.045563782866677546, 0.04651292722852802, 0.04614157986485521, 0.04778239047640881, 0.046933152627297775, 0.04920667512674383, 0.04556395446121027, 0.04624246214101042, 0.04622540765376571, 0.050101880098577634]\n",
            "0.04702742125450752 0.0014619537545720158\n",
            "Test accuracy, mean test accuracy and std test accuracy\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "1.0 0.0\n",
            "Train error, mean train error and std train error\n",
            "[0.019984602485201935, 0.020301494384707137, 0.02028039582528332, 0.02082692809196697, 0.02059802127853551, 0.0217416780156867, 0.020280051279609, 0.020261766114572474, 0.02028747900323322, 0.021613078040008504]\n",
            "0.020617549451880476 0.0005711901171000615\n",
            "Train accuracy, mean train accuracy and std train accuracy\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "1.0 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "beTJYnyafgnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eiFewUHCfgpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdlTuTqsfgrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2KLNWLNPEBeI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}